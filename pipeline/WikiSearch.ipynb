{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d48a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia as wiki\n",
    "from collections import defaultdict, Counter \n",
    "import re\n",
    "import heapq\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import urllib\n",
    "\n",
    "from requests_html import HTMLSession\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html_text\n",
    "\n",
    "import nltk\n",
    "from os.path import isfile, join\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from transformers import pipeline\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a864330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(title):\n",
    "    return title[:-1].lower() if title[-1] == 's' else title.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17d15b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE = clean_title(\"computer architecture\")\n",
    "SUBSECTIONS = 4\n",
    "RELATED_TITLES = wiki.search(TITLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6770326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computer architecture',\n",
       " 'Word (computer architecture)',\n",
       " 'Hazard (computer architecture)',\n",
       " 'Von Neumann architecture',\n",
       " 'Multithreading (computer architecture)',\n",
       " 'Predication (computer architecture)',\n",
       " 'Computer',\n",
       " 'Microarchitecture',\n",
       " 'Computer science',\n",
       " 'Computer architecture simulator']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RELATED_TITLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee63a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsections(data, raw=False):\n",
    "    subsections = re.findall('\\n== ([a-zA-z ]+) ==', data)\n",
    "    subsections = [subsection.lower() for subsection in subsections]\n",
    "    if raw:\n",
    "        return subsections\n",
    "    subsections = re.findall('\\n== ([a-zA-z]+) ==', data)\n",
    "    subsections = [subsection.lower() for subsection in subsections]\n",
    "    if \"references\" in subsections:\n",
    "        subsections.remove(\"references\")\n",
    "    if \"see also\" in subsections:\n",
    "        subsections.remove(\"see also\")\n",
    "    if \"external link\" in subsections:\n",
    "        subsections.remove(\"external link\")\n",
    "    if \"note\" in subsections:\n",
    "        subsections.remove(\"note\")\n",
    "    subsections = [subsection[:-1].lower() if subsection[-1] == 's' else subsection.lower() \\\n",
    "                   for subsection in subsections]\n",
    "    return subsections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "182448a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_subsections_and_content(related_titles):\n",
    "    topics = []\n",
    "    related_paper_section_content = defaultdict(list)\n",
    "    for related_title in related_titles:\n",
    "        try:\n",
    "            related_page = wiki.WikipediaPage(title=related_title)\n",
    "        except wiki.DisambiguationError as e:\n",
    "            continue\n",
    "\n",
    "        content = (related_page.content).lower()\n",
    "        subsections = get_subsections(content, raw=True)\n",
    "        topics.extend(get_subsections(content))\n",
    "        delimiters = ''\n",
    "        for subsection in subsections:\n",
    "            delimiters += '== ' + str(subsection) + ' ==|'\n",
    "        delimiters = delimiters[:-1]\n",
    "        words = re.split(delimiters, content)\n",
    "        words = [word.replace('\\n', '') for word in words]\n",
    "        related_paper_section_content['intro'].append(str(words[0]))\n",
    "        for i, subsection in enumerate(subsections):\n",
    "            if subsection[-1] == 's':\n",
    "                subsection = subsection[:-1]\n",
    "            related_paper_section_content[subsection].append(str(words[i+1]))\n",
    "\n",
    "    common_subsections = Counter(topics)\n",
    "    important_subsections = heapq.nlargest(SUBSECTIONS, common_subsections, key=common_subsections.__getitem__)\n",
    "    return important_subsections, related_paper_section_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94d6fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run related_paper_section_content separately\n",
    "important_subsections, related_paper_section_content = get_important_subsections_and_content(RELATED_TITLES)\n",
    "important_subsections.insert(0, 'intro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b746d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['intro', 'history', 'note', 'source', 'type']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_subsections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c3fc8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['intro', 'history', 'subcategorie', 'role', 'design goal', 'see also', 'reference', 'source', 'external link', 'uses of word', 'word size choice', 'size familie', 'table of word size', 'note', 'background', 'type', 'eliminating hazard', 'capabilitie', 'evolution', 'design limitation', 'further reading', 'overview', 'types of multithreading', 'implementation specific', 'advantage', 'disadvantage', 'etymology', 'hardware', 'software', 'networking and the internet', 'unconventional computer', 'future', 'professions and organization', 'relation to instruction set architecture', 'aspect', 'microarchitectural concept', 'philosophy', 'field', 'discoverie', 'programming paradigm', 'academia', 'education', 'categorie'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_paper_section_content.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e0ebcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cd137b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_embeddings = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fb71ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 5/5 [00:00<00:00, 24244.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsection:  intro\n",
      "paras:  10\n",
      "subsection:  history\n",
      "paras:  5\n",
      "subsection:  note\n",
      "paras:  3\n",
      "subsection:  source\n",
      "paras:  2\n",
      "subsection:  type\n",
      "paras:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for subsections in tqdm(important_subsections):\n",
    "    paras = related_paper_section_content[subsections]\n",
    "    print(\"subsection: \", subsections)\n",
    "    print(\"paras: \", len(paras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "584cfe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:05<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for subsections in tqdm(important_subsections):\n",
    "    paras = related_paper_section_content[subsections]\n",
    "    topic_emb = np.average(model.encode(paras), 0)\n",
    "    features.append(topic_emb)\n",
    "    topic_embeddings[subsections] = topic_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "260925ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'intro': array([-0.02086659, -0.0058955 , -0.00109885, ..., -0.0145632 ,\n",
       "                    -0.01239052,  0.0055468 ], dtype=float32),\n",
       "             'history': array([-0.00404927, -0.00525444,  0.01348941, ..., -0.00970294,\n",
       "                     0.00595382,  0.00850121], dtype=float32),\n",
       "             'note': array([-0.01981773, -0.00571731,  0.02226208, ...,  0.01589679,\n",
       "                     0.00024185,  0.01825439], dtype=float32),\n",
       "             'source': array([-0.01102131, -0.01338195,  0.00431949, ...,  0.0093503 ,\n",
       "                    -0.0110891 ,  0.0082404 ], dtype=float32),\n",
       "             'type': array([ 0.02489298, -0.00868176, -0.01139156, ...,  0.02240594,\n",
       "                     0.01339936,  0.03120553], dtype=float32)})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58392213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(url):\n",
    "    try:\n",
    "        session = HTMLSession()\n",
    "        response = session.get(url)\n",
    "        return response\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "        \n",
    "def scrape_google(query):\n",
    "    query = urllib.parse.quote_plus(query)\n",
    "    response = get_source(\"https://www.google.com/search?q=\" + query)\n",
    "    links = list(set(response.html.absolute_links))\n",
    "    google_domains = ('https://www.google.', \n",
    "                      'https://google.',\n",
    "                      'https://www.google.com/search?',\n",
    "                      'https://webcache.googleusercontent.', \n",
    "                      'http://webcache.googleusercontent.', \n",
    "                      'https://policies.google.',\n",
    "                      'https://support.google.',\n",
    "                      'https://maps.google.',\n",
    "                      'https://www.coursera.org',\n",
    "                      'https://www.youtube.com',\n",
    "                     'https://online.umich.edu/',\n",
    "                      'https://docs.oracle.com/',\n",
    "                      'https://www.cise.ufl.edu/~mssz/CompOrg/CDA-lang.html',\n",
    "                      'https://study.com/academy',\n",
    "                      'https://www.redhat.com',\n",
    "                      'https://www.oreilly.com',\n",
    "                      'https://scholar.google.com',\n",
    "                      'https://machinelearningknowledge',\n",
    "                      'https://interestingengineering.com',\n",
    "                      'https://www.nature.com/',\n",
    "                      'https://machinelearningmastery.com',\n",
    "                      'https://www.thelancet.com/',\n",
    "                      'https://m.youtube.com',\n",
    "                      'https://www.mathworks.com',\n",
    "                      'https://www.deeplearningbook'\n",
    "                     )\n",
    "    \n",
    "    for url in links[:]:\n",
    "        url_check = url.split('#')[0]\n",
    "        if url_check in urls_visited or url.startswith(google_domains):\n",
    "            links.remove(url)\n",
    "        if url_check not in urls_visited:\n",
    "            urls_visited.add(url_check)\n",
    "        if url[-3:] == 'pdf':\n",
    "            links.remove(url)\n",
    "    return links\n",
    "\n",
    "\n",
    "def google_search(query):\n",
    "    response = scrape_google(query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eda5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_from_url(results):\n",
    "    data = []\n",
    "    for url in results:\n",
    "        print(url)\n",
    "        if url.startswith('http://en.wikipedia.org/wiki/') or url.startswith('https://en.wikipedia.org/wiki/'):\n",
    "            search_term = url.replace('http://en.wikipedia.org/wiki/', '').replace('https://en.wikipedia.org/wiki/', '').replace('_', ' ').replace('%E2%80%93', '-').replace('%27', \"'\")\n",
    "            sentences = wiki.WikipediaPage(title=search_term).content\n",
    "            text_info = ''\n",
    "            for sent in sentences.split('.'):\n",
    "                if sent == '' or len(sent) > 500 or len(sent) < 10:\n",
    "                    continue\n",
    "                sent_emb = torch.from_numpy(model.encode(sent))\n",
    "                if float(sent_emb @ topic_emb) < 0.3:\n",
    "                    continue\n",
    "                text_info += (sent + '. ')\n",
    "\n",
    "            item = {\n",
    "                'title': search_term,\n",
    "                'link': url,\n",
    "                'text': text_info,\n",
    "                #'emb': model.encode(text_info)\n",
    "            }\n",
    "            data.append(item) \n",
    "        else:\n",
    "            try: \n",
    "                page = requests.get(url, timeout=(5, 10))\n",
    "            except requests.exceptions.Timeout as err: \n",
    "                #print(\"here\")\n",
    "                continue\n",
    "            #print(page)\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\",from_encoding=\"iso-8859-1\")\n",
    "            p = soup.find_all('p')\n",
    "            paragraphs = []\n",
    "            for x in p:\n",
    "                paragraphs.append(str(x))\n",
    "            if len(paragraphs) == 0:\n",
    "                continue\n",
    "            text_info = ''\n",
    "            for para in paragraphs:\n",
    "                if para == '':\n",
    "                    continue\n",
    "                sentences = html_text.extract_text(para, guess_layout=False)\n",
    "                for sent in sentences.split('.'):\n",
    "                    if sent == '' or len(sent) > 500 or len(sent) < 10:\n",
    "                        continue\n",
    "                    sent_emb = torch.from_numpy(model.encode(sent))\n",
    "                    if float(sent_emb @ topic_emb) < 0.3:\n",
    "                        continue\n",
    "                    text_info += (sent + '. ')\n",
    "            if len(text_info) < 100 or len(text_info) > 10000: \n",
    "                continue\n",
    "            item = {\n",
    "                'title': \"<UNK>\",\n",
    "                'link': url,\n",
    "                'text': text_info,\n",
    "                #'emb': model.encode(text_info)\n",
    "            }\n",
    "            data.append(item)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8d4d4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Category:Computer_architecture',\n",
       " 'https://www.computersciencedegreehub.com/faq/what-is-computer-architecture/',\n",
       " 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'https://geteducationskills.com/computer-architecture/',\n",
       " 'https://www.techopedia.com/definition/26757/computer-architecture',\n",
       " 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'https://www.britannica.com/technology/computer-architecture',\n",
       " 'https://www.sciencedirect.com/topics/computer-science/computer-architecture',\n",
       " 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'https://www.tutorialspoint.com/what-is-computer-architecture',\n",
       " 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'https://dl.acm.org/doi/10.1109/MAHC.1988.10039',\n",
       " 'https://www.computer.org/csdl/magazine/an/1988/04/man1988040277/13rRUxZRbrm',\n",
       " 'https://edurev.in/studytube/A-Brief-History-of-Computer-Architecture-Computer-/987e1c94-0ef4-4ebd-b172-277f3deb72c1_t',\n",
       " 'https://www.researchgate.net/publication/329191354_Lecture_Notes_on_Computer_Architecture',\n",
       " 'https://www.geeksforgeeks.org/last-minute-notes-computer-organization/',\n",
       " 'http://www.cs.iit.edu/~virgil/cs470/Book/',\n",
       " 'https://ocw.mit.edu/courses/6-823-computer-system-architecture-fall-2005/pages/lecture-notes',\n",
       " 'http://www.eecs.harvard.edu/~dbrooks/cs146-spring2004/',\n",
       " 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'https://www.quora.com/What-is-the-best-source-and-method-to-study-computer-architecture',\n",
       " 'https://www.quora.com/What-is-the-best-way-to-learn-computer-organization-and-architecture',\n",
       " 'https://www.quora.com/What-is-the-best-way-and-source-to-learn-computer-architecture',\n",
       " 'https://www.sigarch.org/call-contributions/first-workshop-on-open-source-computer-architecture-research-oscar/',\n",
       " 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'https://www.quora.com/What-is-the-best-way-and-source-to-learn-computer-architecture?top_ans=47987712',\n",
       " 'https://www.quora.com/What-are-some-of-the-currently-hot-research-areas-in-computer-architecture',\n",
       " 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'https://www.researchgate.net/figure/Computer-Architecture-Source_fig10_297766967',\n",
       " 'https://github.com/topics/computer-architecture',\n",
       " 'https://www.w3schools.in/computer-fundamentals/types-of-computer-architecture',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-system-architecture',\n",
       " 'https://www.quora.com/What-are-other-types-of-computer-system-architecture-apart-from-Von-Neumann',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-system-architecture?top_ans=20669228',\n",
       " 'https://www.researchgate.net/publication/241056162_Types_of_Computer_Architectures',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-architectures-in-a-CPU',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-architecture-and-organisations']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_visited = set()\n",
    "results = []\n",
    "for text in important_subsections:\n",
    "    if text == 'intro':\n",
    "        results.extend(google_search(\"what is \" + TITLE))\n",
    "    else:\n",
    "        results.extend(google_search(TITLE + \" \" + text.lower()))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9131984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Category:Computer_architecture 2\n",
      "https://www.computersciencedegreehub.com/faq/what-is-computer-architecture/ 9\n",
      "https://online.sunderland.ac.uk/what-is-computer-architecture/ 22\n",
      "https://geteducationskills.com/computer-architecture/ 22\n",
      "https://www.techopedia.com/definition/26757/computer-architecture 22\n",
      "https://en.wikipedia.org/wiki/Microarchitecture 40\n",
      "https://www.britannica.com/technology/computer-architecture 3\n",
      "https://www.sciencedirect.com/topics/computer-science/computer-architecture 4\n",
      "https://en.wikipedia.org/wiki/Word_(computer_architecture) 27\n",
      "https://www.educba.com/types-of-computer-architecture/ 51\n",
      "https://en.wikipedia.org/wiki/Computer_architecture 32\n",
      "https://www.tutorialspoint.com/what-is-computer-architecture 19\n",
      "https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/ 18\n",
      "https://dl.acm.org/doi/10.1109/MAHC.1988.10039 27\n",
      "https://www.computer.org/csdl/magazine/an/1988/04/man1988040277/13rRUxZRbrm 0\n",
      "https://edurev.in/studytube/A-Brief-History-of-Computer-Architecture-Computer-/987e1c94-0ef4-4ebd-b172-277f3deb72c1_t 8\n",
      "https://www.researchgate.net/publication/329191354_Lecture_Notes_on_Computer_Architecture 8\n",
      "https://www.geeksforgeeks.org/last-minute-notes-computer-organization/ 50\n",
      "http://www.cs.iit.edu/~virgil/cs470/Book/ 0\n",
      "https://ocw.mit.edu/courses/6-823-computer-system-architecture-fall-2005/pages/lecture-notes 36\n",
      "http://www.eecs.harvard.edu/~dbrooks/cs146-spring2004/ 86\n",
      "https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220 76\n",
      "https://www.quora.com/What-is-the-best-source-and-method-to-study-computer-architecture 1\n",
      "https://www.quora.com/What-is-the-best-way-to-learn-computer-organization-and-architecture 1\n",
      "https://www.quora.com/What-is-the-best-way-and-source-to-learn-computer-architecture 1\n",
      "https://www.sigarch.org/call-contributions/first-workshop-on-open-source-computer-architecture-research-oscar/ 17\n",
      "https://en.wikipedia.org/wiki/Instruction_set_architecture 50\n",
      "https://www.quora.com/What-is-the-best-way-and-source-to-learn-computer-architecture?top_ans=47987712 1\n",
      "https://www.quora.com/What-are-some-of-the-currently-hot-research-areas-in-computer-architecture 1\n",
      "https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext 168\n",
      "https://www.researchgate.net/figure/Computer-Architecture-Source_fig10_297766967 8\n",
      "https://github.com/topics/computer-architecture 36\n",
      "https://www.w3schools.in/computer-fundamentals/types-of-computer-architecture 14\n",
      "https://www.quora.com/What-are-the-types-of-computer-system-architecture 1\n",
      "https://www.quora.com/What-are-other-types-of-computer-system-architecture-apart-from-Von-Neumann 1\n",
      "https://www.quora.com/What-are-the-types-of-computer-system-architecture?top_ans=20669228 1\n",
      "https://www.researchgate.net/publication/241056162_Types_of_Computer_Architectures 8\n",
      "https://www.quora.com/What-are-the-types-of-computer-architectures-in-a-CPU 1\n",
      "https://www.quora.com/What-are-the-types-of-computer-architecture-and-organisations 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "raw_dataset = defaultdict(list)\n",
    "cleaned_para = []\n",
    "\n",
    "for result in results:\n",
    "    temp_dataset = ''\n",
    "    paragraphs = []\n",
    "    temp_cleaned_para = []\n",
    "    try:\n",
    "        page = requests.get(result, timeout=(5, 10), headers=headers)\n",
    "    except:\n",
    "        print(\"here\")\n",
    "        continue\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    p = soup.find_all('p')\n",
    "    \n",
    "    \n",
    "    for x in p:\n",
    "        paragraphs.append(str(x))\n",
    "    for i, para in enumerate(paragraphs):\n",
    "        if para != '':\n",
    "            temp_cleaned_para.append(html_text.extract_text(para, guess_layout=False))\n",
    "\n",
    "    for i, para in enumerate(temp_cleaned_para):\n",
    "        if len(nltk.word_tokenize(para)) > 30 and len(nltk.word_tokenize(para)) < 150:\n",
    "            para = re.sub('[\\[].*?[\\]]', '', para)\n",
    "            raw_dataset[result].append(para)\n",
    "            cleaned_para.append(para)\n",
    "    \n",
    "    print(result, len(p))\n",
    "len(cleaned_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6ddae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_reference = {}\n",
    "for key, val in raw_dataset.items():\n",
    "    for v in val:\n",
    "        paragraph_reference[v] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "426228ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Although the term computer architecture sounds very complicated, its definition is easier than one might think. Computer architecture is a science or a set of rules stating how computer software and hardware are joined together and interact to make a computer work. It not only determines how the computer works but also of which technologies the computer is capable. Computers continue to be a major part of our lives, and computer architects continue to develop new and better programs and technologies.': 'https://www.computersciencedegreehub.com/faq/what-is-computer-architecture/',\n",
       " 'Computer architecture is a specification describing how hardware and software technologies interact to create a computer platform or system. When we think of the word architecture, we think of building a house or a building. Keeping that same principle in mind, computer architecture involves building a computer and all that goes into a computer system. Computer architecture consists of three main categories.': 'https://www.computersciencedegreehub.com/faq/what-is-computer-architecture/',\n",
       " 'To become a computer architect, often called computer network architect, the candidate must have at least a bachelor’s degree in computer science, engineering, information systems or a related field. The best programs for aspiring computer architects are computer-based fields because they offer students the most hands-on experience in database design or network security, both of which are important for computer architects. These classes also teach the students various technologies used in different networks.': 'https://www.computersciencedegreehub.com/faq/what-is-computer-architecture/',\n",
       " 'Some students choose to complete an MBA (master’s of business administration) with a focus on information systems. The advantage of this program is that it offers both computer-related and business courses. Even after earning the degree, applicants may be required to have at least five years of experience working with IT systems before being hired as a computer architect. Some computer architects go on to become computer and information systems managers once they’ve obtained sufficient experience.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'As long as we have computers and all the parts that go into a computer system, there will continue to be a demand for computer architects. Computer architects are expected to see an employment growth of 6% between 2016 and 2026 as reported by the U.S. Bureau of Labor Statistics (BLS). While cloud computing has decreased the need for computer architects somewhat, they will continue to be in demand as businesses continue to increase their technology needs. The BLS reports that computer architects nationwide earned wages ranging from $58,160 to $162,390 as of May 2017 with the average wage at $107,870.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'All computers, no matter their size, are based around a set of rules stating how software and hardware join together and interact to make them work. This is what is known as computer architecture. In this article we’re going to delve into what computer architecture actually is.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'Computer architecture is the organisation of the components which make up a computer system and the meaning of the operations which guide its function. It defines what is seen on the machine interface, which is targeted by programming languages and their compilers.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'System design includes all hardware parts of a computer, including data processors, multiprocessors, memory controllers, and direct memory access. It also includes the graphics processing unit (GPU). This part is the physical computer system.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'This includes the functions and capabilities of the central processing unit (CPU). It is the embedded programming language and defines what programming it can perform or process. This part is the software that makes the computer run, such as operating systems like Windows on a PC or iOS on an Apple iPhone, and includes data formats and the programmed instruction set.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'Microarchitecture is also known as computer organisation and defines the data processing and storage element and how they should be implemented into the ISA. It is the hardware implementation of how an ISA is implemented in a particular processor.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'CISC processors have a single processing unit, external memory, and a small register set with hundreds of different instructions. These processors have a single instruction to perform a task, and have the advantage of making the job of the programmer easier, as fewer lines of code are needed to get the job done. This approach uses less memory, but can take longer to complete instructions.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'The RISC architecture was the result of a rethink, which has led to the development of high-performance processors. The hardware is kept as simple and fast as possible, and complex instructions can be performed with simpler instructions.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'Microprocessors are digital systems which read and execute machine language instructions. Instructions are represented in a symbolic format called an assembly language. These are processors which are implemented on a single, integrated circuit. Common microprocessors used today are the Intel Pentium series, IBM PowerPC, and the Sun SPARC, among others. Nearly all modern processors are microprocessors, which are often available as standard on von Neumann machines.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'Mathematician John von Neumann and his colleagues proposed the von Neumann architecture in 1945, which stated that a computer consists of: a processor with an arithmetic and logic unit (ALU) and a control unit; a memory unit that can communicate directly with the processor using connections called buses; connections for input/output devices; and a secondary storage for saving and backing up data.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'The central computation concept of this architecture is that instructions and data are both loaded into the same memory unit, which is the main memory of the computer and consists of a set of addressable locations. The processor can then access the instructions and data required for the execution of a computer program using dedicated connections called buses – an address bus which is used to identify the addressed location and a data bus which is used to transfer the contents to and from a location.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'Computers as physical objects have changed dramatically in the 76 years since the von Neumann architecture was proposed. Supercomputers in the 1940s took up a whole room but had very basic functionality, compared to a modern smartwatch which is small in size but has dramatically higher performance. However, at their core, computers have changed very little and almost all of those created between then and now have been run on virtually the same von Neumann architecture.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'There are a number of reasons why the von Neumann architecture has proven to be so successful. It is relatively easy to implement in hardware, and von Neumann machines are deterministic and introspectable. They can be described mathematically and every step of their computing process is understood. You can also rely on them to always generate the same output on one set of inputs.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'The biggest challenge with von Neumann machines is that they can be difficult to code. This has led to the growth of computer programming, which takes real-world problems and explains them to von Neumann machines.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'When a software program is being written, an algorithm is reduced to the formal instructions that a von Neumann machine can follow. However, the challenge is that not all algorithms and problems are easy to reduce, leaving unsolved problems.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'The Harvard architecture keeps instructions and data in separate memories, and the processor accesses these memories using separate buses. The processor is connected to the ‘instructions memory’ using a dedicated set of address and data buses, and is connected to the ‘data memory’ using a different set of address and data buses.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'At the University of Sunderland we offer a 100% online learning MSc Computer Science course, designed for individuals who aren’t from a computer science background and want to change their career path, or for those who want to incorporate computer science knowledge into their current field for career progression.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'Study part-time and entirely online and grow your global network as you connect with peers from all over the world. Apply today and start within weeks, we have six start dates a year.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'Computer Architecture: In computer manufacturing, computer engineering is a set of rules and methods that describe the functionality, organization, and utilization of computer systems. Some definitions of engineering define it as describing the wherewithals and programming model of a computer but not a particular utilization. In oth er definitio ns computer architecture proves instruction set architecture desig n, microarchitect ure design, logic design, and utilization.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'The term “ engineering ” in computer literature can be delineated to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM’s main research center in 1959. Johnson had the opportunity to write a proprietary research transmission about the Stretch, an IBM-developed supercomputer for Los A lamos National Workshop (at the time known as Los A lamos Scientific Laboratory). To portray the level of detail for discussing the luxuriously embellished computer, he noted that his explanation of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that suggested more useful than “machine management ”.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'Although the term computer engineering sounds very complicated, its definition is easier than one might think. Computer engineering is a science or a set of rules stating how brain software and hardware are joined together and interact to make a computer work. It not only determines how the brain works but also of which technologies the computer is capable. Brains continue to be a major part of our lives, and brain architects reestablish to develop new and better policies and technologies.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'Computer engineering is a specification describing how housewares and software technologies interact to create a brain podium or system. When we think of the word architecture, we think of establishing a house or a building. Keeping that same principle in mind, computer architecture suggests building a computer and all that goes into a brain system. Computer architecture consists of three main categories.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'This book is about designing and manufacturing specialized brains. We all know what a brain is. It’s that box that sits on your desk, quietly purring away (or rattling if the fan is shot), running your programs, and systematically crashing (if you’re not running some diversity of Unix). Inside that box are the televisions that run your software, store your instruction, and connect you to the world. It’s all about processing information. Designing a computer, therefore, is about designing a machine that holds and manipulates data.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'To become a computer architect, often called a computer network architect, the candidate must have at least a bachelor’s degree in computer science, engineering, information systems, or a related field. The best programs for aspiring computer architects are computer-based fields because they offer students the most hands-on experience in database design or network security, both of which are important for computer architects. These classes also teach the students various technologies used in different networks.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'In contrast, the embedded computer is normally dedicated to a specific task. In many cases, an embedded system is used to replace application-specific electronics. The advantage of using an embedded microprocessor over dedicated electronics is that the functionality of the system is determined by the software, not the hardware. This makes the embedded system easier to produce, and much easier to evolve, than a complicated circuit.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'The embedded system typically has one application and one application only, which is permanently running. The embedded computer may or may not have an operating system, and rarely does it provide the user with the ability to arbitrarily install new software. The software is normally contained in the system’s nonvolatile memory, unlike a desktop computer where the nonvolatile memory contains boot software and (maybe) low-level drivers only.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'Embedded hardware is often much simpler than a desktop system, but it can also be far more complex too. An embedded computer may be implemented in a single chip with just a few support components, and its purpose may be as crude as a controller for a garden-watering system. Alternatively, the embedded computer may be a 150-processor, distributed parallel machine responsible for all the flight and control systems of a commercial jet. As diverse as embedded hardware may be, the underlying principles of design are the same.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'This chapter introduces some important concepts relating to computer architecture, with specific emphasis on those topics relevant to embedded systems. Its purpose is to give you grounding before moving on to the more hands-on information that begins in Chapter 2. In this chapter, you’ll learn about the basics of processors, interrupts, the difference between RISC and CISC, parallel systems, memory, and I/O.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'Computer architecture is the organization of the components making up a computer system and the semantics or meaning of the operations that guide its function. As such, the computer architecture governs the design of a family of computers and defines the logical interface that is targeted by programming languages and their compilers. The organization determines the mix of functional units in which the system is composed and the structure of their interconnectivity.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'The architecture semantics is the meaning of what the systems do under user direction and how their functional units are controlled to work together. An important embodiment of semantics is the instruction set architecture (ISA) of the system. The ISA is a logical (usually binary) representative encoding of the basic set of distinct operations that a computer architecture may perform, and by which application programs specify the useful work to be done. At the machine level, the hardware (sometimes controlled by firmware) system directly interprets and executes a sequence or partially ordered set of these basic operations.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'This is true for all computer cores, from those few in the smallest mobile phones to potentially millions making up the world’s largest supercomputers. High-performance computer architecture extends structure to a hierarchy of functional elements, whether small and limited in capability or possibly entire processor cores themselves. In this chapter many different classes of the structure are presented, each exploiting concurrency in its own particular way. But in all cases, this more broad definition of a general architecture for high-performance computing emphasizes aspects of the system that contribute to achieving performance.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'A high-performance computer is designed to go fast, and its organization and semantics are specially devised to deliver computational speed. This chapter introduces the basic foundations of computer architecture in general and for high-performance computer systems in particular. It is here, at the structural and logical levels, that parallelism of operation in its many forms and size is first presented. This chapter provides a first examination of the principal forms of supercomputer architecture and the underlying concepts that govern their performance.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'Cybersecurity Supply Chain Risk Management (C-SCRM) is a systematic process for managing exposure to cybersecurity risks throughout the supply chain. An important goal of C-SCRM is to reduce the likelihood of a supply chain compromise by a cybersecurity threat by improving an enterprise’s... View Full Term': 'https://www.techopedia.com/definition/26757/computer-architecture',\n",
       " 'Computer architecture is a specification detailing how a set of software and hardware technology standards interact to form a computer system or platform. In short, computer architecture refers to how a computer system is designed and what technologies it is compatible with.': 'https://www.techopedia.com/definition/26757/computer-architecture',\n",
       " 'As with other contexts and meanings of the word architecture, computer architecture is likened to the art of determining the needs of the user/system/technology, and creating a logical design and standards based on those requirements.': 'https://www.techopedia.com/definition/26757/computer-architecture',\n",
       " 'A very good example of computer architecture is von Neumann architecture, which is still used by most types of computers today. This was proposed by the mathematician John von Neumann in 1945. It describes the design of an electronic computer with its CPU, which includes the arithmetic logic unit, control unit, registers, memory for data and instructions, an input/output interface and external storage functions.': 'https://www.techopedia.com/definition/26757/computer-architecture',\n",
       " \"Techopedia™ is your go-to tech source for professional IT insight and inspiration. We aim to be a site that isn't trying to be the first to break news stories, but instead help you better understand technology and — we hope — make better decisions as a result.\": 'https://www.techopedia.com/definition/26757/computer-architecture',\n",
       " 'In computer engineering, microarchitecture, also called computer organization and sometimes abbreviated as µarch or uarch, is the way a given instruction set architecture (ISA) is implemented in a particular processor.  A given ISA may be implemented with different microarchitectures;   implementations may vary due to different goals of a given design or due to shifts in technology. ': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'The ISA is roughly the same as the programming model of a processor as seen by an assembly language programmer or compiler writer. The ISA includes the instructions, execution model, processor registers, address and data formats among other things. The microarchitecture includes the constituent parts of the processor and how these interconnect and interoperate to implement the ISA.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'The microarchitecture of a machine is usually represented as (more or less detailed) diagrams that describe the interconnections of the various microarchitectural elements of the machine, which may be anything from single gates and registers, to complete arithmetic logic units (ALUs) and even larger elements. These diagrams generally separate the datapath (where data is placed) and the control path (which can be said to steer the data). ': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Each microarchitectural element is in turn represented by a schematic describing the interconnections of logic gates used to implement it. Each logic gate is in turn represented by a circuit diagram describing the connections of the transistors used to implement it in some particular logic family. Machines with different microarchitectures may have the same instruction set architecture, and thus be capable of executing the same programs. New microarchitectures and/or circuitry solutions, along with advances in semiconductor manufacturing, are what allows newer generations of processors to achieve higher performance while using the same ISA.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'The pipelined datapath is the most commonly used datapath design in microarchitecture today. This technique is used in most modern microprocessors, microcontrollers, and DSPs. The pipelined architecture allows multiple instructions to overlap in execution, much like an assembly line. The pipeline includes several different stages which are fundamental in microarchitecture designs.  Some of these stages include instruction fetch, instruction decode, execute, and write back. Some architectures include other stages such as memory access. The design of pipelines is one of the central microarchitectural tasks.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Execution units are also essential to microarchitecture. Execution units include arithmetic logic units (ALU), floating point units (FPU), load/store units, branch prediction, and SIMD. These units perform the operations or calculations of the processor. The choice of the number of execution units, their latency and throughput is a central microarchitectural design task. The size, latency, throughput and connectivity of memories within the system are also microarchitectural decisions.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'System-level design decisions such as whether or not to include peripherals, such as memory controllers, can be considered part of the microarchitectural design process. This includes decisions on the performance-level and connectivity of these peripherals.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Unlike architectural design, where achieving a specific performance level is the main goal, microarchitectural design pays closer attention to other constraints. Since microarchitecture design decisions directly affect what goes into a system, attention must be paid to issues such as chip area/cost, power consumption, logic complexity, ease of connectivity, manufacturability, ease of debugging, and testability.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Historically, the earliest computers were multicycle designs. The smallest, least-expensive computers often still use this technique. Multicycle architectures often use the least total number of logic elements and reasonable amounts of power. They can be designed to have deterministic timing and high reliability. In particular, they have no pipeline to stall when taking conditional branches or interrupts. However, other microarchitectures often perform more instructions per unit time, using the same logic family. When discussing \"improved performance,\" an improvement is often relative to a multicycle design.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'In a multicycle computer, the computer does the four steps in sequence, over several cycles of the clock. Some designs can perform the sequence in two clock cycles by completing successive stages on alternate clock edges, possibly with longer operations occurring outside the main cycle. For example, stage one on the rising edge of the first cycle, stage two on the falling edge of the first cycle, etc.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Instruction sets have shifted over the years, from originally very simple to sometimes very complex (in various respects). In recent years, load–store architectures, VLIW and EPIC types have been in fashion. Architectures that are dealing with data parallelism include SIMD and Vectors. Some labels used to denote classes of CPU architectures are not particularly descriptive, especially so the CISC label; many early designs retroactively denoted \" CISC\" are in fact significantly simpler than modern RISC processors (in several respects).': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'However, the choice of instruction set architecture may greatly affect the complexity of implementing high-performance devices. The prominent strategy, used to develop the first RISC processors, was to simplify instructions to a minimum of individual semantic complexity combined with high encoding regularity and simplicity. Such uniform instructions were easily fetched, decoded and executed in a pipelined fashion and a simple strategy to reduce the number of logic levels in order to reach high operating frequencies; instruction cache-memories compensated for the higher operating frequency and inherently low code density while large register sets were used to factor out as much of the (slow) memory accesses as possible.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'One of the first, and most powerful, techniques to improve performance is the use of instruction pipelining. Early processor designs would carry out all of the steps above for one instruction before moving onto the next. Large portions of the circuitry were left idle at any one step; for instance, the instruction decoding circuitry would be idle during execution and so on.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Pipelining improves performance by allowing a number of instructions to work their way through the processor at the same time. In the same basic example, the processor would start to decode (step 1) a new instruction while the last one was waiting for results. This would allow up to four instructions to be \"in flight\" at one time, making the processor look four times as fast. Although any one instruction takes just as long to complete (there are still four steps) the CPU as a whole \"retires\" instructions much faster.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'RISC makes pipelines smaller and much easier to construct by cleanly separating each stage of the instruction process and making them take the same amount of time—one cycle. The processor as a whole operates in an assembly line fashion, with instructions coming in one side and results out the other. Due to the reduced complexity of the classic RISC pipeline, the pipelined core and an instruction cache could be placed on the same size die that would otherwise fit the core alone on a CISC design. This was the real reason that RISC was faster. Early designs like the SPARC and MIPS often ran over 10 times as fast as Intel and Motorola CISC solutions at the same clock speed and price.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Pipelines are by no means limited to RISC designs. By 1986 the top-of-the-line VAX implementation (VAX 8800) was a heavily pipelined design, slightly predating the first commercial MIPS and SPARC designs. Most modern CPUs (even embedded CPUs) are now pipelined, and microcoded CPUs with no pipelining are seen only in the most area-constrained embedded processors.  Large CISC machines, from the VAX 8800 to the modern Pentium 4 and Athlon, are implemented with both microcode and pipelines. Improvements in pipelining and caching are the two major microarchitectural advances that have enabled processor performance to keep pace with the circuit technology on which they are based.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'It was not long before improvements in chip manufacturing allowed for even more circuitry to be placed on the die, and designers started looking for ways to use it. One of the most common was to add an ever-increasing amount of cache memory on-die. Cache is very fast and expensive memory. It can be accessed in a few cycles as opposed to many needed to \"talk\" to main memory. The CPU includes a cache controller which automates reading and writing from the cache. If the data is already in the cache it is accessed from there – at considerable time savings, whereas if it is not the processor is \"stalled\" while the cache controller reads it in.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'RISC designs started adding cache in the mid-to-late 1980s, often only 4 KB in total. This number grew over time, and typical CPUs now have at least 2 MB, while more powerful CPUs come with 4 or 6 or 12MB or even 32MB or more, with the most being 768MB in the newly released EPYC Milan-X line, organized in multiple levels of a memory hierarchy. Generally speaking, more cache means more performance, due to reduced stalling.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " \"Caches and pipelines were a perfect match for each other. Previously, it didn't make much sense to build a pipeline that could run faster than the access latency of off-chip memory. Using on-chip cache memory instead, meant that a pipeline could run at the speed of the cache access latency, a much smaller length of time. This allowed the operating frequencies of processors to increase at a much faster rate than that of off-chip memory.\": 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Even with all of the added complexity and gates needed to support the concepts outlined above, improvements in semiconductor manufacturing soon allowed even more logic gates to be used.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'In the outline above the processor processes parts of a single instruction at a time. Computer programs could be executed faster if multiple instructions were processed simultaneously. This is what superscalar processors achieve, by replicating functional units such as ALUs. The replication of functional units was only made possible when the die area of a single-issue processor no longer stretched the limits of what could be reliably manufactured. By the late 1980s, superscalar designs started to enter the market place.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'In modern designs it is common to find two load units, one store (many instructions have no results to store), two or more integer math units, two or more floating point units, and often a SIMD unit of some sort. The instruction issue logic grows in complexity by reading in a huge list of instructions from memory and handing them off to the different execution units that are idle at that point. The results are then collected and re-ordered at the end.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'The addition of caches reduces the frequency or duration of stalls due to waiting for data to be fetched from the memory hierarchy, but does not get rid of these stalls entirely. In early designs a cache miss would force the cache controller to stall the processor and wait. Of course there may be some other instruction in the program whose data is available in the cache at that point. Out-of-order execution allows that ready instruction to be processed while an older instruction waits on the cache, then re-orders the results to make it appear that everything happened in the programmed order. This technique is also used to avoid other operand dependency stalls, such as an instruction awaiting a result from a long latency floating-point operation or other multi-cycle operations.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Register renaming refers to a technique used to avoid unnecessary serialized execution of program instructions because of the reuse of the same registers by those instructions. Suppose we have two groups of instruction that will use the same register. One set of instructions is executed first to leave the register to the other set, but if the other set is assigned to a different similar register, both sets of instructions can be executed in parallel (or) in series.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Computer architects have become stymied by the growing mismatch in CPU operating frequencies and DRAM access times. None of the techniques that exploited instruction-level parallelism (ILP) within one program could make up for the long stalls that occurred when data had to be fetched from main memory. Additionally, the large transistor counts and high operating frequencies needed for the more advanced ILP techniques required power dissipation levels that could no longer be cheaply cooled. For these reasons, newer generations of computers have started to exploit higher levels of parallelism that exist outside of a single program or program thread.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'This trend is sometimes known as throughput computing. This idea originated in the mainframe market where online transaction processing emphasized not just the execution speed of one transaction, but the capacity to deal with massive numbers of transactions. With transaction-based applications such as network routing and web-site serving greatly increasing in the last decade, the computer industry has re-emphasized capacity and throughput issues.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'One technique of how this parallelism is achieved is through multiprocessing systems, computer systems with multiple CPUs. Once reserved for high-end mainframes and supercomputers, small-scale (2–8) multiprocessors servers have become commonplace for the small business market. For large corporations, large scale (16–256) multiprocessors are common. Even personal computers with multiple CPUs have appeared since the 1990s.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " \"With further transistor size reductions made available with semiconductor technology advances, multi-core CPUs have appeared where multiple CPUs are implemented on the same silicon chip. Initially used in chips targeting embedded markets, where simpler and smaller CPUs would allow multiple instantiations to fit on one piece of silicon. By 2005, semiconductor technology allowed dual high-end desktop CPUs CMP chips to be manufactured in volume. Some designs, such as Sun Microsystems ' UltraSPARC T1 have reverted to simpler (scalar, in-order) designs in order to fit more processors on one piece of silicon.\": 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Another technique that has become more popular recently is multithreading. In multithreading, when the processor has to fetch data from slow system memory, instead of stalling for the data to arrive, the processor switches to another program or program thread which is ready to execute. Though this does not speed up a particular program/thread, it increases the overall system throughput by reducing the time the CPU is idle.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Conceptually, multithreading is equivalent to a context switch at the operating system level. The difference is that a multithreaded CPU can do a thread switch in one CPU cycle instead of the hundreds or thousands of CPU cycles a context switch normally requires. This is achieved by replicating the state hardware (such as the register file and program counter) for each active thread.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'computer architecture, structure of a digital computer, encompassing the design and layout of its instruction set and storage registers. The architecture of a computer is chosen with regard to the types of programs that will be run on it (business, scientific, general-purpose, etc.). Its principal components or subsystems, each of which could be said to have an architecture of its own, are input/output, storage, communication, control, and processing.': 'https://www.britannica.com/technology/computer-architecture',\n",
       " 'In computing, a word is the natural unit of data used by a particular processor design. A word is a fixed-sized datum handled as a unit by the instruction set or the hardware of the processor. The number of bits or digits  in a word (the word size, word width, or word length) is an important characteristic of any specific processor design or computer architecture.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'The size of a word is reflected in many aspects of a computer\\'s structure and operation; the majority of the registers in a processor are usually word sized and the largest datum that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. The largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used).': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Documentation for computers with fixed word size commonly stated memory sizes in words rather than bytes or characters. The documentation sometimes used metric prefixes correctly, sometimes with rounding, e.g., 65 kilowords (KW) meaning for 65536 words, and sometimes used them incorrectly, with kilowords (KW) meaning 1024 words (2 10) and megawords (MW) meaning 1,048,576 words (2 20). With standardization on 8-bit bytes and byte addressability, stating memory sizes in bytes, kilobytes, and megabytes with powers of 1024 rather than 1000 has become the norm, although there is some use of the IEC binary prefixes.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Several of the earliest computers (and a few modern as well) used binary-coded decimal rather than plain binary, typically having a word size of 10 or 12 decimal digits, and some early decimal computers had no fixed word length at all. Early binary systems tended to use word lengths that were some multiple of 6-bits, with the 36-bit word being especially common on mainframe computers. The introduction of ASCII led to the move to systems with word lengths that were a multiple of 8-bits, with 16-bit machines being popular in the 1970s before the move to modern processors with 32 or 64 bits.  Special-purpose designs like digital signal processors, may have any word length from 4 to 80 bits. ': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'The size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. If multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see Size families below).': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'When a computer architecture is designed, the choice of a word size is of substantial importance. There are design considerations which encourage particular bit-group sizes for particular uses (e.g. for addresses), and these considerations point to different sizes for different uses. However, considerations of economy in design strongly push for one size, or a very few sizes related by multiples or fractions (submultiples) to a primary size. That preferred size becomes the word size of the architecture.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Character size was in the past (pre-variable-sized character encoding) one of the influences on unit of address resolution and the choice of word size. Before the mid-1960s, characters were most often stored in six bits; this allowed no more than 64 characters, so the alphabet was limited to upper case. Since it is efficient in time and space to have the word size be a multiple of the character size, word sizes in this period were usually multiples of 6 bits (in binary machines). A common choice then was the 36-bit word, which is also a good size for the numeric properties of a floating point format.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'After the introduction of the IBM System/360 design, which used eight-bit characters and supported lower-case letters, the standard size of a character (or more accurately, a byte) became eight bits. Word sizes thereafter were naturally multiples of eight bits, with 16, 32, and 64 bits being commonly used.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Early machine designs included some that used what is often termed a variable word length. In this type of organization, an operand had no fixed length. Depending on the machine and the instruction, the length might be denoted by a count field, by a delimiting character, or by an additional bit called, e.g., flag, word mark. Such machines often used binary-coded decimal in 4-bit digits, or in 6-bit characters, for numbers. This class of machines included the IBM 702, IBM 705, IBM 7080, IBM 7010, UNIVAC 1050, IBM 1401, IBM 1620, and RCA 301.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Most of these machines work on one unit of memory at a time and since each instruction or datum is several units long, each instruction takes several cycles just to access memory. These machines are often quite slow because of this. For example, instruction fetches on an IBM 1620 Model I take 8 cycles just to read the 12 digits of the instruction (the Model II reduced this to 6 cycles, or 4 cycles if the instruction did not need both address fields). Instruction execution took a completely variable number of cycles, depending on the size of the operands.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'The memory model of an architecture is strongly influenced by the word size. In particular, the resolution of a memory address, that is, the smallest unit that can be designated by an address, has often been chosen to be the word. In this approach, the word-addressable machine approach, address values which differ by one designate adjacent memory words. This is natural in machines which deal almost always in word (or multiple-word) units, and has the advantage of allowing instructions to use minimally sized fields to contain addresses, which can permit a smaller instruction size or a larger variety of instructions.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'When byte processing is to be a significant part of the workload, it is usually more advantageous to use the byte, rather than the word, as the unit of address resolution. Address values which differ by one designate adjacent bytes in memory. This allows an arbitrary character within a character string to be addressed straightforwardly. A word can still be addressed, but the address to be used requires a few more bits than the word-resolution alternative. The word size needs to be an integer multiple of the character size in this organization. This addressing approach was used in the IBM 360, and has been the most common approach in machines designed since then.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'When the workload involves processing fields of different sizes, it can be advantageous to address to the bit. Machines with bit addressing may have some instructions that use a programmer-defined byte size and other instructions that operate on fixed data sizes. As an example, on the IBM 7030  (\"Stretch\"), a floating point instruction can only address words while an integer arithmetic instruction can specify a field length of 1-64 bits, a byte size of 1-8 bits and an accumulator offset of 0-127 bits.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'In at byte-addressable machine with storage-to-storage (SS) instructions, there are typically move instructions to copy one or multiple bytes from one arbitrary location to another. In a byte-oriented (byte-addressable) machine without SS instructions, moving a single byte from one arbitrary location to another is typically:': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Individual bytes can be accessed on a word-oriented machine in one of two ways. Bytes can be manipulated by a combination of shift and mask operations in registers. Moving a single byte from one arbitrary location to another may require the equivalent of the following:': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Alternatively many word-oriented machines implement byte operations with instructions using special byte pointers in registers or memory. For example, the PDP-10 byte pointer contained the size of the byte in bits (allowing different-sized bytes to be accessed), the bit position of the byte within the word, and the word address of the data. Instructions could automatically adjust the pointer to the next byte on, for example, load and deposit (store) operations.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Different amounts of memory are used to store data values with different degrees of precision. The commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word). Converting the index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. In some cases this relationship can also avoid the use of division operations. As a result, most modern computer designs have word sizes (and other operand sizes) that are a power of two times the size of a byte.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'As computer designs have grown more complex, the central importance of a single word size to an architecture has decreased. Although more capable hardware can use a wider variety of sizes of data, market forces exert pressure to maintain backward compatibility while extending processor capability. As a result, what might have been the central word size in a fresh design has to coexist as an alternative size to the original word size in a backward compatible design. The original word size remains available in future designs, forming the basis of a size family.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'In the mid-1970s, DEC designed the VAX to be a 32-bit successor of the 16-bit PDP-11. They used word for a 16-bit quantity, while longword referred to a 32-bit quantity; this terminology is the same as the terminology used for the PDP-11. This was in contrast to earlier machines, where the natural unit of addressing memory would be called a word, while a quantity that is one half a word would be called a halfword. In fitting with this scheme, a VAX quadword is 64 bits. They continued this 16-bit word/32-bit longword/64-bit quadword terminology with the 64-bit Alpha.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'A similar phenomenon has developed in Intel\\'s x86 assembly language – because of the support for various sizes (and backward compatibility) in the instruction set, some instruction mnemonics carry \"d\" or \"q\" identifiers denoting \"double-\", \"quad-\" or \"double-quad-\", which are in terms of the architecture\\'s original 16-bit word size.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'An example with a different word size is the IBM System/360 family. In the System/360 architecture, System/370 architecture and System/390 architecture, there are 8-bit byte s, 16-bit halfword s, 32-bit word s and 64-bit doubleword s. The z/Architecture, which is the 64-bit member of that architecture family, continues to refer to 16-bit halfword s, 32-bit word s, and 64-bit doubleword s, and additionally features 128-bit quadword s.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Often carefully written source code – written with source-code compatibility and software portability in mind – can be recompiled to run on a variety of processors, even ones with different data word lengths or different address widths or both.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Computer architecture consists of rules and methods or procedures which describe the implementation, functionality of the computer systems. Architecture is built as per the user’s needs by taking care of the economic and financial constraints. Earlier architecture is designed on paper built with hardware form.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'After it is built-in transistor-transistor logic the architecture is built, tested and formed in the hardware form. We can define computer architecture based on its performance, efficiency, reliability, and cost of the computer system. It deals with software and hardware technology standards. The computer system has the processor, memory, I/O devices and communication channels that connect to it.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'The memory we have a single read/write memory available for read and write instructions and data. When we talk about memory, it is nothing but the single location which is used for reading and writing instructions for the data and instructions are also present in it. Data and instructions are stored in a single read/write memory within the computer system.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'Each memory has multiple locations and each location has a unique address. We can address the contents of memory by its location irrespective of what type of data and instructions are present in the memory, because of which we can read or write any data and instructions. Execution always occurs in a sequential manner unless the change is required. For example, suppose we are executing an instruction from line 1 to line 10 but now we required to execute line 50 instead of line 11 then we jump to instruction 50 and execute it.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'There is a bus (address bus/data bus/control bus) used for the instruction and data code execution. Input device takes data or instruction and the Central processing unit (CPU) performs one operation at a time, either fetching data or instruction in/out of the memory. Once the operation is done it is sent to the output device. Control and logic units for processing operations are within the central processing unit.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'Harvard architecture is used when data and code is present in different memory blocks. A separate memory block is needed for data and instruction. Data can be accessed by one memory location and instruction can be accessed by a different location. It has data storage entirely contained within the central processing unit (CPU). A single set of clock cycles is required. The pipeline is possible. It is complex to design. CPU can read and write instructions and process data access. Harvard architecture has different access codes and data address spaces that is, the instruction address zero is not the same as data address zero. Instruction address zero identifies 24-byte value and data address zero identifies 8-byte value which is not the part of the 24-byte value.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'Modified harvard architecture is like a harvard architecture machine and it has a common address space for the separate data and instruction cache. It has digital signal processors that will execute small or highly audio or video algorithms and it is reproducible. Microcontrollers have a small number of programs and data memory and it speeds up the processing by executing parallel instructions and data access.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'We can observe in the below image, there are separate data and instruction memory that is a bus available to perform operations. It is contained entirely within the Central processing unit. It can perform Input/output operation simultaneously and it has a separate arithmetic and logic unit.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'To make up the architecture, instruction set architecture is needed because it has a set of instructions that the processor understands. It has two instruction set one is RISC (reduced instruction set computer) and the second is CISC (complex instruction set computer).': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'Reduced instruction set computer architecture was realized in the 90’s by IBM. Instruction has multiple address modes, but programs do not use all of them that is the reason multiple address modes were reduced. This helps the compiler to easily write the instructions, performed is increased.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'Complex instruction set architecture is the root of compilers because earlier compilers were not there to write programs, to ease programming instructions are added. The best performance is obtained by using simple instruction from ISA.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'Microarchitecture is known as computer organizations and it is the way when instruction set architecture is a built-in processor. Instruction set architecture is implemented with various microarchitecture and it varies because of changing technology.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'Microarchitecture performs in a certain way. It reads the instruction and decodes it, will find parallel data to process the instruction and then will process the instruction and output will be generated.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'It is used in microprocessors, microcontrollers. Some architectures overlap multiple instructions while executing but this does not happen in microarchitecture. Execution units like arithmetic logic units, floating-point units, load units, etc are needed and it performs the operation of the processor. There are microarchitecture decisions within the system such as size, latency, and connectivity of the memories.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'The name defines itself, the design will satisfy user requirements such as architecture, module, interfaces and data for a system and it is connected to product development. It is the process of taking marketing information and creating product design to be manufacture. Modular systems are made by standardizing hardware and software.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'We have learned about computer architecture and its types. How functionality, implementation works in processing. Instruction set architecture is needed to do the needful instruction execution and data processing should be done in a different and single memory location in different types of computer architectures. Read/write operations are performed.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'This is a guide to Types of Computer Architecture. Here we discuss the basic concept and different types of computer architecture in detail. You may also have a look at the following articles to learn more –': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'This website or its third-party tools use cookies, which are necessary to its functioning and required to achieve the purposes illustrated in the cookie policy. By closing this banner, scrolling this page, clicking a link or continuing to browse otherwise, you agree to our Privacy Policy': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'In computer engineering, computer architecture is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. The architecture of a system refers to its structure in terms of separately specified components of that system and their interrelationships. ': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation.  In other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation. ': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'The first documented computer architecture was in the correspondence between Charles Babbage and Ada Lovelace, describing the analytical engine. When building the computer Z1 in 1936, Konrad Zuse described in two patent applications for his future projects that machine instructions could be stored in the same storage used for data, i.e., the stored-program concept.   Two other early and important examples are:': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " \"The term “architecture” in computer literature can be traced to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM's main research center in 1959. Johnson had the opportunity to write a proprietary research communication about the Stretch, an IBM-developed supercomputer for Los Alamos National Laboratory (at the time known as Los Alamos Scientific Laboratory). To describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that seemed more useful than “machine organization”. \": 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Subsequently, Brooks, a Stretch designer, opened Chapter 2 of a book called Planning a Computer System: Project Stretch by stating, “Computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.” ': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Brooks went on to help develop the IBM System/360 (now called the IBM zSeries) line of computers, in which “architecture” became a noun defining “what the user needs to know”.  Later, computer users came to use the term in many less explicit ways. ': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'The earliest computer architectures were designed on paper and then directly built into the final hardware form.  Later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (TTL) computer—such as the prototypes of the 6800 and the PA-RISC —tested, and tweaked, before committing to the final hardware form. As of the 1990s, new computer architectures are typically \"built\", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a FPGA as a soft microprocessor; or both—before committing to the final hardware form. ': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'There are other technologies in computer architecture. The following technologies are used in bigger companies like Intel, and were estimated in 2002  to count for 1% of all of computer architecture:': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. The case of instruction set architecture can be used to illustrate the balance of these competing factors. More complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 Loop instruction).  However, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. The increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'The implementation involves integrated circuit design, packaging, power, and cooling. Optimization of the design requires familiarity with compilers, operating systems to logic design, and packaging. ': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " \"An instruction set architecture (ISA) is the interface between the computer's software and hardware and also can be viewed as the programmer's view of the machine. Computers do not understand high-level programming languages such as Java, C++, or most programming languages used. A processor only understands instructions encoded in some numerical fashion, usually as binary numbers. Software tools, such as compilers, translate those high level languages into instructions that the processor can understand.\": 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Besides instructions, the ISA defines items in the computer that are available to a program—e.g., data types, registers, addressing modes, and memory. Instructions locate these available items with register indexes (or names) and memory addressing modes.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'The ISA of a computer is usually described in a small instruction manual, which describes how the instructions are encoded. Also, it may define short (vaguely) mnemonic names for the instructions. The names can be recognized by a software development tool called an assembler. An assembler is a computer program that translates a human-readable form of the ISA into a computer-readable form. Disassemblers are also widely available, usually in debuggers and software programs to isolate and correct malfunctions in binary computer programs.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'ISAs vary in quality and completeness. A good ISA compromises between programmer convenience (how easy the code is to understand), size of the code (how much code is required to do a specific action), cost of the computer to interpret the instructions (more complexity means more hardware needed to decode and execute the instructions), and speed of the computer (with more complex decoding hardware comes longer decode time). Memory organization defines how instructions interact with the memory, and how memory interacts with itself.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'During design emulation, emulators can run programs written in a proposed instruction set. Modern emulators can measure size, cost, and speed to determine whether a particular ISA is meeting its goals.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " \"Computer organization helps optimize performance-based products. For example, software engineers need to know the processing power of processors. They may need to optimize software in order to gain the most performance for the lowest price. This can require quite a detailed analysis of the computer's organization. For example, in an SD card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.\": 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Computer organization also helps plan the selection of a processor for a particular project. Multimedia projects may need very rapid data access, while virtual machines may need fast interrupts. Sometimes certain tasks need additional components as well. For example, a computer capable of running a virtual machine needs virtual memory hardware so that the memory of different virtual computers can be kept separated. Computer organization and features also affect power consumption and processor cost.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Once an instruction set and micro-architecture have been designed, a practical machine must be developed. This design process is called the implementation. Implementation is usually not considered architectural design, but rather hardware design engineering. Implementation can be further broken down into several steps:': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'The exact form of a computer system depends on the constraints and goals. Computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. Sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Modern computer performance is often described in instructions per cycle (IPC), which measures the efficiency of the architecture at any clock frequency; a faster IPC rate means the computer is faster. Older computers had IPC counts as low as 0.1 while modern processors easily reach near 1. Superscalar processors may reach three to five IPC by executing several instructions per clock cycle. ': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Counting machine-language instructions would be misleading because they can do varying amounts of work in different ISAs. The \"instruction\" in the standard measurements is not a count of the ISA\\'s machine-language instructions, but a unit of measurement, usually based on the speed of the VAX computer architecture.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " \"Many people used to measure a computer's speed by the clock rate (usually in MHz or GHz). This refers to the cycles per second of the main clock of the CPU. However, this metric is somewhat misleading, as a machine with a higher clock rate may not necessarily have greater performance. As a result, manufacturers have moved away from clock speed as a measure of performance.\": 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'There are two main types of speed: latency and throughput. Latency is the time between the start of a process and its completion. Throughput is the amount of work done per unit time. Interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Performance is affected by a very wide range of design choices — for example, pipelining a processor usually makes latency worse, but makes throughput better. Computers that control machinery usually need low interrupt latencies. These computers operate in a real-time environment and fail if an operation is not completed in a specified amount of time. For example, computer-controlled anti-lock brakes must begin braking within a predictable and limited time period after the brake pedal is sensed or else failure of the brake will occur.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " \"Benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. Although benchmarking shows strengths, it shouldn't be how you choose a computer. Often the measured machines split on different measures. For example, one system might handle scientific applications quickly, while another might render video games more smoothly. Furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but don't offer similar advantages to general tasks.\": 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Power efficiency is another important measurement in modern computers. A higher power efficiency can often be traded for lower speed or higher cost. The typical measurement when referring to power consumption in computer architecture is MIPS/W (millions of instructions per second per watt).': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Modern circuits have less power required per transistor as the number of transistors per chip grows.  This is because each transistor that is put in a new chip requires its own power supply and requires new pathways to be built to power it. However the number of transistors per chip is starting to increase at a slower rate. Therefore, power efficiency is starting to become as important, if not more important than fitting more and more transistors into a single chip. Recent processor designs have shown this emphasis as they put more focus on power efficiency rather than cramming as many transistors into a single chip as possible.  In the world of embedded computers, power efficiency has long been an important goal next to throughput and latency.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Computer architecture can be defined as a set of rules and methods that describe the functionality, management and implementation of computers. To be precise, it is nothing but rules by which a system performs and operates.': 'https://www.tutorialspoint.com/what-is-computer-architecture',\n",
       " 'Instruction set Architecture or ISA − Whenever an instruction is given to processor, its role is to read and act accordingly. It allocates memory to instructions and also acts upon memory address mode (Direct Addressing mode or Indirect Addressing mode).': 'https://www.tutorialspoint.com/what-is-computer-architecture',\n",
       " \"For Example − Instruction set architecture (ISA) acts as a bridge between computer's software and hardware. It works as a programmer's view of a machine.\": 'https://www.tutorialspoint.com/what-is-computer-architecture',\n",
       " 'Computers can only understand binary language (i.e., 0, 1) and users understand high level language (i.e., if else, while, conditions, etc). So to communicate between user and computer, Instruction set Architecture plays a major role here, translating high level language to binary language.': 'https://www.tutorialspoint.com/what-is-computer-architecture',\n",
       " 'I have a bigger agenda. My advisor, Michael D. Smith, taught me “There are no new ideas in computer architecture, only old ones whose time has come.” Mike’s maxim matches my experience: Anton used every parallelism technique I know save threading to show that special-purpose machines could deliver multiple orders of magnitude speedup; the first TPU combined systolic arrays, decoupled access/execute, and CISC, breathing new life into old (and let’s be honest, unpopular) ideas. I’ll bet that the next transformative machine also combines old ideas in surprising new ways.': 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'As this is a blog post, I can blithely ignore peer-reviewed rigor, adopt a more informal, subjective style, fail to remember important contributions, and make tart and most likely wrong comments along the way. But I have to keep things brief, so I’m going to present my history in bullet points and summarize huge, complicated areas with sentence fragments. Also, I’m going to focus on the machines and the people who built them more than particular techniques (although those also play a key role). With all these caveats, here’s my subjective, biased, and incomplete history of computer architecture, as a first draft for the lore and epic tales of our field.': 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'Around WWII, a number of proto-computers are built and used for cryptography, artillery ballistics tables, and the design of nuclear weapons. 5 I find the principled stances of Computer Scientists who refuse government or military funding to be admirable, but I wonder if they know how martial the origins of our field are. They include:': 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'In 1949, the Eckert-Mauchly computer company builds the BINAC, the first commercial computer. UNIVAC follows in 1951, with the US Census as a customer. The computer industry blooms during the 50s, but the Eckert-Mauchly computer company isn’t one of the big winners.': 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'Let me pause here, ending the first installment of this history with IBM largely in control, but with threats to their hegemony on the way. I’ll resume in Part 2 in a few days.': 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'About the Author: Cliff Young is a software engineer in Google Research, where he works on codesign for deep learning accelerators. He is one of the designers of Google’s Tensor Processing Unit (TPU) and one of the founders of the MLPerf benchmark. Previously, Cliff built special-purpose supercomputers for molecular dynamics at D. E. Shaw Research and was a Member of Technical Staff at Bell Labs.': 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'Disclaimer: These posts are written by individual contributors to share their thoughts on the Computer Architecture Today blog for the benefit of the community. Any views or opinions represented in this blog are personal, belong solely to the blog author and do not represent those of ACM SIGARCH or its parent organization, ACM.': 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'SIGARCH serves a unique community of computer professionals working on the forefront of computer design in both industry and academia. It is ACM’s primary forum to interchange ideas about tomorrow’s hardware and its interactions with software.': 'https://www.sigarch.org/call-contributions/first-workshop-on-open-source-computer-architecture-research-oscar/',\n",
       " 'This site is maintained by volunteers working in many programs of ACM SIGARCH. We thank you for visiting! If you have questions about the site, please send a note to our content editor.': 'https://www.sigarch.org/call-contributions/first-workshop-on-open-source-computer-architecture-research-oscar/',\n",
       " 'Computer architecture concentrates on the logical aspects of computer design as opposed to the physical or electronic aspects. The underlying logical design of most modern computers is still based on that of the earliest electronic computers despite decades of progress in electronic circuitry. the innovations that have occurred in computer architecture have been driven by two different goals: higher performance and lower cost. Performance driven improvements have yielded computer systems with increasingly higher computation speeds and throughput. Cost driven improvements have yielded systems that are easier to use and applicable to a broader range of automatic control problems. Improvements in electronic circuitry have not led directly to architectural innovations; computers that pioneered new circuit technologies usually relied on older architectural concepts.': 'https://dl.acm.org/doi/10.1109/MAHC.1988.10039',\n",
       " 'A Brief History of Computer Architecture Computer Architecture is the field of study of selecting and interconnecting hardware components to create computers that satisfy functional performance and cost goals. It refers to those attributes of the computer system that are visible to a programmer and have a direct effect on the execution of a program.': 'https://edurev.in/studytube/A-Brief-History-of-Computer-Architecture-Computer-/987e1c94-0ef4-4ebd-b172-277f3deb72c1_t',\n",
       " 'If you are on a personal connection, like at home, you can run an anti-virus scan on your device to make sure it is not infected with malware.': 'https://www.researchgate.net/publication/241056162_Types_of_Computer_Architectures',\n",
       " 'A control unit (CU) handles all processor control signals. It directs all input and output flow, fetches the code for instructions and controlling how data moves around the system.': 'https://www.geeksforgeeks.org/last-minute-notes-computer-organization/',\n",
       " 'Based on Transfer of control, addressing modes are: PC relative addressing mode: PC relative addressing mode is used to implement intra segment transfer of control, In this mode effective address is obtained by adding displacement to PC. EA= PC + Address field value PC= PC + Relative value. Base register addressing mode: Base register addressing mode is used to implement inter segment transfer of control.In this mode effective address is obtained by adding base register value to address field value. EA= Base register + Address field value. PC= Base register + Relative value. Note: PC relative and based register both addressing modes are suitable for program relocation at runtime. Based register addressing mode is best suitable to write position independent codes. RISC vs CISC Characteristic of RISC –': 'https://www.geeksforgeeks.org/last-minute-notes-computer-organization/',\n",
       " 'Note: PC relative and based register both addressing modes are suitable for program relocation at runtime. Based register addressing mode is best suitable to write position independent codes.': 'https://www.geeksforgeeks.org/last-minute-notes-computer-organization/',\n",
       " 'Hardwired Control Unit – Fixed logic circuits that correspond directly to the Boolean expressions are used to generate the control signals. Hardwired control is faster than micro-programmed control. A controller that uses this approach can operate at high speed. RISC architecture is based on hardwired control unit. Micro-programmed Control Unit –': 'https://www.geeksforgeeks.org/last-minute-notes-computer-organization/',\n",
       " 'The Indirect Cycle is always followed by the Execute Cycle. The Interrupt Cycle is always followed by the Fetch Cycle. For both fetch and execute cycles, the next cycle depends on the state of the system. The Fetch Cycle – At the beginning of the fetch cycle, the address of the next instruction to be executed is in the Program Counter (PC). The Indirect Cycles – Once an instruction is fetched, the next step is to fetch source operands. Source Operand is being fetched by indirect addressing it can be fetched by any addressing mode, here its done by indirect addressing). Register-based operands need not be fetched. Once the opcode is executed, a similar process may be needed to store the result in the main memory.': 'https://www.geeksforgeeks.org/last-minute-notes-computer-organization/',\n",
       " 'Cache Mapping: There are three different types of mapping used for the purpose of cache memory which is as follows: Direct mapping, Associative mapping, and Set-Associative mapping.': 'https://www.geeksforgeeks.org/last-minute-notes-computer-organization/',\n",
       " 'Performance of pipeline with stalls Speed Up (S) = CPI non-pipeline / (1 + Number of stalls per instruction) Dependencies and Data Hazard There are mainly three types of dependencies possible in a pipelined processor. These are : Structural dependency: This dependency arises due to the resource conflict in the pipeline. A resource conflict is a situation when more than one instruction tries to access the same resource in the same cycle. A resource can be a register, memory, or ALU.': 'https://www.geeksforgeeks.org/last-minute-notes-computer-organization/',\n",
       " 'The input/output (I/O) architecture is computer system’s interface to the outside world. Each I/O module interfaces to the system bus and controls one or more peripheral devices. There are three basic forms of input and output systems –': 'https://www.geeksforgeeks.org/last-minute-notes-computer-organization/',\n",
       " 'Formula for finding decimal value: Decimal value = (-1) s * 1.F * 2 (E-Bias), Where E is decimal value of exponent field, F is mantissa and s is sign bit. Flag register (a) Status Flags': 'https://www.geeksforgeeks.org/last-minute-notes-computer-organization/',\n",
       " 'David Brooks Assistant Professor Maxwell Dworkin 141 33 Oxford Street Cambridge MA 02138 Phone: 617-495-3989 Fax: 617-495-2809 E-mail: dbrooks@eecs.harvard.edu Syllabus Meeting time Monday/Wednesday 1:00-2:30PM, MD G135 Related Course CS 246: Advanced Computer Architecture ': 'http://www.eecs.harvard.edu/~dbrooks/cs146-spring2004/',\n",
       " 'Introduction The class will review fundamental structures in modern microprocessor and computer system architecture design. Tentative topics will include computer organization, instruction set design, memory system design, pipelining, and other techniques to exploit parallelism. We will also cover system level topics such as storage subsystems and basics of multiprocessor systems. The class will focus on quantitative evaluation of design alternatives while considering design metrics such as performance and power dissipation. Prerequisites CS 141 (Computing Hardware) or equivalent, C Programming Textbook Textbook: “Computer Architecture: A Quantitative Approach,” Third Edition, John L. Hennessy and David A. Patterson, ISBN 1-55860-596-7A Course Readings': 'http://www.eecs.harvard.edu/~dbrooks/cs146-spring2004/',\n",
       " 'The class will review fundamental structures in modern microprocessor and computer system architecture design. Tentative topics will include computer organization, instruction set design, memory system design, pipelining, and other techniques to exploit parallelism. We will also cover system level topics such as storage subsystems and basics of multiprocessor systems. The class will focus on quantitative evaluation of design alternatives while considering design metrics such as performance and power dissipation. Prerequisites CS 141 (Computing Hardware) or equivalent, C Programming Textbook Textbook: “Computer Architecture: A Quantitative Approach,” Third Edition, John L. Hennessy and David A. Patterson, ISBN 1-55860-596-7A Course Readings': 'http://www.eecs.harvard.edu/~dbrooks/cs146-spring2004/',\n",
       " 'Readings: Tse-Yu Yeh, Yale N. Patt, \"A Comparison of Dynamic Branch Predictors that use Two Levels of Branch History,\" The 20th International Symposium on Computer Architecture, May, 1993.': 'http://www.eecs.harvard.edu/~dbrooks/cs146-spring2004/',\n",
       " 'Readings: J. E. Smith and A. Pleszkun, \"Implementing Precise Interrupts in Pipelined Processors,\" IEEE Transactions on Computers, Volume 37, Issue 5 (May 1988).': 'http://www.eecs.harvard.edu/~dbrooks/cs146-spring2004/',\n",
       " 'Readings: David W. Wall, \"Limits of instruction-level parallelism,\" Architectural Support for Programming Languages and Operating Systems (ASPLOS) 1991. (Also, see updated Tech Report at Western Research Lab: http://research.compaq.com/wrl/techreports/abstracts/93.6.html)': 'http://www.eecs.harvard.edu/~dbrooks/cs146-spring2004/',\n",
       " 'Readings: Subbarao Palacharla, Norman P. Jouppi, James E. Smith, \"Complexity-Effective Superscalar Processors,\" 24th International Symposium on Computer Architecture (ISCA-24), June 1997.': 'http://www.eecs.harvard.edu/~dbrooks/cs146-spring2004/',\n",
       " 'Readings: Eric Rotenberg, Steve Bennett, J. E. Smith, \"Trace Cache: A Low Latency Approach to High Bandwidth Instruction Fetching,\" 29th International Symposium on Microarchitecture (MICRO-29), Dec 1996.': 'http://www.eecs.harvard.edu/~dbrooks/cs146-spring2004/',\n",
       " 'Readings Simultaneous Multithreading: Maximizing On-Chip Parallelism, D.M. Tullsen, S.J. Eggers, and H.M. Levy, In 22nd Annual International Symposium on Computer Architecture, June, 1995.': 'http://www.eecs.harvard.edu/~dbrooks/cs146-spring2004/',\n",
       " \"Readings L. Barroso, K. Gharachorloo, R. McNamara, A. Nowatzyk, S. Qadeer, B. Sano, S. Smith, R. Stets, and B. Verghese. Piranha: A Scalable Architecture Based on Single-Chip Multiprocessing. In Proceedings of the 27th Annual International Symposium on Computer Architecture (ISCA'00), June 2000.\": 'http://www.eecs.harvard.edu/~dbrooks/cs146-spring2004/',\n",
       " 'Readings L. Barroso, J. Dean, and U. Holzle, \"Web search for a planet: The Google Cluster Architecture,\" IEEE Micro, 23, 2, March-April 2003, pp. 22-28.': 'http://www.eecs.harvard.edu/~dbrooks/cs146-spring2004/',\n",
       " 'Purpose of the course To provide an in-depth presentation of computer hardware and software with more emphasis on the more technical aspects of computing such as troubleshooting and upgrading computers.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'II. Hardware and software A. Hardware: input and output devices, backup storage, central processing unit, memory (ROM, RAM). B. Software: Categories of software, System software, applications software, general purpose software, integrated packages and software suites.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'III. Inside the computer A. The p ro c essor ; Ari th m eti c an d Logi c Unit , C ontro l U n it , sy st em c l oc k , registers B. The fetch execute cycle C. The motherboard; form factor, sockets and slots D. Buses; control bus, data bus, Address Bus, SCSI, EISA, MCA': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'Computer architecture or digital computer organization is the conceptual design and fundamental operational structure of a computer system. It is a blueprint and functional description of requirements and design implementations for the various parts of a computer, focusing largely on the way by which the central processing unit (CPU) performs internally and accesses addresses in memory.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " '\\uf0b7 Instruction set architecture, or ISA, is the abstract image of a computing system that is seen by a machine language (or assembly language) programmer, including the instruction set, word size, memory address modes, processor registers, and address and data formats.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " \"\\uf0b7 Microarchitecture, also known as Computer organization is a lower level, more concrete and detailed, description of the system that involves how the constituent parts of the system are interconnected and how they interoperate in order to implement the ISA. The size of a computer's cache for instance, is an organizational issue that generally has nothing to do with the ISA.\": 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'Objectives At the end of the chapter the learner shall be able to; i. Explain the evolution of computing technology and the technological advancement in computer architecture to current technologies ii. Explain the characteristics of computers and how they are different from humans. iii. Explain the different types of computers categorized based on size, price and capabilities iv. Explain the fundamental difference between computer hardware and software': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'When the human race started doing some trade, it felt a need for a calculating device. The first calculating device, which was used 2000 years ago was called abacus and the improvements in the calculating device in that age were slow. The next change came after about 1600 years. Following this, the changes were frequent and the mechanical desk calculator was developed around 1800 A.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'First generation computers (1946-1956) They made use of vacuum tubes to store and process information. The tubes consumed a lot of power and generated a lot of heat (overheating). They were huge in size and occupy a room. They used magnetic tape. Storage capacity was very low i. 2kb and speed of processing was also very low. First machine in this category was ENIAC (electronic discrete variable automatic computer) and later came UNIVAC (universal automatic computers). These computers were mostly computational machines. Their input /output capabilities were usually limited to the keyboard and or punched card input and printer and or punched cart output. The speed of these machines was described in milliseconds (1/1000 of a second)': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'Second generation computers (1957-1967) These computers used transistors after invention of transistors. The transistor is smaller cheaper and produced less heat than vacuum tubes and consumed less power. The cost of computers decreased and the speed increased. The second generation saw the introduction of more complex ALU and CPU, the use of high level languages and provision of system software with the computer. Data access time was measured in micro-seconds. Removable disk storage units were': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'A computer is an electronic device capable of executing instructions, developed based on algorithms stored in its memory, to process data fed to it and produce the required results faster than human beings.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'They are very large in size and use multiple processors and superior technology. Super computers are biggest in size, the most expensive in price than any other is classified and known as super computer. It can process trillions of instructions in seconds. This computer is not used as a PC in a home neither by a student in a college. Governments specially use this type of computer for their different calculations and heavy jobs. Different industries also use this huge computer for designing their products.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'In most of the Hollywood’s movies it is used for animation purposes. This kind of computer is also helpful for forecasting weather reports worldwide. They are known for von Newman’s design i. multiple processor system with parallel processing. In such a system a task is broken down and shared among processes for faster execution. They are used for complex tasks requiring a lot of computational power.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'Mainframe computers A mainframe is another giant computer after the super computer and can also process millions of instruction per second and capable of accessing billions of data .They are physically very large in size with very high capacity of main memory. This computer is commonly used in big hospitals, air line reservations companies, and many other huge companies prefer mainframe because of its capability of retrieving data on a huge basis. They can be linked to smaller computers and handle hundreds of users they are also used in space exploitation. The term mainframe was mainly used for earliest computers as they were big in size though today the term is used to refer to large computers. A large number of peripherals can be attached to them. They are expensive to install.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'Minicomputers They are smaller than the main frame but bigger than microcomputers. They support concurrent users. They can be used as servers in companies. They are slower and less costly compared to mainframe computers but more powerful, reliable and expensive than micro computers.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'Micro computers They are of advanced technology i. the micro era based on large scale integration that confines several physical components per small elements thumb size IC, hence the size reduced. It is the smallest of the three computers. They are usually called personal computers since they are designed to be used by individuals. The micro chip technology has enabled reduction of size of': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " \"temperature, speed etc. and to perform computations on these measurements. Analog computers are mainly used for scientific and engineering applications. 2. Digital Computers: Digital computers are mainly general purpose computers that represent and store data in discrete quantities or numbers. In these computers, all processing is done in terms of numeric representation (Binary Digits) of data and information. Although the user enter data in decimal or character form, it is converted into binary digits (0's and l's). Almost all the computers used nowadays are digital computers and we will discuss the detailed working and components of these computers in subsequent sections of this unit. 3. Hybrid Computers: Hybrid computers incorporate the technology of both analog and digital computers.\": 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " '1 Software and Hardware A computer has to main components; I. Hardware II. Software Computer hardware refers to the physical components of a computer such as the monitor, Keyboard, Mouse, system unit etc': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'At the end of the chapter the learner shall be able to; \\uf0b7 Explain the different hardware units of a computer system such as input, output, Central processing unit (CPU), main memory and secondary storage \\uf0b7 Explain how the different units of a computer interact witch each other to give the user output \\uf0b7 Explain how information is stored in a computer \\uf0b7 Explain the different storage units of a computer such as byte, Kilobyte,': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'Hardware units (Devices) of a computer can be categorized into five units; I. Input unit II. Output III. Central processing unit (CPU) or processor IV. Main Memory V. Secondary storage/Backing Storage': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'It is the main part of a computer system like the brain of a human being. It interprets the instructions in the program and executes one by one. The CPU of a microcomputer is called a microprocessor. Central Processing Unit is implemented in a single piece of silicon device known as a computer chip.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " '\\uf0b7 Fetch – cause the next instruction to be fetched from memory; \\uf0b7 Decode – translate the program instruction into commands that the computer can process \\uf0b7 Execute – cause the instruction to be executed': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " '\\uf0b7 Arithmetic operations – these operations are addition, subtraction, multiplication and division.. \\uf0b7 Logical operations – it compares two data items to determine whether the first one is smaller than, equal to or greater than the second item.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'ROM: A mask programmed read only memory that can be only be produced by the manufacturer. It is designed to perform a specific function and cannot be changed. This is inflexible and so regular ROMs are only used generally for programs that are static (not changing often) and mass-produced. This product is analogous to a commercial software CD-ROM that you purchase in a store.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'Programmable ROM (PROM): This is a type of ROM that can be programmed using special equipment (a PROM programmer.); it can be written to, but only once. This is useful for companies that make their own ROMs from software they write, because when they change their code they can create new PROMs without requiring expensive equipment. This is similar to the way a CD-ROM recorder works by letting you \"burn\" programs onto blanks once and then letting you read from them many times. In fact, programming a PROM is also called burning, just like burning a CD-R, and it is comparable in terms of its flexibility.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'Erasable Programmable ROM (EPROM): An EPROM is a ROM that can be erased and reprogrammed. A little glass window is installed in the top of the ROM package, through which you can actually see the chip that holds the memory. Ultraviolet light of a specific frequency can be shined through this window for a specified period of time, which will erase the EPROM and allow it to be reprogrammed again. Obviously this is much more useful than a regular PROM, but it does require the erasing light. Continuing the \"CD\" analogy, this technology is analogous to a reusable CD-RW.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'Electrically Alterable Read-Only Memory(EAROMs) can be modified a bit at a time, but writing is a slow process and uses non-standard voltages (usually higher voltages around 12 volts). Rewriting an EAROM is intended to be an infrequent operation - most of the time the memory is used as a ROM. EAROM may be used to store critical system setup information in a non-volatile way. For many applications, EAROM has been supplanted by CMOS RAM backed-up by a lithium battery.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'Electrically Erasable Programmable ROM (EEPROM): The next level of erasability is the EEPROM, which can be erased under software control. This is the most flexible type of ROM, and is now commonly used for holding BIOS programs. When you hear reference to a \"flash BIOS\" or doing a BIOS upgrade by \"flashing\", this refers to reprogramming the BIOS EEPROM with a special software program. Here we are blurring the line a bit between what \"read-only\" really means, but remember that this rewriting is done maybe once a year or so,': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'Cache memory After Random Access Memory ( RAM) Cache memory is a type of very fast memory that is used to improve the speed of a computer doubling it in some cases. It acts as an intermediate store between the CPU and the maim memory, and works by storing the most frequently or recently used instructions and data so that it will be very fast to retrieve them again.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'Hard Drive: Floppy Disk: Floppy disks allow information to be transported easily from one computer to another they have limited storage capacity, generally 1 MB. Saving and retrieving information from a floppy disk is slower than on a hard drive. They are more susceptible to physical damage and viruses than the hard drive. The size of a hard drive is usually expressed in terms of megabytes and gigabytes.': 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220',\n",
       " 'OSCAR 2022 is the first edition of a workshop aimed at fostering the community of researchers who are interested in developing and sharing open-source hardware and software for the design of next-generation computer architectures.': 'https://www.sigarch.org/call-contributions/first-workshop-on-open-source-computer-architecture-research-oscar/',\n",
       " 'Workshop Format: OSCAR will have a mix of invited talks and presentations selected from the submissions to this call for participation. Abstract should be submitted in PDF format (max 2 pages) and include title, authors, affiliations and e-mail address of the contact author. Submissions of early works and position papers are encouraged. Workshop submissions do not preclude publishing at future conference venues. While no formal proceedings are planned, the OSCAR organizers may seek the realization of a journal special issue collecting a subset of the contributions, after the workshop.': 'https://www.sigarch.org/call-contributions/first-workshop-on-open-source-computer-architecture-research-oscar/',\n",
       " 'In computer science, an instruction set architecture (ISA), also called computer architecture, is an abstract model of a computer. A device that executes instructions described by that ISA, such as a central processing unit (CPU), is called an implementation.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'In general, an ISA defines the supported instructions, data types, registers, the hardware support for managing main memory, fundamental features (such as the memory consistency, addressing modes, virtual memory), and the input/output model of a family of implementations of the ISA.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'An ISA specifies the behavior of machine code running on implementations of that ISA in a fashion that does not depend on the characteristics of that implementation, providing binary compatibility between implementations. This enables multiple implementations of an ISA that differ in characteristics such as performance, physical size, and monetary cost (among other things), but that are capable of running the same machine code, so that a lower-performance, lower-cost machine can be replaced with a higher-cost, higher-performance machine without having to replace software. It also enables the evolution of the microarchitectures of the implementations of that ISA, so that a newer, higher-performance implementation of an ISA can run software that runs on previous generations of implementations.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'If an operating system maintains a standard and compatible application binary interface (ABI) for a particular ISA, machine code will run on future implementations of that ISA and operating system. However, if an ISA supports running multiple operating systems, it does not guarantee that machine code for one operating system will run on another operating system, unless the first operating system supports running machine code built for the other operating system.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'An ISA can be extended by adding instructions or other capabilities, or adding support for larger addresses and data values; an implementation of the extended ISA will still be able to execute machine code for versions of the ISA without those extensions. Machine code using those extensions will only run on implementations that support those extensions.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'An instruction set architecture is distinguished from a microarchitecture, which is the set of processor design techniques used, in a particular processor, to implement the instruction set. Processors with different microarchitectures can share a common instruction set. For example, the Intel Pentium and the AMD Athlon implement nearly identical versions of the x86 instruction set, but they have radically different internal designs.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " \"Prior to NPL , the company's computer designers had been free to honor cost objectives not only by selecting technologies but also by fashioning functional and architectural refinements. The SPREAD compatibility objective, in contrast, postulated a single architecture for a series of five processors spanning a wide range of cost and performance. None of the five engineering design teams could count on being able to bring about adjustments in architectural specifications as a way of easing difficulties in achieving cost and performance objectives. : p.137\": 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " \"Some virtual machines that support bytecode as their ISA such as Smalltalk, the Java virtual machine, and Microsoft 's Common Language Runtime, implement this by translating the bytecode for commonly used code paths into native machine code. In addition, these virtual machines execute less frequently used code paths by interpretation (see: Just-in-time compilation). Transmeta implemented the x86 instruction set atop VLIW processors in this fashion.\": 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'An ISA may be classified in a number of different ways. A common classification is by architectural complexity. A complex instruction set computer (CISC) has many specialized instructions, some of which may only be rarely used in practical programs. A reduced instruction set computer (RISC) simplifies the processor by efficiently implementing only the instructions that are frequently used in programs, while the less common operations are implemented as subroutines, having their resulting additional processor execution time offset by infrequent use. ': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Other types include very long instruction word (VLIW) architectures, and the closely related long instruction word (LIW) and explicitly parallel instruction computing (EPIC) architectures. These architectures seek to exploit instruction-level parallelism with less hardware than RISC and CISC by making the compiler responsible for instruction issue and scheduling.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Architectures with even less complexity have been studied, such as the minimal instruction set computer (MISC) and one instruction set computer (OISC). These are theoretically important types, but have not been commercialized.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Processors may include \"complex\" instructions in their instruction set. A single \"complex\" instruction does something that may take many instructions on other computers. Such instructions are typified by instructions that take multiple steps, control multiple functional units, or otherwise appear on a larger scale than the bulk of simple instructions implemented by the given processor. Some examples of \"complex\" instructions include:': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Complex instructions are more common in CISC instruction sets than in RISC instruction sets, but RISC instruction sets may include them as well. RISC instruction sets generally do not include ALU operations with memory operands, or instructions to move large blocks of memory, but most RISC instruction sets include SIMD or vector instructions that perform the same arithmetic operation on multiple pieces of data at the same time. SIMD instructions have the ability of manipulating large vectors and matrices in minimal time. SIMD instructions allow easy parallelization of algorithms commonly involved in sound, image, and video processing. Various SIMD implementations have been brought to market under trade names such as MMX, 3DNow!, and AltiVec.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'On traditional architectures, an instruction includes an opcode that specifies the operation to perform, such as add contents of memory to register —and zero or more operand specifiers, which may specify registers, memory locations, or literal data. The operand specifiers may have addressing modes determining their meaning or may be in fixed fields. In very long instruction word (VLIW) architectures, which include many microcode architectures, multiple simultaneous opcodes and operands are specified in a single instruction.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Most stack machines have \" 0-operand\" instruction sets in which arithmetic and logical operations lack any operand specifier fields; only instructions that push operands onto the evaluation stack that pop operands from the stack into variables have operand specifiers. The instruction set carries out most ALU actions with postfix (reverse Polish notation) operations that work only on the expression stack, not on data registers or arbitrary main memory cells. This can be very convenient for compiling high-level languages, because most arithmetic expressions can be easily translated into postfix notation. ': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Conditional instructions often have a predicate field—a few bits that encode the specific condition to cause an operation to be performed rather than not performed. For example, a conditional branch instruction will transfer control if the condition is true, so that execution proceeds to a different part of the program, and not transfer control if the condition is false, so that execution continues sequentially. Some instruction sets also have conditional moves, so that the move will be executed, and the data stored in the target location, if the condition is true, and not executed, and the target location not modified, if the condition is false. Similarly, IBM z/Architecture has a conditional store instruction. A few instruction sets include a predicate field in every instruction; this is called branch predication.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " '(In the examples that follow, a, b, and c are (direct or calculated) addresses referring to memory cells, while reg1 and so on refer to machine registers.)': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Due to the large number of bits needed to encode the three registers of a 3-operand instruction, RISC architectures that have 16-bit instructions are invariably 2-operand designs, such as the Atmel AVR, TI MSP430, and some versions of ARM Thumb. RISC architectures that have 32-bit instructions are usually 3-operand designs, such as the ARM, AVR32, MIPS, Power ISA, and SPARC architectures.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Each instruction specifies some number of operands (registers, memory locations, or immediate values) explicitly. Some instructions give one or both operands implicitly, such as by being stored on top of the stack or in an implicit register. If some of the operands are given implicitly, fewer operands need be specified in the instruction. When a \"destination operand\" explicitly specifies the destination, an additional operand must be supplied. Consequently, the number of operands encoded in an instruction may differ from the mathematically necessary number of arguments for a logical or arithmetic operation (the arity). Operands are either encoded in the \"opcode\" representation of the instruction, or else are given as values or addresses following the opcode.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Register pressure measures the availability of free registers at any point in time during the program execution. Register pressure is high when a large number of the available registers are in use; thus, the higher the register pressure, the more often the register contents must be spilled into memory. Increasing the number of registers in an architecture decreases register pressure but increases the cost. ': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'While embedded instruction sets such as Thumb suffer from extremely high register pressure because they have small register sets, general-purpose RISC ISAs like MIPS and Alpha enjoy low register pressure. CISC ISAs like x86-64 offer low register pressure despite having smaller register sets. This is due to the many addressing modes and optimizations (such as sub-register addressing, memory operands in ALU instructions, absolute addressing, PC-relative addressing, and register-to-register spills) that CISC ISAs offer. ': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'A RISC instruction set normally has a fixed instruction length (often 4 bytes = 32 bits), whereas a typical CISC instruction set may have instructions of widely varying length (1 to 15 bytes for x86). Fixed-length instructions are less complicated to handle than variable-length instructions for several reasons (not having to check whether an instruction straddles a cache line or virtual memory page boundary,  for instance), and are therefore somewhat easier to optimize for speed.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'In early 1960s computers, main memory was expensive and very limited, even on mainframes. Minimizing the size of a program to make sure it would fit in the limited memory was often central. Thus the size of the instructions needed to perform a particular task, the code density, was an important characteristic of any instruction set. It remained important on the initially-tiny memories of minicomputers and then microprocessors. Density remains important today, for smartphone applications, applications downloaded into browsers over slow Internet connections, and in ROMs for embedded applications. A more general advantage of increased density is improved effectiveness of caches and instruction prefetch.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Computers with high code density often have complex instructions for procedure entry, parameterized returns, loops, etc. (therefore retroactively named Complex Instruction Set Computers, CISC). However, more typical, or frequent, \"CISC\" instructions merely combine a basic ALU operation, such as \"add\", with the access of one or more operands in memory (using addressing modes such as direct, indirect, indexed, etc.). Certain architectures may allow two or three operands (including the result) directly in memory or may be able to perform functions such as automatic pointer increment, etc. Software-implemented instruction sets may have even more complex and powerful instructions.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Reduced instruction-set computers, RISC, were first widely implemented during a period of rapidly growing memory subsystems. They sacrifice code density to simplify implementation circuitry, and try to increase performance via higher clock frequencies and more registers. A single RISC instruction typically performs only a single operation, such as an \"add\" of registers or a \"load\" from a memory location into a register. A RISC instruction set normally has a fixed instruction length, whereas a typical CISC instruction set has instructions of widely varying length. However, as RISC computers normally require more and often longer instructions to implement a given task, they inherently make less optimal use of bus bandwidth and cache memories.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Certain embedded RISC ISAs like Thumb and AVR32 typically exhibit very high density owing to a technique called code compression. This technique packs two 16-bit instructions into one 32-bit word, which is then unpacked at the decode stage and executed as two instructions. ': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Minimal instruction set computers (MISC) are a form of stack machine, where there are few separate instructions (16-64), so that multiple instructions can be fit into a single machine word. These types of cores often take little silicon to implement, so they can be easily realized in an FPGA or in a multi-core form. The code density of MISC is similar to the code density of RISC; the increased instruction density is offset by requiring more of the primitive instructions to do a task.  ': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'The instructions constituting a program are rarely specified using their internal, numeric form (machine code); they may be specified by programmers using an assembly language or, more commonly, may be generated from high-level programming languages by compilers.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'The design of instruction sets is a complex issue. There were two stages in history for the microprocessor. The first was the CISC (Complex Instruction Set Computer), which had many different instructions. In the 1970s, however, places like IBM did research and found that many instructions in the set could be eliminated. The result was the RISC (Reduced Instruction Set Computer), an architecture that uses a smaller set of instructions. A simpler instruction set may offer the potential for higher speeds, reduced processor size, and reduced power consumption. However, a more complex set may optimize common operations, improve memory and cache efficiency, or simplify programming.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Some instruction set designers reserve one or more opcodes for some kind of system call or software interrupt. For example, MOS Technology 6502 uses 00 H, Zilog Z80 uses the eight codes C7,CF,D7,DF,E7,EF,F7,FF H  while Motorola 68000 use codes in the range A000..AFFF H.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'The NOP slide used in immunity-aware programming is much easier to implement if the \"unprogrammed\" state of the memory is interpreted as a NOP. ': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'On systems with multiple processors, non-blocking synchronization algorithms are much easier to implement  if the instruction set includes support for something such as \" fetch-and-add\", \" load-link/store-conditional\" (LL/SC), or \"atomic compare-and-swap\".': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Any given instruction set can be implemented in a variety of ways. All ways of implementing a particular instruction set provide the same programming model, and all implementations of that instruction set are able to run the same executables. The various ways of implementing an instruction set give different tradeoffs between cost, performance, power consumption, size, etc.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'When designing the microarchitecture of a processor, engineers use blocks of \"hard-wired\" electronic circuitry (often designed separately) such as adders, multiplexers, counters, registers, ALUs, etc. Some kind of register transfer language is then often used to describe the decoding and sequencing of each instruction of an ISA using this physical microarchitecture. There are two basic ways to build a control unit to implement this description (although many designs use middle ways or compromises):': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Some CPU designs use a writable control store —they compile the instruction set to a writable RAM or flash inside the CPU (such as the Rekursiv processor and the Imsys Cjip),  or an FPGA (reconfigurable computing).': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'An ISA can also be emulated in software by an interpreter. Naturally, due to the interpretation overhead, this is slower than directly running programs on the emulated hardware, unless the hardware running the emulator is an order of magnitude faster. Today, it is common practice for vendors of new ISAs or microarchitectures to make software emulators available to software developers before the hardware implementation is ready.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Often the details of the implementation have a strong influence on the particular instructions selected for the instruction set. For example, many implementations of the instruction pipeline only allow a single memory load or memory store per instruction, leading to a load–store architecture (RISC). For another example, some early ways of implementing the instruction pipeline led to a delay slot.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'The demands of high-speed digital signal processing have pushed in the opposite direction—forcing instructions to be implemented in a particular way. For example, to perform digital filters fast enough, the MAC instruction in a typical digital signal processor (DSP) must use a kind of Harvard architecture that can fetch an instruction and two data words simultaneously, and it requires a single-cycle multiply–accumulate multiplier.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'We began our Turing Lecture June 4, 2018 11 with a review of computer architecture since the 1960s. In addition to that review, here, we highlight current challenges and identify future opportunities, projecting another golden age for the field of computer architecture in the next decade, much like the 1980s when we did the research that led to our award, delivering gains in cost, energy, and security, as well as performance.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Software talks to hardware through a vocabulary called an instruction set architecture (ISA). By the early 1960s, IBM had four incompatible lines of computers, each with its own ISA, software stack, I/O system, and market nichetargeting small business, large business, scientific, and real time, respectively. IBM engineers, including ACM A.M. Turing Award laureate Fred Brooks, Jr., thought they could create a single ISA that would efficiently unify all four of these ISA bases.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'The table here lists four models of the new System/360 ISA IBM announced April 7, 1964. The data paths vary by a factor of 8, memory capacity by a factor of 16, clock rate by nearly 4, performance by 50, and cost by nearly 6. The most expensive computers had the widest control stores because more complicated data paths used more control lines. The least-costly computers had narrower control stores due to simpler hardware but needed more microinstructions since they took more clock cycles to execute a System/360 instruction.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Facilitated by microprogramming, IBM bet the future of the company that the new ISA would revolutionize the computing industry and won the bet. IBM dominated its markets, and IBM mainframe descendants of the computer family announced 55 years ago still bring in $10 billion in revenue per year.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'As seen repeatedly, although the marketplace is an imperfect judge of technological issues, given the close ties between architecture and commercial computers, it eventually determines the success of architecture innovations that often require significant engineering investment.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Integrated circuits, CISC, 432, 8086, IBM PC. When computers began using integrated circuits, Moore's Law meant control stores could become much larger. Larger memories in turn allowed much more complicated ISAs. Consider that the control store of the VAX-11/780 from Digital Equipment Corp. in 1977 was 5,120 words x 96 bits, while its predecessor used only 256 words x 56 bits.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Some manufacturers chose to make microprogramming available by letting select customers add custom features they called \"writable control store\" (WCS). The most famous WCS computer was the Alto 36 Turing laureates Chuck Thacker and Butler Lampson, together with their colleagues, created for the Xerox Palo Alto Research Center in 1973. It was indeed the first personal computer, sporting the first bit-mapped display and first Ethernet local-area network. The device controllers for the novel display and network were microprograms stored in a 4,096-word x 32-bit WCS.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Microprocessors were still in the 8-bit era in the 1970s (such as the Intel 8080) and programmed primarily in assembly language. Rival designers would add novel instructions to outdo one another, showing their advantages through assembly language examples.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Gordon Moore believed Intel's next ISA would last the lifetime of Intel, so he hired many clever computer science Ph.D.'s and sent them to a new facility in Portland to invent the next great ISA. The 8800, as Intel originally named it, was an ambitious computer architecture project for any era, certainly the most aggressive of the 1980s. It had 32-bit capability-based addressing, object-oriented architecture, variable-bit-length instructions, and its own operating system written in the then-new programming language Ada.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'This ambitious project was alas several years late, forcing Intel to start an emergency replacement effort in Santa Clara to deliver a 16-bit microprocessor in 1979. Intel gave the new team 52 weeks to develop the new \"8086\" ISA and design and build the chip. Given the tight schedule, designing the ISA took only 10 person-weeks over three regular calendar weeks, essentially by extending the 8-bit registers and instruction set of the 8080 to 16 bits. The team completed the 8086 on schedule but to little fanfare when announced.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"To Intel's great fortune, IBM was developing a personal computer to compete with the Apple II and needed a 16-bit microprocessor. IBM was interested in the Motorola 68000, which had an ISA similar to the IBM 360, but it was behind IBM's aggressive schedule. IBM switched instead to an 8-bit bus version of the 8086. When IBM announced the PC on August 12, 1981, the hope was to sell 250,000 PCs by 1986. The company instead sold 100 million worldwide, bestowing a very bright future on the emergency replacement Intel ISA.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Intel's original 8800 project was renamed iAPX-432 and finally announced in 1981, but it required several chips and had severe performance problems. It was discontinued in 1986, the year after Intel extended the 16-bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits. Moore's prediction was thus correct that the next ISA would last as long as Intel did, but the marketplace chose the emergency replacement 8086 rather than the anointed 432. As the architects of the Motorola 68000 and iAPX-432 both learned, the marketplace is rarely patient.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'From complex to reduced instruction set computers. The early 1980s saw several investigations into complex instruction set computers (CISC) enabled by the big microprograms in the larger control stores. With Unix demonstrating that even operating systems could use high-level languages, the critical question became: \"What instructions would compilers generate?\" instead of \"What assembly language would programmers use?\" Significantly raising the hardware/software interface created an opportunity for architecture innovation.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"In today's post-PC era, x86 shipments have fallen almost 10% per year since the peak in 2011, while chips with RISC processors have skyrocketed to 20 billion.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'For example, Figure 1 shows the RISC-I 8 and MIPS 12 microprocessors developed at the University of California, Berkeley, and Stanford University in 1982 and 1983, respectively, that demonstrated the benefits of RISC. These chips were eventually presented at the leading circuit conference, the IEEE International Solid-State Circuits Conference, in 1984. 33, 35 It was a remarkable moment when a few graduate students at Berkeley and Stanford could build microprocessors that were arguably superior to what industry could build.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'These academic chips inspired many companies to build RISC microprocessors, which were the fastest for the next 15 years. The explanation is due to the following formula for processor performance:': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'DEC engineers later showed 2 that the more complicated CISC ISA executed about 75% of the number instructions per program as RISC (the first term), but in a similar technology CISC executed about five to six more clock cycles per instruction (the second term), making RISC microprocessors approximately 4x faster.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Such formulas were not part of computer architecture books in the 1980s, leading us to write Computer Architecture: A Quantitative Approach 13 in 1989. The subtitle suggested the theme of the book: Use measurements and benchmarks to evaluate trade-offs quantitatively instead of relying more on the architect's intuition and experience, as in the past. The quantitative approach we used was also inspired by what Turing laureate Donald Knuth's book had done for algorithms. 20\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'VLIW, EPIC, Itanium. The next ISA innovation was supposed to succeed both RISC and CISC. Very long instruction word (VLIW) 7 and its cousin, the explicitly parallel instruction computer (EPIC), the name Intel and Hewlett Packard gave to the approach, used wide instructions with multiple independent operations bundled together in each instruction. VLIW and EPIC advocates at the time believed if a single instruction could specify, say, six independent operationstwo data transfers, two integer operations, and two floating point operationsand compiler technology could efficiently assign operations into the six instruction slots, the hardware could be made simpler. Like the RISC approach, VLIW and EPIC shifted work from the hardware to the compiler.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'AMD and Intel used 500-person design teams and superior semiconductor technology to close the performance gap between x86 and RISC. Again inspired by the performance advantages of pipelining simple vs. complex instructions, the instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly. AMD and Intel then pipelined the execution of the RISC microinstructions. Any ideas RISC designers were using for performanceseparate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneouslycould then be incorporated into the x86. AMD and Intel shipped roughly 350 million x86 microprocessors annually at the peak of the PC era in 2011. The high volumes and low margins of the PC industry also meant lower prices than RISC computers.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Given the hundreds of millions of PCs sold worldwide each year, PC software became a giant market. Whereas software providers for the Unix marketplace would offer different software versions for the different commercial RISC ISAsAlpha, HP-PA, MIPS, Power, and SPARCthe PC market enjoyed a single ISA, so software developers shipped \"shrink wrap\" software that was binary compatible with only the x86 ISA. A much larger software base, similar performance, and lower prices led the x86 to dominate both desktop computers and small-server markets by 2000.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Apple helped launch the post-PC era with the iPhone in 2007. Instead of buying microprocessors, smartphone companies built their own systems on a chip (SoC) using designs from other companies, including RISC processors from ARM. Mobile-device designers valued die area and energy efficiency as much as performance, disadvantaging CISC ISAs. Moreover, arrival of the Internet of Things vastly increased both the number of processors and the required trade-offs in die size, power, cost, and performance. This trend increased the importance of design time and cost, further disadvantaging CISC processors. In today's post-PC era, x86 shipments have fallen almost 10% per year since the peak in 2011, while chips with RISC processors have skyrocketed to 20 billion. Today, 99% of 32-bit and 64-bit processors are RISC.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Concluding this historical review, we can say the marketplace settled the RISC-CISC debate; CISC won the later stages of the PC era, but RISC is winning the post-PC era. There have been no new CISC ISAs in decades. To our surprise, the consensus on the best ISA principles for general-purpose processors today is still RISC, 35 years after their introduction.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '\"If a problem has no solution, it may not be a problem, but a factnot to be solved, but to be coped with over time.\" Shimon Peres': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Although Moore's Law held for many decades (see Figure 2), it began to slow sometime around 2000 and by 2018 showed a roughly 15-fold gap between Moore's prediction and current capability, an observation Moore made in 2003 that was inevitable. 27 The current expectation is that the gap will continue to grow as CMOS technology approaches fundamental limits.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Accompanying Moore\\'s Law was a projection made by Robert Dennard called \"Dennard scaling,\" 5 stating that as transistor density increased, power consumption per transistor would drop, so the power per mm 2 of silicon would be near constant. Since the computational capability of a mm 2 of silicon was increasing with each new generation of technology, computers would become more energy efficient. Dennard scaling began to slow significantly in 2007 and faded to almost nothing by 2012 (see Figure 3).': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Between 1986 and about 2002, the exploitation of instruction level parallelism (ILP) was the primary architectural method for gaining performance and, along with improvements in speed of transistors, led to an annual performance increase of approximately 50%. The end of Dennard scaling meant architects had to find more efficient ways to exploit parallelism.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'To see how challenging such a design is, consider the difficulty of correctly predicting the outcome of 15 branches. If a processor architect wants to limit wasted work to only 10% of the time, the processor must predict each branch correctly 99.3% of the time. Few general-purpose programs have branches that can be predicted so accurately.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'To appreciate how this wasted work adds up, consider the data in Figure 4, showing the fraction of instructions that are effectively executed but turn out to be wasted because the processor speculated incorrectly. On average, 19% of the instructions are wasted for these benchmarks on an Intel Core i7. The amount of wasted energy is greater, however, since the processor must use additional energy to restore the state when it speculates incorrectly. Measurements like these led many to conclude architects needed a different approach to achieve performance improvements. The multicore era was thus born.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Real programs have more complex structures of course, with portions that allow varying numbers of processors to be used at any given moment in time. Nonetheless, the need to communicate and synchronize periodically means most applications have some portions that can effectively use only a fraction of the processors. Although Amdahl's Law is more than 50 years old, it remains a difficult hurdle.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"An era without Dennard scaling, along with reduced Moore's Law and Amdahl's Law in full effect means inefficiency limits improvement in performance to only a few percent per year (see Figure 6). Achieving higher rates of performance improvementas was seen in the 1980s and 1990swill require new architectural approaches that use the integrated-circuit capability much more efficiently. We will return to what approaches might work after discussing another major shortcoming of modern computerstheir support, or lack thereof, for computer security.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Inherent inefficiencies in general-purpose processors, whether from ILP techniques or multicore, combined with the end of Dennard scaling and Moore's Law, make it highly unlikely, in our view, that processor architects and designers can sustain significant rates of performance improvements in general-purpose processors. Given the importance of improving performance to enable new software capabilities, we must ask: What other approaches might be promising?\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'An interesting research direction concerns whether some of the performance gap can be closed with new compiler technology, possibly assisted by architectural enhancements. Although the challenges in efficiently translating and implementing high-level scripting languages like Python are difficult, the potential gain is enormous. Achieving even 25% of the potential gain could result in Python programs running tens to hundreds of times faster. This simple example illustrates how great the gap is between modern languages emphasizing programmer productivity and traditional approaches emphasizing performance.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Second, DSAs can make more effective use of the memory hierarchy. Memory accesses have become much more costly than arithmetic computations, as noted by Horowitz. 16 For example, accessing a block in a 32-kilobyte cache involves an energy cost approximately 200x higher than a 32-bit integer add. This enormous differential makes optimizing memory accesses critical to achieving high-energy efficiency. General-purpose processors run code in which memory accesses typically exhibit spatial and temporal locality but are otherwise not very predictable at compile time. CPUs thus use multilevel caches to increase bandwidth and hide the latency in relatively slow, off-chip DRAMs. These multilevel caches often consume approximately half the energy of the processor but avoid almost all accesses to the off-chip DRAMs that require approximately 10x the energy of a last-level cache access.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'When caches work well. When caches work well, the locality is very high, meaning, by definition, most of the cache is idle most of the time.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'In applications where the memory-access patterns are well defined and discoverable at compile time, which is true of typical DSLs, programmers and compilers can optimize the use of the memory better than can dynamically allocated caches. DSAs thus usually use a hierarchy of memories with movement controlled explicitly by the software, similar to how vector processors operate. For suitable applications, user-controlled memories can use much less energy than caches.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Third, DSAs can use less precision when it is adequate. General-purpose CPUs usually support 32- and 64-bit integer and floating-point (FP) data. For many applications in machine learning and graphics, this is more accuracy than is needed. For example, in deep neural networks (DNNs), inference regularly uses 4-, 8-, or 16-bit integers, improving both data and computational throughput. Likewise, for DNN training applications, FP is useful, but 32 bits is enough and 16 bits often works.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Finally, DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'DSAs require targeting of high-level operations to the architecture, but trying to extract such structure and information from a general-purpose language like Python, Java, C, or Fortran is simply too difficult. Domain specific languages (DSLs) enable this process and make it possible to program DSAs efficiently. For example, DSLs can make vector, dense matrix, and sparse matrix operations explicit, enabling the DSL compiler to map the operations to the processor efficiently. Examples of DSLs include Matlab, a language for operating on matrices, TensorFlow, a dataflow language used for programming DNNs, P4, a language for programming SDNs, and Halide, a language for image processing specifying high-level transformations.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'The challenge when using DSLs is how to retain enough architecture independence that software written in a DSL can be ported to different architectures while also achieving high efficiency in mapping the software to the underlying DSA. For example, the XLA system translates Tensorflow to heterogeneous processors that use Nvidia GPUs or Tensor Processor Units (TPUs). 40 Balancing portability among DSAs along with efficiency is an interesting research challenge for language designers, compiler creators, and DSA architects.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Example DSA TPU v1. As an example DSA, consider the Google TPU v1, which was designed to accelerate neural net inference. 17, 18 The TPU has been in production since 2015 and powers applications ranging from search queries to language translation to image recognition to AlphaGo and AlphaZero, the DeepMind programs for playing Go and Chess. The goal was to improve the performance and energy efficiency of deep neural net inference by a factor of 10.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'CPUs. Intel offers CPUs with many cores enhanced by large multi-level caches and one-dimensional SIMD instructions, the kind of FPGAs used by Microsoft, and a new neural network processor that is closer to a TPU than to a CPU. 19': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'In addition to these large players, dozens of startups are pursuing their own proposals. 25 To meet growing demand, architects are interconnecting hundreds to thousands of such chips to form neural-network supercomputers.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'This avalanche of DNN architectures makes for interesting times in computer architecture. It is difficult to predict in 2019 which (or even if any) of these many directions will win, but the marketplace will surely settle the competition just as it settled the architectural debates of the past.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Inspired by the success of open source software, the second opportunity in computer architecture is open ISAs. To create a \"Linux for processors\" the field needs industry-standard open ISAs so the community can create open source cores, in addition to individual companies owning proprietary ones. If many organizations design processors using the same ISA, the greater competition may drive even quicker innovation. The goal is to provide processors for chips that cost from a few cents to $100.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'The first example is RISC-V (called \"RISC Five\"), the fifth RISC architecture developed at the University of California, Berkeley. 32 RISC-V\\'s has a community that maintains the architecture under the stewardship of the RISC-V Foundation (http://riscv.org/). Being open allows the ISA evolution to occur in public, with hardware and software experts collaborating before decisions are finalized. An added benefit of an open foundation is the ISA is unlikely to expand primarily for marketing reasons, sometimes the only explanation for extensions of proprietary instruction sets.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'RISC-V is a modular instruction set. A small base of instructions run the full open source software stack, followed by optional standard extensions designers can include or omit depending on their needs. This base includes 32-bit address and 64-bit address versions. RISC-V can grow only through optional extensions; the software stack still runs fine even if architects do not embrace new extensions. Proprietary architectures generally require upward binary compatibility, meaning when a processor company adds new feature, all future processors must also include it. Not so for RISC-V, whereby all enhancements are optional and can be deleted if not needed by an application. Here are the standard extensions so far, using initials that stand for their full names:': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'A third distinguishing feature of RISC-V is the simplicity of the ISA. While not readily quantifiable, here are two comparisons to the ARMv8 architecture, as developed by the ARM company contemporaneously:': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Fewer instructions. RISC-V has many fewer instructions. There are 50 in the base that are surprisingly similar in number and nature to the original RISC-I. 30 The remaining standard extensionsM, A, F, and Dadd 53 instructions, plus C added another 34, totaling 137. ARMv8 has more than 500; and': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Simplicity reduces the effort to both design processors and verify hardware correctness. As the RISC-V targets range from data-center chips to IoT devices, design verification can be a significant part of the cost of development.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Fourth, RISC-V is a clean-slate design, starting 25 years later, letting its architects learn from mistakes of its predecessors. Unlike first-generation RISC architectures, it avoids microarchitecture or technology-dependent features (such as delayed branches and delayed loads) or innovations (such as register windows) that were superseded by advances in compiler technology.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Beyond RISC-V, Nvidia also announced (in 2017) a free and open architecture 29 it calls Nvidia Deep Learning Accelerator (NVDLA), a scalable, configurable DSA for machine-learning inference. Configuration options include data type (int8, int16, or fp16 ) and the size of the two-dimensional multiply matrix. Die size scales from 0.5 mm 2 to 3 mm 2 and power from 20 milliWatts to 300 milliWatts. The ISA, software stack, and implementation are all open.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'The Manifesto for Agile Software Development (2001) by Beck et al. 1 revolutionized software development, overcoming the frequent failure of the traditional elaborate planning and documentation in waterfall development. Small programming teams quickly developed working-but-incomplete prototypes and got customer feedback before starting the next iteration. The scrum version of agile development assembles teams of five to 10 programmers doing sprints of two to four weeks per iteration.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Once again inspired by a software success, the third opportunity is agile hardware development. The good news for architects is that modern electronic computer aided design (ECAD) tools raise the level of abstraction, enabling agile development, and this higher level of abstraction increases reuse across designs.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'For research purposes, we could stop at tape in, as area, energy, and performance estimates are highly accurate. However, it would be like running a long race and stopping 100 yards before the finish line because the runner can accurately predict the final time. Despite all the hard work in race preparation, the runner would miss the thrill and satisfaction of actually crossing the finish line. One advantage hardware engineers have over software engineers is they build physical things. Getting chips back to measure, run real programs, and show to their friends and family is a great joy of hardware design.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Many researchers assume they must stop short because fabricating chips is unaffordable. When designs are small, they are surprisingly inexpensive. Architects can order 100 1-mm 2 chips for only $14,000. In 28 nm, 1 mm 2 holds millions of transistors, enough area for both a RISC-V processor and an NVLDA accelerator. The outermost level is expensive if the designer aims to build a large chip, but an architect can demonstrate many novel ideas with small chips.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'To benefit from the lessons of history, architects must appreciate that software innovations can also inspire architects, that raising the abstraction level of the hardware/software interface yields opportunities for innovation, and that the marketplace ultimately settles computer architecture debates. The iAPX-432 and Itanium illustrate how architecture investment can exceed returns, while the S/360, 8086, and ARM deliver high annual returns lasting decades with no end in sight.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"The end of Dennard scaling and Moore's Law and the deceleration of performance gains for standard microprocessors are not problems that must be solved but facts that, recognized, offer breathtaking opportunities. High-level, domain-specific languages and architectures, freeing architects from the chains of proprietary instruction sets, along with demand from the public for improved security, will usher in a new golden age for computer architects. Aided by open source ecosystems, agilely developed chips will convincingly demonstrate advances and thereby accelerate commercial adoption. The ISA philosophy of the general-purpose processors in these chips will likely be RISC, which has stood the test of time. Expect the same rapid improvement as in the last golden age, but this time in terms of cost, energy, and security, as well as in performance.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '1. Beck, K., Beedle, M., Van Bennekum, A., Cockburn, A., Cunningham, W., Fowler, M. ... and Kern, J. Manifesto for Agile Software Development, 2001; https://agilemanifesto.org/': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '2. Bhandarkar, D. and Clark, D.W. Performance from architecture: Comparing a RISC and a CISC with similar hardware organization. In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (Santa Clara, CA, Apr. 811). ACM Press, New York, 1991, 310319.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '4. Dally, W. et al. Hardware-enabled artificial intelligence. In Proceedings of the Symposia on VLSI Technology and Circuits (Honolulu, HI, June 1822). IEEE Press, 2018, 36.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '5. Dennard, R. et al. Design of ion-implanted MOSFETs with very small physical dimensions. IEEE Journal of Solid State Circuits 9, 5 (Oct. 1974), 256268.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '6. Emer, J. and Clark, D. A characterization of processor performance in the VAX-11/780. In Proceedings of the 11 th International Symposium on Computer Architecture (Ann Arbor, MI, June). ACM Press, New York, 1984, 301310.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '8. Fitzpatrick, D.T., Foderaro, J.K., Katevenis, M.G., Landman, H.A., Patterson, D.A., Peek, J.B., Peshkess, Z., Séquin, C.H., Sherburne, R.W., and Van Dyke, K.S. A RISCy approach to VLSI. ACM SIGARCH Computer Architecture News 10, 1 (Jan. 1982), 2832.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '10. Fowers, J. et al. A configurable cloud-scale DNN processor for real-time AI. In Proceedings of the 45 th ACM/IEEE Annual International Symposium on Computer Architecture (Los Angeles, CA, June 26). IEEE, 2018, 114.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '11. Hennessy, J. and Patterson, D. A New Golden Age for Computer Architecture. Turing Lecture delivered at the 45 th ACM/IEEE Annual International Symposium on Computer Architecture (Los Angeles, CA, June 4, 2018); http://iscaconf.org/isca2018/turing_lecture.html; https://www.youtube.com/watch?v=3LVeEjsn8Ts': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '12. Hennessy, J., Jouppi, N., Przybylski, S., Rowen, C., Gross, T., Baskett, F., and Gill, J. MIPS: A microprocessor architecture. ACM SIGMICRO Newsletter 13, 4 (Oct. 5, 1982), 1722.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '14. Hill, M. A primer on the meltdown and Spectre hardware security design flaws and their important implications, Computer Architecture Today blog (Feb. 15, 2018); https://www.sigarch.org/a-primer-on-the-meltdown-spectre-hardware-security-design-flaws-and-their-important-implications/': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '15. Hopkins, M. A critical look at IA-64: Massive resources, massive ILP, but can it deliver? Microprocessor Report 14, 2 (Feb. 7, 2000), 15.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"16. Horowitz M. Computing's energy problem (and what we can do about it). In Proceedings of the IEEE International Solid-State Circuits Conference Digest of Technical Papers (San Francisco, CA, Feb. 913). IEEE Press, 2014, 1014.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '17. Jouppi, N., Young, C., Patil, N., and Patterson, D. A domain-specific architecture for deep neural networks. Commun. ACM 61, 9 (Sept. 2018), 5058.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '18. Jouppi, N.P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R., Bates, S., Bhatia, S., Boden, N., Borchers, A., and Boyle, R. In-datacenter performance analysis of a tensor processing unit. In Proceedings of the 44 th ACM/IEEE Annual International Symposium on Computer Architecture (Toronto, ON, Canada, June 2428). IEEE Computer Society, 2017, 112.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '22. Kung, H. and Leiserson, C. Systolic arrays (for VLSI). Chapter in Sparse Matrix Proceedings Vol. 1. Society for Industrial and Applied Mathematics, Philadelphia, PA, 1979, 256282.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '23. Lee, Y., Waterman, A., Cook, H., Zimmer, B., Keller, B., Puggelli, A. ... and Chiu, P. An agile approach to building RISC-V microprocessors. IEEE Micro 36, 2 (Feb. 2016), 820.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '25. Metz, C. Big bets on A.I. open a new frontier for chip start-ups, too. The New York Times (Jan. 14, 2018).': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"27. Moore, G. No exponential is forever: But 'forever' can be delayed! . In Proceedings of the IEEE International Solid-State Circuits Conference Digest of Technical Papers (San Francisco, CA, Feb. 13). IEEE, 2003, 2023.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '28. Moore, G. Progress in digital integrated electronics. In Proceedings of the International Electronic Devices Meeting (Washington, D.C., Dec.). IEEE, New York, 1975, 1113.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '33. Rowen, C., Przbylski, S., Jouppi, N., Gross, T., Shott, J., and Hennessy, J. A pipelined 32b NMOS microprocessor. In Proceedings of the IEEE International Solid-State Circuits Conference Digest of Technical Papers (San Francisco, CA, Feb. 2224) IEEE, 1984, 180181.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '34. Schwarz, M., Schwarzl, M., Lipp, M., and Gruss, D. Netspectre: Read arbitrary memory over network. arXiv preprint, 2018; https://arxiv.org/pdf/1807.10535.pdf': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '35. Sherburne, R., Katevenis, M., Patterson, D., and Sequin, C. A 32b NMOS microprocessor with a large register file. In Proceedings of the IEEE International Solid-State Circuits Conference (San Francisco, CA, Feb. 2224). IEEE Press, 1984, 168169.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '36. Thacker, C., MacCreight, E., and Lampson, B. Alto: A Personal Computer. CSL-79-11, Xerox Palo Alto Research Center, Palo Alto, CA, Aug. 7,1979; http://people.scs.carleton.ca/~soma/distos/fall2008/alto.pdf': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"37. Turner, P., Parseghian, P., and Linton, M. Protecting against the new 'L1TF' speculative vulnerabilities. Google blog, Aug. 14, 2018; https://cloud.google.com/blog/products/gcp/protectingagainst-the-new-l1tf-speculative-vulnerabilities\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '38. Van Bulck, J. et al. Foreshadow: Extracting the keys to the Intel SGX kingdom with transient out-of-order execution. In Proceedings of the 27 th USENIX Security Symposium (Baltimore, MD, Aug. 1517). USENIX Association, Berkeley, CA, 2018.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '39. Wilkes, M. and Stringer, J. Micro-programming and the design of the control circuits in an electronic digital computer. Mathematical Proceedings of the Cambridge Philosophical Society 49, 2 (Apr. 1953), 230238.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'John L. Hennessy (hennnessy@stanford.edu) is Past-President of Stanford University, Stanford, CA, USA, and is Chairman of Alphabet Inc., Mountain View, CA, USA.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'David A. Patterson (pattrsn@berkeley.edu) is the Pardee Professor of Computer Science, Emeritus at the University of California, Berkeley, CA, USA, and a Distinguished Engineer at Google, Mountain View, CA, USA.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and full citation on the first page. Copyright for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or fee. Request permission to publish from permissions@acm.org or fax (212) 869-0481.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'For those who want the fastest possible simulation, and do not care about any form of datapath visualization, there should be an option to select an ISA simulator processor model.': 'https://github.com/topics/computer-architecture',\n",
       " 'A list of time-lasting classic books, which could not only help you figure out how it works, but also grasp when it works and why it works in that way.': 'https://github.com/topics/computer-architecture',\n",
       " 'Using HDL, from Boolean algebra and elementary logic gates to building a Central Processing Unit, a memory system, and a hardware platform, leading up to a 16-bit general-purpose computer. Then, implementing the modern software hierarchy designed to enable the translation and execution of object-based, high-level languages on a bare-bone computer hardware platform; Including Virtual machine,Compiler and Operating system.': 'https://github.com/topics/computer-architecture',\n",
       " 'A collection of curated resources for learning Computer Science subjects and skills, that I garnered throughout my tenure as a CSE student. Contributions, and report of broken links are welcome.': 'https://github.com/topics/computer-architecture',\n",
       " '通过issue和README来记录日常学习研究笔记 关注 机器学习系统，深度学习， LLVM，性能剖视， Linux操作系统内核 话题 关注 C/C++. JAVA. Python. Golang. Chisel. 编程语言话题 ( Writing Blogs using github issue and markdown! (inculding Machine Learning algs and system, LLVM, Linux kernel, java, python, c++, golang)': 'https://github.com/topics/computer-architecture',\n",
       " 'Earlier, computer architects designed computer architecture on paper. It was then directly built into a final hardware form. Later, they assembled computer architecture designs materially in the form of transistor-transistor logic (TTL) computers. By the 1990s, new computer architectures are typically built, examined, and tweaked inside another computer architecture, in a computer architecture simulator, or the interior part of an FPGA, as a microprocessor before perpetrating to the ultimate hardware form.': 'https://www.w3schools.in/computer-fundamentals/types-of-computer-architecture',\n",
       " 'It enables versatile implementations of an ISA; commonly differ in features such as performance, physical size, and monetary price. It empowers the evolution of the micro-architectures, implementing ISA as an exclusive, higher-performance system that can run software on preceding generations of execution.': 'https://www.w3schools.in/computer-fundamentals/types-of-computer-architecture',\n",
       " 'Simply, it is a logical form of all electronic elements and data pathways present in the microprocessor, designed in a specific way. It allows for the optimal completion of instructions. In academe, it is called computer organization. System Design System design itself defines a design that can serve user requirements like system architecture, computer modules having various interfaces, and data management within a system. The term product development is connective to the system design. It is the process by which we can take marketing information to create a product design. report this ad': 'https://www.w3schools.in/computer-fundamentals/types-of-computer-architecture',\n",
       " 'System design itself defines a design that can serve user requirements like system architecture, computer modules having various interfaces, and data management within a system. The term product development is connective to the system design. It is the process by which we can take marketing information to create a product design. report this ad': 'https://www.w3schools.in/computer-fundamentals/types-of-computer-architecture'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f40d817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "link_2_title = {}\n",
    "\n",
    "raw_dataset = defaultdict(str)\n",
    "\n",
    "for result in results:\n",
    "    temp_dataset = ''\n",
    "    paragraphs = []\n",
    "    temp_cleaned_para = []\n",
    "    try:\n",
    "        page = requests.get(result, timeout=(5, 10), headers=headers)\n",
    "    except:\n",
    "        continue\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    p = soup.find_all('p')\n",
    "    title = str(soup.find('title'))\n",
    "    link_2_title[result] = html_text.extract_text(title)\n",
    "    \n",
    "    for x in p:\n",
    "        paragraphs.append(str(x))\n",
    "    for i, para in enumerate(paragraphs):\n",
    "        if para != '':\n",
    "            temp_cleaned_para.append(html_text.extract_text(para, guess_layout=False))\n",
    "\n",
    "    for i, para in enumerate(temp_cleaned_para):\n",
    "        if len(nltk.word_tokenize(para)) > 30 and len(nltk.word_tokenize(para)) < 150:\n",
    "            para = re.sub('[\\[].*?[\\]]', '', para)\n",
    "            cleaned_para.append(para)\n",
    "            temp_dataset += para\n",
    "            \n",
    "    raw_dataset[result] = temp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3ef9d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://en.wikipedia.org/wiki/Category:Computer_architecture': 'Category:Computer architecture - Wikipedia',\n",
       " 'https://www.computersciencedegreehub.com/faq/what-is-computer-architecture/': 'What is Computer Architecture? - Computer Science Degree Hub',\n",
       " 'https://online.sunderland.ac.uk/what-is-computer-architecture/': 'What is computer architecture? - University of Sunderland',\n",
       " 'https://geteducationskills.com/computer-architecture/': 'What Is Computer Architecture? – Get Education',\n",
       " 'https://www.techopedia.com/definition/26757/computer-architecture': 'What is Computer Architecture? - Definition from Techopedia',\n",
       " 'https://en.wikipedia.org/wiki/Microarchitecture': 'Microarchitecture - Wikipedia',\n",
       " 'https://www.britannica.com/technology/computer-architecture': 'computer architecture | Definition & Facts | Britannica',\n",
       " 'https://www.sciencedirect.com/topics/computer-science/computer-architecture': 'Just a moment...',\n",
       " 'https://en.wikipedia.org/wiki/Word_(computer_architecture)': 'Word (computer architecture) - Wikipedia',\n",
       " 'https://www.educba.com/types-of-computer-architecture/': 'Types of Computer Architecture | 5 Useful Types of Computer Architecture',\n",
       " 'https://en.wikipedia.org/wiki/Computer_architecture': 'Computer architecture - Wikipedia',\n",
       " 'https://www.tutorialspoint.com/what-is-computer-architecture': 'What is computer architecture?',\n",
       " 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/': 'A Brief and Biased History of Computer Architecture (Part 1) | SIGARCH',\n",
       " 'https://dl.acm.org/doi/10.1109/MAHC.1988.10039': 'A Historical Overview of Computer Architecture | IEEE Annals of the History of Computing',\n",
       " 'https://www.computer.org/csdl/magazine/an/1988/04/man1988040277/13rRUxZRbrm': 'CSDL | IEEE Computer Society',\n",
       " 'https://edurev.in/studytube/A-Brief-History-of-Computer-Architecture-Computer-/987e1c94-0ef4-4ebd-b172-277f3deb72c1_t': 'A Brief History of Computer Architecture Notes - Computer Science Engineering (CSE)',\n",
       " 'https://www.researchgate.net/publication/329191354_Lecture_Notes_on_Computer_Architecture': 'Please Wait... | Cloudflare',\n",
       " 'https://www.geeksforgeeks.org/last-minute-notes-computer-organization/': 'Last Minute Notes Computer Organization - GeeksforGeeks',\n",
       " 'http://www.cs.iit.edu/~virgil/cs470/Book/': 'Computer Architecture - Class notes',\n",
       " 'https://ocw.mit.edu/courses/6-823-computer-system-architecture-fall-2005/pages/lecture-notes': 'Lecture Notes | Computer System Architecture | Electrical Engineering and Computer Science | MIT OpenCourseWare',\n",
       " 'http://www.eecs.harvard.edu/~dbrooks/cs146-spring2004/': 'CS 146: Computer Architecture',\n",
       " 'https://www.studocu.com/row/document/mount-kenya-university/computer-architecture/bit-1101-computer-architecture-complete-lecture-notes-for-first-years-and-all/18977220': 'BIT 1101 Computer Architecture complete lecture notes for first years and all - P. Box 342-01000 - StuDocu',\n",
       " 'https://www.quora.com/What-is-the-best-source-and-method-to-study-computer-architecture': 'What is the best source and method to study computer architecture? - Quora',\n",
       " 'https://www.quora.com/What-is-the-best-way-to-learn-computer-organization-and-architecture': 'What is the best way to learn computer organization and architecture? - Quora',\n",
       " 'https://www.quora.com/What-is-the-best-way-and-source-to-learn-computer-architecture': 'What is the best way and source to learn computer architecture? - Quora',\n",
       " 'https://www.sigarch.org/call-contributions/first-workshop-on-open-source-computer-architecture-research-oscar/': 'First Workshop on Open-Source Computer Architecture Research (OSCAR) | SIGARCH',\n",
       " 'https://en.wikipedia.org/wiki/Instruction_set_architecture': 'Instruction set architecture - Wikipedia',\n",
       " 'https://www.quora.com/What-is-the-best-way-and-source-to-learn-computer-architecture?top_ans=47987712': 'What is the best way and source to learn computer architecture? - Quora',\n",
       " 'https://www.quora.com/What-are-some-of-the-currently-hot-research-areas-in-computer-architecture': 'What are some of the currently hot research areas in computer architecture? - Quora',\n",
       " 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext': 'A New Golden Age for Computer Architecture | February 2019 | Communications of the ACM',\n",
       " 'https://www.researchgate.net/figure/Computer-Architecture-Source_fig10_297766967': 'Please Wait... | Cloudflare',\n",
       " 'https://github.com/topics/computer-architecture': 'computer-architecture · GitHub Topics · GitHub',\n",
       " 'https://www.w3schools.in/computer-fundamentals/types-of-computer-architecture': 'Types of Computer Architecture - Computer Fundamentals',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-system-architecture': 'What are the types of computer system architecture? - Quora',\n",
       " 'https://www.quora.com/What-are-other-types-of-computer-system-architecture-apart-from-Von-Neumann': 'What are other types of computer system architecture apart from Von Neumann? - Quora',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-system-architecture?top_ans=20669228': 'What are the types of computer system architecture? - Quora',\n",
       " 'https://www.researchgate.net/publication/241056162_Types_of_Computer_Architectures': 'Please Wait... | Cloudflare',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-architectures-in-a-CPU': 'What are the types of computer architectures in a CPU? - Quora',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-architecture-and-organisations': 'What are the types of computer architecture and organisations? - Quora'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_2_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3049524",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"/Users/arpan/Documents/FORWARD_LAB\"\n",
    "word_embeddings = {}\n",
    "f = open(join(mypath, 'glove.6B.300d.txt'), encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e966a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_vectors = []\n",
    "webside_embeddings = {}\n",
    "for key, val in raw_dataset.items():\n",
    "    if len(val) != 0:\n",
    "        v = sum([word_embeddings.get(w, np.zeros((300,))) for w in val.split()])/(len(val.split())+0.001)\n",
    "    else:\n",
    "        v = np.zeros((300,))\n",
    "    webside_embeddings[key] = v\n",
    "    website_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebfb12a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(website_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fdbcf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = np.zeros([len(website_vectors), len(website_vectors)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98eae614",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(website_vectors)):\n",
    "    for j in range(len(website_vectors)):\n",
    "        if i != j:\n",
    "            sim_mat[i][j] = cosine_similarity\\\n",
    "            (website_vectors[i].reshape(1,300), \\\n",
    "             website_vectors[j].reshape(1,300))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f12a1b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.98459789, ..., 0.90930794, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.98459789, 0.        , ..., 0.91273369, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.90930794, 0.91273369, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e0f9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e576156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(raw_dataset.keys())), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9b1e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_para = list(set(cleaned_para))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bbb209f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd27063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = []\n",
    "for i in cleaned_para:\n",
    "    if len(i) != 0:\n",
    "        v = sum([word_embeddings.get(w, np.zeros((300,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "    else:\n",
    "        v = np.zeros((300,))\n",
    "    sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "713948b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = np.zeros([len(cleaned_para), len(cleaned_para)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90dc95db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cleaned_para)):\n",
    "    for j in range(len(cleaned_para)):\n",
    "        if i != j:\n",
    "            sim_mat[i][j] = cosine_similarity\\\n",
    "            (sentence_vectors[i].reshape(1,300), \\\n",
    "             sentence_vectors[j].reshape(1,300))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6757000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b96357cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(cleaned_para)), reverse=True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea022b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = []\n",
    "for sent in cleaned_para:\n",
    "    for _, sentence in ranked_sentences:\n",
    "        if sent == sentence:\n",
    "            paragraphs.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb8d7d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97019712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Electrically Erasable Programmable ROM (EEPROM): The next level of erasability is the EEPROM, which can be erased under software control. This is the most flexible type of ROM, and is now commonly used for holding BIOS programs. When you hear reference to a \"flash BIOS\" or doing a BIOS upgrade by \"flashing\", this refers to reprogramming the BIOS EEPROM with a special software program. Here we are blurring the line a bit between what \"read-only\" really means, but remember that this rewriting is done maybe once a year or so,',\n",
       " 'Different amounts of memory are used to store data values with different degrees of precision. The commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word). Converting the index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. In some cases this relationship can also avoid the use of division operations. As a result, most modern computer designs have word sizes (and other operand sizes) that are a power of two times the size of a byte.',\n",
       " 'An ISA specifies the behavior of machine code running on implementations of that ISA in a fashion that does not depend on the characteristics of that implementation, providing binary compatibility between implementations. This enables multiple implementations of an ISA that differ in characteristics such as performance, physical size, and monetary cost (among other things), but that are capable of running the same machine code, so that a lower-performance, lower-cost machine can be replaced with a higher-cost, higher-performance machine without having to replace software. It also enables the evolution of the microarchitectures of the implementations of that ISA, so that a newer, higher-performance implementation of an ISA can run software that runs on previous generations of implementations.',\n",
       " 'Programmable ROM (PROM): This is a type of ROM that can be programmed using special equipment (a PROM programmer.); it can be written to, but only once. This is useful for companies that make their own ROMs from software they write, because when they change their code they can create new PROMs without requiring expensive equipment. This is similar to the way a CD-ROM recorder works by letting you \"burn\" programs onto blanks once and then letting you read from them many times. In fact, programming a PROM is also called burning, just like burning a CD-R, and it is comparable in terms of its flexibility.',\n",
       " 'Pipelining improves performance by allowing a number of instructions to work their way through the processor at the same time. In the same basic example, the processor would start to decode (step 1) a new instruction while the last one was waiting for results. This would allow up to four instructions to be \"in flight\" at one time, making the processor look four times as fast. Although any one instruction takes just as long to complete (there are still four steps) the CPU as a whole \"retires\" instructions much faster.',\n",
       " 'When byte processing is to be a significant part of the workload, it is usually more advantageous to use the byte, rather than the word, as the unit of address resolution. Address values which differ by one designate adjacent bytes in memory. This allows an arbitrary character within a character string to be addressed straightforwardly. A word can still be addressed, but the address to be used requires a few more bits than the word-resolution alternative. The word size needs to be an integer multiple of the character size in this organization. This addressing approach was used in the IBM 360, and has been the most common approach in machines designed since then.',\n",
       " 'The memory model of an architecture is strongly influenced by the word size. In particular, the resolution of a memory address, that is, the smallest unit that can be designated by an address, has often been chosen to be the word. In this approach, the word-addressable machine approach, address values which differ by one designate adjacent memory words. This is natural in machines which deal almost always in word (or multiple-word) units, and has the advantage of allowing instructions to use minimally sized fields to contain addresses, which can permit a smaller instruction size or a larger variety of instructions.',\n",
       " 'Computer architecture is the organisation of the components which make up a computer system and the meaning of the operations which guide its function. It defines what is seen on the machine interface, which is targeted by programming languages and their compilers.',\n",
       " 'However, the choice of instruction set architecture may greatly affect the complexity of implementing high-performance devices. The prominent strategy, used to develop the first RISC processors, was to simplify instructions to a minimum of individual semantic complexity combined with high encoding regularity and simplicity. Such uniform instructions were easily fetched, decoded and executed in a pipelined fashion and a simple strategy to reduce the number of logic levels in order to reach high operating frequencies; instruction cache-memories compensated for the higher operating frequency and inherently low code density while large register sets were used to factor out as much of the (slow) memory accesses as possible.',\n",
       " 'This is a guide to Types of Computer Architecture. Here we discuss the basic concept and different types of computer architecture in detail. You may also have a look at the following articles to learn more –',\n",
       " 'The size of a word is reflected in many aspects of a computer\\'s structure and operation; the majority of the registers in a processor are usually word sized and the largest datum that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. The largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used).',\n",
       " 'Pipelines are by no means limited to RISC designs. By 1986 the top-of-the-line VAX implementation (VAX 8800) was a heavily pipelined design, slightly predating the first commercial MIPS and SPARC designs. Most modern CPUs (even embedded CPUs) are now pipelined, and microcoded CPUs with no pipelining are seen only in the most area-constrained embedded processors.  Large CISC machines, from the VAX 8800 to the modern Pentium 4 and Athlon, are implemented with both microcode and pipelines. Improvements in pipelining and caching are the two major microarchitectural advances that have enabled processor performance to keep pace with the circuit technology on which they are based.',\n",
       " 'We have learned about computer architecture and its types. How functionality, implementation works in processing. Instruction set architecture is needed to do the needful instruction execution and data processing should be done in a different and single memory location in different types of computer architectures. Read/write operations are performed.',\n",
       " 'In applications where the memory-access patterns are well defined and discoverable at compile time, which is true of typical DSLs, programmers and compilers can optimize the use of the memory better than can dynamically allocated caches. DSAs thus usually use a hierarchy of memories with movement controlled explicitly by the software, similar to how vector processors operate. For suitable applications, user-controlled memories can use much less energy than caches.',\n",
       " 'The earliest computer architectures were designed on paper and then directly built into the final hardware form.  Later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (TTL) computer—such as the prototypes of the 6800 and the PA-RISC —tested, and tweaked, before committing to the final hardware form. As of the 1990s, new computer architectures are typically \"built\", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a FPGA as a soft microprocessor; or both—before committing to the final hardware form. ',\n",
       " 'Many researchers assume they must stop short because fabricating chips is unaffordable. When designs are small, they are surprisingly inexpensive. Architects can order 100 1-mm 2 chips for only $14,000. In 28 nm, 1 mm 2 holds millions of transistors, enough area for both a RISC-V processor and an NVLDA accelerator. The outermost level is expensive if the designer aims to build a large chip, but an architect can demonstrate many novel ideas with small chips.',\n",
       " 'They are very large in size and use multiple processors and superior technology. Super computers are biggest in size, the most expensive in price than any other is classified and known as super computer. It can process trillions of instructions in seconds. This computer is not used as a PC in a home neither by a student in a college. Governments specially use this type of computer for their different calculations and heavy jobs. Different industries also use this huge computer for designing their products.',\n",
       " \"\\uf0b7 Microarchitecture, also known as Computer organization is a lower level, more concrete and detailed, description of the system that involves how the constituent parts of the system are interconnected and how they interoperate in order to implement the ISA. The size of a computer's cache for instance, is an organizational issue that generally has nothing to do with the ISA.\",\n",
       " 'Software talks to hardware through a vocabulary called an instruction set architecture (ISA). By the early 1960s, IBM had four incompatible lines of computers, each with its own ISA, software stack, I/O system, and market nichetargeting small business, large business, scientific, and real time, respectively. IBM engineers, including ACM A.M. Turing Award laureate Fred Brooks, Jr., thought they could create a single ISA that would efficiently unify all four of these ISA bases.',\n",
       " 'Computer architecture concentrates on the logical aspects of computer design as opposed to the physical or electronic aspects. The underlying logical design of most modern computers is still based on that of the earliest electronic computers despite decades of progress in electronic circuitry. the innovations that have occurred in computer architecture have been driven by two different goals: higher performance and lower cost. Performance driven improvements have yielded computer systems with increasingly higher computation speeds and throughput. Cost driven improvements have yielded systems that are easier to use and applicable to a broader range of automatic control problems. Improvements in electronic circuitry have not led directly to architectural innovations; computers that pioneered new circuit technologies usually relied on older architectural concepts.',\n",
       " 'Another technique that has become more popular recently is multithreading. In multithreading, when the processor has to fetch data from slow system memory, instead of stalling for the data to arrive, the processor switches to another program or program thread which is ready to execute. Though this does not speed up a particular program/thread, it increases the overall system throughput by reducing the time the CPU is idle.',\n",
       " 'In modern designs it is common to find two load units, one store (many instructions have no results to store), two or more integer math units, two or more floating point units, and often a SIMD unit of some sort. The instruction issue logic grows in complexity by reading in a huge list of instructions from memory and handing them off to the different execution units that are idle at that point. The results are then collected and re-ordered at the end.',\n",
       " \"Gordon Moore believed Intel's next ISA would last the lifetime of Intel, so he hired many clever computer science Ph.D.'s and sent them to a new facility in Portland to invent the next great ISA. The 8800, as Intel originally named it, was an ambitious computer architecture project for any era, certainly the most aggressive of the 1980s. It had 32-bit capability-based addressing, object-oriented architecture, variable-bit-length instructions, and its own operating system written in the then-new programming language Ada.\",\n",
       " 'Conceptually, multithreading is equivalent to a context switch at the operating system level. The difference is that a multithreaded CPU can do a thread switch in one CPU cycle instead of the hundreds or thousands of CPU cycles a context switch normally requires. This is achieved by replicating the state hardware (such as the register file and program counter) for each active thread.',\n",
       " 'Modified harvard architecture is like a harvard architecture machine and it has a common address space for the separate data and instruction cache. It has digital signal processors that will execute small or highly audio or video algorithms and it is reproducible. Microcontrollers have a small number of programs and data memory and it speeds up the processing by executing parallel instructions and data access.',\n",
       " 'Harvard architecture is used when data and code is present in different memory blocks. A separate memory block is needed for data and instruction. Data can be accessed by one memory location and instruction can be accessed by a different location. It has data storage entirely contained within the central processing unit (CPU). A single set of clock cycles is required. The pipeline is possible. It is complex to design. CPU can read and write instructions and process data access. Harvard architecture has different access codes and data address spaces that is, the instruction address zero is not the same as data address zero. Instruction address zero identifies 24-byte value and data address zero identifies 8-byte value which is not the part of the 24-byte value.',\n",
       " 'computer architecture, structure of a digital computer, encompassing the design and layout of its instruction set and storage registers. The architecture of a computer is chosen with regard to the types of programs that will be run on it (business, scientific, general-purpose, etc.). Its principal components or subsystems, each of which could be said to have an architecture of its own, are input/output, storage, communication, control, and processing.',\n",
       " 'We began our Turing Lecture June 4, 2018 11 with a review of computer architecture since the 1960s. In addition to that review, here, we highlight current challenges and identify future opportunities, projecting another golden age for the field of computer architecture in the next decade, much like the 1980s when we did the research that led to our award, delivering gains in cost, energy, and security, as well as performance.',\n",
       " \"Real programs have more complex structures of course, with portions that allow varying numbers of processors to be used at any given moment in time. Nonetheless, the need to communicate and synchronize periodically means most applications have some portions that can effectively use only a fraction of the processors. Although Amdahl's Law is more than 50 years old, it remains a difficult hurdle.\",\n",
       " \"Benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. Although benchmarking shows strengths, it shouldn't be how you choose a computer. Often the measured machines split on different measures. For example, one system might handle scientific applications quickly, while another might render video games more smoothly. Furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but don't offer similar advantages to general tasks.\",\n",
       " 'In most of the Hollywood’s movies it is used for animation purposes. This kind of computer is also helpful for forecasting weather reports worldwide. They are known for von Newman’s design i. multiple processor system with parallel processing. In such a system a task is broken down and shared among processes for faster execution. They are used for complex tasks requiring a lot of computational power.',\n",
       " 'Although the term computer engineering sounds very complicated, its definition is easier than one might think. Computer engineering is a science or a set of rules stating how brain software and hardware are joined together and interact to make a computer work. It not only determines how the brain works but also of which technologies the computer is capable. Brains continue to be a major part of our lives, and brain architects reestablish to develop new and better policies and technologies.',\n",
       " 'Simply, it is a logical form of all electronic elements and data pathways present in the microprocessor, designed in a specific way. It allows for the optimal completion of instructions. In academe, it is called computer organization. System Design System design itself defines a design that can serve user requirements like system architecture, computer modules having various interfaces, and data management within a system. The term product development is connective to the system design. It is the process by which we can take marketing information to create a product design. report this ad',\n",
       " 'The first example is RISC-V (called \"RISC Five\"), the fifth RISC architecture developed at the University of California, Berkeley. 32 RISC-V\\'s has a community that maintains the architecture under the stewardship of the RISC-V Foundation (http://riscv.org/). Being open allows the ISA evolution to occur in public, with hardware and software experts collaborating before decisions are finalized. An added benefit of an open foundation is the ISA is unlikely to expand primarily for marketing reasons, sometimes the only explanation for extensions of proprietary instruction sets.',\n",
       " 'One of the first, and most powerful, techniques to improve performance is the use of instruction pipelining. Early processor designs would carry out all of the steps above for one instruction before moving onto the next. Large portions of the circuitry were left idle at any one step; for instance, the instruction decoding circuitry would be idle during execution and so on.',\n",
       " 'Historically, the earliest computers were multicycle designs. The smallest, least-expensive computers often still use this technique. Multicycle architectures often use the least total number of logic elements and reasonable amounts of power. They can be designed to have deterministic timing and high reliability. In particular, they have no pipeline to stall when taking conditional branches or interrupts. However, other microarchitectures often perform more instructions per unit time, using the same logic family. When discussing \"improved performance,\" an improvement is often relative to a multicycle design.',\n",
       " 'The central computation concept of this architecture is that instructions and data are both loaded into the same memory unit, which is the main memory of the computer and consists of a set of addressable locations. The processor can then access the instructions and data required for the execution of a computer program using dedicated connections called buses – an address bus which is used to identify the addressed location and a data bus which is used to transfer the contents to and from a location.',\n",
       " 'Inspired by the success of open source software, the second opportunity in computer architecture is open ISAs. To create a \"Linux for processors\" the field needs industry-standard open ISAs so the community can create open source cores, in addition to individual companies owning proprietary ones. If many organizations design processors using the same ISA, the greater competition may drive even quicker innovation. The goal is to provide processors for chips that cost from a few cents to $100.',\n",
       " 'The design of instruction sets is a complex issue. There were two stages in history for the microprocessor. The first was the CISC (Complex Instruction Set Computer), which had many different instructions. In the 1970s, however, places like IBM did research and found that many instructions in the set could be eliminated. The result was the RISC (Reduced Instruction Set Computer), an architecture that uses a smaller set of instructions. A simpler instruction set may offer the potential for higher speeds, reduced processor size, and reduced power consumption. However, a more complex set may optimize common operations, improve memory and cache efficiency, or simplify programming.',\n",
       " 'When designing the microarchitecture of a processor, engineers use blocks of \"hard-wired\" electronic circuitry (often designed separately) such as adders, multiplexers, counters, registers, ALUs, etc. Some kind of register transfer language is then often used to describe the decoding and sequencing of each instruction of an ISA using this physical microarchitecture. There are two basic ways to build a control unit to implement this description (although many designs use middle ways or compromises):',\n",
       " 'The term “ engineering ” in computer literature can be delineated to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM’s main research center in 1959. Johnson had the opportunity to write a proprietary research transmission about the Stretch, an IBM-developed supercomputer for Los A lamos National Workshop (at the time known as Los A lamos Scientific Laboratory). To portray the level of detail for discussing the luxuriously embellished computer, he noted that his explanation of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that suggested more useful than “machine management ”.',\n",
       " 'Mainframe computers A mainframe is another giant computer after the super computer and can also process millions of instruction per second and capable of accessing billions of data .They are physically very large in size with very high capacity of main memory. This computer is commonly used in big hospitals, air line reservations companies, and many other huge companies prefer mainframe because of its capability of retrieving data on a huge basis. They can be linked to smaller computers and handle hundreds of users they are also used in space exploitation. The term mainframe was mainly used for earliest computers as they were big in size though today the term is used to refer to large computers. A large number of peripherals can be attached to them. They are expensive to install.',\n",
       " 'Character size was in the past (pre-variable-sized character encoding) one of the influences on unit of address resolution and the choice of word size. Before the mid-1960s, characters were most often stored in six bits; this allowed no more than 64 characters, so the alphabet was limited to upper case. Since it is efficient in time and space to have the word size be a multiple of the character size, word sizes in this period were usually multiples of 6 bits (in binary machines). A common choice then was the 36-bit word, which is also a good size for the numeric properties of a floating point format.',\n",
       " 'In early 1960s computers, main memory was expensive and very limited, even on mainframes. Minimizing the size of a program to make sure it would fit in the limited memory was often central. Thus the size of the instructions needed to perform a particular task, the code density, was an important characteristic of any instruction set. It remained important on the initially-tiny memories of minicomputers and then microprocessors. Density remains important today, for smartphone applications, applications downloaded into browsers over slow Internet connections, and in ROMs for embedded applications. A more general advantage of increased density is improved effectiveness of caches and instruction prefetch.',\n",
       " 'Each memory has multiple locations and each location has a unique address. We can address the contents of memory by its location irrespective of what type of data and instructions are present in the memory, because of which we can read or write any data and instructions. Execution always occurs in a sequential manner unless the change is required. For example, suppose we are executing an instruction from line 1 to line 10 but now we required to execute line 50 instead of line 11 then we jump to instruction 50 and execute it.',\n",
       " 'To appreciate how this wasted work adds up, consider the data in Figure 4, showing the fraction of instructions that are effectively executed but turn out to be wasted because the processor speculated incorrectly. On average, 19% of the instructions are wasted for these benchmarks on an Intel Core i7. The amount of wasted energy is greater, however, since the processor must use additional energy to restore the state when it speculates incorrectly. Measurements like these led many to conclude architects needed a different approach to achieve performance improvements. The multicore era was thus born.',\n",
       " 'Reduced instruction-set computers, RISC, were first widely implemented during a period of rapidly growing memory subsystems. They sacrifice code density to simplify implementation circuitry, and try to increase performance via higher clock frequencies and more registers. A single RISC instruction typically performs only a single operation, such as an \"add\" of registers or a \"load\" from a memory location into a register. A RISC instruction set normally has a fixed instruction length, whereas a typical CISC instruction set has instructions of widely varying length. However, as RISC computers normally require more and often longer instructions to implement a given task, they inherently make less optimal use of bus bandwidth and cache memories.',\n",
       " 'Although the term computer architecture sounds very complicated, its definition is easier than one might think. Computer architecture is a science or a set of rules stating how computer software and hardware are joined together and interact to make a computer work. It not only determines how the computer works but also of which technologies the computer is capable. Computers continue to be a major part of our lives, and computer architects continue to develop new and better programs and technologies.',\n",
       " 'At the end of the chapter the learner shall be able to; \\uf0b7 Explain the different hardware units of a computer system such as input, output, Central processing unit (CPU), main memory and secondary storage \\uf0b7 Explain how the different units of a computer interact witch each other to give the user output \\uf0b7 Explain how information is stored in a computer \\uf0b7 Explain the different storage units of a computer such as byte, Kilobyte,',\n",
       " 'In contrast, the embedded computer is normally dedicated to a specific task. In many cases, an embedded system is used to replace application-specific electronics. The advantage of using an embedded microprocessor over dedicated electronics is that the functionality of the system is determined by the software, not the hardware. This makes the embedded system easier to produce, and much easier to evolve, than a complicated circuit.',\n",
       " 'Some manufacturers chose to make microprogramming available by letting select customers add custom features they called \"writable control store\" (WCS). The most famous WCS computer was the Alto 36 Turing laureates Chuck Thacker and Butler Lampson, together with their colleagues, created for the Xerox Palo Alto Research Center in 1973. It was indeed the first personal computer, sporting the first bit-mapped display and first Ethernet local-area network. The device controllers for the novel display and network were microprograms stored in a 4,096-word x 32-bit WCS.',\n",
       " 'In the outline above the processor processes parts of a single instruction at a time. Computer programs could be executed faster if multiple instructions were processed simultaneously. This is what superscalar processors achieve, by replicating functional units such as ALUs. The replication of functional units was only made possible when the die area of a single-issue processor no longer stretched the limits of what could be reliably manufactured. By the late 1980s, superscalar designs started to enter the market place.',\n",
       " 'The architecture semantics is the meaning of what the systems do under user direction and how their functional units are controlled to work together. An important embodiment of semantics is the instruction set architecture (ISA) of the system. The ISA is a logical (usually binary) representative encoding of the basic set of distinct operations that a computer architecture may perform, and by which application programs specify the useful work to be done. At the machine level, the hardware (sometimes controlled by firmware) system directly interprets and executes a sequence or partially ordered set of these basic operations.',\n",
       " 'Several of the earliest computers (and a few modern as well) used binary-coded decimal rather than plain binary, typically having a word size of 10 or 12 decimal digits, and some early decimal computers had no fixed word length at all. Early binary systems tended to use word lengths that were some multiple of 6-bits, with the 36-bit word being especially common on mainframe computers. The introduction of ASCII led to the move to systems with word lengths that were a multiple of 8-bits, with 16-bit machines being popular in the 1970s before the move to modern processors with 32 or 64 bits.  Special-purpose designs like digital signal processors, may have any word length from 4 to 80 bits. ',\n",
       " 'Conditional instructions often have a predicate field—a few bits that encode the specific condition to cause an operation to be performed rather than not performed. For example, a conditional branch instruction will transfer control if the condition is true, so that execution proceeds to a different part of the program, and not transfer control if the condition is false, so that execution continues sequentially. Some instruction sets also have conditional moves, so that the move will be executed, and the data stored in the target location, if the condition is true, and not executed, and the target location not modified, if the condition is false. Similarly, IBM z/Architecture has a conditional store instruction. A few instruction sets include a predicate field in every instruction; this is called branch predication.',\n",
       " 'A Brief History of Computer Architecture Computer Architecture is the field of study of selecting and interconnecting hardware components to create computers that satisfy functional performance and cost goals. It refers to those attributes of the computer system that are visible to a programmer and have a direct effect on the execution of a program.',\n",
       " 'The addition of caches reduces the frequency or duration of stalls due to waiting for data to be fetched from the memory hierarchy, but does not get rid of these stalls entirely. In early designs a cache miss would force the cache controller to stall the processor and wait. Of course there may be some other instruction in the program whose data is available in the cache at that point. Out-of-order execution allows that ready instruction to be processed while an older instruction waits on the cache, then re-orders the results to make it appear that everything happened in the programmed order. This technique is also used to avoid other operand dependency stalls, such as an instruction awaiting a result from a long latency floating-point operation or other multi-cycle operations.',\n",
       " 'Computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. The case of instruction set architecture can be used to illustrate the balance of these competing factors. More complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 Loop instruction).  However, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. The increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.',\n",
       " 'The challenge when using DSLs is how to retain enough architecture independence that software written in a DSL can be ported to different architectures while also achieving high efficiency in mapping the software to the underlying DSA. For example, the XLA system translates Tensorflow to heterogeneous processors that use Nvidia GPUs or Tensor Processor Units (TPUs). 40 Balancing portability among DSAs along with efficiency is an interesting research challenge for language designers, compiler creators, and DSA architects.',\n",
       " \"Prior to NPL , the company's computer designers had been free to honor cost objectives not only by selecting technologies but also by fashioning functional and architectural refinements. The SPREAD compatibility objective, in contrast, postulated a single architecture for a series of five processors spanning a wide range of cost and performance. None of the five engineering design teams could count on being able to bring about adjustments in architectural specifications as a way of easing difficulties in achieving cost and performance objectives. : p.137\",\n",
       " 'Some students choose to complete an MBA (master’s of business administration) with a focus on information systems. The advantage of this program is that it offers both computer-related and business courses. Even after earning the degree, applicants may be required to have at least five years of experience working with IT systems before being hired as a computer architect. Some computer architects go on to become computer and information systems managers once they’ve obtained sufficient experience.',\n",
       " 'Complex instructions are more common in CISC instruction sets than in RISC instruction sets, but RISC instruction sets may include them as well. RISC instruction sets generally do not include ALU operations with memory operands, or instructions to move large blocks of memory, but most RISC instruction sets include SIMD or vector instructions that perform the same arithmetic operation on multiple pieces of data at the same time. SIMD instructions have the ability of manipulating large vectors and matrices in minimal time. SIMD instructions allow easy parallelization of algorithms commonly involved in sound, image, and video processing. Various SIMD implementations have been brought to market under trade names such as MMX, 3DNow!, and AltiVec.',\n",
       " 'It was not long before improvements in chip manufacturing allowed for even more circuitry to be placed on the die, and designers started looking for ways to use it. One of the most common was to add an ever-increasing amount of cache memory on-die. Cache is very fast and expensive memory. It can be accessed in a few cycles as opposed to many needed to \"talk\" to main memory. The CPU includes a cache controller which automates reading and writing from the cache. If the data is already in the cache it is accessed from there – at considerable time savings, whereas if it is not the processor is \"stalled\" while the cache controller reads it in.',\n",
       " 'The size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. If multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see Size families below).',\n",
       " 'The RISC architecture was the result of a rethink, which has led to the development of high-performance processors. The hardware is kept as simple and fast as possible, and complex instructions can be performed with simpler instructions.',\n",
       " 'There are two main types of speed: latency and throughput. Latency is the time between the start of a process and its completion. Throughput is the amount of work done per unit time. Interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).',\n",
       " \"The term “architecture” in computer literature can be traced to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM's main research center in 1959. Johnson had the opportunity to write a proprietary research communication about the Stretch, an IBM-developed supercomputer for Los Alamos National Laboratory (at the time known as Los Alamos Scientific Laboratory). To describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that seemed more useful than “machine organization”. \",\n",
       " 'This is true for all computer cores, from those few in the smallest mobile phones to potentially millions making up the world’s largest supercomputers. High-performance computer architecture extends structure to a hierarchy of functional elements, whether small and limited in capability or possibly entire processor cores themselves. In this chapter many different classes of the structure are presented, each exploiting concurrency in its own particular way. But in all cases, this more broad definition of a general architecture for high-performance computing emphasizes aspects of the system that contribute to achieving performance.',\n",
       " \"Inherent inefficiencies in general-purpose processors, whether from ILP techniques or multicore, combined with the end of Dennard scaling and Moore's Law, make it highly unlikely, in our view, that processor architects and designers can sustain significant rates of performance improvements in general-purpose processors. Given the importance of improving performance to enable new software capabilities, we must ask: What other approaches might be promising?\",\n",
       " 'An ISA may be classified in a number of different ways. A common classification is by architectural complexity. A complex instruction set computer (CISC) has many specialized instructions, some of which may only be rarely used in practical programs. A reduced instruction set computer (RISC) simplifies the processor by efficiently implementing only the instructions that are frequently used in programs, while the less common operations are implemented as subroutines, having their resulting additional processor execution time offset by infrequent use. ',\n",
       " 'Microarchitecture is also known as computer organisation and defines the data processing and storage element and how they should be implemented into the ISA. It is the hardware implementation of how an ISA is implemented in a particular processor.',\n",
       " \"The end of Dennard scaling and Moore's Law and the deceleration of performance gains for standard microprocessors are not problems that must be solved but facts that, recognized, offer breathtaking opportunities. High-level, domain-specific languages and architectures, freeing architects from the chains of proprietary instruction sets, along with demand from the public for improved security, will usher in a new golden age for computer architects. Aided by open source ecosystems, agilely developed chips will convincingly demonstrate advances and thereby accelerate commercial adoption. The ISA philosophy of the general-purpose processors in these chips will likely be RISC, which has stood the test of time. Expect the same rapid improvement as in the last golden age, but this time in terms of cost, energy, and security, as well as in performance.\",\n",
       " 'Erasable Programmable ROM (EPROM): An EPROM is a ROM that can be erased and reprogrammed. A little glass window is installed in the top of the ROM package, through which you can actually see the chip that holds the memory. Ultraviolet light of a specific frequency can be shined through this window for a specified period of time, which will erase the EPROM and allow it to be reprogrammed again. Obviously this is much more useful than a regular PROM, but it does require the erasing light. Continuing the \"CD\" analogy, this technology is analogous to a reusable CD-RW.',\n",
       " 'Each microarchitectural element is in turn represented by a schematic describing the interconnections of logic gates used to implement it. Each logic gate is in turn represented by a circuit diagram describing the connections of the transistors used to implement it in some particular logic family. Machines with different microarchitectures may have the same instruction set architecture, and thus be capable of executing the same programs. New microarchitectures and/or circuitry solutions, along with advances in semiconductor manufacturing, are what allows newer generations of processors to achieve higher performance while using the same ISA.',\n",
       " 'The exact form of a computer system depends on the constraints and goals. Computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. Sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.',\n",
       " 'AMD and Intel used 500-person design teams and superior semiconductor technology to close the performance gap between x86 and RISC. Again inspired by the performance advantages of pipelining simple vs. complex instructions, the instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly. AMD and Intel then pipelined the execution of the RISC microinstructions. Any ideas RISC designers were using for performanceseparate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneouslycould then be incorporated into the x86. AMD and Intel shipped roughly 350 million x86 microprocessors annually at the peak of the PC era in 2011. The high volumes and low margins of the PC industry also meant lower prices than RISC computers.',\n",
       " 'A high-performance computer is designed to go fast, and its organization and semantics are specially devised to deliver computational speed. This chapter introduces the basic foundations of computer architecture in general and for high-performance computer systems in particular. It is here, at the structural and logical levels, that parallelism of operation in its many forms and size is first presented. This chapter provides a first examination of the principal forms of supercomputer architecture and the underlying concepts that govern their performance.',\n",
       " 'The demands of high-speed digital signal processing have pushed in the opposite direction—forcing instructions to be implemented in a particular way. For example, to perform digital filters fast enough, the MAC instruction in a typical digital signal processor (DSP) must use a kind of Harvard architecture that can fetch an instruction and two data words simultaneously, and it requires a single-cycle multiply–accumulate multiplier.',\n",
       " 'As computer designs have grown more complex, the central importance of a single word size to an architecture has decreased. Although more capable hardware can use a wider variety of sizes of data, market forces exert pressure to maintain backward compatibility while extending processor capability. As a result, what might have been the central word size in a fresh design has to coexist as an alternative size to the original word size in a backward compatible design. The original word size remains available in future designs, forming the basis of a size family.',\n",
       " 'VLIW, EPIC, Itanium. The next ISA innovation was supposed to succeed both RISC and CISC. Very long instruction word (VLIW) 7 and its cousin, the explicitly parallel instruction computer (EPIC), the name Intel and Hewlett Packard gave to the approach, used wide instructions with multiple independent operations bundled together in each instruction. VLIW and EPIC advocates at the time believed if a single instruction could specify, say, six independent operationstwo data transfers, two integer operations, and two floating point operationsand compiler technology could efficiently assign operations into the six instruction slots, the hardware could be made simpler. Like the RISC approach, VLIW and EPIC shifted work from the hardware to the compiler.',\n",
       " 'Register renaming refers to a technique used to avoid unnecessary serialized execution of program instructions because of the reuse of the same registers by those instructions. Suppose we have two groups of instruction that will use the same register. One set of instructions is executed first to leave the register to the other set, but if the other set is assigned to a different similar register, both sets of instructions can be executed in parallel (or) in series.',\n",
       " 'Cache memory After Random Access Memory ( RAM) Cache memory is a type of very fast memory that is used to improve the speed of a computer doubling it in some cases. It acts as an intermediate store between the CPU and the maim memory, and works by storing the most frequently or recently used instructions and data so that it will be very fast to retrieve them again.',\n",
       " 'Minimal instruction set computers (MISC) are a form of stack machine, where there are few separate instructions (16-64), so that multiple instructions can be fit into a single machine word. These types of cores often take little silicon to implement, so they can be easily realized in an FPGA or in a multi-core form. The code density of MISC is similar to the code density of RISC; the increased instruction density is offset by requiring more of the primitive instructions to do a task.  ',\n",
       " 'Most of these machines work on one unit of memory at a time and since each instruction or datum is several units long, each instruction takes several cycles just to access memory. These machines are often quite slow because of this. For example, instruction fetches on an IBM 1620 Model I take 8 cycles just to read the 12 digits of the instruction (the Model II reduced this to 6 cycles, or 4 cycles if the instruction did not need both address fields). Instruction execution took a completely variable number of cycles, depending on the size of the operands.',\n",
       " 'Embedded hardware is often much simpler than a desktop system, but it can also be far more complex too. An embedded computer may be implemented in a single chip with just a few support components, and its purpose may be as crude as a controller for a garden-watering system. Alternatively, the embedded computer may be a 150-processor, distributed parallel machine responsible for all the flight and control systems of a commercial jet. As diverse as embedded hardware may be, the underlying principles of design are the same.',\n",
       " \"Computer organization helps optimize performance-based products. For example, software engineers need to know the processing power of processors. They may need to optimize software in order to gain the most performance for the lowest price. This can require quite a detailed analysis of the computer's organization. For example, in an SD card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.\",\n",
       " 'In computer engineering, microarchitecture, also called computer organization and sometimes abbreviated as µarch or uarch, is the way a given instruction set architecture (ISA) is implemented in a particular processor.  A given ISA may be implemented with different microarchitectures;   implementations may vary due to different goals of a given design or due to shifts in technology. ',\n",
       " 'An instruction set architecture is distinguished from a microarchitecture, which is the set of processor design techniques used, in a particular processor, to implement the instruction set. Processors with different microarchitectures can share a common instruction set. For example, the Intel Pentium and the AMD Athlon implement nearly identical versions of the x86 instruction set, but they have radically different internal designs.',\n",
       " 'The microarchitecture of a machine is usually represented as (more or less detailed) diagrams that describe the interconnections of the various microarchitectural elements of the machine, which may be anything from single gates and registers, to complete arithmetic logic units (ALUs) and even larger elements. These diagrams generally separate the datapath (where data is placed) and the control path (which can be said to steer the data). ',\n",
       " 'Counting machine-language instructions would be misleading because they can do varying amounts of work in different ISAs. The \"instruction\" in the standard measurements is not a count of the ISA\\'s machine-language instructions, but a unit of measurement, usually based on the speed of the VAX computer architecture.',\n",
       " 'This includes the functions and capabilities of the central processing unit (CPU). It is the embedded programming language and defines what programming it can perform or process. This part is the software that makes the computer run, such as operating systems like Windows on a PC or iOS on an Apple iPhone, and includes data formats and the programmed instruction set.',\n",
       " 'Subsequently, Brooks, a Stretch designer, opened Chapter 2 of a book called Planning a Computer System: Project Stretch by stating, “Computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.” ',\n",
       " 'RISC makes pipelines smaller and much easier to construct by cleanly separating each stage of the instruction process and making them take the same amount of time—one cycle. The processor as a whole operates in an assembly line fashion, with instructions coming in one side and results out the other. Due to the reduced complexity of the classic RISC pipeline, the pipelined core and an instruction cache could be placed on the same size die that would otherwise fit the core alone on a CISC design. This was the real reason that RISC was faster. Early designs like the SPARC and MIPS often ran over 10 times as fast as Intel and Motorola CISC solutions at the same clock speed and price.',\n",
       " 'There are a number of reasons why the von Neumann architecture has proven to be so successful. It is relatively easy to implement in hardware, and von Neumann machines are deterministic and introspectable. They can be described mathematically and every step of their computing process is understood. You can also rely on them to always generate the same output on one set of inputs.',\n",
       " 'Computer architects have become stymied by the growing mismatch in CPU operating frequencies and DRAM access times. None of the techniques that exploited instruction-level parallelism (ILP) within one program could make up for the long stalls that occurred when data had to be fetched from main memory. Additionally, the large transistor counts and high operating frequencies needed for the more advanced ILP techniques required power dissipation levels that could no longer be cheaply cooled. For these reasons, newer generations of computers have started to exploit higher levels of parallelism that exist outside of a single program or program thread.',\n",
       " \"An era without Dennard scaling, along with reduced Moore's Law and Amdahl's Law in full effect means inefficiency limits improvement in performance to only a few percent per year (see Figure 6). Achieving higher rates of performance improvementas was seen in the 1980s and 1990swill require new architectural approaches that use the integrated-circuit capability much more efficiently. We will return to what approaches might work after discussing another major shortcoming of modern computerstheir support, or lack thereof, for computer security.\",\n",
       " 'Reduced instruction set computer architecture was realized in the 90’s by IBM. Instruction has multiple address modes, but programs do not use all of them that is the reason multiple address modes were reduced. This helps the compiler to easily write the instructions, performed is increased.',\n",
       " 'ROM: A mask programmed read only memory that can be only be produced by the manufacturer. It is designed to perform a specific function and cannot be changed. This is inflexible and so regular ROMs are only used generally for programs that are static (not changing often) and mass-produced. This product is analogous to a commercial software CD-ROM that you purchase in a store.',\n",
       " 'An ISA can also be emulated in software by an interpreter. Naturally, due to the interpretation overhead, this is slower than directly running programs on the emulated hardware, unless the hardware running the emulator is an order of magnitude faster. Today, it is common practice for vendors of new ISAs or microarchitectures to make software emulators available to software developers before the hardware implementation is ready.',\n",
       " 'CISC processors have a single processing unit, external memory, and a small register set with hundreds of different instructions. These processors have a single instruction to perform a task, and have the advantage of making the job of the programmer easier, as fewer lines of code are needed to get the job done. This approach uses less memory, but can take longer to complete instructions.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cfa0c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [01:38<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = defaultdict(list)\n",
    "label = []\n",
    "for sentence in tqdm(paragraphs):\n",
    "    temp = []\n",
    "    for i in features:\n",
    "        temp.append(float(cosine_similarity([i], [model.encode(sentence)])[0][0]))\n",
    "    label.append(important_subsections[np.argmax(temp)])\n",
    "    dataset[important_subsections[np.argmax(temp)]].append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19d51465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "74\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for k, v in dataset.items():\n",
    "    print(len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29384c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba5d8940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['type', 'intro', 'history'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1f69ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:20<00:00,  4.94it/s]\n"
     ]
    }
   ],
   "source": [
    "embs = []\n",
    "\n",
    "for sentence in tqdm(paragraphs):\n",
    "    embs.append(model.encode(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa432f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "x = pca.fit_transform(embs)[:,0]\n",
    "y = pca.fit_transform(embs)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4765a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bef5be25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"darkgrid\", rc = {'figure.figsize':(10,10)})\n",
    "sns.scatterplot(x=x, y=y, hue=label, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3d1da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "x = pca.fit_transform(features)[:,0]\n",
    "y = pca.fit_transform(features)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12486b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7ce57c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"darkgrid\", rc = {'figure.figsize':(10,10)})\n",
    "sns.scatterplot(x=x, y=y, hue=important_subsections, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "326c8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_paras = []\n",
    "with open('../notebooks/bad_sentences.txt') as f:\n",
    "    for line in f:\n",
    "        bad_paras.append(line[:-1])\n",
    "bad_emb = torch.from_numpy(model.encode(bad_paras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9458d1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5057) tensor([-0.0223, -0.0101, -0.0047,  ..., -0.0330, -0.0543,  0.0088]) Although the term computer architecture sounds very complicated, its definition is easier than one might think. Computer architecture is a science or a set of rules stating how computer software and hardware are joined together and interact to make a computer work. It not only determines how the computer works but also of which technologies the computer is capable. Computers continue to be a major part of our lives, and computer architects continue to develop new and better programs and technologies.\n",
      "tensor(0.5132) tensor([-0.0262,  0.0024, -0.0032,  ..., -0.0153, -0.0432,  0.0054]) A Brief History of Computer Architecture Computer Architecture is the field of study of selecting and interconnecting hardware components to create computers that satisfy functional performance and cost goals. It refers to those attributes of the computer system that are visible to a programmer and have a direct effect on the execution of a program.\n",
      "tensor(0.9863) tensor([-0.0191,  0.0069, -0.0172,  ..., -0.0588, -0.0408, -0.0024]) Some students choose to complete an MBA (master’s of business administration) with a focus on information systems. The advantage of this program is that it offers both computer-related and business courses. Even after earning the degree, applicants may be required to have at least five years of experience working with IT systems before being hired as a computer architect. Some computer architects go on to become computer and information systems managers once they’ve obtained sufficient experience.\n"
     ]
    }
   ],
   "source": [
    "dataset_clean = defaultdict(list)\n",
    "for section in important_subsections:\n",
    "    for paras in dataset[section]:\n",
    "        prag_emb = torch.from_numpy(model.encode(paras))\n",
    "        if torch.max(prag_emb @ bad_emb.T) < 0.5 and paras != '':\n",
    "            dataset_clean[section].append(paras)\n",
    "        else:\n",
    "            print(torch.max(prag_emb @ bad_emb.T), prag_emb, paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fccd5d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline('summarization', model=\"sshleifer/distilbart-cnn-12-6\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f43e245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkIt(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc811bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ad61df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf709584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "final_summary = defaultdict(list)\n",
    "references = defaultdict(list)\n",
    "for i, subsection in tqdm(enumerate(important_subsections)):\n",
    "    text = dataset_clean[subsection]\n",
    "    if text == []:\n",
    "        continue\n",
    "        \n",
    "    num_paras = len(text)\n",
    "    if num_paras > 5:\n",
    "        groups = chunkIt(text, num_paras//5)\n",
    "        #print(len(groups))\n",
    "        \n",
    "        for group in groups:\n",
    "            ref = []\n",
    "            for sentence in group:\n",
    "                ref.append(paragraph_reference[sentence])\n",
    "            references[subsection].append(ref)\n",
    "            data = ''.join(group)\n",
    "            #print(len(tokenizer([data])['input_ids'][0]))\n",
    "            if len(tokenizer([data])['input_ids'][0]) > 1023:\n",
    "                count = 0\n",
    "                data_nlp = nlp(data)\n",
    "                sentences = list(data_nlp.sents)\n",
    "                #print(sentences)\n",
    "                data = \"\"\n",
    "                for sentence in sentences:\n",
    "                    sentence = str(sentence)\n",
    "                    #print(type(sentence))\n",
    "                    count += (2 + len(word_tokenize(sentence)))\n",
    "                    if count < 924:\n",
    "                        data += sentence\n",
    "            #print(len(tokenizer([data])['input_ids'][0]))\n",
    "            \n",
    "            summary_text = summarizer(data, max_length=len(word_tokenize(data))//2, \\\n",
    "                              min_length = len(word_tokenize(data))//4)[0]['summary_text']\n",
    "            summary_text = summary_text.replace(u'\\xa0', u' ')\n",
    "            final_summary[subsection].append(summary_text)\n",
    "    else:\n",
    "        data = ''.join(text)\n",
    "        summary_text = summarizer(data, max_length=len(word_tokenize(data))//2, \\\n",
    "                          min_length = len(word_tokenize(data))//4)[0]['summary_text']\n",
    "        summary_text = summary_text.replace(u'\\xa0', u' ')\n",
    "        final_summary[subsection].append(summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6afe209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageTool('en-US') \n",
    "for key, val in final_summary.items():\n",
    "    for i in range(len(val)):\n",
    "        val[i] = tool.correct(val[i])\n",
    "tool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "878766d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['intro', 'history', 'type'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c0898c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'intro': [' Different amounts of memory are used to store data values with different degrees of precision. The commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word) Converting index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. In some cases this relationship can also avoid the use of division operations. Most modern computer designs have word sizes (and other operand sizes) that are two times the size of a byte. An ISA specifies the behavior of machine code running on implementations of that ISA in a fashion that does not depend on the characteristics of that implementation. This enables multiple implementations of an ISA that differ in characteristics such',\n",
       "              ' Computer architecture is the organization of the components which make up a computer system. It defines what is seen on the machine interface, which is targeted by programming languages and their compilers. The choice of instruction set architecture may greatly affect the complexity of implementing high-performance devices. The largest possible address size, used to designate a location in memory, is typically a hardware word. Data processing should be done in a different and single memory location in different types of computer architectures.',\n",
       "              ' In applications where the memory-access patterns are well-defined and discoverable at compile time, programmers and compilers can optimize the use of the memory better than can dynamically allocated caches. SAS usually use a hierarchy of memories with movement controlled explicitly by the software, similar to how vector processors operate. The underlying logical design of most modern computers is still based on that of the earliest electronic computers despite decades of progress in electronic circuitry. Super computers are biggest, the most expensive in price than any other is classified and known as super computer. This computer is not used as a PC in a home nor by a student in a college.',\n",
       "              ' In multithreading, when the processor has to fetch data from slow system memory, instead of stalling for the data to arrive, the processor switches to another program or program thread which is ready to execute. The instruction issue logic grows in complexity by reading in a huge list of instructions from memory and handing them off to the different execution units that are idle at that point. The results are then collected and re-ordered at the end. The difference is that a multithreaded CPU can do a thread switch in one CPU cycle instead of the hundreds or thousands of CPU cycles a context switch normally requires.',\n",
       "              ' The architecture of a computer is chosen with regard to the types of programs that will be run on it. Its principal components or subsystems, each of which could be said to have an architecture of its own, are input/output, storage, communication, control, and processing. In most of the Hollywood’s movies it is used for animation purposes. This kind of computer is also helpful for forecasting weather reports worldwide. In such a system a task is broken down and shared among processes for faster execution. They are used for complex tasks requiring a lot of computational power.',\n",
       "              ' Computer engineering is a science or a set of rules stating how brain software and hardware are joined together and interact to make a computer work. System design itself defines a design that can serve user requirements like system architecture, computer modules having various interfaces, and data management within a system. RISC-V (called \"RISC Five\") is the fifth RISC architecture developed at the University of California, Berkeley. Multicycle architectures often use the least total number of logic elements and reasonable amounts of power. The smallest, least-expensive computers often still use this technique. Multicycle architecture is often relative to multicycle designs.',\n",
       "              ' To create a \"Linux for processors\" the field needs industry-standard open ISA\\'s, so the community can create open source cores. If many organizations design processors using the same ISA, the greater competition may drive even quicker innovation. The goal is to provide processors for chips that cost from a few cents to $100. The term“ engineering” in computer literature can be delineated to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM’s main research center in 1959. Minimizing the size of a program to make sure it would fit in the limited memory was often central. The size of the instructions needed to perform a particular task, the code density',\n",
       "              ' On average, 19% of the instructions are wasted for benchmarks on an Intel Core i7. Figure 4 shows the fraction of instructions that are effectively executed but turn out to be wasted because the processor speculates incorrectly. The advantage of using an embedded microprocessor over dedicated electronics is that the functionality of the system is determined by the software, not the hardware. The architecture semantics is the meaning of what the systems do under user direction and how their functional units are controlled to work together. In many cases, an embedded system is used to replace application-specific electronics. This makes the embedded system easier to produce, and much easier to. Evolve, then a complicated circuit than a. Complicated circuit.',\n",
       "              ' Computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. Complex instruction sets enable programmers to write more space efficient programs. Longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. The challenge when using DSL is how to retain enough architecture independence that software written in a DSL can be ported to different architectures while achieving high efficiency in mapping the software to the underlying DSA. For example, the LA system translates TensorFlow to heterogeneous processors that use Nvidia GPUs or Tensor Processor Units.',\n",
       "              \" The term ‘architecture’ in computer literature can be traced to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM's main research center in 1959. The end of Dennard scaling and Moore's Law and the deceleration of performance gains for standard microprocessors are not problems that must be solved but facts that, recognized, offer breathtaking opportunities. Expect the same rapid improvement as in the last golden age, but this time in terms of cost, energy, and security, as well as in performance.\",\n",
       "              ' AMD and Intel used 500-person design teams and superior semiconductor technology to close the performance gap between x86 and RISC. The instruction decoder translated complex x86 instructions into internal RISC-like microinstructions on the fly. The demands of high-speed digital signal processing have pushed in the opposite direction—forcing instructions to be implemented in a particular way. This chapter provides a first examination of the principal forms of supercomputer architecture and the underlying concepts that govern their performance. A high-performance computer is designed to go fast, and its organization and semantics are specially devised to deliver computational speed.',\n",
       "              ' Cache memory is a type of very fast memory that is used to improve the speed of a computer doubling it in some cases. Cache memory acts as an intermediate store between the CPU and the maim memory, and works by storing the most frequently or recently used instructions and data so that it will be very fast to retrieve them again. Embedded hardware is often much simpler than a desktop system, but it can also be far more complex too. An embedded computer may be implemented in a single chip with just a few support components, and its purpose may be as crude as a controller for a garden-watering system.',\n",
       "              ' In computer engineering, microarchitecture, also called computer organization and sometimes abbreviated as March or March, is the way a given instruction set architecture (ISA) is implemented in a particular processor. A given ISA may be implemented with different microarcharchitectures; implementations may vary due to different goals of a given design or due to shifts in technology. For example, the Intel Pentium and AMD Athlon implement nearly identical versions of the x86 instruction set, but they have radically different internal designs.',\n",
       "              ' There are a number of reasons why the von Neumann architecture has proven to be so successful. Computer architects have become stymied by the growing mismatch in CPU operating frequencies and DRAM access times. Older generations of computers have started to exploit higher levels of parallelism that exist outside a single program or program thread. We will return to what approaches might work after discussing another major shortcoming of modern computers their support, or lack thereof, for computer security.',\n",
       "              ' CISC processors have a single instruction to perform a task, and have the advantage of making the job of the programmer easier. This approach uses less memory, but can'],\n",
       "             'history': [' By 1986 the top-of-the-line VAX implementation (VAX 8800) was a heavily pipeline design, predating the first commercial MIPS and SPARC designs. Large CISC machines, from the VAX to the modern Pentium 4 and Athlon, are implemented with both microcode and pipelines. Improvements in pipe lining and caching are the two major microarchitectural advances that have enabled processor performance to keep pace with the circuit technology on which they are based. In 28 nm, 1 mm 2 holds millions of transistors, enough area for both a RISC-V processor and an NELDA accelerator. A simpler instruction set may offer the potential for higher speeds, reduced processor size, and reduced power consumption, but a more complex set may optimize common operations, improve memory and cache efficiency, or simplify programming.',\n",
       "              ' In the outline above the processor processes parts of a single instruction at a time. Multiple instructions could be executed faster if multiple instructions were processed simultaneously. This is what super scalar processors achieve, by replicating functional units such as ALUs. Early designs like SPARC and MIPS often ran over 10 times as fast as Intel and Motorola CISC solutions at the same clock speed and price. Some manufacturers chose to make microprogramming available by letting select customers add custom features they called \"writable control store\" (WCS) The most famous WCS computer was the Alto 36 Turing laureates Chuck Thicker and Butler Sampson, together with their colleagues, created for the Xerox Palo Alto Research Center in 1973. It was indeed the first personal computer, sporting the first bit-mapped display and first Ethernet local-area network. The device controllers for the novel display and network were microprograms'],\n",
       "             'type': [' The next level of erasability is the EEPROM, which can be erased under software control. This is the most flexible type of ROM, and is now commonly used for holding BIOS programs. When you hear reference to a \"flash BIOS\" or doing a BIOS upgrade by \"flashing\" this refers to reprogramming the BIOS EEPROM with a special software program. The addition of caches reduces the frequency or duration of stalls due to waiting for data to be fetched from the memory hierarchy, but does not get rid of these stalls entirely. SIMS instructions allow easy parallelization of algorithms commonly involved in sound, image, and video processing. At the end of the chapter the learner shall be able to. Explain the different hardware units of a computer system such as input, output, Central processing unit (CPU), main memory and secondary storage',\n",
       "              ' Latency is the time between the start of a process and its completion. Throughput is the amount of work done per unit time. Erasable Programmable ROM (EPROM) is a ROM that can be erased and reprogrammed. The size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. If multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see Size Families below) Register renaming refers to a technique used to avoid unnecessary serialized execution of program instructions.']})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6608c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics selection - intro, syntax, feature, history\n",
    "\n",
    "# intro - 5 pars -> 3 webstes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc5a7a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# INTRO\n",
    "\n",
    "# website 1 url\n",
    "# website 1 title\n",
    "\n",
    "# (2 paras ralated to intro) -> summarize this in a few sentences\n",
    "\n",
    "\n",
    "# website 2 url\n",
    "# website 2 title\n",
    "\n",
    "# (1 paras ralated to intro) -> summarize this in a few sentences\n",
    "\n",
    "# website 3 url\n",
    "# website 3 title\n",
    "\n",
    "# (12 paras ralated to intro) -> summarize this in a few sentences\n",
    "\n",
    "\n",
    "\n",
    "# HISTORY\n",
    "\n",
    "# website 1 url\n",
    "# website 1 title\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ARTICLE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f4151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67c0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5f908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f9be11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b14a1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
