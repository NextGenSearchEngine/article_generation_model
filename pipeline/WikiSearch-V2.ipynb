{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d48a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia as wiki\n",
    "from collections import defaultdict, Counter \n",
    "import re\n",
    "import heapq\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import urllib\n",
    "\n",
    "from requests_html import HTMLSession\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html_text\n",
    "\n",
    "import nltk\n",
    "from os.path import isfile, join\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from transformers import pipeline\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a864330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes extraneous s from the end of a title\n",
    "def clean_title(title):\n",
    "    return title[:-1].lower() if title[-1] == 's' else title.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17d15b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE = clean_title(\"computer architecture\")\n",
    "SUBSECTIONS = 4\n",
    "RELATED_TITLES = wiki.search(TITLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6770326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computer architecture',\n",
       " 'Word (computer architecture)',\n",
       " 'Hazard (computer architecture)',\n",
       " 'Multithreading (computer architecture)',\n",
       " 'Von Neumann architecture',\n",
       " 'Predication (computer architecture)',\n",
       " 'Computer',\n",
       " 'Computer science',\n",
       " 'Microarchitecture',\n",
       " 'Computer architecture simulator']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RELATED_TITLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bee63a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filtered or raw (dependent on raw argument) sub sections for an article's content\n",
    "def get_subsections(data, raw=False):\n",
    "    subsections = re.findall('\\n== ([a-zA-z ]+) ==', data)\n",
    "    if raw:\n",
    "        return [subsection.lower() for subsection in subsections]\n",
    "    \n",
    "    subsections = [clean_title(subsection) for subsection in subsections]\n",
    "    blacklisted_articles = [\"reference\", \"see also\", \"external link\", \"note\"]\n",
    "    subsections = [subsection.lower() for subsection in subsections if subsection not in blacklisted_articles]\n",
    "    return subsections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "182448a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts subsections and content from related pages (cleans formatting)\n",
    "def get_important_subsections_and_content(related_titles):\n",
    "    topics = []\n",
    "    related_paper_section_content = defaultdict(list)\n",
    "    for related_title in related_titles:\n",
    "        # Get a WikipediaPage for every string title\n",
    "        try:\n",
    "            related_page = wiki.WikipediaPage(title=related_title)\n",
    "        except wiki.DisambiguationError as e:\n",
    "            continue\n",
    "\n",
    "        content = (related_page.content).lower()\n",
    "        subsections = get_subsections(content, raw=True)\n",
    "        topics.extend(get_subsections(content))\n",
    "        delimiters = ''\n",
    "        for subsection in subsections:\n",
    "            delimiters += '== ' + str(subsection) + ' ==|'\n",
    "        delimiters = delimiters[:-1]\n",
    "        words = re.split(delimiters, content)\n",
    "        words = [word.replace('\\n', '') for word in words]\n",
    "        related_paper_section_content['intro'].append(str(words[0]))\n",
    "        for i, subsection in enumerate(subsections):\n",
    "            if subsection[-1] == 's':\n",
    "                subsection = subsection[:-1]\n",
    "            related_paper_section_content[subsection].append(str(words[i+1]))\n",
    "\n",
    "    common_subsections = Counter(topics)\n",
    "    important_subsections = heapq.nlargest(SUBSECTIONS, common_subsections, key=common_subsections.__getitem__)\n",
    "    return important_subsections, related_paper_section_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94d6fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['history', 'subcategorie', 'role', 'design goal', 'source']\n",
      "defaultdict(<class 'list'>, {'intro': ['in computer engineering, computer architecture is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. the architecture of a system refers to its structure in terms of separately specified components of that system and their interrelationships.some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation. in other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation.'], 'history': ['the first documented computer architecture was in the correspondence between charles babbage and ada lovelace, describing the analytical engine. when building the computer z1 in 1936, konrad zuse described in two patent applications for his future projects that machine instructions could be stored in the same storage used for data, i.e., the stored-program concept. two other early and important examples are:john von neumann\\'s 1945 paper, first draft of a report on the edvac, which described an organization of logical elements; andalan turing\\'s more detailed proposed electronic calculator for the automatic computing engine, also 1945 and which cited john von neumann\\'s paper.the term “architecture” in computer literature can be traced to the work of lyle r. johnson and frederick p. brooks, jr., members of the machine organization department in ibm\\'s main research center in 1959. johnson had the opportunity to write a proprietary research communication about the stretch, an ibm-developed supercomputer for los alamos national laboratory (at the time known as los alamos scientific laboratory). to describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that seemed more useful than “machine organization”.subsequently, brooks, a stretch designer, opened chapter 2 of a book called planning a computer system: project stretch by stating, “computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.”brooks went on to help develop the ibm system/360 (now called the ibm zseries) line of computers, in which “architecture” became a noun defining “what the user needs to know”. later, computer users came to use the term in many less explicit ways.the earliest computer architectures were designed on paper and then directly built into the final hardware form.later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (ttl) computer—such as the prototypes of the 6800 and the pa-risc—tested, and tweaked, before committing to the final hardware form.as of the 1990s, new computer architectures are typically \"built\", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a fpga as a soft microprocessor; or both—before committing to the final hardware form.'], 'subcategorie': ['the discipline of computer architecture has three main subcategories:instruction set architecture (isa): defines the machine code that a processor reads and acts upon as well as the word size, memory address modes, processor registers, and data type.microarchitecture: also known as \"computer organization\", this describes how a particular processor will implement the isa. the size of a computer\\'s cpu cache for instance, is an issue that generally has nothing to do with the isa.systems design: includes all of the other hardware components within a computing system, such as data processing other than the cpu (e.g., direct memory access), virtualization, and multiprocessing.there are other technologies in computer architecture. the following technologies are used in bigger companies like intel, and were estimated in 2002 to count for 1% of all of computer architecture:macroarchitecture: architectural layers more abstract than microarchitectureassembly instruction set architecture: a smart assembler may convert an abstract assembly language common to a group of machines into slightly different machine language for different implementations.programmer-visible macroarchitecture: higher-level language tools such as compilers may define a consistent interface or contract to programmers using them, abstracting differences between underlying isa, uisa, and microarchitectures. for example, the c, c++, or java standards define different programmer-visible macroarchitectures.microcode: microcode is software that translates instructions to run on a chip. it acts like a wrapper around the hardware, presenting a preferred version of the hardware\\'s instruction set interface. this instruction translation facility gives chip designers flexible options: e.g. 1. a new improved version of the chip can use microcode to present the exact same instruction set as the old chip version, so all software targeting that instruction set will run on the new chip without needing changes. e.g. 2. microcode can present a variety of instruction sets for the same underlying chip, allowing it to run a wider variety of software.uisa: user instruction set architecture, refers to one of three subsets of the risc cpu instructions provided by powerpc risc processors. the uisa subset, are those risc instructions of interest to application developers. the other two subsets are vea (virtual environment architecture) instructions used by virtualization system developers, and oea (operating environment architecture) used by operation system developers.pin architecture: the hardware functions that a microprocessor should provide to a hardware platform, e.g., the x86 pins a20m, ferr/ignne or flush. also, messages that the processor should emit so that external caches can be invalidated (emptied). pin architecture functions are more flexible than isa functions because external hardware can adapt to new encodings, or change from a pin to a message. the term \"architecture\" fits, because the functions must be provided for compatible systems, even if the detailed method changes.'], 'role': [\"=== definition ===computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. the case of instruction set architecture can be used to illustrate the balance of these competing factors. more complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 loop instruction). however, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. the increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.the implementation involves integrated circuit design, packaging, power, and cooling. optimization of the design requires familiarity with compilers, operating systems to logic design, and packaging.=== instruction set architecture ===an instruction set architecture (isa) is the interface between the computer's software and hardware and also can be viewed as the programmer's view of the machine. computers do not understand high-level programming languages such as java, c++, or most programming languages used. a processor only understands instructions encoded in some numerical fashion, usually as binary numbers. software tools, such as compilers, translate those high level languages into instructions that the processor can understand.besides instructions, the isa defines items in the computer that are available to a program—e.g., data types, registers, addressing modes, and memory.  instructions locate these available items with register indexes (or names) and memory addressing modes.the isa of a computer is usually described in a small instruction manual, which describes how the instructions are encoded. also, it may define short (vaguely) mnemonic names for the instructions. the names can be recognized by a software development tool called an assembler.  an assembler is a computer program that translates a human-readable form of the isa into a computer-readable form.  disassemblers are also widely available, usually in debuggers and software programs to isolate and correct malfunctions in binary computer programs.isas vary in quality and completeness.  a good isa compromises between programmer convenience (how easy the code is to understand), size of the code (how much code is required to do a specific action), cost of the computer to interpret the instructions (more complexity means more hardware needed to decode and execute the instructions), and speed of the computer (with more complex decoding hardware comes longer decode time).  memory organization defines how instructions interact with the memory, and how memory interacts with itself.during design emulation, emulators can run programs written in a proposed instruction set. modern emulators can measure size, cost, and speed to determine whether a particular isa is meeting its goals.=== computer organization ===computer organization helps optimize performance-based products. for example, software engineers need to know the processing power of processors. they may need to optimize software in order to gain the most performance for the lowest price. this can require quite a detailed analysis of the computer's organization.  for example, in an sd card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.computer organization also helps plan the selection of a processor for a particular project. multimedia projects may need very rapid data access, while virtual machines may need fast interrupts. sometimes certain tasks need additional components as well.  for example, a computer capable of running a virtual machine needs virtual memory hardware so that the memory of different virtual computers can be kept separated. computer organization and features also affect power consumption and processor cost.=== implementation ===once an instruction set and micro-architecture have been designed, a practical machine must be developed. this design process is called the implementation. implementation is usually not considered architectural design, but rather hardware design engineering. implementation can be further broken down into several steps:logic implementation designs the circuits required at a logic-gate level.circuit implementation does transistor-level designs of basic elements (e.g., gates, multiplexers, latches) as well as of some larger blocks (alus, caches etc.) that may be implemented at the logic-gate level, or even at the physical level if the design calls for it.physical implementation draws physical circuits.  the different circuit components are placed in a chip floor plan or on a board and the wires connecting them are created.design validation tests the computer as a whole to see if it works in all situations and all timings. once the design validation process starts, the design at the logic level are tested using logic emulators. however, this is usually too slow to run a realistic test.  so, after making corrections based on the first test, prototypes are constructed using field-programmable gate-arrays (fpgas). most hobby projects stop at this stage.  the final step is to test prototype integrated circuits, which may require several redesigns.for cpus, the entire implementation process is organized differently and is often referred to as cpu design.\"], 'design goal': ['the exact form of a computer system depends on the constraints and goals. computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.the most common scheme does an in-depth power analysis and figures out how to keep power consumption low while maintaining adequate performance.=== performance ===modern computer performance is often described in instructions per cycle (ipc), which measures the efficiency of the architecture at any clock frequency; a faster ipc rate means the computer is faster. older computers had ipc counts as low as 0.1 while modern processors easily reach near 1. superscalar processors may reach three to five ipc by executing several instructions per clock cycle.counting machine-language instructions would be misleading because they can do varying amounts of work in different isas. the \"instruction\" in the standard measurements is not a count of the isa\\'s machine-language instructions, but a unit of measurement, usually based on the speed of the vax computer architecture.many people used to measure a computer\\'s speed by the clock rate (usually in mhz or ghz). this refers to the cycles per second of the main clock of the cpu. however, this metric is somewhat misleading, as a machine with a higher clock rate may not necessarily have greater performance. as a result, manufacturers have moved away from clock speed as a measure of performance.other factors influence speed, such as the mix of functional units, bus speeds, available memory, and the type and order of instructions in the programs.there are two main types of speed: latency and throughput. latency is the time between the start of a process and its completion. throughput is the amount of work done per unit time.  interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).performance is affected by a very wide range of design choices — for example, pipelining a processor usually makes latency worse, but makes throughput better. computers that control machinery usually need low interrupt latencies. these computers operate in a real-time environment and fail if an operation is not completed in a specified amount of time. for example, computer-controlled anti-lock brakes must begin braking within a predictable and limited time period after the brake pedal is sensed or else failure of the brake will occur.benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. although benchmarking shows strengths, it shouldn\\'t be how you choose a computer. often the measured machines split on different measures. for example, one system might handle scientific applications quickly, while another might render video games more smoothly. furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but don\\'t offer similar advantages to general tasks.=== power efficiency ===power efficiency is another important measurement in modern computers. a higher power efficiency can often be traded for lower speed or higher cost. the typical measurement when referring to power consumption in computer architecture is mips/w (millions of instructions per second per watt).modern circuits have less power required per transistor as the number of transistors per chip grows. this is because each transistor that is put in a new chip requires its own power supply and requires new pathways to be built to power it. however the number of transistors per chip is starting to increase at a slower rate. therefore, power efficiency is starting to become as important, if not more important than fitting more and more transistors into a single chip. recent processor designs have shown this emphasis as they put more focus on power efficiency rather than cramming as many transistors into a single chip as possible. in the world of embedded computers, power efficiency has long been an important goal next to throughput and latency.=== shifts in market demand ===increases in clock frequency have grown more slowly over the past few years, compared to power reduction improvements. this has been driven by the end of moore\\'s law and demand for longer battery life and reductions in size for mobile technology. this change in focus from higher clock rates to power consumption and miniaturization can be shown by the significant reductions in power consumption, as much as 50%, that were reported by intel in their release of the haswell microarchitecture; where they dropped their power consumption benchmark from 30 to 40 watts down to 10-20 watts. comparing this to the processing speed increase of 3 ghz to 4 ghz (2002 to 2006) it can be seen that the focus in research and development are shifting away from clock frequency and moving towards consuming less power and taking up less space.'], 'see also': [''], 'reference': [''], 'source': ['john l. hennessy and david patterson (2006). computer architecture: a quantitative approach (fourth ed.). morgan kaufmann. isbn 978-0-12-370490-0.barton, robert s., \"functional design of computers\", communications of the acm 4(9): 405 (1961).barton, robert s., \"a new approach to the functional design of a digital computer\", proceedings of the western joint computer conference, may 1961, pp. 393–396. about the design of the burroughs b5000 computer.bell, c. gordon; and newell, allen (1971). \"computer structures: readings and examples\", mcgraw-hill.blaauw, g.a., and brooks, f.p., jr., \"the structure of system/360, part i-outline of the logical structure\", ibm systems journal, vol. 3, no. 2, pp. 119–135, 1964.tanenbaum, andrew s. (1979). structured computer organization. englewood cliffs, new jersey: prentice-hall. isbn 0-13-148521-0.'], 'external link': ['isca: proceedings of the international symposium on computer architecturemicro: ieee/acm international symposium on microarchitecturehpca: international symposium on high performance computer architectureasplos: international conference on architectural support for programming languages and operating systemsacm transactions on architecture and code optimizationieee transactions on computersthe von neumann architecture of computer systems']})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uses of word', 'word size choice', 'size familie', 'table of word size']\n",
      "defaultdict(<class 'list'>, {'intro': ['in computer engineering, computer architecture is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. the architecture of a system refers to its structure in terms of separately specified components of that system and their interrelationships.some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation. in other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation.', 'in computing, a word is the natural unit of data used by a particular processor design. a word is a fixed-sized datum handled as a unit by the instruction set or the hardware of the processor. the number of bits or digits in a word (the word size, word width, or word length) is an important characteristic of any specific processor design or computer architecture.the size of a word is reflected in many aspects of a computer\\'s structure and operation; the majority of the registers in a processor are usually word sized and the largest datum that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. the largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used).documentation for computers with fixed word size commonly stated memory sizes in words rather than bytes or characters.  the documentation sometimes used metric prefixes correctly, sometimes with rounding, e.g., 65 kilowords (kw) meaning for 65536 words, and sometimes used them incorrectly, with kilowords (kw) meaning 1024 words (210) and megawords (mw) meaning 1,048,576 words (220). with standardization on 8-bit bytes and byte addressability, stating memory sizes in bytes, kilobytes, and megabytes with powers of 1024 rather than 1000 has become the norm, although there is some use of the iec binary prefixes.several of the earliest computers (and a few modern as well) used binary-coded decimal rather than plain binary, typically having a word size of 10 or 12 decimal digits, and some early decimal computers had no fixed word length at all. early binary systems tended to use word lengths that were some multiple of 6-bits, with the 36-bit word being especially common on mainframe computers. the introduction of ascii led to the move to systems with word lengths that were a multiple of 8-bits, with 16-bit machines being popular in the 1970s before the move to modern processors with 32 or 64 bits. special-purpose designs like digital signal processors, may have any word length from 4 to 80 bits.the size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. if multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see size families below).'], 'history': ['the first documented computer architecture was in the correspondence between charles babbage and ada lovelace, describing the analytical engine. when building the computer z1 in 1936, konrad zuse described in two patent applications for his future projects that machine instructions could be stored in the same storage used for data, i.e., the stored-program concept. two other early and important examples are:john von neumann\\'s 1945 paper, first draft of a report on the edvac, which described an organization of logical elements; andalan turing\\'s more detailed proposed electronic calculator for the automatic computing engine, also 1945 and which cited john von neumann\\'s paper.the term “architecture” in computer literature can be traced to the work of lyle r. johnson and frederick p. brooks, jr., members of the machine organization department in ibm\\'s main research center in 1959. johnson had the opportunity to write a proprietary research communication about the stretch, an ibm-developed supercomputer for los alamos national laboratory (at the time known as los alamos scientific laboratory). to describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that seemed more useful than “machine organization”.subsequently, brooks, a stretch designer, opened chapter 2 of a book called planning a computer system: project stretch by stating, “computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.”brooks went on to help develop the ibm system/360 (now called the ibm zseries) line of computers, in which “architecture” became a noun defining “what the user needs to know”. later, computer users came to use the term in many less explicit ways.the earliest computer architectures were designed on paper and then directly built into the final hardware form.later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (ttl) computer—such as the prototypes of the 6800 and the pa-risc—tested, and tweaked, before committing to the final hardware form.as of the 1990s, new computer architectures are typically \"built\", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a fpga as a soft microprocessor; or both—before committing to the final hardware form.'], 'subcategorie': ['the discipline of computer architecture has three main subcategories:instruction set architecture (isa): defines the machine code that a processor reads and acts upon as well as the word size, memory address modes, processor registers, and data type.microarchitecture: also known as \"computer organization\", this describes how a particular processor will implement the isa. the size of a computer\\'s cpu cache for instance, is an issue that generally has nothing to do with the isa.systems design: includes all of the other hardware components within a computing system, such as data processing other than the cpu (e.g., direct memory access), virtualization, and multiprocessing.there are other technologies in computer architecture. the following technologies are used in bigger companies like intel, and were estimated in 2002 to count for 1% of all of computer architecture:macroarchitecture: architectural layers more abstract than microarchitectureassembly instruction set architecture: a smart assembler may convert an abstract assembly language common to a group of machines into slightly different machine language for different implementations.programmer-visible macroarchitecture: higher-level language tools such as compilers may define a consistent interface or contract to programmers using them, abstracting differences between underlying isa, uisa, and microarchitectures. for example, the c, c++, or java standards define different programmer-visible macroarchitectures.microcode: microcode is software that translates instructions to run on a chip. it acts like a wrapper around the hardware, presenting a preferred version of the hardware\\'s instruction set interface. this instruction translation facility gives chip designers flexible options: e.g. 1. a new improved version of the chip can use microcode to present the exact same instruction set as the old chip version, so all software targeting that instruction set will run on the new chip without needing changes. e.g. 2. microcode can present a variety of instruction sets for the same underlying chip, allowing it to run a wider variety of software.uisa: user instruction set architecture, refers to one of three subsets of the risc cpu instructions provided by powerpc risc processors. the uisa subset, are those risc instructions of interest to application developers. the other two subsets are vea (virtual environment architecture) instructions used by virtualization system developers, and oea (operating environment architecture) used by operation system developers.pin architecture: the hardware functions that a microprocessor should provide to a hardware platform, e.g., the x86 pins a20m, ferr/ignne or flush. also, messages that the processor should emit so that external caches can be invalidated (emptied). pin architecture functions are more flexible than isa functions because external hardware can adapt to new encodings, or change from a pin to a message. the term \"architecture\" fits, because the functions must be provided for compatible systems, even if the detailed method changes.'], 'role': [\"=== definition ===computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. the case of instruction set architecture can be used to illustrate the balance of these competing factors. more complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 loop instruction). however, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. the increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.the implementation involves integrated circuit design, packaging, power, and cooling. optimization of the design requires familiarity with compilers, operating systems to logic design, and packaging.=== instruction set architecture ===an instruction set architecture (isa) is the interface between the computer's software and hardware and also can be viewed as the programmer's view of the machine. computers do not understand high-level programming languages such as java, c++, or most programming languages used. a processor only understands instructions encoded in some numerical fashion, usually as binary numbers. software tools, such as compilers, translate those high level languages into instructions that the processor can understand.besides instructions, the isa defines items in the computer that are available to a program—e.g., data types, registers, addressing modes, and memory.  instructions locate these available items with register indexes (or names) and memory addressing modes.the isa of a computer is usually described in a small instruction manual, which describes how the instructions are encoded. also, it may define short (vaguely) mnemonic names for the instructions. the names can be recognized by a software development tool called an assembler.  an assembler is a computer program that translates a human-readable form of the isa into a computer-readable form.  disassemblers are also widely available, usually in debuggers and software programs to isolate and correct malfunctions in binary computer programs.isas vary in quality and completeness.  a good isa compromises between programmer convenience (how easy the code is to understand), size of the code (how much code is required to do a specific action), cost of the computer to interpret the instructions (more complexity means more hardware needed to decode and execute the instructions), and speed of the computer (with more complex decoding hardware comes longer decode time).  memory organization defines how instructions interact with the memory, and how memory interacts with itself.during design emulation, emulators can run programs written in a proposed instruction set. modern emulators can measure size, cost, and speed to determine whether a particular isa is meeting its goals.=== computer organization ===computer organization helps optimize performance-based products. for example, software engineers need to know the processing power of processors. they may need to optimize software in order to gain the most performance for the lowest price. this can require quite a detailed analysis of the computer's organization.  for example, in an sd card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.computer organization also helps plan the selection of a processor for a particular project. multimedia projects may need very rapid data access, while virtual machines may need fast interrupts. sometimes certain tasks need additional components as well.  for example, a computer capable of running a virtual machine needs virtual memory hardware so that the memory of different virtual computers can be kept separated. computer organization and features also affect power consumption and processor cost.=== implementation ===once an instruction set and micro-architecture have been designed, a practical machine must be developed. this design process is called the implementation. implementation is usually not considered architectural design, but rather hardware design engineering. implementation can be further broken down into several steps:logic implementation designs the circuits required at a logic-gate level.circuit implementation does transistor-level designs of basic elements (e.g., gates, multiplexers, latches) as well as of some larger blocks (alus, caches etc.) that may be implemented at the logic-gate level, or even at the physical level if the design calls for it.physical implementation draws physical circuits.  the different circuit components are placed in a chip floor plan or on a board and the wires connecting them are created.design validation tests the computer as a whole to see if it works in all situations and all timings. once the design validation process starts, the design at the logic level are tested using logic emulators. however, this is usually too slow to run a realistic test.  so, after making corrections based on the first test, prototypes are constructed using field-programmable gate-arrays (fpgas). most hobby projects stop at this stage.  the final step is to test prototype integrated circuits, which may require several redesigns.for cpus, the entire implementation process is organized differently and is often referred to as cpu design.\"], 'design goal': ['the exact form of a computer system depends on the constraints and goals. computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.the most common scheme does an in-depth power analysis and figures out how to keep power consumption low while maintaining adequate performance.=== performance ===modern computer performance is often described in instructions per cycle (ipc), which measures the efficiency of the architecture at any clock frequency; a faster ipc rate means the computer is faster. older computers had ipc counts as low as 0.1 while modern processors easily reach near 1. superscalar processors may reach three to five ipc by executing several instructions per clock cycle.counting machine-language instructions would be misleading because they can do varying amounts of work in different isas. the \"instruction\" in the standard measurements is not a count of the isa\\'s machine-language instructions, but a unit of measurement, usually based on the speed of the vax computer architecture.many people used to measure a computer\\'s speed by the clock rate (usually in mhz or ghz). this refers to the cycles per second of the main clock of the cpu. however, this metric is somewhat misleading, as a machine with a higher clock rate may not necessarily have greater performance. as a result, manufacturers have moved away from clock speed as a measure of performance.other factors influence speed, such as the mix of functional units, bus speeds, available memory, and the type and order of instructions in the programs.there are two main types of speed: latency and throughput. latency is the time between the start of a process and its completion. throughput is the amount of work done per unit time.  interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).performance is affected by a very wide range of design choices — for example, pipelining a processor usually makes latency worse, but makes throughput better. computers that control machinery usually need low interrupt latencies. these computers operate in a real-time environment and fail if an operation is not completed in a specified amount of time. for example, computer-controlled anti-lock brakes must begin braking within a predictable and limited time period after the brake pedal is sensed or else failure of the brake will occur.benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. although benchmarking shows strengths, it shouldn\\'t be how you choose a computer. often the measured machines split on different measures. for example, one system might handle scientific applications quickly, while another might render video games more smoothly. furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but don\\'t offer similar advantages to general tasks.=== power efficiency ===power efficiency is another important measurement in modern computers. a higher power efficiency can often be traded for lower speed or higher cost. the typical measurement when referring to power consumption in computer architecture is mips/w (millions of instructions per second per watt).modern circuits have less power required per transistor as the number of transistors per chip grows. this is because each transistor that is put in a new chip requires its own power supply and requires new pathways to be built to power it. however the number of transistors per chip is starting to increase at a slower rate. therefore, power efficiency is starting to become as important, if not more important than fitting more and more transistors into a single chip. recent processor designs have shown this emphasis as they put more focus on power efficiency rather than cramming as many transistors into a single chip as possible. in the world of embedded computers, power efficiency has long been an important goal next to throughput and latency.=== shifts in market demand ===increases in clock frequency have grown more slowly over the past few years, compared to power reduction improvements. this has been driven by the end of moore\\'s law and demand for longer battery life and reductions in size for mobile technology. this change in focus from higher clock rates to power consumption and miniaturization can be shown by the significant reductions in power consumption, as much as 50%, that were reported by intel in their release of the haswell microarchitecture; where they dropped their power consumption benchmark from 30 to 40 watts down to 10-20 watts. comparing this to the processing speed increase of 3 ghz to 4 ghz (2002 to 2006) it can be seen that the focus in research and development are shifting away from clock frequency and moving towards consuming less power and taking up less space.'], 'see also': ['', 'integer (computer science)'], 'reference': ['', ''], 'source': ['john l. hennessy and david patterson (2006). computer architecture: a quantitative approach (fourth ed.). morgan kaufmann. isbn 978-0-12-370490-0.barton, robert s., \"functional design of computers\", communications of the acm 4(9): 405 (1961).barton, robert s., \"a new approach to the functional design of a digital computer\", proceedings of the western joint computer conference, may 1961, pp. 393–396. about the design of the burroughs b5000 computer.bell, c. gordon; and newell, allen (1971). \"computer structures: readings and examples\", mcgraw-hill.blaauw, g.a., and brooks, f.p., jr., \"the structure of system/360, part i-outline of the logical structure\", ibm systems journal, vol. 3, no. 2, pp. 119–135, 1964.tanenbaum, andrew s. (1979). structured computer organization. englewood cliffs, new jersey: prentice-hall. isbn 0-13-148521-0.'], 'external link': ['isca: proceedings of the international symposium on computer architecturemicro: ieee/acm international symposium on microarchitecturehpca: international symposium on high performance computer architectureasplos: international conference on architectural support for programming languages and operating systemsacm transactions on architecture and code optimizationieee transactions on computersthe von neumann architecture of computer systems'], 'uses of word': ['depending on how a computer is organized, word-size units may be used for:fixed-point numbersholders for fixed point, usually integer, numerical values may be available in one or in several different sizes, but one of the sizes available will almost always be the word. the other sizes, if any, are likely to be multiples or fractions of the word size. the smaller sizes are normally used only for efficient use of memory; when loaded into the processor, their values usually go into a larger, word sized holder.floating-point numbersholders for floating-point numerical values are typically either a word or a multiple of a word.addressesholders for memory addresses must be of a size capable of expressing the needed range of values but not be excessively large, so often the size used is the word though it can also be a multiple or fraction of the word size.registersprocessor registers are designed with a size appropriate for the type of data they hold, e.g. integers, floating-point numbers, or addresses. many computer architectures use general-purpose registers that are capable of storing data in multiple representations.memory–processor transferwhen the processor reads from the memory subsystem into a register or writes a register\\'s value to memory, the amount of data transferred is often a word. historically, this amount of bits which could be transferred in one cycle was also called a catena in some environments (such as the bull gamma 60). in simple memory subsystems, the word is transferred over the memory data bus, which typically has a width of a word or half-word. in memory subsystems that use caches, the word-sized transfer is the one between the processor and the first level of cache; at lower levels of the memory hierarchy larger transfers (which are a multiple of the word size) are normally used.unit of address resolutionin a given architecture, successive address values designate successive units of memory; this unit is the unit of address resolution. in most computers, the unit is either a character (e.g. a byte) or a word. (a few computers have used bit resolution.) if the unit is a word, then a larger amount of memory can be accessed using an address of a given size at the cost of added complexity to access individual characters. on the other hand, if the unit is a byte, then individual characters can be addressed (i.e. selected during the memory operation).instructionsmachine instructions are normally the size of the architecture\\'s word, such as in risc architectures, or a multiple of the \"char\" size that is a fraction of it. this is a natural choice since instructions and data usually share the same memory subsystem. in harvard architectures the word sizes of instructions and data need not be related, as instructions and data are stored in different memories; for example, the processor in the 1ess electronic telephone switch had 37-bit instructions and 23-bit data words.'], 'word size choice': ['when a computer architecture is designed, the choice of a word size is of substantial importance.  there are design considerations which encourage particular bit-group sizes for particular uses (e.g. for addresses), and these considerations point to different sizes for different uses.  however, considerations of economy in design strongly push for one size, or a very few sizes related by multiples or fractions (submultiples) to a primary size.  that preferred size becomes the word size of the architecture.character size was in the past (pre-variable-sized character encoding) one of the influences on unit of address resolution and the choice of word size.  before the mid-1960s, characters were most often stored in six bits; this allowed no more than 64 characters, so the alphabet was limited to upper case.  since it is efficient in time and space to have the word size be a multiple of the character size, word sizes in this period were usually multiples of 6 bits (in binary machines).  a common choice then was the 36-bit word, which is also a good size for the numeric properties of a floating point format.after the introduction of the ibm system/360 design, which used eight-bit characters and supported lower-case letters, the standard size of a character (or more accurately, a byte) became eight bits.  word sizes thereafter were naturally multiples of eight bits, with 16, 32, and 64 bits being commonly used.=== variable-word architectures ===early machine designs included some that used what is often termed a variable word length.  in this type of organization, an operand had no fixed length. depending on the machine and the instruction, the length might be denoted by a count field, by a delimiting character, or by an additional bit called, e.g., flag, word mark.  such machines often used binary-coded decimal in 4-bit digits, or in 6-bit characters, for numbers.  this class of machines included the ibm 702, ibm 705, ibm 7080, ibm 7010, univac 1050, ibm 1401, ibm 1620, and rca 301.most of these machines work on one unit of memory at a time and since each instruction or datum is several units long, each instruction takes several cycles just to access memory.  these machines are often quite slow because of this.  for example, instruction fetches on an ibm 1620 model i take 8 cycles just to read the 12 digits of the instruction (the model ii reduced this to 6 cycles, or 4 cycles if the instruction did not need both address fields). instruction execution took a completely variable number of cycles, depending on the size of the operands.=== word, bit and byte addressing ===the memory model of an architecture is strongly influenced by the word size.  in particular, the resolution of a memory address, that is, the smallest unit that can be designated by an address, has often been chosen to be the word.  in this approach, the word-addressable machine approach, address values which differ by one designate adjacent memory words.  this is natural in machines which deal almost always in word (or multiple-word) units, and has the advantage of allowing instructions to use minimally sized fields to contain addresses, which can permit a smaller instruction size or a larger variety of instructions.when byte processing is to be a significant part of the workload, it is usually more advantageous to use the byte, rather than the word, as the unit of address resolution. address values which differ by one designate adjacent bytes in memory.  this allows an arbitrary character within a character string to be addressed straightforwardly.  a word can still be addressed, but the address to be used requires a few more bits than the word-resolution alternative.  the word size needs to be an integer multiple of the character size in this organization.  this addressing approach was used in the ibm 360, and has been the most common approach in machines designed since then.when the workload involves processing fields of different sizes, it can be advantageous to address to the bit. machines with bit addressing may have some instructions that use a programmer-defined byte size and other instructions that operate on fixed data sizes. as an example, on the ibm 7030 (\"stretch\"), a floating point instruction can only address words while an integer arithmetic instruction can specify a field length of 1-64 bits, a byte size of 1-8 bits and an accumulator offset of 0-127 bits. in at byte-addressable machine with storage-to-storage (ss) instructions, there are typically move instructions to copy one or multiple bytes from one arbitrary location to another. in a byte-oriented (byte-addressable) machine without ss instructions, moving a single byte from one arbitrary location to another is typically:load the source bytestore the result back in the target byteindividual bytes can be accessed on a word-oriented machine in one of two ways.  bytes can be manipulated by a combination of shift and mask operations in registers. moving a single byte from one arbitrary location to another may require the equivalent of the following:load the word containing the source byteshift the source word to align the desired byte to the correct position in the target wordand the source word with a mask to zero out all but the desired bitsload the word containing the target byteand the target word with a mask to zero out the target byteor the registers containing the source and target words to insert the source bytestore the result back in the target locationalternatively many word-oriented machines implement byte operations with instructions using special byte pointers in registers or memory.  for example, the pdp-10 byte pointer contained the size of the byte in bits (allowing different-sized bytes to be accessed), the bit position of the byte within the word, and the word address of the data.  instructions could automatically adjust the pointer to the next byte on, for example, load and deposit (store) operations.=== powers of two ===different amounts of memory are used to store data values with different degrees of precision. the commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word).  converting the index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. in some cases this relationship can also avoid the use of division operations. as a result, most modern computer designs have word sizes (and other operand sizes) that are a power of two times the size of a byte.'], 'size familie': ['as computer designs have grown more complex, the central importance of a single word size to an architecture has decreased.  although more capable hardware can use a wider variety of sizes of data, market forces exert pressure to maintain backward compatibility while extending processor capability.  as a result, what might have been the central word size in a fresh design has to coexist as an alternative size to the original word size in a backward compatible design. the original word size remains available in future designs, forming the basis of a size family.in the mid-1970s, dec designed the vax to be a 32-bit successor of the 16-bit pdp-11. they used word for a 16-bit quantity, while longword referred to a 32-bit quantity; this terminology is the same as the terminology used for the pdp-11. this was in contrast to earlier machines, where the natural unit of addressing memory would be called a word, while a quantity that is one half a word would be called a halfword. in fitting with this scheme, a vax quadword is 64 bits.  they continued this 16-bit word/32-bit longword/64-bit quadword terminology with the 64-bit alpha.another example is the x86 family, of which processors of three different word lengths (16-bit, later 32- and 64-bit) have been released, while word continues to designate a 16-bit quantity. as software is routinely ported from one word-length to the next, some apis and documentation define or refer to an older (and thus shorter) word-length than the full word length on the cpu that software may be compiled for. also, similar to how bytes are used for small numbers in many programs, a shorter word (16 or 32 bits) may be used in contexts where the range of a wider word is not needed (especially where this can save considerable stack space or cache memory space). for example, microsoft\\'s windows api maintains the programming language definition of word as 16 bits, despite the fact that the api may be used on a 32- or 64-bit x86 processor, where the standard word size would be 32 or 64 bits, respectively. data structures containing such different sized words refer to them as:word (16 bits/2 bytes)dword (32 bits/4 bytes)qword (64 bits/8 bytes)a similar phenomenon has developed in intel\\'s x86 assembly language – because of the support for various sizes (and backward compatibility) in the instruction set, some instruction mnemonics carry \"d\" or \"q\" identifiers denoting \"double-\", \"quad-\" or \"double-quad-\", which are in terms of the architecture\\'s original 16-bit word size.an example with a different word size is the ibm system/360 family. in the system/360 architecture, system/370 architecture and system/390 architecture, there are 8-bit bytes, 16-bit halfwords, 32-bit words and 64-bit doublewords. the z/architecture, which is the 64-bit member of that architecture family, continues to refer to 16-bit halfwords, 32-bit words, and 64-bit doublewords, and additionally features 128-bit quadwords.in general, new processors must use the same data word lengths and virtual address widths as an older processor to have binary compatibility with that older processor.often carefully written source code – written with source-code compatibility and software portability in mind – can be recompiled to run on a variety of processors, even ones with different data word lengths or different address widths or both.'], 'table of word size': [''], 'note': ['']})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['background', 'type', 'eliminating hazard']\n",
      "defaultdict(<class 'list'>, {'intro': ['in computer engineering, computer architecture is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. the architecture of a system refers to its structure in terms of separately specified components of that system and their interrelationships.some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation. in other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation.', 'in computing, a word is the natural unit of data used by a particular processor design. a word is a fixed-sized datum handled as a unit by the instruction set or the hardware of the processor. the number of bits or digits in a word (the word size, word width, or word length) is an important characteristic of any specific processor design or computer architecture.the size of a word is reflected in many aspects of a computer\\'s structure and operation; the majority of the registers in a processor are usually word sized and the largest datum that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. the largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used).documentation for computers with fixed word size commonly stated memory sizes in words rather than bytes or characters.  the documentation sometimes used metric prefixes correctly, sometimes with rounding, e.g., 65 kilowords (kw) meaning for 65536 words, and sometimes used them incorrectly, with kilowords (kw) meaning 1024 words (210) and megawords (mw) meaning 1,048,576 words (220). with standardization on 8-bit bytes and byte addressability, stating memory sizes in bytes, kilobytes, and megabytes with powers of 1024 rather than 1000 has become the norm, although there is some use of the iec binary prefixes.several of the earliest computers (and a few modern as well) used binary-coded decimal rather than plain binary, typically having a word size of 10 or 12 decimal digits, and some early decimal computers had no fixed word length at all. early binary systems tended to use word lengths that were some multiple of 6-bits, with the 36-bit word being especially common on mainframe computers. the introduction of ascii led to the move to systems with word lengths that were a multiple of 8-bits, with 16-bit machines being popular in the 1970s before the move to modern processors with 32 or 64 bits. special-purpose designs like digital signal processors, may have any word length from 4 to 80 bits.the size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. if multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see size families below).', 'in the domain of central processing unit (cpu) design, hazards are problems with the instruction pipeline in cpu microarchitectures when the next instruction cannot execute in the following clock cycle, and can potentially lead to incorrect computation results. three common types of hazards are data hazards, structural hazards, and control hazards (branching hazards).there are several methods used to deal with hazards, including pipeline stalls/pipeline bubbling, operand forwarding, and in the case of out-of-order execution, the scoreboarding method and the tomasulo algorithm.'], 'history': ['the first documented computer architecture was in the correspondence between charles babbage and ada lovelace, describing the analytical engine. when building the computer z1 in 1936, konrad zuse described in two patent applications for his future projects that machine instructions could be stored in the same storage used for data, i.e., the stored-program concept. two other early and important examples are:john von neumann\\'s 1945 paper, first draft of a report on the edvac, which described an organization of logical elements; andalan turing\\'s more detailed proposed electronic calculator for the automatic computing engine, also 1945 and which cited john von neumann\\'s paper.the term “architecture” in computer literature can be traced to the work of lyle r. johnson and frederick p. brooks, jr., members of the machine organization department in ibm\\'s main research center in 1959. johnson had the opportunity to write a proprietary research communication about the stretch, an ibm-developed supercomputer for los alamos national laboratory (at the time known as los alamos scientific laboratory). to describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that seemed more useful than “machine organization”.subsequently, brooks, a stretch designer, opened chapter 2 of a book called planning a computer system: project stretch by stating, “computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.”brooks went on to help develop the ibm system/360 (now called the ibm zseries) line of computers, in which “architecture” became a noun defining “what the user needs to know”. later, computer users came to use the term in many less explicit ways.the earliest computer architectures were designed on paper and then directly built into the final hardware form.later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (ttl) computer—such as the prototypes of the 6800 and the pa-risc—tested, and tweaked, before committing to the final hardware form.as of the 1990s, new computer architectures are typically \"built\", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a fpga as a soft microprocessor; or both—before committing to the final hardware form.'], 'subcategorie': ['the discipline of computer architecture has three main subcategories:instruction set architecture (isa): defines the machine code that a processor reads and acts upon as well as the word size, memory address modes, processor registers, and data type.microarchitecture: also known as \"computer organization\", this describes how a particular processor will implement the isa. the size of a computer\\'s cpu cache for instance, is an issue that generally has nothing to do with the isa.systems design: includes all of the other hardware components within a computing system, such as data processing other than the cpu (e.g., direct memory access), virtualization, and multiprocessing.there are other technologies in computer architecture. the following technologies are used in bigger companies like intel, and were estimated in 2002 to count for 1% of all of computer architecture:macroarchitecture: architectural layers more abstract than microarchitectureassembly instruction set architecture: a smart assembler may convert an abstract assembly language common to a group of machines into slightly different machine language for different implementations.programmer-visible macroarchitecture: higher-level language tools such as compilers may define a consistent interface or contract to programmers using them, abstracting differences between underlying isa, uisa, and microarchitectures. for example, the c, c++, or java standards define different programmer-visible macroarchitectures.microcode: microcode is software that translates instructions to run on a chip. it acts like a wrapper around the hardware, presenting a preferred version of the hardware\\'s instruction set interface. this instruction translation facility gives chip designers flexible options: e.g. 1. a new improved version of the chip can use microcode to present the exact same instruction set as the old chip version, so all software targeting that instruction set will run on the new chip without needing changes. e.g. 2. microcode can present a variety of instruction sets for the same underlying chip, allowing it to run a wider variety of software.uisa: user instruction set architecture, refers to one of three subsets of the risc cpu instructions provided by powerpc risc processors. the uisa subset, are those risc instructions of interest to application developers. the other two subsets are vea (virtual environment architecture) instructions used by virtualization system developers, and oea (operating environment architecture) used by operation system developers.pin architecture: the hardware functions that a microprocessor should provide to a hardware platform, e.g., the x86 pins a20m, ferr/ignne or flush. also, messages that the processor should emit so that external caches can be invalidated (emptied). pin architecture functions are more flexible than isa functions because external hardware can adapt to new encodings, or change from a pin to a message. the term \"architecture\" fits, because the functions must be provided for compatible systems, even if the detailed method changes.'], 'role': [\"=== definition ===computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. the case of instruction set architecture can be used to illustrate the balance of these competing factors. more complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 loop instruction). however, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. the increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.the implementation involves integrated circuit design, packaging, power, and cooling. optimization of the design requires familiarity with compilers, operating systems to logic design, and packaging.=== instruction set architecture ===an instruction set architecture (isa) is the interface between the computer's software and hardware and also can be viewed as the programmer's view of the machine. computers do not understand high-level programming languages such as java, c++, or most programming languages used. a processor only understands instructions encoded in some numerical fashion, usually as binary numbers. software tools, such as compilers, translate those high level languages into instructions that the processor can understand.besides instructions, the isa defines items in the computer that are available to a program—e.g., data types, registers, addressing modes, and memory.  instructions locate these available items with register indexes (or names) and memory addressing modes.the isa of a computer is usually described in a small instruction manual, which describes how the instructions are encoded. also, it may define short (vaguely) mnemonic names for the instructions. the names can be recognized by a software development tool called an assembler.  an assembler is a computer program that translates a human-readable form of the isa into a computer-readable form.  disassemblers are also widely available, usually in debuggers and software programs to isolate and correct malfunctions in binary computer programs.isas vary in quality and completeness.  a good isa compromises between programmer convenience (how easy the code is to understand), size of the code (how much code is required to do a specific action), cost of the computer to interpret the instructions (more complexity means more hardware needed to decode and execute the instructions), and speed of the computer (with more complex decoding hardware comes longer decode time).  memory organization defines how instructions interact with the memory, and how memory interacts with itself.during design emulation, emulators can run programs written in a proposed instruction set. modern emulators can measure size, cost, and speed to determine whether a particular isa is meeting its goals.=== computer organization ===computer organization helps optimize performance-based products. for example, software engineers need to know the processing power of processors. they may need to optimize software in order to gain the most performance for the lowest price. this can require quite a detailed analysis of the computer's organization.  for example, in an sd card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.computer organization also helps plan the selection of a processor for a particular project. multimedia projects may need very rapid data access, while virtual machines may need fast interrupts. sometimes certain tasks need additional components as well.  for example, a computer capable of running a virtual machine needs virtual memory hardware so that the memory of different virtual computers can be kept separated. computer organization and features also affect power consumption and processor cost.=== implementation ===once an instruction set and micro-architecture have been designed, a practical machine must be developed. this design process is called the implementation. implementation is usually not considered architectural design, but rather hardware design engineering. implementation can be further broken down into several steps:logic implementation designs the circuits required at a logic-gate level.circuit implementation does transistor-level designs of basic elements (e.g., gates, multiplexers, latches) as well as of some larger blocks (alus, caches etc.) that may be implemented at the logic-gate level, or even at the physical level if the design calls for it.physical implementation draws physical circuits.  the different circuit components are placed in a chip floor plan or on a board and the wires connecting them are created.design validation tests the computer as a whole to see if it works in all situations and all timings. once the design validation process starts, the design at the logic level are tested using logic emulators. however, this is usually too slow to run a realistic test.  so, after making corrections based on the first test, prototypes are constructed using field-programmable gate-arrays (fpgas). most hobby projects stop at this stage.  the final step is to test prototype integrated circuits, which may require several redesigns.for cpus, the entire implementation process is organized differently and is often referred to as cpu design.\"], 'design goal': ['the exact form of a computer system depends on the constraints and goals. computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.the most common scheme does an in-depth power analysis and figures out how to keep power consumption low while maintaining adequate performance.=== performance ===modern computer performance is often described in instructions per cycle (ipc), which measures the efficiency of the architecture at any clock frequency; a faster ipc rate means the computer is faster. older computers had ipc counts as low as 0.1 while modern processors easily reach near 1. superscalar processors may reach three to five ipc by executing several instructions per clock cycle.counting machine-language instructions would be misleading because they can do varying amounts of work in different isas. the \"instruction\" in the standard measurements is not a count of the isa\\'s machine-language instructions, but a unit of measurement, usually based on the speed of the vax computer architecture.many people used to measure a computer\\'s speed by the clock rate (usually in mhz or ghz). this refers to the cycles per second of the main clock of the cpu. however, this metric is somewhat misleading, as a machine with a higher clock rate may not necessarily have greater performance. as a result, manufacturers have moved away from clock speed as a measure of performance.other factors influence speed, such as the mix of functional units, bus speeds, available memory, and the type and order of instructions in the programs.there are two main types of speed: latency and throughput. latency is the time between the start of a process and its completion. throughput is the amount of work done per unit time.  interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).performance is affected by a very wide range of design choices — for example, pipelining a processor usually makes latency worse, but makes throughput better. computers that control machinery usually need low interrupt latencies. these computers operate in a real-time environment and fail if an operation is not completed in a specified amount of time. for example, computer-controlled anti-lock brakes must begin braking within a predictable and limited time period after the brake pedal is sensed or else failure of the brake will occur.benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. although benchmarking shows strengths, it shouldn\\'t be how you choose a computer. often the measured machines split on different measures. for example, one system might handle scientific applications quickly, while another might render video games more smoothly. furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but don\\'t offer similar advantages to general tasks.=== power efficiency ===power efficiency is another important measurement in modern computers. a higher power efficiency can often be traded for lower speed or higher cost. the typical measurement when referring to power consumption in computer architecture is mips/w (millions of instructions per second per watt).modern circuits have less power required per transistor as the number of transistors per chip grows. this is because each transistor that is put in a new chip requires its own power supply and requires new pathways to be built to power it. however the number of transistors per chip is starting to increase at a slower rate. therefore, power efficiency is starting to become as important, if not more important than fitting more and more transistors into a single chip. recent processor designs have shown this emphasis as they put more focus on power efficiency rather than cramming as many transistors into a single chip as possible. in the world of embedded computers, power efficiency has long been an important goal next to throughput and latency.=== shifts in market demand ===increases in clock frequency have grown more slowly over the past few years, compared to power reduction improvements. this has been driven by the end of moore\\'s law and demand for longer battery life and reductions in size for mobile technology. this change in focus from higher clock rates to power consumption and miniaturization can be shown by the significant reductions in power consumption, as much as 50%, that were reported by intel in their release of the haswell microarchitecture; where they dropped their power consumption benchmark from 30 to 40 watts down to 10-20 watts. comparing this to the processing speed increase of 3 ghz to 4 ghz (2002 to 2006) it can be seen that the focus in research and development are shifting away from clock frequency and moving towards consuming less power and taking up less space.'], 'see also': ['', 'integer (computer science)', ''], 'reference': ['', '', '=== general ==='], 'source': ['john l. hennessy and david patterson (2006). computer architecture: a quantitative approach (fourth ed.). morgan kaufmann. isbn 978-0-12-370490-0.barton, robert s., \"functional design of computers\", communications of the acm 4(9): 405 (1961).barton, robert s., \"a new approach to the functional design of a digital computer\", proceedings of the western joint computer conference, may 1961, pp. 393–396. about the design of the burroughs b5000 computer.bell, c. gordon; and newell, allen (1971). \"computer structures: readings and examples\", mcgraw-hill.blaauw, g.a., and brooks, f.p., jr., \"the structure of system/360, part i-outline of the logical structure\", ibm systems journal, vol. 3, no. 2, pp. 119–135, 1964.tanenbaum, andrew s. (1979). structured computer organization. englewood cliffs, new jersey: prentice-hall. isbn 0-13-148521-0.'], 'external link': ['isca: proceedings of the international symposium on computer architecturemicro: ieee/acm international symposium on microarchitecturehpca: international symposium on high performance computer architectureasplos: international conference on architectural support for programming languages and operating systemsacm transactions on architecture and code optimizationieee transactions on computersthe von neumann architecture of computer systems', '\"automatic pipelining from transactional datapath specifications\" (pdf). retrieved 23 july 2014.tulsen, dean (18 january 2005). \"pipeline hazards\" (pdf).'], 'uses of word': ['depending on how a computer is organized, word-size units may be used for:fixed-point numbersholders for fixed point, usually integer, numerical values may be available in one or in several different sizes, but one of the sizes available will almost always be the word. the other sizes, if any, are likely to be multiples or fractions of the word size. the smaller sizes are normally used only for efficient use of memory; when loaded into the processor, their values usually go into a larger, word sized holder.floating-point numbersholders for floating-point numerical values are typically either a word or a multiple of a word.addressesholders for memory addresses must be of a size capable of expressing the needed range of values but not be excessively large, so often the size used is the word though it can also be a multiple or fraction of the word size.registersprocessor registers are designed with a size appropriate for the type of data they hold, e.g. integers, floating-point numbers, or addresses. many computer architectures use general-purpose registers that are capable of storing data in multiple representations.memory–processor transferwhen the processor reads from the memory subsystem into a register or writes a register\\'s value to memory, the amount of data transferred is often a word. historically, this amount of bits which could be transferred in one cycle was also called a catena in some environments (such as the bull gamma 60). in simple memory subsystems, the word is transferred over the memory data bus, which typically has a width of a word or half-word. in memory subsystems that use caches, the word-sized transfer is the one between the processor and the first level of cache; at lower levels of the memory hierarchy larger transfers (which are a multiple of the word size) are normally used.unit of address resolutionin a given architecture, successive address values designate successive units of memory; this unit is the unit of address resolution. in most computers, the unit is either a character (e.g. a byte) or a word. (a few computers have used bit resolution.) if the unit is a word, then a larger amount of memory can be accessed using an address of a given size at the cost of added complexity to access individual characters. on the other hand, if the unit is a byte, then individual characters can be addressed (i.e. selected during the memory operation).instructionsmachine instructions are normally the size of the architecture\\'s word, such as in risc architectures, or a multiple of the \"char\" size that is a fraction of it. this is a natural choice since instructions and data usually share the same memory subsystem. in harvard architectures the word sizes of instructions and data need not be related, as instructions and data are stored in different memories; for example, the processor in the 1ess electronic telephone switch had 37-bit instructions and 23-bit data words.'], 'word size choice': ['when a computer architecture is designed, the choice of a word size is of substantial importance.  there are design considerations which encourage particular bit-group sizes for particular uses (e.g. for addresses), and these considerations point to different sizes for different uses.  however, considerations of economy in design strongly push for one size, or a very few sizes related by multiples or fractions (submultiples) to a primary size.  that preferred size becomes the word size of the architecture.character size was in the past (pre-variable-sized character encoding) one of the influences on unit of address resolution and the choice of word size.  before the mid-1960s, characters were most often stored in six bits; this allowed no more than 64 characters, so the alphabet was limited to upper case.  since it is efficient in time and space to have the word size be a multiple of the character size, word sizes in this period were usually multiples of 6 bits (in binary machines).  a common choice then was the 36-bit word, which is also a good size for the numeric properties of a floating point format.after the introduction of the ibm system/360 design, which used eight-bit characters and supported lower-case letters, the standard size of a character (or more accurately, a byte) became eight bits.  word sizes thereafter were naturally multiples of eight bits, with 16, 32, and 64 bits being commonly used.=== variable-word architectures ===early machine designs included some that used what is often termed a variable word length.  in this type of organization, an operand had no fixed length. depending on the machine and the instruction, the length might be denoted by a count field, by a delimiting character, or by an additional bit called, e.g., flag, word mark.  such machines often used binary-coded decimal in 4-bit digits, or in 6-bit characters, for numbers.  this class of machines included the ibm 702, ibm 705, ibm 7080, ibm 7010, univac 1050, ibm 1401, ibm 1620, and rca 301.most of these machines work on one unit of memory at a time and since each instruction or datum is several units long, each instruction takes several cycles just to access memory.  these machines are often quite slow because of this.  for example, instruction fetches on an ibm 1620 model i take 8 cycles just to read the 12 digits of the instruction (the model ii reduced this to 6 cycles, or 4 cycles if the instruction did not need both address fields). instruction execution took a completely variable number of cycles, depending on the size of the operands.=== word, bit and byte addressing ===the memory model of an architecture is strongly influenced by the word size.  in particular, the resolution of a memory address, that is, the smallest unit that can be designated by an address, has often been chosen to be the word.  in this approach, the word-addressable machine approach, address values which differ by one designate adjacent memory words.  this is natural in machines which deal almost always in word (or multiple-word) units, and has the advantage of allowing instructions to use minimally sized fields to contain addresses, which can permit a smaller instruction size or a larger variety of instructions.when byte processing is to be a significant part of the workload, it is usually more advantageous to use the byte, rather than the word, as the unit of address resolution. address values which differ by one designate adjacent bytes in memory.  this allows an arbitrary character within a character string to be addressed straightforwardly.  a word can still be addressed, but the address to be used requires a few more bits than the word-resolution alternative.  the word size needs to be an integer multiple of the character size in this organization.  this addressing approach was used in the ibm 360, and has been the most common approach in machines designed since then.when the workload involves processing fields of different sizes, it can be advantageous to address to the bit. machines with bit addressing may have some instructions that use a programmer-defined byte size and other instructions that operate on fixed data sizes. as an example, on the ibm 7030 (\"stretch\"), a floating point instruction can only address words while an integer arithmetic instruction can specify a field length of 1-64 bits, a byte size of 1-8 bits and an accumulator offset of 0-127 bits. in at byte-addressable machine with storage-to-storage (ss) instructions, there are typically move instructions to copy one or multiple bytes from one arbitrary location to another. in a byte-oriented (byte-addressable) machine without ss instructions, moving a single byte from one arbitrary location to another is typically:load the source bytestore the result back in the target byteindividual bytes can be accessed on a word-oriented machine in one of two ways.  bytes can be manipulated by a combination of shift and mask operations in registers. moving a single byte from one arbitrary location to another may require the equivalent of the following:load the word containing the source byteshift the source word to align the desired byte to the correct position in the target wordand the source word with a mask to zero out all but the desired bitsload the word containing the target byteand the target word with a mask to zero out the target byteor the registers containing the source and target words to insert the source bytestore the result back in the target locationalternatively many word-oriented machines implement byte operations with instructions using special byte pointers in registers or memory.  for example, the pdp-10 byte pointer contained the size of the byte in bits (allowing different-sized bytes to be accessed), the bit position of the byte within the word, and the word address of the data.  instructions could automatically adjust the pointer to the next byte on, for example, load and deposit (store) operations.=== powers of two ===different amounts of memory are used to store data values with different degrees of precision. the commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word).  converting the index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. in some cases this relationship can also avoid the use of division operations. as a result, most modern computer designs have word sizes (and other operand sizes) that are a power of two times the size of a byte.'], 'size familie': ['as computer designs have grown more complex, the central importance of a single word size to an architecture has decreased.  although more capable hardware can use a wider variety of sizes of data, market forces exert pressure to maintain backward compatibility while extending processor capability.  as a result, what might have been the central word size in a fresh design has to coexist as an alternative size to the original word size in a backward compatible design. the original word size remains available in future designs, forming the basis of a size family.in the mid-1970s, dec designed the vax to be a 32-bit successor of the 16-bit pdp-11. they used word for a 16-bit quantity, while longword referred to a 32-bit quantity; this terminology is the same as the terminology used for the pdp-11. this was in contrast to earlier machines, where the natural unit of addressing memory would be called a word, while a quantity that is one half a word would be called a halfword. in fitting with this scheme, a vax quadword is 64 bits.  they continued this 16-bit word/32-bit longword/64-bit quadword terminology with the 64-bit alpha.another example is the x86 family, of which processors of three different word lengths (16-bit, later 32- and 64-bit) have been released, while word continues to designate a 16-bit quantity. as software is routinely ported from one word-length to the next, some apis and documentation define or refer to an older (and thus shorter) word-length than the full word length on the cpu that software may be compiled for. also, similar to how bytes are used for small numbers in many programs, a shorter word (16 or 32 bits) may be used in contexts where the range of a wider word is not needed (especially where this can save considerable stack space or cache memory space). for example, microsoft\\'s windows api maintains the programming language definition of word as 16 bits, despite the fact that the api may be used on a 32- or 64-bit x86 processor, where the standard word size would be 32 or 64 bits, respectively. data structures containing such different sized words refer to them as:word (16 bits/2 bytes)dword (32 bits/4 bytes)qword (64 bits/8 bytes)a similar phenomenon has developed in intel\\'s x86 assembly language – because of the support for various sizes (and backward compatibility) in the instruction set, some instruction mnemonics carry \"d\" or \"q\" identifiers denoting \"double-\", \"quad-\" or \"double-quad-\", which are in terms of the architecture\\'s original 16-bit word size.an example with a different word size is the ibm system/360 family. in the system/360 architecture, system/370 architecture and system/390 architecture, there are 8-bit bytes, 16-bit halfwords, 32-bit words and 64-bit doublewords. the z/architecture, which is the 64-bit member of that architecture family, continues to refer to 16-bit halfwords, 32-bit words, and 64-bit doublewords, and additionally features 128-bit quadwords.in general, new processors must use the same data word lengths and virtual address widths as an older processor to have binary compatibility with that older processor.often carefully written source code – written with source-code compatibility and software portability in mind – can be recompiled to run on a variety of processors, even ones with different data word lengths or different address widths or both.'], 'table of word size': [''], 'note': [''], 'background': ['instructions in a pipelined processor are performed in several stages, so that at any given time several instructions are being processed in the various stages of the pipeline, such as fetch and execute. there are many different instruction pipeline microarchitectures, and instructions may be executed out-of-order. a hazard occurs when two or more of these simultaneous (possibly out of order) instructions conflict.'], 'type': ['=== data hazards ===data hazards occur when instructions that exhibit data dependence modify data in different stages of a pipeline. ignoring potential data hazards can result in race conditions (also termed race hazards). there are three situations in which a data hazard can occur:read after write (raw), a true dependencywrite after read (war), an anti-dependencywrite after write (waw), an output dependencyread after read (rar) is not a hazard case.consider two instructions i1 and i2, with i1 occurring before i2 in program order.==== read after write (raw) ====(i2 tries to read a source before i1 writes to it)a read after write (raw) data hazard refers to a situation where an instruction refers to a result that has not yet been calculated or retrieved. this can occur because even though an instruction is executed after a prior instruction, the prior instruction has been processed only partly through the pipeline.===== example =====for example:i1. r2 <- r5 + r3i2. r4 <- r2 + r3the first instruction is calculating a value to be saved in register r2, and the second is going to use this value to compute a result for register r4. however, in a pipeline, when operands are fetched for the 2nd operation, the results from the first have not yet been saved, and hence a data dependency occurs.a data dependency occurs with instruction i2, as it is dependent on the completion of instruction i1.==== write after read (war) ====(i2 tries to write a destination before it is read by i1)a write after read (war) data hazard represents a problem with concurrent execution.===== example =====for example:i1. r4 <- r1 + r5i2. r5 <- r1 + r2in any situation with a chance that i2 may finish before i1 (i.e., with concurrent execution), it must be ensured that the result of register r5 is not stored before i1 has had a chance to fetch the operands.==== write after write (waw) ====(i2 tries to write an operand before it is written by i1)a write after write (waw) data hazard may occur in a concurrent execution environment.===== example =====for example:i1. r2 <- r4 + r7i2. r2 <- r1 + r3the write back (wb) of i2 must be delayed until i1 finishes executing.=== structural hazards ===a structural hazard occurs when two (or more) instructions that are already in pipeline need the same resource. the result is that instruction must be executed in series rather than parallel for a portion of pipeline. structural hazards are sometime referred to as resource hazards.example:a situation in which multiple instructions are ready to enter the execute instruction phase and there is a single alu (arithmetic logic unit). one solution to such resource hazard is to increase available resources, such as having multiple ports into main memory and multiple alu (arithmetic logic unit) units.=== control hazards (branch hazards or instruction hazards) ===control hazard occurs when the pipeline makes wrong decisions on branch prediction and therefore brings instructions into the pipeline that must subsequently be discarded. the term branch hazard also refers to a control hazard.'], 'eliminating hazard': ['=== generic ======= pipeline bubbling ====bubbling the pipeline, also termed a pipeline break or pipeline stall, is a method to preclude data, structural, and branch hazards. as instructions are fetched, control logic determines whether a hazard could/will occur. if this is true, then the control logic inserts no operations (nops) into the pipeline. thus, before the next instruction (which would cause the hazard) executes, the prior one will have had sufficient time to finish and prevent the hazard. if the number of nops equals the number of stages in the pipeline, the processor has been cleared of all instructions and can proceed free from hazards. all forms of stalling introduce a delay before the processor can resume execution.flushing the pipeline occurs when a branch instruction jumps to a new memory location, invalidating all prior stages in the pipeline.  these prior stages are cleared, allowing the pipeline to continue at the new instruction indicated by the branch.=== data hazards ===there are several main solutions and algorithms used to resolve data hazards:insert a pipeline bubble whenever a read after write (raw) dependency is encountered, guaranteed to increase latency, oruse out-of-order execution to potentially prevent the need for pipeline bubblesuse operand forwarding to use data from later stages in the pipelinein the case of out-of-order execution, the algorithm used can be:scoreboarding, in which case a pipeline bubble is needed only when there is no functional unit availablethe tomasulo algorithm, which uses register renaming, allowing continual issuing of instructionsthe task of removing data dependencies can be delegated to the compiler, which can fill in an appropriate number of nop instructions between dependent instructions to ensure correct operation, or re-order instructions where possible.==== operand forwarding ======== examples ====in the following examples, computed values are in bold, while register numbers are not.for example, to write the value 3 to register 1, (which already contains a 6), and then add 7 to register 1 and store the result in register 2, i.e.:i0: r1 = 6i1: r1 = 3i2: r2 = r1 + 7 = 10following execution, register 2 should contain the value 10. however, if i1 (write 3 to register 1) does not fully exit the pipeline before i2 starts executing, it means that r1 does not contain the value 3 when i2 performs its addition. in such an event, i2 adds 7 to the old value of register 1 (6), and so register 2 contains 13 instead, i.e.:i0: r1 = 6i2: r2 = r1 + 7 = 13i1: r1 = 3this error occurs because i2 reads register 1 before i1 has committed/stored the result of its write operation to register 1. so when i2 is reading the contents of register 1, register 1 still contains 6, not 3.forwarding (described below) helps correct such errors by depending on the fact that the output of i1 (which is 3) can be used by subsequent instructions before the value 3 is committed to/stored in register 1.forwarding applied to the example means that there is no wait to commit/store the output of i1 in register 1 (in this example, the output is 3) before making that output available to the subsequent instruction (in this case, i2). the effect is that i2 uses the correct (the more recent) value of register 1: the commit/store was made immediately and not pipelined.with forwarding enabled, the instruction decode/execution (id/ex) stage of the pipeline now has two inputs: the value read from the register specified (in this example, the value 6 from register 1), and the new value of register 1 (in this example, this value is 3) which is sent from the next stage instruction execute/memory access (ex/mem). added control logic is used to determine which input to use.=== control hazards (branch hazards) ===to avoid control hazards microarchitectures can:insert a pipeline bubble (discussed above), guaranteed to increase latency, oruse branch prediction and essentially make educated guesses about which instructions to insert, in which case a pipeline bubble will only be needed in the case of an incorrect predictionin the event that a branch causes a pipeline bubble after incorrect instructions have entered the pipeline, care must be taken to prevent any of the wrongly-loaded instructions from having any effect on the processor state excluding energy wasted processing them before they were discovered to be loaded incorrectly.=== other techniques ===memory latency is another factor that designers must attend to, because the delay could reduce performance. different types of memory have different accessing time to the memory. thus, by choosing a suitable type of memory, designers can improve the performance of the pipelined data path.']})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['overview', 'types of multithreading', 'implementation specific']\n",
      "defaultdict(<class 'list'>, {'intro': ['in computer engineering, computer architecture is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. the architecture of a system refers to its structure in terms of separately specified components of that system and their interrelationships.some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation. in other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation.', 'in computing, a word is the natural unit of data used by a particular processor design. a word is a fixed-sized datum handled as a unit by the instruction set or the hardware of the processor. the number of bits or digits in a word (the word size, word width, or word length) is an important characteristic of any specific processor design or computer architecture.the size of a word is reflected in many aspects of a computer\\'s structure and operation; the majority of the registers in a processor are usually word sized and the largest datum that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. the largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used).documentation for computers with fixed word size commonly stated memory sizes in words rather than bytes or characters.  the documentation sometimes used metric prefixes correctly, sometimes with rounding, e.g., 65 kilowords (kw) meaning for 65536 words, and sometimes used them incorrectly, with kilowords (kw) meaning 1024 words (210) and megawords (mw) meaning 1,048,576 words (220). with standardization on 8-bit bytes and byte addressability, stating memory sizes in bytes, kilobytes, and megabytes with powers of 1024 rather than 1000 has become the norm, although there is some use of the iec binary prefixes.several of the earliest computers (and a few modern as well) used binary-coded decimal rather than plain binary, typically having a word size of 10 or 12 decimal digits, and some early decimal computers had no fixed word length at all. early binary systems tended to use word lengths that were some multiple of 6-bits, with the 36-bit word being especially common on mainframe computers. the introduction of ascii led to the move to systems with word lengths that were a multiple of 8-bits, with 16-bit machines being popular in the 1970s before the move to modern processors with 32 or 64 bits. special-purpose designs like digital signal processors, may have any word length from 4 to 80 bits.the size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. if multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see size families below).', 'in the domain of central processing unit (cpu) design, hazards are problems with the instruction pipeline in cpu microarchitectures when the next instruction cannot execute in the following clock cycle, and can potentially lead to incorrect computation results. three common types of hazards are data hazards, structural hazards, and control hazards (branching hazards).there are several methods used to deal with hazards, including pipeline stalls/pipeline bubbling, operand forwarding, and in the case of out-of-order execution, the scoreboarding method and the tomasulo algorithm.', 'in computer architecture, multithreading is the ability of a central processing unit (cpu) (or a single core in a multi-core processor) to provide multiple threads of execution concurrently, supported by the operating system. this approach differs from multiprocessing. in a multithreaded application, the threads share the resources of a single or multiple cores, which include the computing units, the cpu caches, and the translation lookaside buffer (tlb).where multiprocessing systems include multiple complete processing units in one or more cores, multithreading aims to increase utilization of a single core by using thread-level parallelism, as well as instruction-level parallelism. as the two techniques are complementary, they are combined in nearly all modern systems architectures with multiple multithreading cpus and with cpus with multiple multithreading cores.'], 'history': ['the first documented computer architecture was in the correspondence between charles babbage and ada lovelace, describing the analytical engine. when building the computer z1 in 1936, konrad zuse described in two patent applications for his future projects that machine instructions could be stored in the same storage used for data, i.e., the stored-program concept. two other early and important examples are:john von neumann\\'s 1945 paper, first draft of a report on the edvac, which described an organization of logical elements; andalan turing\\'s more detailed proposed electronic calculator for the automatic computing engine, also 1945 and which cited john von neumann\\'s paper.the term “architecture” in computer literature can be traced to the work of lyle r. johnson and frederick p. brooks, jr., members of the machine organization department in ibm\\'s main research center in 1959. johnson had the opportunity to write a proprietary research communication about the stretch, an ibm-developed supercomputer for los alamos national laboratory (at the time known as los alamos scientific laboratory). to describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that seemed more useful than “machine organization”.subsequently, brooks, a stretch designer, opened chapter 2 of a book called planning a computer system: project stretch by stating, “computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.”brooks went on to help develop the ibm system/360 (now called the ibm zseries) line of computers, in which “architecture” became a noun defining “what the user needs to know”. later, computer users came to use the term in many less explicit ways.the earliest computer architectures were designed on paper and then directly built into the final hardware form.later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (ttl) computer—such as the prototypes of the 6800 and the pa-risc—tested, and tweaked, before committing to the final hardware form.as of the 1990s, new computer architectures are typically \"built\", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a fpga as a soft microprocessor; or both—before committing to the final hardware form.'], 'subcategorie': ['the discipline of computer architecture has three main subcategories:instruction set architecture (isa): defines the machine code that a processor reads and acts upon as well as the word size, memory address modes, processor registers, and data type.microarchitecture: also known as \"computer organization\", this describes how a particular processor will implement the isa. the size of a computer\\'s cpu cache for instance, is an issue that generally has nothing to do with the isa.systems design: includes all of the other hardware components within a computing system, such as data processing other than the cpu (e.g., direct memory access), virtualization, and multiprocessing.there are other technologies in computer architecture. the following technologies are used in bigger companies like intel, and were estimated in 2002 to count for 1% of all of computer architecture:macroarchitecture: architectural layers more abstract than microarchitectureassembly instruction set architecture: a smart assembler may convert an abstract assembly language common to a group of machines into slightly different machine language for different implementations.programmer-visible macroarchitecture: higher-level language tools such as compilers may define a consistent interface or contract to programmers using them, abstracting differences between underlying isa, uisa, and microarchitectures. for example, the c, c++, or java standards define different programmer-visible macroarchitectures.microcode: microcode is software that translates instructions to run on a chip. it acts like a wrapper around the hardware, presenting a preferred version of the hardware\\'s instruction set interface. this instruction translation facility gives chip designers flexible options: e.g. 1. a new improved version of the chip can use microcode to present the exact same instruction set as the old chip version, so all software targeting that instruction set will run on the new chip without needing changes. e.g. 2. microcode can present a variety of instruction sets for the same underlying chip, allowing it to run a wider variety of software.uisa: user instruction set architecture, refers to one of three subsets of the risc cpu instructions provided by powerpc risc processors. the uisa subset, are those risc instructions of interest to application developers. the other two subsets are vea (virtual environment architecture) instructions used by virtualization system developers, and oea (operating environment architecture) used by operation system developers.pin architecture: the hardware functions that a microprocessor should provide to a hardware platform, e.g., the x86 pins a20m, ferr/ignne or flush. also, messages that the processor should emit so that external caches can be invalidated (emptied). pin architecture functions are more flexible than isa functions because external hardware can adapt to new encodings, or change from a pin to a message. the term \"architecture\" fits, because the functions must be provided for compatible systems, even if the detailed method changes.'], 'role': [\"=== definition ===computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. the case of instruction set architecture can be used to illustrate the balance of these competing factors. more complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 loop instruction). however, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. the increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.the implementation involves integrated circuit design, packaging, power, and cooling. optimization of the design requires familiarity with compilers, operating systems to logic design, and packaging.=== instruction set architecture ===an instruction set architecture (isa) is the interface between the computer's software and hardware and also can be viewed as the programmer's view of the machine. computers do not understand high-level programming languages such as java, c++, or most programming languages used. a processor only understands instructions encoded in some numerical fashion, usually as binary numbers. software tools, such as compilers, translate those high level languages into instructions that the processor can understand.besides instructions, the isa defines items in the computer that are available to a program—e.g., data types, registers, addressing modes, and memory.  instructions locate these available items with register indexes (or names) and memory addressing modes.the isa of a computer is usually described in a small instruction manual, which describes how the instructions are encoded. also, it may define short (vaguely) mnemonic names for the instructions. the names can be recognized by a software development tool called an assembler.  an assembler is a computer program that translates a human-readable form of the isa into a computer-readable form.  disassemblers are also widely available, usually in debuggers and software programs to isolate and correct malfunctions in binary computer programs.isas vary in quality and completeness.  a good isa compromises between programmer convenience (how easy the code is to understand), size of the code (how much code is required to do a specific action), cost of the computer to interpret the instructions (more complexity means more hardware needed to decode and execute the instructions), and speed of the computer (with more complex decoding hardware comes longer decode time).  memory organization defines how instructions interact with the memory, and how memory interacts with itself.during design emulation, emulators can run programs written in a proposed instruction set. modern emulators can measure size, cost, and speed to determine whether a particular isa is meeting its goals.=== computer organization ===computer organization helps optimize performance-based products. for example, software engineers need to know the processing power of processors. they may need to optimize software in order to gain the most performance for the lowest price. this can require quite a detailed analysis of the computer's organization.  for example, in an sd card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.computer organization also helps plan the selection of a processor for a particular project. multimedia projects may need very rapid data access, while virtual machines may need fast interrupts. sometimes certain tasks need additional components as well.  for example, a computer capable of running a virtual machine needs virtual memory hardware so that the memory of different virtual computers can be kept separated. computer organization and features also affect power consumption and processor cost.=== implementation ===once an instruction set and micro-architecture have been designed, a practical machine must be developed. this design process is called the implementation. implementation is usually not considered architectural design, but rather hardware design engineering. implementation can be further broken down into several steps:logic implementation designs the circuits required at a logic-gate level.circuit implementation does transistor-level designs of basic elements (e.g., gates, multiplexers, latches) as well as of some larger blocks (alus, caches etc.) that may be implemented at the logic-gate level, or even at the physical level if the design calls for it.physical implementation draws physical circuits.  the different circuit components are placed in a chip floor plan or on a board and the wires connecting them are created.design validation tests the computer as a whole to see if it works in all situations and all timings. once the design validation process starts, the design at the logic level are tested using logic emulators. however, this is usually too slow to run a realistic test.  so, after making corrections based on the first test, prototypes are constructed using field-programmable gate-arrays (fpgas). most hobby projects stop at this stage.  the final step is to test prototype integrated circuits, which may require several redesigns.for cpus, the entire implementation process is organized differently and is often referred to as cpu design.\"], 'design goal': ['the exact form of a computer system depends on the constraints and goals. computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.the most common scheme does an in-depth power analysis and figures out how to keep power consumption low while maintaining adequate performance.=== performance ===modern computer performance is often described in instructions per cycle (ipc), which measures the efficiency of the architecture at any clock frequency; a faster ipc rate means the computer is faster. older computers had ipc counts as low as 0.1 while modern processors easily reach near 1. superscalar processors may reach three to five ipc by executing several instructions per clock cycle.counting machine-language instructions would be misleading because they can do varying amounts of work in different isas. the \"instruction\" in the standard measurements is not a count of the isa\\'s machine-language instructions, but a unit of measurement, usually based on the speed of the vax computer architecture.many people used to measure a computer\\'s speed by the clock rate (usually in mhz or ghz). this refers to the cycles per second of the main clock of the cpu. however, this metric is somewhat misleading, as a machine with a higher clock rate may not necessarily have greater performance. as a result, manufacturers have moved away from clock speed as a measure of performance.other factors influence speed, such as the mix of functional units, bus speeds, available memory, and the type and order of instructions in the programs.there are two main types of speed: latency and throughput. latency is the time between the start of a process and its completion. throughput is the amount of work done per unit time.  interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).performance is affected by a very wide range of design choices — for example, pipelining a processor usually makes latency worse, but makes throughput better. computers that control machinery usually need low interrupt latencies. these computers operate in a real-time environment and fail if an operation is not completed in a specified amount of time. for example, computer-controlled anti-lock brakes must begin braking within a predictable and limited time period after the brake pedal is sensed or else failure of the brake will occur.benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. although benchmarking shows strengths, it shouldn\\'t be how you choose a computer. often the measured machines split on different measures. for example, one system might handle scientific applications quickly, while another might render video games more smoothly. furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but don\\'t offer similar advantages to general tasks.=== power efficiency ===power efficiency is another important measurement in modern computers. a higher power efficiency can often be traded for lower speed or higher cost. the typical measurement when referring to power consumption in computer architecture is mips/w (millions of instructions per second per watt).modern circuits have less power required per transistor as the number of transistors per chip grows. this is because each transistor that is put in a new chip requires its own power supply and requires new pathways to be built to power it. however the number of transistors per chip is starting to increase at a slower rate. therefore, power efficiency is starting to become as important, if not more important than fitting more and more transistors into a single chip. recent processor designs have shown this emphasis as they put more focus on power efficiency rather than cramming as many transistors into a single chip as possible. in the world of embedded computers, power efficiency has long been an important goal next to throughput and latency.=== shifts in market demand ===increases in clock frequency have grown more slowly over the past few years, compared to power reduction improvements. this has been driven by the end of moore\\'s law and demand for longer battery life and reductions in size for mobile technology. this change in focus from higher clock rates to power consumption and miniaturization can be shown by the significant reductions in power consumption, as much as 50%, that were reported by intel in their release of the haswell microarchitecture; where they dropped their power consumption benchmark from 30 to 40 watts down to 10-20 watts. comparing this to the processing speed increase of 3 ghz to 4 ghz (2002 to 2006) it can be seen that the focus in research and development are shifting away from clock frequency and moving towards consuming less power and taking up less space.'], 'see also': ['', 'integer (computer science)', '', 'super-threadingspeculative multithreading'], 'reference': ['', '', '=== general ===', ''], 'source': ['john l. hennessy and david patterson (2006). computer architecture: a quantitative approach (fourth ed.). morgan kaufmann. isbn 978-0-12-370490-0.barton, robert s., \"functional design of computers\", communications of the acm 4(9): 405 (1961).barton, robert s., \"a new approach to the functional design of a digital computer\", proceedings of the western joint computer conference, may 1961, pp. 393–396. about the design of the burroughs b5000 computer.bell, c. gordon; and newell, allen (1971). \"computer structures: readings and examples\", mcgraw-hill.blaauw, g.a., and brooks, f.p., jr., \"the structure of system/360, part i-outline of the logical structure\", ibm systems journal, vol. 3, no. 2, pp. 119–135, 1964.tanenbaum, andrew s. (1979). structured computer organization. englewood cliffs, new jersey: prentice-hall. isbn 0-13-148521-0.'], 'external link': ['isca: proceedings of the international symposium on computer architecturemicro: ieee/acm international symposium on microarchitecturehpca: international symposium on high performance computer architectureasplos: international conference on architectural support for programming languages and operating systemsacm transactions on architecture and code optimizationieee transactions on computersthe von neumann architecture of computer systems', '\"automatic pipelining from transactional datapath specifications\" (pdf). retrieved 23 july 2014.tulsen, dean (18 january 2005). \"pipeline hazards\" (pdf).', 'a survey of processors with explicit multithreading, acm, march 2003, by theo ungerer, borut robi and jurij silcoperating system | difference between multitasking, multithreading and multiprocessing geeksforgeeks, 6 sept. 2018.'], 'uses of word': ['depending on how a computer is organized, word-size units may be used for:fixed-point numbersholders for fixed point, usually integer, numerical values may be available in one or in several different sizes, but one of the sizes available will almost always be the word. the other sizes, if any, are likely to be multiples or fractions of the word size. the smaller sizes are normally used only for efficient use of memory; when loaded into the processor, their values usually go into a larger, word sized holder.floating-point numbersholders for floating-point numerical values are typically either a word or a multiple of a word.addressesholders for memory addresses must be of a size capable of expressing the needed range of values but not be excessively large, so often the size used is the word though it can also be a multiple or fraction of the word size.registersprocessor registers are designed with a size appropriate for the type of data they hold, e.g. integers, floating-point numbers, or addresses. many computer architectures use general-purpose registers that are capable of storing data in multiple representations.memory–processor transferwhen the processor reads from the memory subsystem into a register or writes a register\\'s value to memory, the amount of data transferred is often a word. historically, this amount of bits which could be transferred in one cycle was also called a catena in some environments (such as the bull gamma 60). in simple memory subsystems, the word is transferred over the memory data bus, which typically has a width of a word or half-word. in memory subsystems that use caches, the word-sized transfer is the one between the processor and the first level of cache; at lower levels of the memory hierarchy larger transfers (which are a multiple of the word size) are normally used.unit of address resolutionin a given architecture, successive address values designate successive units of memory; this unit is the unit of address resolution. in most computers, the unit is either a character (e.g. a byte) or a word. (a few computers have used bit resolution.) if the unit is a word, then a larger amount of memory can be accessed using an address of a given size at the cost of added complexity to access individual characters. on the other hand, if the unit is a byte, then individual characters can be addressed (i.e. selected during the memory operation).instructionsmachine instructions are normally the size of the architecture\\'s word, such as in risc architectures, or a multiple of the \"char\" size that is a fraction of it. this is a natural choice since instructions and data usually share the same memory subsystem. in harvard architectures the word sizes of instructions and data need not be related, as instructions and data are stored in different memories; for example, the processor in the 1ess electronic telephone switch had 37-bit instructions and 23-bit data words.'], 'word size choice': ['when a computer architecture is designed, the choice of a word size is of substantial importance.  there are design considerations which encourage particular bit-group sizes for particular uses (e.g. for addresses), and these considerations point to different sizes for different uses.  however, considerations of economy in design strongly push for one size, or a very few sizes related by multiples or fractions (submultiples) to a primary size.  that preferred size becomes the word size of the architecture.character size was in the past (pre-variable-sized character encoding) one of the influences on unit of address resolution and the choice of word size.  before the mid-1960s, characters were most often stored in six bits; this allowed no more than 64 characters, so the alphabet was limited to upper case.  since it is efficient in time and space to have the word size be a multiple of the character size, word sizes in this period were usually multiples of 6 bits (in binary machines).  a common choice then was the 36-bit word, which is also a good size for the numeric properties of a floating point format.after the introduction of the ibm system/360 design, which used eight-bit characters and supported lower-case letters, the standard size of a character (or more accurately, a byte) became eight bits.  word sizes thereafter were naturally multiples of eight bits, with 16, 32, and 64 bits being commonly used.=== variable-word architectures ===early machine designs included some that used what is often termed a variable word length.  in this type of organization, an operand had no fixed length. depending on the machine and the instruction, the length might be denoted by a count field, by a delimiting character, or by an additional bit called, e.g., flag, word mark.  such machines often used binary-coded decimal in 4-bit digits, or in 6-bit characters, for numbers.  this class of machines included the ibm 702, ibm 705, ibm 7080, ibm 7010, univac 1050, ibm 1401, ibm 1620, and rca 301.most of these machines work on one unit of memory at a time and since each instruction or datum is several units long, each instruction takes several cycles just to access memory.  these machines are often quite slow because of this.  for example, instruction fetches on an ibm 1620 model i take 8 cycles just to read the 12 digits of the instruction (the model ii reduced this to 6 cycles, or 4 cycles if the instruction did not need both address fields). instruction execution took a completely variable number of cycles, depending on the size of the operands.=== word, bit and byte addressing ===the memory model of an architecture is strongly influenced by the word size.  in particular, the resolution of a memory address, that is, the smallest unit that can be designated by an address, has often been chosen to be the word.  in this approach, the word-addressable machine approach, address values which differ by one designate adjacent memory words.  this is natural in machines which deal almost always in word (or multiple-word) units, and has the advantage of allowing instructions to use minimally sized fields to contain addresses, which can permit a smaller instruction size or a larger variety of instructions.when byte processing is to be a significant part of the workload, it is usually more advantageous to use the byte, rather than the word, as the unit of address resolution. address values which differ by one designate adjacent bytes in memory.  this allows an arbitrary character within a character string to be addressed straightforwardly.  a word can still be addressed, but the address to be used requires a few more bits than the word-resolution alternative.  the word size needs to be an integer multiple of the character size in this organization.  this addressing approach was used in the ibm 360, and has been the most common approach in machines designed since then.when the workload involves processing fields of different sizes, it can be advantageous to address to the bit. machines with bit addressing may have some instructions that use a programmer-defined byte size and other instructions that operate on fixed data sizes. as an example, on the ibm 7030 (\"stretch\"), a floating point instruction can only address words while an integer arithmetic instruction can specify a field length of 1-64 bits, a byte size of 1-8 bits and an accumulator offset of 0-127 bits. in at byte-addressable machine with storage-to-storage (ss) instructions, there are typically move instructions to copy one or multiple bytes from one arbitrary location to another. in a byte-oriented (byte-addressable) machine without ss instructions, moving a single byte from one arbitrary location to another is typically:load the source bytestore the result back in the target byteindividual bytes can be accessed on a word-oriented machine in one of two ways.  bytes can be manipulated by a combination of shift and mask operations in registers. moving a single byte from one arbitrary location to another may require the equivalent of the following:load the word containing the source byteshift the source word to align the desired byte to the correct position in the target wordand the source word with a mask to zero out all but the desired bitsload the word containing the target byteand the target word with a mask to zero out the target byteor the registers containing the source and target words to insert the source bytestore the result back in the target locationalternatively many word-oriented machines implement byte operations with instructions using special byte pointers in registers or memory.  for example, the pdp-10 byte pointer contained the size of the byte in bits (allowing different-sized bytes to be accessed), the bit position of the byte within the word, and the word address of the data.  instructions could automatically adjust the pointer to the next byte on, for example, load and deposit (store) operations.=== powers of two ===different amounts of memory are used to store data values with different degrees of precision. the commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word).  converting the index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. in some cases this relationship can also avoid the use of division operations. as a result, most modern computer designs have word sizes (and other operand sizes) that are a power of two times the size of a byte.'], 'size familie': ['as computer designs have grown more complex, the central importance of a single word size to an architecture has decreased.  although more capable hardware can use a wider variety of sizes of data, market forces exert pressure to maintain backward compatibility while extending processor capability.  as a result, what might have been the central word size in a fresh design has to coexist as an alternative size to the original word size in a backward compatible design. the original word size remains available in future designs, forming the basis of a size family.in the mid-1970s, dec designed the vax to be a 32-bit successor of the 16-bit pdp-11. they used word for a 16-bit quantity, while longword referred to a 32-bit quantity; this terminology is the same as the terminology used for the pdp-11. this was in contrast to earlier machines, where the natural unit of addressing memory would be called a word, while a quantity that is one half a word would be called a halfword. in fitting with this scheme, a vax quadword is 64 bits.  they continued this 16-bit word/32-bit longword/64-bit quadword terminology with the 64-bit alpha.another example is the x86 family, of which processors of three different word lengths (16-bit, later 32- and 64-bit) have been released, while word continues to designate a 16-bit quantity. as software is routinely ported from one word-length to the next, some apis and documentation define or refer to an older (and thus shorter) word-length than the full word length on the cpu that software may be compiled for. also, similar to how bytes are used for small numbers in many programs, a shorter word (16 or 32 bits) may be used in contexts where the range of a wider word is not needed (especially where this can save considerable stack space or cache memory space). for example, microsoft\\'s windows api maintains the programming language definition of word as 16 bits, despite the fact that the api may be used on a 32- or 64-bit x86 processor, where the standard word size would be 32 or 64 bits, respectively. data structures containing such different sized words refer to them as:word (16 bits/2 bytes)dword (32 bits/4 bytes)qword (64 bits/8 bytes)a similar phenomenon has developed in intel\\'s x86 assembly language – because of the support for various sizes (and backward compatibility) in the instruction set, some instruction mnemonics carry \"d\" or \"q\" identifiers denoting \"double-\", \"quad-\" or \"double-quad-\", which are in terms of the architecture\\'s original 16-bit word size.an example with a different word size is the ibm system/360 family. in the system/360 architecture, system/370 architecture and system/390 architecture, there are 8-bit bytes, 16-bit halfwords, 32-bit words and 64-bit doublewords. the z/architecture, which is the 64-bit member of that architecture family, continues to refer to 16-bit halfwords, 32-bit words, and 64-bit doublewords, and additionally features 128-bit quadwords.in general, new processors must use the same data word lengths and virtual address widths as an older processor to have binary compatibility with that older processor.often carefully written source code – written with source-code compatibility and software portability in mind – can be recompiled to run on a variety of processors, even ones with different data word lengths or different address widths or both.'], 'table of word size': [''], 'note': [''], 'background': ['instructions in a pipelined processor are performed in several stages, so that at any given time several instructions are being processed in the various stages of the pipeline, such as fetch and execute. there are many different instruction pipeline microarchitectures, and instructions may be executed out-of-order. a hazard occurs when two or more of these simultaneous (possibly out of order) instructions conflict.'], 'type': ['=== data hazards ===data hazards occur when instructions that exhibit data dependence modify data in different stages of a pipeline. ignoring potential data hazards can result in race conditions (also termed race hazards). there are three situations in which a data hazard can occur:read after write (raw), a true dependencywrite after read (war), an anti-dependencywrite after write (waw), an output dependencyread after read (rar) is not a hazard case.consider two instructions i1 and i2, with i1 occurring before i2 in program order.==== read after write (raw) ====(i2 tries to read a source before i1 writes to it)a read after write (raw) data hazard refers to a situation where an instruction refers to a result that has not yet been calculated or retrieved. this can occur because even though an instruction is executed after a prior instruction, the prior instruction has been processed only partly through the pipeline.===== example =====for example:i1. r2 <- r5 + r3i2. r4 <- r2 + r3the first instruction is calculating a value to be saved in register r2, and the second is going to use this value to compute a result for register r4. however, in a pipeline, when operands are fetched for the 2nd operation, the results from the first have not yet been saved, and hence a data dependency occurs.a data dependency occurs with instruction i2, as it is dependent on the completion of instruction i1.==== write after read (war) ====(i2 tries to write a destination before it is read by i1)a write after read (war) data hazard represents a problem with concurrent execution.===== example =====for example:i1. r4 <- r1 + r5i2. r5 <- r1 + r2in any situation with a chance that i2 may finish before i1 (i.e., with concurrent execution), it must be ensured that the result of register r5 is not stored before i1 has had a chance to fetch the operands.==== write after write (waw) ====(i2 tries to write an operand before it is written by i1)a write after write (waw) data hazard may occur in a concurrent execution environment.===== example =====for example:i1. r2 <- r4 + r7i2. r2 <- r1 + r3the write back (wb) of i2 must be delayed until i1 finishes executing.=== structural hazards ===a structural hazard occurs when two (or more) instructions that are already in pipeline need the same resource. the result is that instruction must be executed in series rather than parallel for a portion of pipeline. structural hazards are sometime referred to as resource hazards.example:a situation in which multiple instructions are ready to enter the execute instruction phase and there is a single alu (arithmetic logic unit). one solution to such resource hazard is to increase available resources, such as having multiple ports into main memory and multiple alu (arithmetic logic unit) units.=== control hazards (branch hazards or instruction hazards) ===control hazard occurs when the pipeline makes wrong decisions on branch prediction and therefore brings instructions into the pipeline that must subsequently be discarded. the term branch hazard also refers to a control hazard.'], 'eliminating hazard': ['=== generic ======= pipeline bubbling ====bubbling the pipeline, also termed a pipeline break or pipeline stall, is a method to preclude data, structural, and branch hazards. as instructions are fetched, control logic determines whether a hazard could/will occur. if this is true, then the control logic inserts no operations (nops) into the pipeline. thus, before the next instruction (which would cause the hazard) executes, the prior one will have had sufficient time to finish and prevent the hazard. if the number of nops equals the number of stages in the pipeline, the processor has been cleared of all instructions and can proceed free from hazards. all forms of stalling introduce a delay before the processor can resume execution.flushing the pipeline occurs when a branch instruction jumps to a new memory location, invalidating all prior stages in the pipeline.  these prior stages are cleared, allowing the pipeline to continue at the new instruction indicated by the branch.=== data hazards ===there are several main solutions and algorithms used to resolve data hazards:insert a pipeline bubble whenever a read after write (raw) dependency is encountered, guaranteed to increase latency, oruse out-of-order execution to potentially prevent the need for pipeline bubblesuse operand forwarding to use data from later stages in the pipelinein the case of out-of-order execution, the algorithm used can be:scoreboarding, in which case a pipeline bubble is needed only when there is no functional unit availablethe tomasulo algorithm, which uses register renaming, allowing continual issuing of instructionsthe task of removing data dependencies can be delegated to the compiler, which can fill in an appropriate number of nop instructions between dependent instructions to ensure correct operation, or re-order instructions where possible.==== operand forwarding ======== examples ====in the following examples, computed values are in bold, while register numbers are not.for example, to write the value 3 to register 1, (which already contains a 6), and then add 7 to register 1 and store the result in register 2, i.e.:i0: r1 = 6i1: r1 = 3i2: r2 = r1 + 7 = 10following execution, register 2 should contain the value 10. however, if i1 (write 3 to register 1) does not fully exit the pipeline before i2 starts executing, it means that r1 does not contain the value 3 when i2 performs its addition. in such an event, i2 adds 7 to the old value of register 1 (6), and so register 2 contains 13 instead, i.e.:i0: r1 = 6i2: r2 = r1 + 7 = 13i1: r1 = 3this error occurs because i2 reads register 1 before i1 has committed/stored the result of its write operation to register 1. so when i2 is reading the contents of register 1, register 1 still contains 6, not 3.forwarding (described below) helps correct such errors by depending on the fact that the output of i1 (which is 3) can be used by subsequent instructions before the value 3 is committed to/stored in register 1.forwarding applied to the example means that there is no wait to commit/store the output of i1 in register 1 (in this example, the output is 3) before making that output available to the subsequent instruction (in this case, i2). the effect is that i2 uses the correct (the more recent) value of register 1: the commit/store was made immediately and not pipelined.with forwarding enabled, the instruction decode/execution (id/ex) stage of the pipeline now has two inputs: the value read from the register specified (in this example, the value 6 from register 1), and the new value of register 1 (in this example, this value is 3) which is sent from the next stage instruction execute/memory access (ex/mem). added control logic is used to determine which input to use.=== control hazards (branch hazards) ===to avoid control hazards microarchitectures can:insert a pipeline bubble (discussed above), guaranteed to increase latency, oruse branch prediction and essentially make educated guesses about which instructions to insert, in which case a pipeline bubble will only be needed in the case of an incorrect predictionin the event that a branch causes a pipeline bubble after incorrect instructions have entered the pipeline, care must be taken to prevent any of the wrongly-loaded instructions from having any effect on the processor state excluding energy wasted processing them before they were discovered to be loaded incorrectly.=== other techniques ===memory latency is another factor that designers must attend to, because the delay could reduce performance. different types of memory have different accessing time to the memory. thus, by choosing a suitable type of memory, designers can improve the performance of the pipelined data path.'], 'overview': [\"the multithreading paradigm has become more popular as efforts to further exploit instruction-level parallelism have stalled since the late 1990s. this allowed the concept of throughput computing to re-emerge from the more specialized field of transaction processing. even though it is very difficult to further speed up a single thread or single program, most computer systems are actually multitasking among multiple threads or programs. thus, techniques that improve the throughput of all tasks result in overall performance gains.two major techniques for throughput computing are multithreading and multiprocessing.=== advantages ===if a thread gets a lot of cache misses, the other threads can continue taking advantage of the unused computing resources, which may lead to faster overall execution, as these resources would have been idle if only a single thread were executed. also, if a thread cannot use all the computing resources of the cpu (because instructions depend on each other's result), running another thread may prevent those resources from becoming idle.=== disadvantages ===multiple threads can interfere with each other when sharing hardware resources such as caches or translation lookaside buffers (tlbs). as a result, execution times of a single thread are not improved and can be degraded, even when only one thread is executing, due to lower frequencies or additional pipeline stages that are necessary to accommodate thread-switching hardware.overall efficiency varies; intel claims up to 30% improvement with its hyper-threading technology, while a synthetic program just performing a loop of non-optimized dependent floating-point operations actually gains a 100% speed improvement when run in parallel. on the other hand, hand-tuned assembly language programs using mmx or altivec extensions and performing data prefetches (as a good video encoder might) do not suffer from cache misses or idle computing resources. such programs therefore do not benefit from hardware multithreading and can indeed see degraded performance due to contention for shared resources.from the software standpoint, hardware support for multithreading is more visible to software, requiring more changes to both application programs and operating systems than multiprocessing. hardware techniques used to support multithreading often parallel the software techniques used for computer multitasking. thread scheduling is also a major problem in multithreading.\"], 'types of multithreading': ['=== interleaved/temporal multithreading ======= coarse-grained multithreading ====the simplest type of multithreading occurs when one thread runs until it is blocked by an event that normally would create a long-latency stall. such a stall might be a cache miss that has to access off-chip memory, which might take hundreds of cpu cycles for the data to return. instead of waiting for the stall to resolve, a threaded processor would switch execution to another thread that was ready to run. only when the data for the previous thread had arrived, would the previous thread be placed back on the list of ready-to-run threads.for example:cycle i: instruction j from thread a is issued.cycle i + 1: instruction j + 1 from thread a is issued.cycle i + 2: instruction j + 2 from thread a is issued, which is a load instruction that misses in all caches.cycle i + 3: thread scheduler invoked, switches to thread b.cycle i + 4: instruction k from thread b is issued.cycle i + 5: instruction k + 1 from thread b is issued.conceptually, it is similar to cooperative multi-tasking used in real-time operating systems, in which tasks voluntarily give up execution time when they need to wait upon some type of the event. this type of multithreading is known as block, cooperative or coarse-grained multithreading.the goal of multithreading hardware support is to allow quick switching between a blocked thread and another thread ready to run. switching from one thread to another means the hardware switches from using one register set to another. to achieve this goal, the hardware for the program visible registers, as well as some processor control registers (such as the program counter), is replicated. for example, to quickly switch between two threads, the processor is built with two sets of registers.additional hardware support for multithreading allows thread switching to be done in one cpu cycle, bringing performance improvements. also, additional hardware allows each thread to behave as if it were executing alone and not sharing any hardware resources with other threads, minimizing the amount of software changes needed within the application and the operating system to support multithreading.many families of microcontrollers and embedded processors have multiple register banks to allow quick context switching for interrupts. such schemes can be considered a type of block multithreading among the user program thread and the interrupt threads.==== interleaved multithreading ====the purpose of interleaved multithreading is to remove all data dependency stalls from the execution pipeline. since one thread is relatively independent from other threads, there is less chance of one instruction in one pipelining stage needing an output from an older instruction in the pipeline. conceptually, it is similar to preemptive multitasking used in operating systems; an analogy would be that the time slice given to each active thread is one cpu cycle.for example:cycle i + 1: an instruction from thread b is issued.cycle i + 2: an instruction from thread c is issued.this type of multithreading was first called barrel processing, in which the staves of a barrel represent the pipeline stages and their executing threads. interleaved, preemptive, fine-grained or time-sliced multithreading are more modern terminology.in addition to the hardware costs discussed in the block type of multithreading, interleaved multithreading has an additional cost of each pipeline stage tracking the thread id of the instruction it is processing. also, since there are more threads being executed concurrently in the pipeline, shared resources such as caches and tlbs need to be larger to avoid thrashing between the different threads.=== simultaneous multithreading ===the most advanced type of multithreading applies to superscalar processors. whereas a normal superscalar processor issues multiple instructions from a single thread every cpu cycle, in simultaneous multithreading (smt) a superscalar processor can issue instructions from multiple threads every cpu cycle. recognizing that any single thread has a limited amount of instruction-level parallelism, this type of multithreading tries to exploit parallelism available across multiple threads to decrease the waste associated with unused issue slots.for example:cycle i: instructions j and j + 1 from thread a and instruction k from thread b are simultaneously issued.cycle i + 1: instruction j + 2 from thread a, instruction k + 1 from thread b, and instruction m from thread c are all simultaneously issued.cycle i + 2: instruction j + 3 from thread a and instructions m + 1 and m + 2 from thread c are all simultaneously issued.to distinguish the other types of multithreading from smt, the term \"temporal multithreading\" is used to denote when instructions from only one thread can be issued at a time.in addition to the hardware costs discussed for interleaved multithreading, smt has the additional cost of each pipeline stage tracking the thread id of each instruction being processed. again, shared resources such as caches and tlbs have to be sized for the large number of active threads being processed.implementations include dec (later compaq) ev8 (not completed), intel hyper-threading technology, ibm power5/power6/power7/power8/power9, ibm z13/z14/z15, sun microsystems ultrasparc t2, cray xmt, and amd bulldozer and zen microarchitectures.'], 'implementation specific': ['a major area of research is the thread scheduler that must quickly choose from among the list of ready-to-run threads to execute next, as well as maintain the ready-to-run and stalled thread lists. an important subtopic is the different thread priority schemes that can be used by the scheduler. the thread scheduler might be implemented totally in software, totally in hardware, or as a hardware/software combination.another area of research is what type of events should cause a thread switch: cache misses, inter-thread communication, dma completion, etc.if the multithreading scheme replicates all of the software-visible state, including privileged control registers and tlbs, then it enables virtual machines to be created for each thread. this allows each thread to run its own operating system on the same processor. on the other hand, if only user-mode state is saved, then less hardware is required, which would allow more threads to be active at one time for the same die area or cost.']})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['history', 'capabilitie', 'evolution', 'design limitation', 'further reading']\n",
      "defaultdict(<class 'list'>, {'intro': ['in computer engineering, computer architecture is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. the architecture of a system refers to its structure in terms of separately specified components of that system and their interrelationships.some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation. in other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation.', 'in computing, a word is the natural unit of data used by a particular processor design. a word is a fixed-sized datum handled as a unit by the instruction set or the hardware of the processor. the number of bits or digits in a word (the word size, word width, or word length) is an important characteristic of any specific processor design or computer architecture.the size of a word is reflected in many aspects of a computer\\'s structure and operation; the majority of the registers in a processor are usually word sized and the largest datum that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. the largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used).documentation for computers with fixed word size commonly stated memory sizes in words rather than bytes or characters.  the documentation sometimes used metric prefixes correctly, sometimes with rounding, e.g., 65 kilowords (kw) meaning for 65536 words, and sometimes used them incorrectly, with kilowords (kw) meaning 1024 words (210) and megawords (mw) meaning 1,048,576 words (220). with standardization on 8-bit bytes and byte addressability, stating memory sizes in bytes, kilobytes, and megabytes with powers of 1024 rather than 1000 has become the norm, although there is some use of the iec binary prefixes.several of the earliest computers (and a few modern as well) used binary-coded decimal rather than plain binary, typically having a word size of 10 or 12 decimal digits, and some early decimal computers had no fixed word length at all. early binary systems tended to use word lengths that were some multiple of 6-bits, with the 36-bit word being especially common on mainframe computers. the introduction of ascii led to the move to systems with word lengths that were a multiple of 8-bits, with 16-bit machines being popular in the 1970s before the move to modern processors with 32 or 64 bits. special-purpose designs like digital signal processors, may have any word length from 4 to 80 bits.the size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. if multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see size families below).', 'in the domain of central processing unit (cpu) design, hazards are problems with the instruction pipeline in cpu microarchitectures when the next instruction cannot execute in the following clock cycle, and can potentially lead to incorrect computation results. three common types of hazards are data hazards, structural hazards, and control hazards (branching hazards).there are several methods used to deal with hazards, including pipeline stalls/pipeline bubbling, operand forwarding, and in the case of out-of-order execution, the scoreboarding method and the tomasulo algorithm.', 'in computer architecture, multithreading is the ability of a central processing unit (cpu) (or a single core in a multi-core processor) to provide multiple threads of execution concurrently, supported by the operating system. this approach differs from multiprocessing. in a multithreaded application, the threads share the resources of a single or multiple cores, which include the computing units, the cpu caches, and the translation lookaside buffer (tlb).where multiprocessing systems include multiple complete processing units in one or more cores, multithreading aims to increase utilization of a single core by using thread-level parallelism, as well as instruction-level parallelism. as the two techniques are complementary, they are combined in nearly all modern systems architectures with multiple multithreading cpus and with cpus with multiple multithreading cores.', 'the von neumann architecture — also known as the von neumann model or princeton architecture — is a computer architecture based on a 1945 description by john von neumann, and by others, in the first draft of a report on the edvac. the document describes a design architecture for an electronic digital computer with these components:a processing unit with both an arithmetic logic unit and processor registersa control unit that includes an instruction register and a program countermemory that stores data and instructionsexternal mass storageinput and output mechanismsthe term \"von neumann architecture\" has evolved to refer to any stored-program computer in which an instruction fetch and a data operation cannot occur at the same time (since they share a common bus). this is referred to as the von neumann bottleneck, which often limits the performance of the corresponding system.the design of a von neumann architecture machine is simpler than in a harvard architecture machine—which is also a stored-program system, yet has one dedicated set of address and data buses for reading and writing to memory, and another set of address and data buses to fetch instructions.a stored-program digital computer keeps both program instructions and data in read–write, random-access memory (ram).  stored-program computers were an advancement over the program-controlled computers of the 1940s, such as the colossus and the eniac. those were programmed by setting switches and inserting patch cables to route data and control signals between various functional units. the vast majority of modern computers use the same memory for both data and program instructions, but have caches between the cpu and memory, and, for the caches closest to the cpu, have separate caches for instructions and data, so that most instruction and data fetches use separate buses (split cache architecture).'], 'history': ['the first documented computer architecture was in the correspondence between charles babbage and ada lovelace, describing the analytical engine. when building the computer z1 in 1936, konrad zuse described in two patent applications for his future projects that machine instructions could be stored in the same storage used for data, i.e., the stored-program concept. two other early and important examples are:john von neumann\\'s 1945 paper, first draft of a report on the edvac, which described an organization of logical elements; andalan turing\\'s more detailed proposed electronic calculator for the automatic computing engine, also 1945 and which cited john von neumann\\'s paper.the term “architecture” in computer literature can be traced to the work of lyle r. johnson and frederick p. brooks, jr., members of the machine organization department in ibm\\'s main research center in 1959. johnson had the opportunity to write a proprietary research communication about the stretch, an ibm-developed supercomputer for los alamos national laboratory (at the time known as los alamos scientific laboratory). to describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that seemed more useful than “machine organization”.subsequently, brooks, a stretch designer, opened chapter 2 of a book called planning a computer system: project stretch by stating, “computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.”brooks went on to help develop the ibm system/360 (now called the ibm zseries) line of computers, in which “architecture” became a noun defining “what the user needs to know”. later, computer users came to use the term in many less explicit ways.the earliest computer architectures were designed on paper and then directly built into the final hardware form.later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (ttl) computer—such as the prototypes of the 6800 and the pa-risc—tested, and tweaked, before committing to the final hardware form.as of the 1990s, new computer architectures are typically \"built\", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a fpga as a soft microprocessor; or both—before committing to the final hardware form.', 'the earliest computing machines had fixed programs.  some very simple computers still use this design, either for simplicity or training purposes.  for example, a desk calculator (in principle) is a fixed program computer.  it can do basic mathematics, but it cannot run a word processor or games.  changing the program of a fixed-program machine requires rewiring, restructuring, or redesigning the machine.  the earliest computers were not so much \"programmed\" as  \"designed\" for a particular task.  \"reprogramming\" – when possible at all – was a laborious process that started with flowcharts and paper notes, followed by detailed engineering designs, and then the often-arduous process of physically rewiring and rebuilding the machine. it could take three weeks to set up and debug a program on eniac.with the proposal of the stored-program computer, this changed. a stored-program computer includes, by design, an instruction set, and can store in memory a set of instructions (a program) that details the computation.a stored-program design also allows for self-modifying code. one early motivation for such a facility was the need for a program to increment or otherwise modify the address portion of instructions, which operators had to do manually in early designs. this became less important when index registers and indirect addressing became usual features of machine architecture. another use was to embed frequently used data in the instruction stream using immediate addressing. self-modifying code has largely fallen out of favor, since it is usually hard to understand and debug, as well as being inefficient under modern processor pipelining and caching schemes.'], 'subcategorie': ['the discipline of computer architecture has three main subcategories:instruction set architecture (isa): defines the machine code that a processor reads and acts upon as well as the word size, memory address modes, processor registers, and data type.microarchitecture: also known as \"computer organization\", this describes how a particular processor will implement the isa. the size of a computer\\'s cpu cache for instance, is an issue that generally has nothing to do with the isa.systems design: includes all of the other hardware components within a computing system, such as data processing other than the cpu (e.g., direct memory access), virtualization, and multiprocessing.there are other technologies in computer architecture. the following technologies are used in bigger companies like intel, and were estimated in 2002 to count for 1% of all of computer architecture:macroarchitecture: architectural layers more abstract than microarchitectureassembly instruction set architecture: a smart assembler may convert an abstract assembly language common to a group of machines into slightly different machine language for different implementations.programmer-visible macroarchitecture: higher-level language tools such as compilers may define a consistent interface or contract to programmers using them, abstracting differences between underlying isa, uisa, and microarchitectures. for example, the c, c++, or java standards define different programmer-visible macroarchitectures.microcode: microcode is software that translates instructions to run on a chip. it acts like a wrapper around the hardware, presenting a preferred version of the hardware\\'s instruction set interface. this instruction translation facility gives chip designers flexible options: e.g. 1. a new improved version of the chip can use microcode to present the exact same instruction set as the old chip version, so all software targeting that instruction set will run on the new chip without needing changes. e.g. 2. microcode can present a variety of instruction sets for the same underlying chip, allowing it to run a wider variety of software.uisa: user instruction set architecture, refers to one of three subsets of the risc cpu instructions provided by powerpc risc processors. the uisa subset, are those risc instructions of interest to application developers. the other two subsets are vea (virtual environment architecture) instructions used by virtualization system developers, and oea (operating environment architecture) used by operation system developers.pin architecture: the hardware functions that a microprocessor should provide to a hardware platform, e.g., the x86 pins a20m, ferr/ignne or flush. also, messages that the processor should emit so that external caches can be invalidated (emptied). pin architecture functions are more flexible than isa functions because external hardware can adapt to new encodings, or change from a pin to a message. the term \"architecture\" fits, because the functions must be provided for compatible systems, even if the detailed method changes.'], 'role': [\"=== definition ===computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. the case of instruction set architecture can be used to illustrate the balance of these competing factors. more complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 loop instruction). however, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. the increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.the implementation involves integrated circuit design, packaging, power, and cooling. optimization of the design requires familiarity with compilers, operating systems to logic design, and packaging.=== instruction set architecture ===an instruction set architecture (isa) is the interface between the computer's software and hardware and also can be viewed as the programmer's view of the machine. computers do not understand high-level programming languages such as java, c++, or most programming languages used. a processor only understands instructions encoded in some numerical fashion, usually as binary numbers. software tools, such as compilers, translate those high level languages into instructions that the processor can understand.besides instructions, the isa defines items in the computer that are available to a program—e.g., data types, registers, addressing modes, and memory.  instructions locate these available items with register indexes (or names) and memory addressing modes.the isa of a computer is usually described in a small instruction manual, which describes how the instructions are encoded. also, it may define short (vaguely) mnemonic names for the instructions. the names can be recognized by a software development tool called an assembler.  an assembler is a computer program that translates a human-readable form of the isa into a computer-readable form.  disassemblers are also widely available, usually in debuggers and software programs to isolate and correct malfunctions in binary computer programs.isas vary in quality and completeness.  a good isa compromises between programmer convenience (how easy the code is to understand), size of the code (how much code is required to do a specific action), cost of the computer to interpret the instructions (more complexity means more hardware needed to decode and execute the instructions), and speed of the computer (with more complex decoding hardware comes longer decode time).  memory organization defines how instructions interact with the memory, and how memory interacts with itself.during design emulation, emulators can run programs written in a proposed instruction set. modern emulators can measure size, cost, and speed to determine whether a particular isa is meeting its goals.=== computer organization ===computer organization helps optimize performance-based products. for example, software engineers need to know the processing power of processors. they may need to optimize software in order to gain the most performance for the lowest price. this can require quite a detailed analysis of the computer's organization.  for example, in an sd card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.computer organization also helps plan the selection of a processor for a particular project. multimedia projects may need very rapid data access, while virtual machines may need fast interrupts. sometimes certain tasks need additional components as well.  for example, a computer capable of running a virtual machine needs virtual memory hardware so that the memory of different virtual computers can be kept separated. computer organization and features also affect power consumption and processor cost.=== implementation ===once an instruction set and micro-architecture have been designed, a practical machine must be developed. this design process is called the implementation. implementation is usually not considered architectural design, but rather hardware design engineering. implementation can be further broken down into several steps:logic implementation designs the circuits required at a logic-gate level.circuit implementation does transistor-level designs of basic elements (e.g., gates, multiplexers, latches) as well as of some larger blocks (alus, caches etc.) that may be implemented at the logic-gate level, or even at the physical level if the design calls for it.physical implementation draws physical circuits.  the different circuit components are placed in a chip floor plan or on a board and the wires connecting them are created.design validation tests the computer as a whole to see if it works in all situations and all timings. once the design validation process starts, the design at the logic level are tested using logic emulators. however, this is usually too slow to run a realistic test.  so, after making corrections based on the first test, prototypes are constructed using field-programmable gate-arrays (fpgas). most hobby projects stop at this stage.  the final step is to test prototype integrated circuits, which may require several redesigns.for cpus, the entire implementation process is organized differently and is often referred to as cpu design.\"], 'design goal': ['the exact form of a computer system depends on the constraints and goals. computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.the most common scheme does an in-depth power analysis and figures out how to keep power consumption low while maintaining adequate performance.=== performance ===modern computer performance is often described in instructions per cycle (ipc), which measures the efficiency of the architecture at any clock frequency; a faster ipc rate means the computer is faster. older computers had ipc counts as low as 0.1 while modern processors easily reach near 1. superscalar processors may reach three to five ipc by executing several instructions per clock cycle.counting machine-language instructions would be misleading because they can do varying amounts of work in different isas. the \"instruction\" in the standard measurements is not a count of the isa\\'s machine-language instructions, but a unit of measurement, usually based on the speed of the vax computer architecture.many people used to measure a computer\\'s speed by the clock rate (usually in mhz or ghz). this refers to the cycles per second of the main clock of the cpu. however, this metric is somewhat misleading, as a machine with a higher clock rate may not necessarily have greater performance. as a result, manufacturers have moved away from clock speed as a measure of performance.other factors influence speed, such as the mix of functional units, bus speeds, available memory, and the type and order of instructions in the programs.there are two main types of speed: latency and throughput. latency is the time between the start of a process and its completion. throughput is the amount of work done per unit time.  interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).performance is affected by a very wide range of design choices — for example, pipelining a processor usually makes latency worse, but makes throughput better. computers that control machinery usually need low interrupt latencies. these computers operate in a real-time environment and fail if an operation is not completed in a specified amount of time. for example, computer-controlled anti-lock brakes must begin braking within a predictable and limited time period after the brake pedal is sensed or else failure of the brake will occur.benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. although benchmarking shows strengths, it shouldn\\'t be how you choose a computer. often the measured machines split on different measures. for example, one system might handle scientific applications quickly, while another might render video games more smoothly. furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but don\\'t offer similar advantages to general tasks.=== power efficiency ===power efficiency is another important measurement in modern computers. a higher power efficiency can often be traded for lower speed or higher cost. the typical measurement when referring to power consumption in computer architecture is mips/w (millions of instructions per second per watt).modern circuits have less power required per transistor as the number of transistors per chip grows. this is because each transistor that is put in a new chip requires its own power supply and requires new pathways to be built to power it. however the number of transistors per chip is starting to increase at a slower rate. therefore, power efficiency is starting to become as important, if not more important than fitting more and more transistors into a single chip. recent processor designs have shown this emphasis as they put more focus on power efficiency rather than cramming as many transistors into a single chip as possible. in the world of embedded computers, power efficiency has long been an important goal next to throughput and latency.=== shifts in market demand ===increases in clock frequency have grown more slowly over the past few years, compared to power reduction improvements. this has been driven by the end of moore\\'s law and demand for longer battery life and reductions in size for mobile technology. this change in focus from higher clock rates to power consumption and miniaturization can be shown by the significant reductions in power consumption, as much as 50%, that were reported by intel in their release of the haswell microarchitecture; where they dropped their power consumption benchmark from 30 to 40 watts down to 10-20 watts. comparing this to the processing speed increase of 3 ghz to 4 ghz (2002 to 2006) it can be seen that the focus in research and development are shifting away from clock frequency and moving towards consuming less power and taking up less space.'], 'see also': ['', 'integer (computer science)', '', 'super-threadingspeculative multithreading', 'cardboard illustrative aid to computationinterconnect bottlenecklittle man computerrandom-access machineharvard architectureturing machineeckert architecture'], 'reference': ['', '', '=== general ===', '', ''], 'source': ['john l. hennessy and david patterson (2006). computer architecture: a quantitative approach (fourth ed.). morgan kaufmann. isbn 978-0-12-370490-0.barton, robert s., \"functional design of computers\", communications of the acm 4(9): 405 (1961).barton, robert s., \"a new approach to the functional design of a digital computer\", proceedings of the western joint computer conference, may 1961, pp. 393–396. about the design of the burroughs b5000 computer.bell, c. gordon; and newell, allen (1971). \"computer structures: readings and examples\", mcgraw-hill.blaauw, g.a., and brooks, f.p., jr., \"the structure of system/360, part i-outline of the logical structure\", ibm systems journal, vol. 3, no. 2, pp. 119–135, 1964.tanenbaum, andrew s. (1979). structured computer organization. englewood cliffs, new jersey: prentice-hall. isbn 0-13-148521-0.'], 'external link': ['isca: proceedings of the international symposium on computer architecturemicro: ieee/acm international symposium on microarchitecturehpca: international symposium on high performance computer architectureasplos: international conference on architectural support for programming languages and operating systemsacm transactions on architecture and code optimizationieee transactions on computersthe von neumann architecture of computer systems', '\"automatic pipelining from transactional datapath specifications\" (pdf). retrieved 23 july 2014.tulsen, dean (18 january 2005). \"pipeline hazards\" (pdf).', 'a survey of processors with explicit multithreading, acm, march 2003, by theo ungerer, borut robi and jurij silcoperating system | difference between multitasking, multithreading and multiprocessing geeksforgeeks, 6 sept. 2018.', 'harvard vs von neumanna tool that emulates the behavior of a von neumann machinejohnny: a simple open source simulator of a von neumann machine for educational purposes'], 'uses of word': ['depending on how a computer is organized, word-size units may be used for:fixed-point numbersholders for fixed point, usually integer, numerical values may be available in one or in several different sizes, but one of the sizes available will almost always be the word. the other sizes, if any, are likely to be multiples or fractions of the word size. the smaller sizes are normally used only for efficient use of memory; when loaded into the processor, their values usually go into a larger, word sized holder.floating-point numbersholders for floating-point numerical values are typically either a word or a multiple of a word.addressesholders for memory addresses must be of a size capable of expressing the needed range of values but not be excessively large, so often the size used is the word though it can also be a multiple or fraction of the word size.registersprocessor registers are designed with a size appropriate for the type of data they hold, e.g. integers, floating-point numbers, or addresses. many computer architectures use general-purpose registers that are capable of storing data in multiple representations.memory–processor transferwhen the processor reads from the memory subsystem into a register or writes a register\\'s value to memory, the amount of data transferred is often a word. historically, this amount of bits which could be transferred in one cycle was also called a catena in some environments (such as the bull gamma 60). in simple memory subsystems, the word is transferred over the memory data bus, which typically has a width of a word or half-word. in memory subsystems that use caches, the word-sized transfer is the one between the processor and the first level of cache; at lower levels of the memory hierarchy larger transfers (which are a multiple of the word size) are normally used.unit of address resolutionin a given architecture, successive address values designate successive units of memory; this unit is the unit of address resolution. in most computers, the unit is either a character (e.g. a byte) or a word. (a few computers have used bit resolution.) if the unit is a word, then a larger amount of memory can be accessed using an address of a given size at the cost of added complexity to access individual characters. on the other hand, if the unit is a byte, then individual characters can be addressed (i.e. selected during the memory operation).instructionsmachine instructions are normally the size of the architecture\\'s word, such as in risc architectures, or a multiple of the \"char\" size that is a fraction of it. this is a natural choice since instructions and data usually share the same memory subsystem. in harvard architectures the word sizes of instructions and data need not be related, as instructions and data are stored in different memories; for example, the processor in the 1ess electronic telephone switch had 37-bit instructions and 23-bit data words.'], 'word size choice': ['when a computer architecture is designed, the choice of a word size is of substantial importance.  there are design considerations which encourage particular bit-group sizes for particular uses (e.g. for addresses), and these considerations point to different sizes for different uses.  however, considerations of economy in design strongly push for one size, or a very few sizes related by multiples or fractions (submultiples) to a primary size.  that preferred size becomes the word size of the architecture.character size was in the past (pre-variable-sized character encoding) one of the influences on unit of address resolution and the choice of word size.  before the mid-1960s, characters were most often stored in six bits; this allowed no more than 64 characters, so the alphabet was limited to upper case.  since it is efficient in time and space to have the word size be a multiple of the character size, word sizes in this period were usually multiples of 6 bits (in binary machines).  a common choice then was the 36-bit word, which is also a good size for the numeric properties of a floating point format.after the introduction of the ibm system/360 design, which used eight-bit characters and supported lower-case letters, the standard size of a character (or more accurately, a byte) became eight bits.  word sizes thereafter were naturally multiples of eight bits, with 16, 32, and 64 bits being commonly used.=== variable-word architectures ===early machine designs included some that used what is often termed a variable word length.  in this type of organization, an operand had no fixed length. depending on the machine and the instruction, the length might be denoted by a count field, by a delimiting character, or by an additional bit called, e.g., flag, word mark.  such machines often used binary-coded decimal in 4-bit digits, or in 6-bit characters, for numbers.  this class of machines included the ibm 702, ibm 705, ibm 7080, ibm 7010, univac 1050, ibm 1401, ibm 1620, and rca 301.most of these machines work on one unit of memory at a time and since each instruction or datum is several units long, each instruction takes several cycles just to access memory.  these machines are often quite slow because of this.  for example, instruction fetches on an ibm 1620 model i take 8 cycles just to read the 12 digits of the instruction (the model ii reduced this to 6 cycles, or 4 cycles if the instruction did not need both address fields). instruction execution took a completely variable number of cycles, depending on the size of the operands.=== word, bit and byte addressing ===the memory model of an architecture is strongly influenced by the word size.  in particular, the resolution of a memory address, that is, the smallest unit that can be designated by an address, has often been chosen to be the word.  in this approach, the word-addressable machine approach, address values which differ by one designate adjacent memory words.  this is natural in machines which deal almost always in word (or multiple-word) units, and has the advantage of allowing instructions to use minimally sized fields to contain addresses, which can permit a smaller instruction size or a larger variety of instructions.when byte processing is to be a significant part of the workload, it is usually more advantageous to use the byte, rather than the word, as the unit of address resolution. address values which differ by one designate adjacent bytes in memory.  this allows an arbitrary character within a character string to be addressed straightforwardly.  a word can still be addressed, but the address to be used requires a few more bits than the word-resolution alternative.  the word size needs to be an integer multiple of the character size in this organization.  this addressing approach was used in the ibm 360, and has been the most common approach in machines designed since then.when the workload involves processing fields of different sizes, it can be advantageous to address to the bit. machines with bit addressing may have some instructions that use a programmer-defined byte size and other instructions that operate on fixed data sizes. as an example, on the ibm 7030 (\"stretch\"), a floating point instruction can only address words while an integer arithmetic instruction can specify a field length of 1-64 bits, a byte size of 1-8 bits and an accumulator offset of 0-127 bits. in at byte-addressable machine with storage-to-storage (ss) instructions, there are typically move instructions to copy one or multiple bytes from one arbitrary location to another. in a byte-oriented (byte-addressable) machine without ss instructions, moving a single byte from one arbitrary location to another is typically:load the source bytestore the result back in the target byteindividual bytes can be accessed on a word-oriented machine in one of two ways.  bytes can be manipulated by a combination of shift and mask operations in registers. moving a single byte from one arbitrary location to another may require the equivalent of the following:load the word containing the source byteshift the source word to align the desired byte to the correct position in the target wordand the source word with a mask to zero out all but the desired bitsload the word containing the target byteand the target word with a mask to zero out the target byteor the registers containing the source and target words to insert the source bytestore the result back in the target locationalternatively many word-oriented machines implement byte operations with instructions using special byte pointers in registers or memory.  for example, the pdp-10 byte pointer contained the size of the byte in bits (allowing different-sized bytes to be accessed), the bit position of the byte within the word, and the word address of the data.  instructions could automatically adjust the pointer to the next byte on, for example, load and deposit (store) operations.=== powers of two ===different amounts of memory are used to store data values with different degrees of precision. the commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word).  converting the index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. in some cases this relationship can also avoid the use of division operations. as a result, most modern computer designs have word sizes (and other operand sizes) that are a power of two times the size of a byte.'], 'size familie': ['as computer designs have grown more complex, the central importance of a single word size to an architecture has decreased.  although more capable hardware can use a wider variety of sizes of data, market forces exert pressure to maintain backward compatibility while extending processor capability.  as a result, what might have been the central word size in a fresh design has to coexist as an alternative size to the original word size in a backward compatible design. the original word size remains available in future designs, forming the basis of a size family.in the mid-1970s, dec designed the vax to be a 32-bit successor of the 16-bit pdp-11. they used word for a 16-bit quantity, while longword referred to a 32-bit quantity; this terminology is the same as the terminology used for the pdp-11. this was in contrast to earlier machines, where the natural unit of addressing memory would be called a word, while a quantity that is one half a word would be called a halfword. in fitting with this scheme, a vax quadword is 64 bits.  they continued this 16-bit word/32-bit longword/64-bit quadword terminology with the 64-bit alpha.another example is the x86 family, of which processors of three different word lengths (16-bit, later 32- and 64-bit) have been released, while word continues to designate a 16-bit quantity. as software is routinely ported from one word-length to the next, some apis and documentation define or refer to an older (and thus shorter) word-length than the full word length on the cpu that software may be compiled for. also, similar to how bytes are used for small numbers in many programs, a shorter word (16 or 32 bits) may be used in contexts where the range of a wider word is not needed (especially where this can save considerable stack space or cache memory space). for example, microsoft\\'s windows api maintains the programming language definition of word as 16 bits, despite the fact that the api may be used on a 32- or 64-bit x86 processor, where the standard word size would be 32 or 64 bits, respectively. data structures containing such different sized words refer to them as:word (16 bits/2 bytes)dword (32 bits/4 bytes)qword (64 bits/8 bytes)a similar phenomenon has developed in intel\\'s x86 assembly language – because of the support for various sizes (and backward compatibility) in the instruction set, some instruction mnemonics carry \"d\" or \"q\" identifiers denoting \"double-\", \"quad-\" or \"double-quad-\", which are in terms of the architecture\\'s original 16-bit word size.an example with a different word size is the ibm system/360 family. in the system/360 architecture, system/370 architecture and system/390 architecture, there are 8-bit bytes, 16-bit halfwords, 32-bit words and 64-bit doublewords. the z/architecture, which is the 64-bit member of that architecture family, continues to refer to 16-bit halfwords, 32-bit words, and 64-bit doublewords, and additionally features 128-bit quadwords.in general, new processors must use the same data word lengths and virtual address widths as an older processor to have binary compatibility with that older processor.often carefully written source code – written with source-code compatibility and software portability in mind – can be recompiled to run on a variety of processors, even ones with different data word lengths or different address widths or both.'], 'table of word size': [''], 'note': [''], 'background': ['instructions in a pipelined processor are performed in several stages, so that at any given time several instructions are being processed in the various stages of the pipeline, such as fetch and execute. there are many different instruction pipeline microarchitectures, and instructions may be executed out-of-order. a hazard occurs when two or more of these simultaneous (possibly out of order) instructions conflict.'], 'type': ['=== data hazards ===data hazards occur when instructions that exhibit data dependence modify data in different stages of a pipeline. ignoring potential data hazards can result in race conditions (also termed race hazards). there are three situations in which a data hazard can occur:read after write (raw), a true dependencywrite after read (war), an anti-dependencywrite after write (waw), an output dependencyread after read (rar) is not a hazard case.consider two instructions i1 and i2, with i1 occurring before i2 in program order.==== read after write (raw) ====(i2 tries to read a source before i1 writes to it)a read after write (raw) data hazard refers to a situation where an instruction refers to a result that has not yet been calculated or retrieved. this can occur because even though an instruction is executed after a prior instruction, the prior instruction has been processed only partly through the pipeline.===== example =====for example:i1. r2 <- r5 + r3i2. r4 <- r2 + r3the first instruction is calculating a value to be saved in register r2, and the second is going to use this value to compute a result for register r4. however, in a pipeline, when operands are fetched for the 2nd operation, the results from the first have not yet been saved, and hence a data dependency occurs.a data dependency occurs with instruction i2, as it is dependent on the completion of instruction i1.==== write after read (war) ====(i2 tries to write a destination before it is read by i1)a write after read (war) data hazard represents a problem with concurrent execution.===== example =====for example:i1. r4 <- r1 + r5i2. r5 <- r1 + r2in any situation with a chance that i2 may finish before i1 (i.e., with concurrent execution), it must be ensured that the result of register r5 is not stored before i1 has had a chance to fetch the operands.==== write after write (waw) ====(i2 tries to write an operand before it is written by i1)a write after write (waw) data hazard may occur in a concurrent execution environment.===== example =====for example:i1. r2 <- r4 + r7i2. r2 <- r1 + r3the write back (wb) of i2 must be delayed until i1 finishes executing.=== structural hazards ===a structural hazard occurs when two (or more) instructions that are already in pipeline need the same resource. the result is that instruction must be executed in series rather than parallel for a portion of pipeline. structural hazards are sometime referred to as resource hazards.example:a situation in which multiple instructions are ready to enter the execute instruction phase and there is a single alu (arithmetic logic unit). one solution to such resource hazard is to increase available resources, such as having multiple ports into main memory and multiple alu (arithmetic logic unit) units.=== control hazards (branch hazards or instruction hazards) ===control hazard occurs when the pipeline makes wrong decisions on branch prediction and therefore brings instructions into the pipeline that must subsequently be discarded. the term branch hazard also refers to a control hazard.'], 'eliminating hazard': ['=== generic ======= pipeline bubbling ====bubbling the pipeline, also termed a pipeline break or pipeline stall, is a method to preclude data, structural, and branch hazards. as instructions are fetched, control logic determines whether a hazard could/will occur. if this is true, then the control logic inserts no operations (nops) into the pipeline. thus, before the next instruction (which would cause the hazard) executes, the prior one will have had sufficient time to finish and prevent the hazard. if the number of nops equals the number of stages in the pipeline, the processor has been cleared of all instructions and can proceed free from hazards. all forms of stalling introduce a delay before the processor can resume execution.flushing the pipeline occurs when a branch instruction jumps to a new memory location, invalidating all prior stages in the pipeline.  these prior stages are cleared, allowing the pipeline to continue at the new instruction indicated by the branch.=== data hazards ===there are several main solutions and algorithms used to resolve data hazards:insert a pipeline bubble whenever a read after write (raw) dependency is encountered, guaranteed to increase latency, oruse out-of-order execution to potentially prevent the need for pipeline bubblesuse operand forwarding to use data from later stages in the pipelinein the case of out-of-order execution, the algorithm used can be:scoreboarding, in which case a pipeline bubble is needed only when there is no functional unit availablethe tomasulo algorithm, which uses register renaming, allowing continual issuing of instructionsthe task of removing data dependencies can be delegated to the compiler, which can fill in an appropriate number of nop instructions between dependent instructions to ensure correct operation, or re-order instructions where possible.==== operand forwarding ======== examples ====in the following examples, computed values are in bold, while register numbers are not.for example, to write the value 3 to register 1, (which already contains a 6), and then add 7 to register 1 and store the result in register 2, i.e.:i0: r1 = 6i1: r1 = 3i2: r2 = r1 + 7 = 10following execution, register 2 should contain the value 10. however, if i1 (write 3 to register 1) does not fully exit the pipeline before i2 starts executing, it means that r1 does not contain the value 3 when i2 performs its addition. in such an event, i2 adds 7 to the old value of register 1 (6), and so register 2 contains 13 instead, i.e.:i0: r1 = 6i2: r2 = r1 + 7 = 13i1: r1 = 3this error occurs because i2 reads register 1 before i1 has committed/stored the result of its write operation to register 1. so when i2 is reading the contents of register 1, register 1 still contains 6, not 3.forwarding (described below) helps correct such errors by depending on the fact that the output of i1 (which is 3) can be used by subsequent instructions before the value 3 is committed to/stored in register 1.forwarding applied to the example means that there is no wait to commit/store the output of i1 in register 1 (in this example, the output is 3) before making that output available to the subsequent instruction (in this case, i2). the effect is that i2 uses the correct (the more recent) value of register 1: the commit/store was made immediately and not pipelined.with forwarding enabled, the instruction decode/execution (id/ex) stage of the pipeline now has two inputs: the value read from the register specified (in this example, the value 6 from register 1), and the new value of register 1 (in this example, this value is 3) which is sent from the next stage instruction execute/memory access (ex/mem). added control logic is used to determine which input to use.=== control hazards (branch hazards) ===to avoid control hazards microarchitectures can:insert a pipeline bubble (discussed above), guaranteed to increase latency, oruse branch prediction and essentially make educated guesses about which instructions to insert, in which case a pipeline bubble will only be needed in the case of an incorrect predictionin the event that a branch causes a pipeline bubble after incorrect instructions have entered the pipeline, care must be taken to prevent any of the wrongly-loaded instructions from having any effect on the processor state excluding energy wasted processing them before they were discovered to be loaded incorrectly.=== other techniques ===memory latency is another factor that designers must attend to, because the delay could reduce performance. different types of memory have different accessing time to the memory. thus, by choosing a suitable type of memory, designers can improve the performance of the pipelined data path.'], 'overview': [\"the multithreading paradigm has become more popular as efforts to further exploit instruction-level parallelism have stalled since the late 1990s. this allowed the concept of throughput computing to re-emerge from the more specialized field of transaction processing. even though it is very difficult to further speed up a single thread or single program, most computer systems are actually multitasking among multiple threads or programs. thus, techniques that improve the throughput of all tasks result in overall performance gains.two major techniques for throughput computing are multithreading and multiprocessing.=== advantages ===if a thread gets a lot of cache misses, the other threads can continue taking advantage of the unused computing resources, which may lead to faster overall execution, as these resources would have been idle if only a single thread were executed. also, if a thread cannot use all the computing resources of the cpu (because instructions depend on each other's result), running another thread may prevent those resources from becoming idle.=== disadvantages ===multiple threads can interfere with each other when sharing hardware resources such as caches or translation lookaside buffers (tlbs). as a result, execution times of a single thread are not improved and can be degraded, even when only one thread is executing, due to lower frequencies or additional pipeline stages that are necessary to accommodate thread-switching hardware.overall efficiency varies; intel claims up to 30% improvement with its hyper-threading technology, while a synthetic program just performing a loop of non-optimized dependent floating-point operations actually gains a 100% speed improvement when run in parallel. on the other hand, hand-tuned assembly language programs using mmx or altivec extensions and performing data prefetches (as a good video encoder might) do not suffer from cache misses or idle computing resources. such programs therefore do not benefit from hardware multithreading and can indeed see degraded performance due to contention for shared resources.from the software standpoint, hardware support for multithreading is more visible to software, requiring more changes to both application programs and operating systems than multiprocessing. hardware techniques used to support multithreading often parallel the software techniques used for computer multitasking. thread scheduling is also a major problem in multithreading.\"], 'types of multithreading': ['=== interleaved/temporal multithreading ======= coarse-grained multithreading ====the simplest type of multithreading occurs when one thread runs until it is blocked by an event that normally would create a long-latency stall. such a stall might be a cache miss that has to access off-chip memory, which might take hundreds of cpu cycles for the data to return. instead of waiting for the stall to resolve, a threaded processor would switch execution to another thread that was ready to run. only when the data for the previous thread had arrived, would the previous thread be placed back on the list of ready-to-run threads.for example:cycle i: instruction j from thread a is issued.cycle i + 1: instruction j + 1 from thread a is issued.cycle i + 2: instruction j + 2 from thread a is issued, which is a load instruction that misses in all caches.cycle i + 3: thread scheduler invoked, switches to thread b.cycle i + 4: instruction k from thread b is issued.cycle i + 5: instruction k + 1 from thread b is issued.conceptually, it is similar to cooperative multi-tasking used in real-time operating systems, in which tasks voluntarily give up execution time when they need to wait upon some type of the event. this type of multithreading is known as block, cooperative or coarse-grained multithreading.the goal of multithreading hardware support is to allow quick switching between a blocked thread and another thread ready to run. switching from one thread to another means the hardware switches from using one register set to another. to achieve this goal, the hardware for the program visible registers, as well as some processor control registers (such as the program counter), is replicated. for example, to quickly switch between two threads, the processor is built with two sets of registers.additional hardware support for multithreading allows thread switching to be done in one cpu cycle, bringing performance improvements. also, additional hardware allows each thread to behave as if it were executing alone and not sharing any hardware resources with other threads, minimizing the amount of software changes needed within the application and the operating system to support multithreading.many families of microcontrollers and embedded processors have multiple register banks to allow quick context switching for interrupts. such schemes can be considered a type of block multithreading among the user program thread and the interrupt threads.==== interleaved multithreading ====the purpose of interleaved multithreading is to remove all data dependency stalls from the execution pipeline. since one thread is relatively independent from other threads, there is less chance of one instruction in one pipelining stage needing an output from an older instruction in the pipeline. conceptually, it is similar to preemptive multitasking used in operating systems; an analogy would be that the time slice given to each active thread is one cpu cycle.for example:cycle i + 1: an instruction from thread b is issued.cycle i + 2: an instruction from thread c is issued.this type of multithreading was first called barrel processing, in which the staves of a barrel represent the pipeline stages and their executing threads. interleaved, preemptive, fine-grained or time-sliced multithreading are more modern terminology.in addition to the hardware costs discussed in the block type of multithreading, interleaved multithreading has an additional cost of each pipeline stage tracking the thread id of the instruction it is processing. also, since there are more threads being executed concurrently in the pipeline, shared resources such as caches and tlbs need to be larger to avoid thrashing between the different threads.=== simultaneous multithreading ===the most advanced type of multithreading applies to superscalar processors. whereas a normal superscalar processor issues multiple instructions from a single thread every cpu cycle, in simultaneous multithreading (smt) a superscalar processor can issue instructions from multiple threads every cpu cycle. recognizing that any single thread has a limited amount of instruction-level parallelism, this type of multithreading tries to exploit parallelism available across multiple threads to decrease the waste associated with unused issue slots.for example:cycle i: instructions j and j + 1 from thread a and instruction k from thread b are simultaneously issued.cycle i + 1: instruction j + 2 from thread a, instruction k + 1 from thread b, and instruction m from thread c are all simultaneously issued.cycle i + 2: instruction j + 3 from thread a and instructions m + 1 and m + 2 from thread c are all simultaneously issued.to distinguish the other types of multithreading from smt, the term \"temporal multithreading\" is used to denote when instructions from only one thread can be issued at a time.in addition to the hardware costs discussed for interleaved multithreading, smt has the additional cost of each pipeline stage tracking the thread id of each instruction being processed. again, shared resources such as caches and tlbs have to be sized for the large number of active threads being processed.implementations include dec (later compaq) ev8 (not completed), intel hyper-threading technology, ibm power5/power6/power7/power8/power9, ibm z13/z14/z15, sun microsystems ultrasparc t2, cray xmt, and amd bulldozer and zen microarchitectures.'], 'implementation specific': ['a major area of research is the thread scheduler that must quickly choose from among the list of ready-to-run threads to execute next, as well as maintain the ready-to-run and stalled thread lists. an important subtopic is the different thread priority schemes that can be used by the scheduler. the thread scheduler might be implemented totally in software, totally in hardware, or as a hardware/software combination.another area of research is what type of events should cause a thread switch: cache misses, inter-thread communication, dma completion, etc.if the multithreading scheme replicates all of the software-visible state, including privileged control registers and tlbs, then it enables virtual machines to be created for each thread. this allows each thread to run its own operating system on the same processor. on the other hand, if only user-mode state is saved, then less hardware is required, which would allow more threads to be active at one time for the same die area or cost.'], 'capabilitie': ['on a large scale, the ability to treat instructions as data is what makes assemblers, compilers, linkers, loaders, and other automated programming tools possible. it makes \"programs that write programs\" possible.  this has made a sophisticated self-hosting computing ecosystem flourish around von neumann architecture machines.some high level languages leverage the von neumann architecture by providing an abstract, machine-independent way to manipulate executable code at runtime (e.g., lisp), or by using runtime information to tune just-in-time compilation (e.g. languages hosted on the java virtual machine, or languages embedded in web browsers).on a smaller scale, some repetitive operations such as bitblt or pixel and vertex shaders can be accelerated on general purpose processors with just-in-time compilation techniques. this is one use of self-modifying code that has remained popular.== development of the stored-program concept ==the mathematician alan turing, who had been alerted to a problem of mathematical logic by the lectures of max newman at the university of cambridge, wrote a paper in 1936 entitled on computable numbers, with an application to the entscheidungsproblem, which was published in the proceedings of the london mathematical society. in it he described a hypothetical machine he called a universal computing machine, now known as the \"universal turing machine\". the hypothetical machine had an infinite store (memory in today\\'s terminology) that contained both instructions and data. john von neumann became acquainted with turing while he was a visiting professor at cambridge in 1935, and also during turing\\'s phd year at the institute for advanced study in princeton, new jersey during 1936–1937. whether he knew of turing\\'s paper of 1936 at that time is not clear.in 1936, konrad zuse also anticipated, in two patent applications, that machine instructions could be stored in the same storage used for data.independently, j. presper eckert and john mauchly, who were developing the eniac at the moore school of electrical engineering of the university of pennsylvania, wrote about the stored-program concept in december 1943. in planning a new machine, edvac, eckert wrote in january 1944 that they would store data and programs in a new addressable memory device, a mercury metal delay-line memory. this was the first time the construction of a practical stored-program machine was proposed.  at that time, he and mauchly were not aware of turing\\'s work.von neumann was involved in the manhattan project at the los alamos national laboratory. it required huge amounts of calculation, and thus drew him to the eniac project, during the summer of 1944. there he joined the ongoing discussions on the design of this stored-program computer, the edvac. as part of that group, he wrote up a description titled first draft of a report on the edvac based on the work of eckert and mauchly. it was unfinished when his colleague herman goldstine circulated it, and bore only von neumann\\'s name (to the consternation of eckert and mauchly). the paper was read by dozens of von neumann\\'s colleagues in america and europe, and influenced the next round of computer designs.jack copeland considers that it is \"historically inappropriate to refer to electronic stored-program digital computers as \\'von neumann machines\\'\". his los alamos colleague stan frankel said of von neumann\\'s regard for turing\\'s ideasi know that in or about 1943 or \\'44 von neumann was well aware of the fundamental importance of turing\\'s paper of 1936….von neumann introduced me to that paper and at his urging i studied it with care. many people have acclaimed von neumann as the \"father of the computer\" (in a modern sense of the term) but i am sure that he would never have made that mistake himself. he might well be called the midwife, perhaps, but he firmly emphasized to me, and to others i am sure, that the fundamental conception is owing to turing— in so far as not anticipated by babbage…. both turing and von neumann, of course, also made substantial contributions to the \"reduction to practice\" of these concepts but i would not regard these as comparable in importance with the introduction and explication of the concept of a computer able to store in its memory its program of activities and of modifying that program in the course of these activities.at the time that the \"first draft\" report was circulated, turing was producing a report entitled proposed electronic calculator. it described in engineering and programming detail, his idea of a machine he called the automatic computing engine (ace). he presented this to the executive committee of the british national physical laboratory on february 19, 1946. although turing knew from his wartime experience at bletchley park that what he proposed was feasible, the secrecy surrounding colossus, that was subsequently maintained for several decades, prevented him from saying so. various successful implementations of the ace design were produced.both von neumann\\'s and turing\\'s papers described stored-program computers, but von neumann\\'s earlier paper achieved greater circulation and the computer architecture it outlined became known as the \"von neumann architecture\". in the 1953 publication faster than thought: a symposium on digital computing machines (edited by b. v. bowden), a section in the chapter on computers in america reads as follows:the machine of the institute for advanced studies, princetonin 1945, professor j. von neumann, who was then working at the moore school of engineering in philadelphia, where the e.n.i.a.c. had been built, issued on behalf of a group of his co-workers, a report on the logical design of digital computers. the report contained a detailed proposal for the design of the machine that has since become known as the e.d.v.a.c. (electronic discrete variable automatic computer). this machine has only recently been completed in america, but the von neumann report inspired the construction of the e.d.s.a.c. (electronic delay-storage automatic calculator) in cambridge (see page 130).in 1947, burks, goldstine and von neumann published another report that outlined the design of another type of machine (a parallel machine this time) that would be exceedingly fast, capable perhaps of 20,000 operations per second. they pointed out that the outstanding problem in constructing such a machine was the development of suitable memory with instantaneously accessible contents. at first they suggested using a special vacuum tube—called the \"selectron\"—which the princeton laboratories of rca had invented. these tubes were expensive and difficult to make, so von neumann subsequently decided to build a machine based on the williams memory. this machine—completed in june, 1952 in princeton—has become popularly known as the maniac. the design of this machine inspired at least half a dozen machines now being built in america, all known affectionately as \"johniacs\".in the same book, the first two paragraphs of a chapter on ace read as follows:automatic computation at the national physical laboratoryone of the most modern digital computers which embodies developments and improvements in the technique of automatic electronic computing was recently demonstrated at the national physical laboratory, teddington, where it has been designed and built by a small team of mathematicians and electronics research engineers on the staff of the laboratory, assisted by a number of production engineers from the english electric company, limited. the equipment so far erected at the laboratory is only the pilot model of a much larger installation which will be known as the automatic computing engine, but although comparatively small in bulk and containing only about 800 thermionic valves, as can be judged from plates xii, xiii and xiv, it is an extremely rapid and versatile calculating machine.the basic concepts and abstract principles of computation by a machine were formulated by dr. a. m. turing, f.r.s., in a paper1. read before the london mathematical society in 1936, but work on such machines in britain was delayed by the war. in 1945, however, an examination of the problems was made at the national physical laboratory by mr. j. r. womersley, then superintendent of the mathematics division of the laboratory. he was joined by dr. turing and a small staff of specialists, and, by 1947, the preliminary planning was sufficiently advanced to warrant the establishment of the special group already mentioned. in april, 1948, the latter became the electronics section of the laboratory, under the charge of mr. f. m. colebrook.== early von neumann-architecture computers ==the first draft described a design that was used by many universities and corporations to construct their computers. among these various computers, only illiac and ordvac had compatible instruction sets.arc2 (birkbeck, university of london) officially came online on may 12, 1948.manchester baby (victoria university of manchester, england) made its first successful run of a stored program on june 21, 1948.edsac (university of cambridge, england) was the first practical stored-program electronic computer (may 1949)manchester mark 1 (university of manchester, england) developed from the baby (june 1949)csirac (council for scientific and industrial research) australia (november 1949)mesm in kyiv, ukraine (november 1950)edvac (ballistic research laboratory, computing laboratory at aberdeen proving ground 1951)ordvac (u-illinois) at aberdeen proving ground, maryland (completed november 1951)ias machine at princeton university (january 1952)maniac i at los alamos scientific laboratory (march 1952)illiac at the university of illinois, (september 1952)besm-1 in moscow (1952)avidac at argonne national laboratory (1953)oracle at oak ridge national laboratory (june 1953)besk in stockholm (1953)johnniac at rand corporation (january 1954)dask in denmark (1955)weizac at the weizmann institute of science in rehovot, israel (1955)perm in munich (1956)silliac in sydney (1956)== early stored-program computers ==the date information in the following chronology is difficult to put into proper order. some dates are for first running a test program, some dates are the first time the computer was demonstrated or completed, and some dates are for the first delivery or installation.the ibm ssec had the ability to treat instructions as data, and was publicly demonstrated on january 27, 1948. this ability was claimed in a us patent. however it was partially electromechanical, not fully electronic. in practice, instructions were read from paper tape due to its limited memory.the arc2 developed by andrew booth and kathleen booth at birkbeck, university of london officially came online on may 12, 1948. it featured the first rotating drum storage device.the manchester baby was the first fully electronic computer to run a stored program. it ran a factoring program for 52 minutes on june 21, 1948, after running a simple division program and a program to show that two numbers were relatively prime.the eniac was modified to run as a primitive read-only stored-program computer (using the function tables for program rom) and was demonstrated as such on september 16, 1948, running a program by adele goldstine for von neumann.the binac ran some test programs in february, march, and april 1949, although was not completed until september 1949.the manchester mark 1 developed from the baby project.  an intermediate version of the mark 1 was available to run programs in april 1949, but was not completed until october 1949.the edsac ran its first program on may 6, 1949.the edvac was delivered in august 1949, but it had problems that kept it from being put into regular operation until 1951.the csir mk i ran its first program in november 1949.the seac was demonstrated in april 1950.the pilot ace ran its first program on may 10, 1950, and was demonstrated in december 1950.the swac was completed in july 1950.the whirlwind was completed in december 1950 and was in actual use in april 1951.the first era atlas (later the commercial era 1101/univac 1101) was installed in december 1950.'], 'evolution': ['through the decades of the 1960s and 1970s computers generally became both smaller and faster, which led to evolutions in their architecture. for example, memory-mapped i/o lets input and output devices be treated the same as memory. a single system bus could be used to provide a modular system with lower cost. this is sometimes called a \"streamlining\" of the architecture.in subsequent decades, simple microcontrollers would sometimes omit features of the model to lower cost and size.larger computers added features for higher performance.'], 'design limitation': ['=== von neumann bottleneck ===the shared bus between the program memory and data memory leads to the von neumann bottleneck, the limited throughput (data transfer rate) between the central processing unit (cpu) and memory compared to the amount of memory.  because the single bus can only access one of the two classes of memory at a time, throughput is lower than the rate at which the cpu can work.  this seriously limits the effective processing speed when the cpu is required to perform minimal processing on large amounts of data.  the cpu is continually forced to wait for needed data to move to or from memory.  since cpu speed and memory size have increased much faster than the throughput between them, the bottleneck has become more of a problem, a problem whose severity increases with every new generation of cpu.the von neumann bottleneck was described by john backus in his 1977 acm turing award lecture.  according to backus:surely there must be a less primitive way of making big changes in the store than by pushing vast numbers of words back and forth through the von neumann bottleneck. not only is this tube a literal bottleneck for the data traffic of a problem, but, more importantly, it is an intellectual bottleneck that has kept us tied to word-at-a-time thinking instead of encouraging us to think in terms of the larger conceptual units of the task at hand. thus programming is basically planning and detailing the enormous traffic of words through the von neumann bottleneck, and much of that traffic concerns not significant data itself, but where to find it.==== mitigations ====there are several known methods for mitigating the von neumann performance bottleneck.  for example, the following all can improve performance:providing a cache between the cpu and the main memoryproviding separate caches or separate access paths for data and instructions (the so-called modified harvard architecture)using branch predictor algorithms and logicproviding a limited cpu stack or other on-chip scratchpad memory to reduce memory accessimplementing the cpu and the memory hierarchy as a system on chip, providing greater locality of reference and thus reducing latency and increasing throughput between processor registers and main memorythe problem can also be sidestepped somewhat by using parallel computing, using for example the non-uniform memory access (numa) architecture—this approach is commonly employed by supercomputers. it is less clear whether the intellectual bottleneck that backus criticized has changed much since 1977. backus\\'s proposed solution has not had a major influence. modern functional programming and object-oriented programming are much less geared towards \"pushing vast numbers of words back and forth\" than earlier languages like fortran were, but internally, that is still what computers spend much of their time doing, even highly parallel supercomputers.as of 1996, a database benchmark study found that three out of four cpu cycles were spent waiting for memory. researchers expect that increasing the number of simultaneous instruction streams with multithreading or single-chip multiprocessing will make this bottleneck even worse.  in the context of multi-core processors, additional overhead is required to maintain cache coherence between processors and threads.=== self-modifying code ===aside from the von neumann bottleneck, program modifications can be quite harmful, either by accident or design.  in some simple stored-program computer designs, a malfunctioning program can damage itself, other programs, or the operating system, possibly leading to a computer crash. memory protection and other forms of access control can usually protect against both accidental and malicious program changes.'], 'further reading': ['']})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['overview', 'advantage', 'disadvantage', 'history', 'further reading']\n",
      "defaultdict(<class 'list'>, {'intro': ['in computer engineering, computer architecture is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. the architecture of a system refers to its structure in terms of separately specified components of that system and their interrelationships.some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation. in other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation.', 'in computing, a word is the natural unit of data used by a particular processor design. a word is a fixed-sized datum handled as a unit by the instruction set or the hardware of the processor. the number of bits or digits in a word (the word size, word width, or word length) is an important characteristic of any specific processor design or computer architecture.the size of a word is reflected in many aspects of a computer\\'s structure and operation; the majority of the registers in a processor are usually word sized and the largest datum that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. the largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used).documentation for computers with fixed word size commonly stated memory sizes in words rather than bytes or characters.  the documentation sometimes used metric prefixes correctly, sometimes with rounding, e.g., 65 kilowords (kw) meaning for 65536 words, and sometimes used them incorrectly, with kilowords (kw) meaning 1024 words (210) and megawords (mw) meaning 1,048,576 words (220). with standardization on 8-bit bytes and byte addressability, stating memory sizes in bytes, kilobytes, and megabytes with powers of 1024 rather than 1000 has become the norm, although there is some use of the iec binary prefixes.several of the earliest computers (and a few modern as well) used binary-coded decimal rather than plain binary, typically having a word size of 10 or 12 decimal digits, and some early decimal computers had no fixed word length at all. early binary systems tended to use word lengths that were some multiple of 6-bits, with the 36-bit word being especially common on mainframe computers. the introduction of ascii led to the move to systems with word lengths that were a multiple of 8-bits, with 16-bit machines being popular in the 1970s before the move to modern processors with 32 or 64 bits. special-purpose designs like digital signal processors, may have any word length from 4 to 80 bits.the size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. if multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see size families below).', 'in the domain of central processing unit (cpu) design, hazards are problems with the instruction pipeline in cpu microarchitectures when the next instruction cannot execute in the following clock cycle, and can potentially lead to incorrect computation results. three common types of hazards are data hazards, structural hazards, and control hazards (branching hazards).there are several methods used to deal with hazards, including pipeline stalls/pipeline bubbling, operand forwarding, and in the case of out-of-order execution, the scoreboarding method and the tomasulo algorithm.', 'in computer architecture, multithreading is the ability of a central processing unit (cpu) (or a single core in a multi-core processor) to provide multiple threads of execution concurrently, supported by the operating system. this approach differs from multiprocessing. in a multithreaded application, the threads share the resources of a single or multiple cores, which include the computing units, the cpu caches, and the translation lookaside buffer (tlb).where multiprocessing systems include multiple complete processing units in one or more cores, multithreading aims to increase utilization of a single core by using thread-level parallelism, as well as instruction-level parallelism. as the two techniques are complementary, they are combined in nearly all modern systems architectures with multiple multithreading cpus and with cpus with multiple multithreading cores.', 'the von neumann architecture — also known as the von neumann model or princeton architecture — is a computer architecture based on a 1945 description by john von neumann, and by others, in the first draft of a report on the edvac. the document describes a design architecture for an electronic digital computer with these components:a processing unit with both an arithmetic logic unit and processor registersa control unit that includes an instruction register and a program countermemory that stores data and instructionsexternal mass storageinput and output mechanismsthe term \"von neumann architecture\" has evolved to refer to any stored-program computer in which an instruction fetch and a data operation cannot occur at the same time (since they share a common bus). this is referred to as the von neumann bottleneck, which often limits the performance of the corresponding system.the design of a von neumann architecture machine is simpler than in a harvard architecture machine—which is also a stored-program system, yet has one dedicated set of address and data buses for reading and writing to memory, and another set of address and data buses to fetch instructions.a stored-program digital computer keeps both program instructions and data in read–write, random-access memory (ram).  stored-program computers were an advancement over the program-controlled computers of the 1940s, such as the colossus and the eniac. those were programmed by setting switches and inserting patch cables to route data and control signals between various functional units. the vast majority of modern computers use the same memory for both data and program instructions, but have caches between the cpu and memory, and, for the caches closest to the cpu, have separate caches for instructions and data, so that most instruction and data fetches use separate buses (split cache architecture).', 'in computer science, predication is an architectural feature that provides an alternative to conditional transfer of control, as implemented by conditional branch machine instructions. predication works by having conditional (predicated) non-branch instructions associated with a predicate, a boolean value used by the instruction to control whether the instruction is allowed to modify the architectural state or not.  if the predicate specified in the instruction is true, the instruction modifies the architectural state; otherwise, the architectural state is unchanged.  for example, a predicated move instruction (a conditional move) will only modify the destination if the predicate is true.  thus, instead of using a conditional branch to select an instruction or a sequence of instructions to execute based on the predicate that controls whether the branch occurs, the instructions to be executed are associated with that predicate, so that they will be executed, or not executed, based on whether that predicate is true or false.vector processors, some simd isas (such as avx2 and avx-512) and gpus in general make heavy use of predication, applying one bit of a conditional mask vector to the corresponding elements in the vector registers being processed, whereas scalar predication in scalar instruction sets only need the one predicate bit.  where predicate masks become particularly powerful in vector processing is if an array of condition codes, one per vector element, may feed back into predicate masks that are then applied to subsequent vector instructions.'], 'history': ['the first documented computer architecture was in the correspondence between charles babbage and ada lovelace, describing the analytical engine. when building the computer z1 in 1936, konrad zuse described in two patent applications for his future projects that machine instructions could be stored in the same storage used for data, i.e., the stored-program concept. two other early and important examples are:john von neumann\\'s 1945 paper, first draft of a report on the edvac, which described an organization of logical elements; andalan turing\\'s more detailed proposed electronic calculator for the automatic computing engine, also 1945 and which cited john von neumann\\'s paper.the term “architecture” in computer literature can be traced to the work of lyle r. johnson and frederick p. brooks, jr., members of the machine organization department in ibm\\'s main research center in 1959. johnson had the opportunity to write a proprietary research communication about the stretch, an ibm-developed supercomputer for los alamos national laboratory (at the time known as los alamos scientific laboratory). to describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that seemed more useful than “machine organization”.subsequently, brooks, a stretch designer, opened chapter 2 of a book called planning a computer system: project stretch by stating, “computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.”brooks went on to help develop the ibm system/360 (now called the ibm zseries) line of computers, in which “architecture” became a noun defining “what the user needs to know”. later, computer users came to use the term in many less explicit ways.the earliest computer architectures were designed on paper and then directly built into the final hardware form.later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (ttl) computer—such as the prototypes of the 6800 and the pa-risc—tested, and tweaked, before committing to the final hardware form.as of the 1990s, new computer architectures are typically \"built\", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a fpga as a soft microprocessor; or both—before committing to the final hardware form.', 'the earliest computing machines had fixed programs.  some very simple computers still use this design, either for simplicity or training purposes.  for example, a desk calculator (in principle) is a fixed program computer.  it can do basic mathematics, but it cannot run a word processor or games.  changing the program of a fixed-program machine requires rewiring, restructuring, or redesigning the machine.  the earliest computers were not so much \"programmed\" as  \"designed\" for a particular task.  \"reprogramming\" – when possible at all – was a laborious process that started with flowcharts and paper notes, followed by detailed engineering designs, and then the often-arduous process of physically rewiring and rebuilding the machine. it could take three weeks to set up and debug a program on eniac.with the proposal of the stored-program computer, this changed. a stored-program computer includes, by design, an instruction set, and can store in memory a set of instructions (a program) that details the computation.a stored-program design also allows for self-modifying code. one early motivation for such a facility was the need for a program to increment or otherwise modify the address portion of instructions, which operators had to do manually in early designs. this became less important when index registers and indirect addressing became usual features of machine architecture. another use was to embed frequently used data in the instruction stream using immediate addressing. self-modifying code has largely fallen out of favor, since it is usually hard to understand and debug, as well as being inefficient under modern processor pipelining and caching schemes.', 'predicated instructions were popular in european computer designs of the 1950s, including the mailüfterl (1955), the zuse z22 (1955), the zebra (1958), and the electrologica x1 (1958). the ibm acs-1 design of 1967 allocated a \"skip\" bit in its instruction formats, and the cdc flexible processor in 1976 allocated three conditional execution bits in its microinstruction formats.hewlett-packard\\'s pa-risc architecture (1986) had a feature called nullification, which allowed most instructions to be predicated by the previous instruction. ibm\\'s power architecture (1990) featured conditional move instructions. power\\'s successor, powerpc (1993), dropped these instructions. digital equipment corporation\\'s alpha architecture (1992) also featured conditional move instructions. mips gained conditional move instructions in 1994 with the mips iv version; and sparc was extended in version 9 (1994) with conditional move instructions for both integer and floating-point registers.in the hewlett-packard/intel ia-64 architecture, most instructions are predicated. the predicates are stored in 64 special-purpose predicate registers; and one of the predicate registers is always true so that unpredicated instructions are simply instructions predicated with the value true. the use of predication is essential in ia-64\\'s implementation of software pipelining because it avoids the need for writing separated code for prologs and epilogs.in the x86 architecture, a family of conditional move instructions (cmov and fcmov) were added to the architecture by the intel pentium pro (1995) processor. the cmov instructions copied the contents of the source register to the destination register depending on a predicate supplied by the value of the flag register.in the arm architecture, the original 32-bit instruction set provides a feature called conditional execution that allows most instructions to be predicated by one of 13 predicates that are based on some combination of the four condition codes set by the previous instruction. arm\\'s thumb instruction set (1994) dropped conditional execution to reduce the size of instructions so they could fit in 16 bits, but its successor, thumb-2 (2003) overcame this problem by using a special instruction which has no effect other than to supply predicates for the following four instructions. the 64-bit instruction set introduced in armv8-a (2011) replaced conditional execution with conditional selection instructions.== simd, simt and vector predication ==some simd instruction sets, like avx2, have the ability to use a logical mask to conditionally load/store values to memory, a parallel form of the conditional move, and may also apply individual mask bits to individual arithmetic units executing a parallel operation.  the technique is known in flynn\\'s taxonomy as \"associative processing\".this form of predication is also used in vector processors and single instruction, multiple threads gpu computing.  all the techniques, advantages and disadvantages of single scalar predication apply just as well to the parallel processing case.'], 'subcategorie': ['the discipline of computer architecture has three main subcategories:instruction set architecture (isa): defines the machine code that a processor reads and acts upon as well as the word size, memory address modes, processor registers, and data type.microarchitecture: also known as \"computer organization\", this describes how a particular processor will implement the isa. the size of a computer\\'s cpu cache for instance, is an issue that generally has nothing to do with the isa.systems design: includes all of the other hardware components within a computing system, such as data processing other than the cpu (e.g., direct memory access), virtualization, and multiprocessing.there are other technologies in computer architecture. the following technologies are used in bigger companies like intel, and were estimated in 2002 to count for 1% of all of computer architecture:macroarchitecture: architectural layers more abstract than microarchitectureassembly instruction set architecture: a smart assembler may convert an abstract assembly language common to a group of machines into slightly different machine language for different implementations.programmer-visible macroarchitecture: higher-level language tools such as compilers may define a consistent interface or contract to programmers using them, abstracting differences between underlying isa, uisa, and microarchitectures. for example, the c, c++, or java standards define different programmer-visible macroarchitectures.microcode: microcode is software that translates instructions to run on a chip. it acts like a wrapper around the hardware, presenting a preferred version of the hardware\\'s instruction set interface. this instruction translation facility gives chip designers flexible options: e.g. 1. a new improved version of the chip can use microcode to present the exact same instruction set as the old chip version, so all software targeting that instruction set will run on the new chip without needing changes. e.g. 2. microcode can present a variety of instruction sets for the same underlying chip, allowing it to run a wider variety of software.uisa: user instruction set architecture, refers to one of three subsets of the risc cpu instructions provided by powerpc risc processors. the uisa subset, are those risc instructions of interest to application developers. the other two subsets are vea (virtual environment architecture) instructions used by virtualization system developers, and oea (operating environment architecture) used by operation system developers.pin architecture: the hardware functions that a microprocessor should provide to a hardware platform, e.g., the x86 pins a20m, ferr/ignne or flush. also, messages that the processor should emit so that external caches can be invalidated (emptied). pin architecture functions are more flexible than isa functions because external hardware can adapt to new encodings, or change from a pin to a message. the term \"architecture\" fits, because the functions must be provided for compatible systems, even if the detailed method changes.'], 'role': [\"=== definition ===computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. the case of instruction set architecture can be used to illustrate the balance of these competing factors. more complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 loop instruction). however, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. the increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.the implementation involves integrated circuit design, packaging, power, and cooling. optimization of the design requires familiarity with compilers, operating systems to logic design, and packaging.=== instruction set architecture ===an instruction set architecture (isa) is the interface between the computer's software and hardware and also can be viewed as the programmer's view of the machine. computers do not understand high-level programming languages such as java, c++, or most programming languages used. a processor only understands instructions encoded in some numerical fashion, usually as binary numbers. software tools, such as compilers, translate those high level languages into instructions that the processor can understand.besides instructions, the isa defines items in the computer that are available to a program—e.g., data types, registers, addressing modes, and memory.  instructions locate these available items with register indexes (or names) and memory addressing modes.the isa of a computer is usually described in a small instruction manual, which describes how the instructions are encoded. also, it may define short (vaguely) mnemonic names for the instructions. the names can be recognized by a software development tool called an assembler.  an assembler is a computer program that translates a human-readable form of the isa into a computer-readable form.  disassemblers are also widely available, usually in debuggers and software programs to isolate and correct malfunctions in binary computer programs.isas vary in quality and completeness.  a good isa compromises between programmer convenience (how easy the code is to understand), size of the code (how much code is required to do a specific action), cost of the computer to interpret the instructions (more complexity means more hardware needed to decode and execute the instructions), and speed of the computer (with more complex decoding hardware comes longer decode time).  memory organization defines how instructions interact with the memory, and how memory interacts with itself.during design emulation, emulators can run programs written in a proposed instruction set. modern emulators can measure size, cost, and speed to determine whether a particular isa is meeting its goals.=== computer organization ===computer organization helps optimize performance-based products. for example, software engineers need to know the processing power of processors. they may need to optimize software in order to gain the most performance for the lowest price. this can require quite a detailed analysis of the computer's organization.  for example, in an sd card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.computer organization also helps plan the selection of a processor for a particular project. multimedia projects may need very rapid data access, while virtual machines may need fast interrupts. sometimes certain tasks need additional components as well.  for example, a computer capable of running a virtual machine needs virtual memory hardware so that the memory of different virtual computers can be kept separated. computer organization and features also affect power consumption and processor cost.=== implementation ===once an instruction set and micro-architecture have been designed, a practical machine must be developed. this design process is called the implementation. implementation is usually not considered architectural design, but rather hardware design engineering. implementation can be further broken down into several steps:logic implementation designs the circuits required at a logic-gate level.circuit implementation does transistor-level designs of basic elements (e.g., gates, multiplexers, latches) as well as of some larger blocks (alus, caches etc.) that may be implemented at the logic-gate level, or even at the physical level if the design calls for it.physical implementation draws physical circuits.  the different circuit components are placed in a chip floor plan or on a board and the wires connecting them are created.design validation tests the computer as a whole to see if it works in all situations and all timings. once the design validation process starts, the design at the logic level are tested using logic emulators. however, this is usually too slow to run a realistic test.  so, after making corrections based on the first test, prototypes are constructed using field-programmable gate-arrays (fpgas). most hobby projects stop at this stage.  the final step is to test prototype integrated circuits, which may require several redesigns.for cpus, the entire implementation process is organized differently and is often referred to as cpu design.\"], 'design goal': ['the exact form of a computer system depends on the constraints and goals. computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.the most common scheme does an in-depth power analysis and figures out how to keep power consumption low while maintaining adequate performance.=== performance ===modern computer performance is often described in instructions per cycle (ipc), which measures the efficiency of the architecture at any clock frequency; a faster ipc rate means the computer is faster. older computers had ipc counts as low as 0.1 while modern processors easily reach near 1. superscalar processors may reach three to five ipc by executing several instructions per clock cycle.counting machine-language instructions would be misleading because they can do varying amounts of work in different isas. the \"instruction\" in the standard measurements is not a count of the isa\\'s machine-language instructions, but a unit of measurement, usually based on the speed of the vax computer architecture.many people used to measure a computer\\'s speed by the clock rate (usually in mhz or ghz). this refers to the cycles per second of the main clock of the cpu. however, this metric is somewhat misleading, as a machine with a higher clock rate may not necessarily have greater performance. as a result, manufacturers have moved away from clock speed as a measure of performance.other factors influence speed, such as the mix of functional units, bus speeds, available memory, and the type and order of instructions in the programs.there are two main types of speed: latency and throughput. latency is the time between the start of a process and its completion. throughput is the amount of work done per unit time.  interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).performance is affected by a very wide range of design choices — for example, pipelining a processor usually makes latency worse, but makes throughput better. computers that control machinery usually need low interrupt latencies. these computers operate in a real-time environment and fail if an operation is not completed in a specified amount of time. for example, computer-controlled anti-lock brakes must begin braking within a predictable and limited time period after the brake pedal is sensed or else failure of the brake will occur.benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. although benchmarking shows strengths, it shouldn\\'t be how you choose a computer. often the measured machines split on different measures. for example, one system might handle scientific applications quickly, while another might render video games more smoothly. furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but don\\'t offer similar advantages to general tasks.=== power efficiency ===power efficiency is another important measurement in modern computers. a higher power efficiency can often be traded for lower speed or higher cost. the typical measurement when referring to power consumption in computer architecture is mips/w (millions of instructions per second per watt).modern circuits have less power required per transistor as the number of transistors per chip grows. this is because each transistor that is put in a new chip requires its own power supply and requires new pathways to be built to power it. however the number of transistors per chip is starting to increase at a slower rate. therefore, power efficiency is starting to become as important, if not more important than fitting more and more transistors into a single chip. recent processor designs have shown this emphasis as they put more focus on power efficiency rather than cramming as many transistors into a single chip as possible. in the world of embedded computers, power efficiency has long been an important goal next to throughput and latency.=== shifts in market demand ===increases in clock frequency have grown more slowly over the past few years, compared to power reduction improvements. this has been driven by the end of moore\\'s law and demand for longer battery life and reductions in size for mobile technology. this change in focus from higher clock rates to power consumption and miniaturization can be shown by the significant reductions in power consumption, as much as 50%, that were reported by intel in their release of the haswell microarchitecture; where they dropped their power consumption benchmark from 30 to 40 watts down to 10-20 watts. comparing this to the processing speed increase of 3 ghz to 4 ghz (2002 to 2006) it can be seen that the focus in research and development are shifting away from clock frequency and moving towards consuming less power and taking up less space.'], 'see also': ['', 'integer (computer science)', '', 'super-threadingspeculative multithreading', 'cardboard illustrative aid to computationinterconnect bottlenecklittle man computerrandom-access machineharvard architectureturing machineeckert architecture', ''], 'reference': ['', '', '=== general ===', '', '', ''], 'source': ['john l. hennessy and david patterson (2006). computer architecture: a quantitative approach (fourth ed.). morgan kaufmann. isbn 978-0-12-370490-0.barton, robert s., \"functional design of computers\", communications of the acm 4(9): 405 (1961).barton, robert s., \"a new approach to the functional design of a digital computer\", proceedings of the western joint computer conference, may 1961, pp. 393–396. about the design of the burroughs b5000 computer.bell, c. gordon; and newell, allen (1971). \"computer structures: readings and examples\", mcgraw-hill.blaauw, g.a., and brooks, f.p., jr., \"the structure of system/360, part i-outline of the logical structure\", ibm systems journal, vol. 3, no. 2, pp. 119–135, 1964.tanenbaum, andrew s. (1979). structured computer organization. englewood cliffs, new jersey: prentice-hall. isbn 0-13-148521-0.'], 'external link': ['isca: proceedings of the international symposium on computer architecturemicro: ieee/acm international symposium on microarchitecturehpca: international symposium on high performance computer architectureasplos: international conference on architectural support for programming languages and operating systemsacm transactions on architecture and code optimizationieee transactions on computersthe von neumann architecture of computer systems', '\"automatic pipelining from transactional datapath specifications\" (pdf). retrieved 23 july 2014.tulsen, dean (18 january 2005). \"pipeline hazards\" (pdf).', 'a survey of processors with explicit multithreading, acm, march 2003, by theo ungerer, borut robi and jurij silcoperating system | difference between multitasking, multithreading and multiprocessing geeksforgeeks, 6 sept. 2018.', 'harvard vs von neumanna tool that emulates the behavior of a von neumann machinejohnny: a simple open source simulator of a von neumann machine for educational purposes'], 'uses of word': ['depending on how a computer is organized, word-size units may be used for:fixed-point numbersholders for fixed point, usually integer, numerical values may be available in one or in several different sizes, but one of the sizes available will almost always be the word. the other sizes, if any, are likely to be multiples or fractions of the word size. the smaller sizes are normally used only for efficient use of memory; when loaded into the processor, their values usually go into a larger, word sized holder.floating-point numbersholders for floating-point numerical values are typically either a word or a multiple of a word.addressesholders for memory addresses must be of a size capable of expressing the needed range of values but not be excessively large, so often the size used is the word though it can also be a multiple or fraction of the word size.registersprocessor registers are designed with a size appropriate for the type of data they hold, e.g. integers, floating-point numbers, or addresses. many computer architectures use general-purpose registers that are capable of storing data in multiple representations.memory–processor transferwhen the processor reads from the memory subsystem into a register or writes a register\\'s value to memory, the amount of data transferred is often a word. historically, this amount of bits which could be transferred in one cycle was also called a catena in some environments (such as the bull gamma 60). in simple memory subsystems, the word is transferred over the memory data bus, which typically has a width of a word or half-word. in memory subsystems that use caches, the word-sized transfer is the one between the processor and the first level of cache; at lower levels of the memory hierarchy larger transfers (which are a multiple of the word size) are normally used.unit of address resolutionin a given architecture, successive address values designate successive units of memory; this unit is the unit of address resolution. in most computers, the unit is either a character (e.g. a byte) or a word. (a few computers have used bit resolution.) if the unit is a word, then a larger amount of memory can be accessed using an address of a given size at the cost of added complexity to access individual characters. on the other hand, if the unit is a byte, then individual characters can be addressed (i.e. selected during the memory operation).instructionsmachine instructions are normally the size of the architecture\\'s word, such as in risc architectures, or a multiple of the \"char\" size that is a fraction of it. this is a natural choice since instructions and data usually share the same memory subsystem. in harvard architectures the word sizes of instructions and data need not be related, as instructions and data are stored in different memories; for example, the processor in the 1ess electronic telephone switch had 37-bit instructions and 23-bit data words.'], 'word size choice': ['when a computer architecture is designed, the choice of a word size is of substantial importance.  there are design considerations which encourage particular bit-group sizes for particular uses (e.g. for addresses), and these considerations point to different sizes for different uses.  however, considerations of economy in design strongly push for one size, or a very few sizes related by multiples or fractions (submultiples) to a primary size.  that preferred size becomes the word size of the architecture.character size was in the past (pre-variable-sized character encoding) one of the influences on unit of address resolution and the choice of word size.  before the mid-1960s, characters were most often stored in six bits; this allowed no more than 64 characters, so the alphabet was limited to upper case.  since it is efficient in time and space to have the word size be a multiple of the character size, word sizes in this period were usually multiples of 6 bits (in binary machines).  a common choice then was the 36-bit word, which is also a good size for the numeric properties of a floating point format.after the introduction of the ibm system/360 design, which used eight-bit characters and supported lower-case letters, the standard size of a character (or more accurately, a byte) became eight bits.  word sizes thereafter were naturally multiples of eight bits, with 16, 32, and 64 bits being commonly used.=== variable-word architectures ===early machine designs included some that used what is often termed a variable word length.  in this type of organization, an operand had no fixed length. depending on the machine and the instruction, the length might be denoted by a count field, by a delimiting character, or by an additional bit called, e.g., flag, word mark.  such machines often used binary-coded decimal in 4-bit digits, or in 6-bit characters, for numbers.  this class of machines included the ibm 702, ibm 705, ibm 7080, ibm 7010, univac 1050, ibm 1401, ibm 1620, and rca 301.most of these machines work on one unit of memory at a time and since each instruction or datum is several units long, each instruction takes several cycles just to access memory.  these machines are often quite slow because of this.  for example, instruction fetches on an ibm 1620 model i take 8 cycles just to read the 12 digits of the instruction (the model ii reduced this to 6 cycles, or 4 cycles if the instruction did not need both address fields). instruction execution took a completely variable number of cycles, depending on the size of the operands.=== word, bit and byte addressing ===the memory model of an architecture is strongly influenced by the word size.  in particular, the resolution of a memory address, that is, the smallest unit that can be designated by an address, has often been chosen to be the word.  in this approach, the word-addressable machine approach, address values which differ by one designate adjacent memory words.  this is natural in machines which deal almost always in word (or multiple-word) units, and has the advantage of allowing instructions to use minimally sized fields to contain addresses, which can permit a smaller instruction size or a larger variety of instructions.when byte processing is to be a significant part of the workload, it is usually more advantageous to use the byte, rather than the word, as the unit of address resolution. address values which differ by one designate adjacent bytes in memory.  this allows an arbitrary character within a character string to be addressed straightforwardly.  a word can still be addressed, but the address to be used requires a few more bits than the word-resolution alternative.  the word size needs to be an integer multiple of the character size in this organization.  this addressing approach was used in the ibm 360, and has been the most common approach in machines designed since then.when the workload involves processing fields of different sizes, it can be advantageous to address to the bit. machines with bit addressing may have some instructions that use a programmer-defined byte size and other instructions that operate on fixed data sizes. as an example, on the ibm 7030 (\"stretch\"), a floating point instruction can only address words while an integer arithmetic instruction can specify a field length of 1-64 bits, a byte size of 1-8 bits and an accumulator offset of 0-127 bits. in at byte-addressable machine with storage-to-storage (ss) instructions, there are typically move instructions to copy one or multiple bytes from one arbitrary location to another. in a byte-oriented (byte-addressable) machine without ss instructions, moving a single byte from one arbitrary location to another is typically:load the source bytestore the result back in the target byteindividual bytes can be accessed on a word-oriented machine in one of two ways.  bytes can be manipulated by a combination of shift and mask operations in registers. moving a single byte from one arbitrary location to another may require the equivalent of the following:load the word containing the source byteshift the source word to align the desired byte to the correct position in the target wordand the source word with a mask to zero out all but the desired bitsload the word containing the target byteand the target word with a mask to zero out the target byteor the registers containing the source and target words to insert the source bytestore the result back in the target locationalternatively many word-oriented machines implement byte operations with instructions using special byte pointers in registers or memory.  for example, the pdp-10 byte pointer contained the size of the byte in bits (allowing different-sized bytes to be accessed), the bit position of the byte within the word, and the word address of the data.  instructions could automatically adjust the pointer to the next byte on, for example, load and deposit (store) operations.=== powers of two ===different amounts of memory are used to store data values with different degrees of precision. the commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word).  converting the index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. in some cases this relationship can also avoid the use of division operations. as a result, most modern computer designs have word sizes (and other operand sizes) that are a power of two times the size of a byte.'], 'size familie': ['as computer designs have grown more complex, the central importance of a single word size to an architecture has decreased.  although more capable hardware can use a wider variety of sizes of data, market forces exert pressure to maintain backward compatibility while extending processor capability.  as a result, what might have been the central word size in a fresh design has to coexist as an alternative size to the original word size in a backward compatible design. the original word size remains available in future designs, forming the basis of a size family.in the mid-1970s, dec designed the vax to be a 32-bit successor of the 16-bit pdp-11. they used word for a 16-bit quantity, while longword referred to a 32-bit quantity; this terminology is the same as the terminology used for the pdp-11. this was in contrast to earlier machines, where the natural unit of addressing memory would be called a word, while a quantity that is one half a word would be called a halfword. in fitting with this scheme, a vax quadword is 64 bits.  they continued this 16-bit word/32-bit longword/64-bit quadword terminology with the 64-bit alpha.another example is the x86 family, of which processors of three different word lengths (16-bit, later 32- and 64-bit) have been released, while word continues to designate a 16-bit quantity. as software is routinely ported from one word-length to the next, some apis and documentation define or refer to an older (and thus shorter) word-length than the full word length on the cpu that software may be compiled for. also, similar to how bytes are used for small numbers in many programs, a shorter word (16 or 32 bits) may be used in contexts where the range of a wider word is not needed (especially where this can save considerable stack space or cache memory space). for example, microsoft\\'s windows api maintains the programming language definition of word as 16 bits, despite the fact that the api may be used on a 32- or 64-bit x86 processor, where the standard word size would be 32 or 64 bits, respectively. data structures containing such different sized words refer to them as:word (16 bits/2 bytes)dword (32 bits/4 bytes)qword (64 bits/8 bytes)a similar phenomenon has developed in intel\\'s x86 assembly language – because of the support for various sizes (and backward compatibility) in the instruction set, some instruction mnemonics carry \"d\" or \"q\" identifiers denoting \"double-\", \"quad-\" or \"double-quad-\", which are in terms of the architecture\\'s original 16-bit word size.an example with a different word size is the ibm system/360 family. in the system/360 architecture, system/370 architecture and system/390 architecture, there are 8-bit bytes, 16-bit halfwords, 32-bit words and 64-bit doublewords. the z/architecture, which is the 64-bit member of that architecture family, continues to refer to 16-bit halfwords, 32-bit words, and 64-bit doublewords, and additionally features 128-bit quadwords.in general, new processors must use the same data word lengths and virtual address widths as an older processor to have binary compatibility with that older processor.often carefully written source code – written with source-code compatibility and software portability in mind – can be recompiled to run on a variety of processors, even ones with different data word lengths or different address widths or both.'], 'table of word size': [''], 'note': [''], 'background': ['instructions in a pipelined processor are performed in several stages, so that at any given time several instructions are being processed in the various stages of the pipeline, such as fetch and execute. there are many different instruction pipeline microarchitectures, and instructions may be executed out-of-order. a hazard occurs when two or more of these simultaneous (possibly out of order) instructions conflict.'], 'type': ['=== data hazards ===data hazards occur when instructions that exhibit data dependence modify data in different stages of a pipeline. ignoring potential data hazards can result in race conditions (also termed race hazards). there are three situations in which a data hazard can occur:read after write (raw), a true dependencywrite after read (war), an anti-dependencywrite after write (waw), an output dependencyread after read (rar) is not a hazard case.consider two instructions i1 and i2, with i1 occurring before i2 in program order.==== read after write (raw) ====(i2 tries to read a source before i1 writes to it)a read after write (raw) data hazard refers to a situation where an instruction refers to a result that has not yet been calculated or retrieved. this can occur because even though an instruction is executed after a prior instruction, the prior instruction has been processed only partly through the pipeline.===== example =====for example:i1. r2 <- r5 + r3i2. r4 <- r2 + r3the first instruction is calculating a value to be saved in register r2, and the second is going to use this value to compute a result for register r4. however, in a pipeline, when operands are fetched for the 2nd operation, the results from the first have not yet been saved, and hence a data dependency occurs.a data dependency occurs with instruction i2, as it is dependent on the completion of instruction i1.==== write after read (war) ====(i2 tries to write a destination before it is read by i1)a write after read (war) data hazard represents a problem with concurrent execution.===== example =====for example:i1. r4 <- r1 + r5i2. r5 <- r1 + r2in any situation with a chance that i2 may finish before i1 (i.e., with concurrent execution), it must be ensured that the result of register r5 is not stored before i1 has had a chance to fetch the operands.==== write after write (waw) ====(i2 tries to write an operand before it is written by i1)a write after write (waw) data hazard may occur in a concurrent execution environment.===== example =====for example:i1. r2 <- r4 + r7i2. r2 <- r1 + r3the write back (wb) of i2 must be delayed until i1 finishes executing.=== structural hazards ===a structural hazard occurs when two (or more) instructions that are already in pipeline need the same resource. the result is that instruction must be executed in series rather than parallel for a portion of pipeline. structural hazards are sometime referred to as resource hazards.example:a situation in which multiple instructions are ready to enter the execute instruction phase and there is a single alu (arithmetic logic unit). one solution to such resource hazard is to increase available resources, such as having multiple ports into main memory and multiple alu (arithmetic logic unit) units.=== control hazards (branch hazards or instruction hazards) ===control hazard occurs when the pipeline makes wrong decisions on branch prediction and therefore brings instructions into the pipeline that must subsequently be discarded. the term branch hazard also refers to a control hazard.'], 'eliminating hazard': ['=== generic ======= pipeline bubbling ====bubbling the pipeline, also termed a pipeline break or pipeline stall, is a method to preclude data, structural, and branch hazards. as instructions are fetched, control logic determines whether a hazard could/will occur. if this is true, then the control logic inserts no operations (nops) into the pipeline. thus, before the next instruction (which would cause the hazard) executes, the prior one will have had sufficient time to finish and prevent the hazard. if the number of nops equals the number of stages in the pipeline, the processor has been cleared of all instructions and can proceed free from hazards. all forms of stalling introduce a delay before the processor can resume execution.flushing the pipeline occurs when a branch instruction jumps to a new memory location, invalidating all prior stages in the pipeline.  these prior stages are cleared, allowing the pipeline to continue at the new instruction indicated by the branch.=== data hazards ===there are several main solutions and algorithms used to resolve data hazards:insert a pipeline bubble whenever a read after write (raw) dependency is encountered, guaranteed to increase latency, oruse out-of-order execution to potentially prevent the need for pipeline bubblesuse operand forwarding to use data from later stages in the pipelinein the case of out-of-order execution, the algorithm used can be:scoreboarding, in which case a pipeline bubble is needed only when there is no functional unit availablethe tomasulo algorithm, which uses register renaming, allowing continual issuing of instructionsthe task of removing data dependencies can be delegated to the compiler, which can fill in an appropriate number of nop instructions between dependent instructions to ensure correct operation, or re-order instructions where possible.==== operand forwarding ======== examples ====in the following examples, computed values are in bold, while register numbers are not.for example, to write the value 3 to register 1, (which already contains a 6), and then add 7 to register 1 and store the result in register 2, i.e.:i0: r1 = 6i1: r1 = 3i2: r2 = r1 + 7 = 10following execution, register 2 should contain the value 10. however, if i1 (write 3 to register 1) does not fully exit the pipeline before i2 starts executing, it means that r1 does not contain the value 3 when i2 performs its addition. in such an event, i2 adds 7 to the old value of register 1 (6), and so register 2 contains 13 instead, i.e.:i0: r1 = 6i2: r2 = r1 + 7 = 13i1: r1 = 3this error occurs because i2 reads register 1 before i1 has committed/stored the result of its write operation to register 1. so when i2 is reading the contents of register 1, register 1 still contains 6, not 3.forwarding (described below) helps correct such errors by depending on the fact that the output of i1 (which is 3) can be used by subsequent instructions before the value 3 is committed to/stored in register 1.forwarding applied to the example means that there is no wait to commit/store the output of i1 in register 1 (in this example, the output is 3) before making that output available to the subsequent instruction (in this case, i2). the effect is that i2 uses the correct (the more recent) value of register 1: the commit/store was made immediately and not pipelined.with forwarding enabled, the instruction decode/execution (id/ex) stage of the pipeline now has two inputs: the value read from the register specified (in this example, the value 6 from register 1), and the new value of register 1 (in this example, this value is 3) which is sent from the next stage instruction execute/memory access (ex/mem). added control logic is used to determine which input to use.=== control hazards (branch hazards) ===to avoid control hazards microarchitectures can:insert a pipeline bubble (discussed above), guaranteed to increase latency, oruse branch prediction and essentially make educated guesses about which instructions to insert, in which case a pipeline bubble will only be needed in the case of an incorrect predictionin the event that a branch causes a pipeline bubble after incorrect instructions have entered the pipeline, care must be taken to prevent any of the wrongly-loaded instructions from having any effect on the processor state excluding energy wasted processing them before they were discovered to be loaded incorrectly.=== other techniques ===memory latency is another factor that designers must attend to, because the delay could reduce performance. different types of memory have different accessing time to the memory. thus, by choosing a suitable type of memory, designers can improve the performance of the pipelined data path.'], 'overview': [\"the multithreading paradigm has become more popular as efforts to further exploit instruction-level parallelism have stalled since the late 1990s. this allowed the concept of throughput computing to re-emerge from the more specialized field of transaction processing. even though it is very difficult to further speed up a single thread or single program, most computer systems are actually multitasking among multiple threads or programs. thus, techniques that improve the throughput of all tasks result in overall performance gains.two major techniques for throughput computing are multithreading and multiprocessing.=== advantages ===if a thread gets a lot of cache misses, the other threads can continue taking advantage of the unused computing resources, which may lead to faster overall execution, as these resources would have been idle if only a single thread were executed. also, if a thread cannot use all the computing resources of the cpu (because instructions depend on each other's result), running another thread may prevent those resources from becoming idle.=== disadvantages ===multiple threads can interfere with each other when sharing hardware resources such as caches or translation lookaside buffers (tlbs). as a result, execution times of a single thread are not improved and can be degraded, even when only one thread is executing, due to lower frequencies or additional pipeline stages that are necessary to accommodate thread-switching hardware.overall efficiency varies; intel claims up to 30% improvement with its hyper-threading technology, while a synthetic program just performing a loop of non-optimized dependent floating-point operations actually gains a 100% speed improvement when run in parallel. on the other hand, hand-tuned assembly language programs using mmx or altivec extensions and performing data prefetches (as a good video encoder might) do not suffer from cache misses or idle computing resources. such programs therefore do not benefit from hardware multithreading and can indeed see degraded performance due to contention for shared resources.from the software standpoint, hardware support for multithreading is more visible to software, requiring more changes to both application programs and operating systems than multiprocessing. hardware techniques used to support multithreading often parallel the software techniques used for computer multitasking. thread scheduling is also a major problem in multithreading.\", \"most computer programs contain conditional code, which will be executed only under specific conditions depending on factors that cannot be determined beforehand, for example depending on user input. as the majority of processors simply execute the next instruction in a sequence, the traditional solution is to insert branch instructions that allow a program to conditionally branch to a different section of code, thus changing the next step in the sequence. this was sufficient until designers began improving performance by implementing instruction pipelining, a method which is slowed down by branches. for a more thorough description of the problems which arose, and a popular solution, see branch predictor.luckily, one of the more common patterns of code that normally relies on branching has a more elegant solution. consider the following pseudocode:on a system that uses conditional branching, this might translate to machine instructions looking similar to:with predication, all possible branch paths are coded inline, but some instructions execute while others do not. the basic idea is that each instruction is associated with a predicate (the word here used similarly to its usage in predicate logic) and that the instruction will only be executed if the predicate is true. the machine code for the above example using predication might look something like this:besides eliminating branches, less code is needed in total, provided the architecture provides predicated instructions. while this does not guarantee faster execution in general, it will if the dosomething and dosomethingelse blocks of code are short enough.predication's simplest form is partial predication, where the architecture has conditional move or conditional select instructions. conditional move instructions write the contents of one register over another only if the predicate's value is true, whereas conditional select instructions choose which of two registers has its contents written to a third based on the predicate's value. a more generalized and capable form is full predication. full predication has a set of predicate registers for storing predicates (which allows multiple nested or sequential branches to be simultaneously eliminated) and most instructions in the architecture have a register specifier field to specify which predicate register supplies the predicate.\"], 'types of multithreading': ['=== interleaved/temporal multithreading ======= coarse-grained multithreading ====the simplest type of multithreading occurs when one thread runs until it is blocked by an event that normally would create a long-latency stall. such a stall might be a cache miss that has to access off-chip memory, which might take hundreds of cpu cycles for the data to return. instead of waiting for the stall to resolve, a threaded processor would switch execution to another thread that was ready to run. only when the data for the previous thread had arrived, would the previous thread be placed back on the list of ready-to-run threads.for example:cycle i: instruction j from thread a is issued.cycle i + 1: instruction j + 1 from thread a is issued.cycle i + 2: instruction j + 2 from thread a is issued, which is a load instruction that misses in all caches.cycle i + 3: thread scheduler invoked, switches to thread b.cycle i + 4: instruction k from thread b is issued.cycle i + 5: instruction k + 1 from thread b is issued.conceptually, it is similar to cooperative multi-tasking used in real-time operating systems, in which tasks voluntarily give up execution time when they need to wait upon some type of the event. this type of multithreading is known as block, cooperative or coarse-grained multithreading.the goal of multithreading hardware support is to allow quick switching between a blocked thread and another thread ready to run. switching from one thread to another means the hardware switches from using one register set to another. to achieve this goal, the hardware for the program visible registers, as well as some processor control registers (such as the program counter), is replicated. for example, to quickly switch between two threads, the processor is built with two sets of registers.additional hardware support for multithreading allows thread switching to be done in one cpu cycle, bringing performance improvements. also, additional hardware allows each thread to behave as if it were executing alone and not sharing any hardware resources with other threads, minimizing the amount of software changes needed within the application and the operating system to support multithreading.many families of microcontrollers and embedded processors have multiple register banks to allow quick context switching for interrupts. such schemes can be considered a type of block multithreading among the user program thread and the interrupt threads.==== interleaved multithreading ====the purpose of interleaved multithreading is to remove all data dependency stalls from the execution pipeline. since one thread is relatively independent from other threads, there is less chance of one instruction in one pipelining stage needing an output from an older instruction in the pipeline. conceptually, it is similar to preemptive multitasking used in operating systems; an analogy would be that the time slice given to each active thread is one cpu cycle.for example:cycle i + 1: an instruction from thread b is issued.cycle i + 2: an instruction from thread c is issued.this type of multithreading was first called barrel processing, in which the staves of a barrel represent the pipeline stages and their executing threads. interleaved, preemptive, fine-grained or time-sliced multithreading are more modern terminology.in addition to the hardware costs discussed in the block type of multithreading, interleaved multithreading has an additional cost of each pipeline stage tracking the thread id of the instruction it is processing. also, since there are more threads being executed concurrently in the pipeline, shared resources such as caches and tlbs need to be larger to avoid thrashing between the different threads.=== simultaneous multithreading ===the most advanced type of multithreading applies to superscalar processors. whereas a normal superscalar processor issues multiple instructions from a single thread every cpu cycle, in simultaneous multithreading (smt) a superscalar processor can issue instructions from multiple threads every cpu cycle. recognizing that any single thread has a limited amount of instruction-level parallelism, this type of multithreading tries to exploit parallelism available across multiple threads to decrease the waste associated with unused issue slots.for example:cycle i: instructions j and j + 1 from thread a and instruction k from thread b are simultaneously issued.cycle i + 1: instruction j + 2 from thread a, instruction k + 1 from thread b, and instruction m from thread c are all simultaneously issued.cycle i + 2: instruction j + 3 from thread a and instructions m + 1 and m + 2 from thread c are all simultaneously issued.to distinguish the other types of multithreading from smt, the term \"temporal multithreading\" is used to denote when instructions from only one thread can be issued at a time.in addition to the hardware costs discussed for interleaved multithreading, smt has the additional cost of each pipeline stage tracking the thread id of each instruction being processed. again, shared resources such as caches and tlbs have to be sized for the large number of active threads being processed.implementations include dec (later compaq) ev8 (not completed), intel hyper-threading technology, ibm power5/power6/power7/power8/power9, ibm z13/z14/z15, sun microsystems ultrasparc t2, cray xmt, and amd bulldozer and zen microarchitectures.'], 'implementation specific': ['a major area of research is the thread scheduler that must quickly choose from among the list of ready-to-run threads to execute next, as well as maintain the ready-to-run and stalled thread lists. an important subtopic is the different thread priority schemes that can be used by the scheduler. the thread scheduler might be implemented totally in software, totally in hardware, or as a hardware/software combination.another area of research is what type of events should cause a thread switch: cache misses, inter-thread communication, dma completion, etc.if the multithreading scheme replicates all of the software-visible state, including privileged control registers and tlbs, then it enables virtual machines to be created for each thread. this allows each thread to run its own operating system on the same processor. on the other hand, if only user-mode state is saved, then less hardware is required, which would allow more threads to be active at one time for the same die area or cost.'], 'capabilitie': ['on a large scale, the ability to treat instructions as data is what makes assemblers, compilers, linkers, loaders, and other automated programming tools possible. it makes \"programs that write programs\" possible.  this has made a sophisticated self-hosting computing ecosystem flourish around von neumann architecture machines.some high level languages leverage the von neumann architecture by providing an abstract, machine-independent way to manipulate executable code at runtime (e.g., lisp), or by using runtime information to tune just-in-time compilation (e.g. languages hosted on the java virtual machine, or languages embedded in web browsers).on a smaller scale, some repetitive operations such as bitblt or pixel and vertex shaders can be accelerated on general purpose processors with just-in-time compilation techniques. this is one use of self-modifying code that has remained popular.== development of the stored-program concept ==the mathematician alan turing, who had been alerted to a problem of mathematical logic by the lectures of max newman at the university of cambridge, wrote a paper in 1936 entitled on computable numbers, with an application to the entscheidungsproblem, which was published in the proceedings of the london mathematical society. in it he described a hypothetical machine he called a universal computing machine, now known as the \"universal turing machine\". the hypothetical machine had an infinite store (memory in today\\'s terminology) that contained both instructions and data. john von neumann became acquainted with turing while he was a visiting professor at cambridge in 1935, and also during turing\\'s phd year at the institute for advanced study in princeton, new jersey during 1936–1937. whether he knew of turing\\'s paper of 1936 at that time is not clear.in 1936, konrad zuse also anticipated, in two patent applications, that machine instructions could be stored in the same storage used for data.independently, j. presper eckert and john mauchly, who were developing the eniac at the moore school of electrical engineering of the university of pennsylvania, wrote about the stored-program concept in december 1943. in planning a new machine, edvac, eckert wrote in january 1944 that they would store data and programs in a new addressable memory device, a mercury metal delay-line memory. this was the first time the construction of a practical stored-program machine was proposed.  at that time, he and mauchly were not aware of turing\\'s work.von neumann was involved in the manhattan project at the los alamos national laboratory. it required huge amounts of calculation, and thus drew him to the eniac project, during the summer of 1944. there he joined the ongoing discussions on the design of this stored-program computer, the edvac. as part of that group, he wrote up a description titled first draft of a report on the edvac based on the work of eckert and mauchly. it was unfinished when his colleague herman goldstine circulated it, and bore only von neumann\\'s name (to the consternation of eckert and mauchly). the paper was read by dozens of von neumann\\'s colleagues in america and europe, and influenced the next round of computer designs.jack copeland considers that it is \"historically inappropriate to refer to electronic stored-program digital computers as \\'von neumann machines\\'\". his los alamos colleague stan frankel said of von neumann\\'s regard for turing\\'s ideasi know that in or about 1943 or \\'44 von neumann was well aware of the fundamental importance of turing\\'s paper of 1936….von neumann introduced me to that paper and at his urging i studied it with care. many people have acclaimed von neumann as the \"father of the computer\" (in a modern sense of the term) but i am sure that he would never have made that mistake himself. he might well be called the midwife, perhaps, but he firmly emphasized to me, and to others i am sure, that the fundamental conception is owing to turing— in so far as not anticipated by babbage…. both turing and von neumann, of course, also made substantial contributions to the \"reduction to practice\" of these concepts but i would not regard these as comparable in importance with the introduction and explication of the concept of a computer able to store in its memory its program of activities and of modifying that program in the course of these activities.at the time that the \"first draft\" report was circulated, turing was producing a report entitled proposed electronic calculator. it described in engineering and programming detail, his idea of a machine he called the automatic computing engine (ace). he presented this to the executive committee of the british national physical laboratory on february 19, 1946. although turing knew from his wartime experience at bletchley park that what he proposed was feasible, the secrecy surrounding colossus, that was subsequently maintained for several decades, prevented him from saying so. various successful implementations of the ace design were produced.both von neumann\\'s and turing\\'s papers described stored-program computers, but von neumann\\'s earlier paper achieved greater circulation and the computer architecture it outlined became known as the \"von neumann architecture\". in the 1953 publication faster than thought: a symposium on digital computing machines (edited by b. v. bowden), a section in the chapter on computers in america reads as follows:the machine of the institute for advanced studies, princetonin 1945, professor j. von neumann, who was then working at the moore school of engineering in philadelphia, where the e.n.i.a.c. had been built, issued on behalf of a group of his co-workers, a report on the logical design of digital computers. the report contained a detailed proposal for the design of the machine that has since become known as the e.d.v.a.c. (electronic discrete variable automatic computer). this machine has only recently been completed in america, but the von neumann report inspired the construction of the e.d.s.a.c. (electronic delay-storage automatic calculator) in cambridge (see page 130).in 1947, burks, goldstine and von neumann published another report that outlined the design of another type of machine (a parallel machine this time) that would be exceedingly fast, capable perhaps of 20,000 operations per second. they pointed out that the outstanding problem in constructing such a machine was the development of suitable memory with instantaneously accessible contents. at first they suggested using a special vacuum tube—called the \"selectron\"—which the princeton laboratories of rca had invented. these tubes were expensive and difficult to make, so von neumann subsequently decided to build a machine based on the williams memory. this machine—completed in june, 1952 in princeton—has become popularly known as the maniac. the design of this machine inspired at least half a dozen machines now being built in america, all known affectionately as \"johniacs\".in the same book, the first two paragraphs of a chapter on ace read as follows:automatic computation at the national physical laboratoryone of the most modern digital computers which embodies developments and improvements in the technique of automatic electronic computing was recently demonstrated at the national physical laboratory, teddington, where it has been designed and built by a small team of mathematicians and electronics research engineers on the staff of the laboratory, assisted by a number of production engineers from the english electric company, limited. the equipment so far erected at the laboratory is only the pilot model of a much larger installation which will be known as the automatic computing engine, but although comparatively small in bulk and containing only about 800 thermionic valves, as can be judged from plates xii, xiii and xiv, it is an extremely rapid and versatile calculating machine.the basic concepts and abstract principles of computation by a machine were formulated by dr. a. m. turing, f.r.s., in a paper1. read before the london mathematical society in 1936, but work on such machines in britain was delayed by the war. in 1945, however, an examination of the problems was made at the national physical laboratory by mr. j. r. womersley, then superintendent of the mathematics division of the laboratory. he was joined by dr. turing and a small staff of specialists, and, by 1947, the preliminary planning was sufficiently advanced to warrant the establishment of the special group already mentioned. in april, 1948, the latter became the electronics section of the laboratory, under the charge of mr. f. m. colebrook.== early von neumann-architecture computers ==the first draft described a design that was used by many universities and corporations to construct their computers. among these various computers, only illiac and ordvac had compatible instruction sets.arc2 (birkbeck, university of london) officially came online on may 12, 1948.manchester baby (victoria university of manchester, england) made its first successful run of a stored program on june 21, 1948.edsac (university of cambridge, england) was the first practical stored-program electronic computer (may 1949)manchester mark 1 (university of manchester, england) developed from the baby (june 1949)csirac (council for scientific and industrial research) australia (november 1949)mesm in kyiv, ukraine (november 1950)edvac (ballistic research laboratory, computing laboratory at aberdeen proving ground 1951)ordvac (u-illinois) at aberdeen proving ground, maryland (completed november 1951)ias machine at princeton university (january 1952)maniac i at los alamos scientific laboratory (march 1952)illiac at the university of illinois, (september 1952)besm-1 in moscow (1952)avidac at argonne national laboratory (1953)oracle at oak ridge national laboratory (june 1953)besk in stockholm (1953)johnniac at rand corporation (january 1954)dask in denmark (1955)weizac at the weizmann institute of science in rehovot, israel (1955)perm in munich (1956)silliac in sydney (1956)== early stored-program computers ==the date information in the following chronology is difficult to put into proper order. some dates are for first running a test program, some dates are the first time the computer was demonstrated or completed, and some dates are for the first delivery or installation.the ibm ssec had the ability to treat instructions as data, and was publicly demonstrated on january 27, 1948. this ability was claimed in a us patent. however it was partially electromechanical, not fully electronic. in practice, instructions were read from paper tape due to its limited memory.the arc2 developed by andrew booth and kathleen booth at birkbeck, university of london officially came online on may 12, 1948. it featured the first rotating drum storage device.the manchester baby was the first fully electronic computer to run a stored program. it ran a factoring program for 52 minutes on june 21, 1948, after running a simple division program and a program to show that two numbers were relatively prime.the eniac was modified to run as a primitive read-only stored-program computer (using the function tables for program rom) and was demonstrated as such on september 16, 1948, running a program by adele goldstine for von neumann.the binac ran some test programs in february, march, and april 1949, although was not completed until september 1949.the manchester mark 1 developed from the baby project.  an intermediate version of the mark 1 was available to run programs in april 1949, but was not completed until october 1949.the edsac ran its first program on may 6, 1949.the edvac was delivered in august 1949, but it had problems that kept it from being put into regular operation until 1951.the csir mk i ran its first program in november 1949.the seac was demonstrated in april 1950.the pilot ace ran its first program on may 10, 1950, and was demonstrated in december 1950.the swac was completed in july 1950.the whirlwind was completed in december 1950 and was in actual use in april 1951.the first era atlas (later the commercial era 1101/univac 1101) was installed in december 1950.'], 'evolution': ['through the decades of the 1960s and 1970s computers generally became both smaller and faster, which led to evolutions in their architecture. for example, memory-mapped i/o lets input and output devices be treated the same as memory. a single system bus could be used to provide a modular system with lower cost. this is sometimes called a \"streamlining\" of the architecture.in subsequent decades, simple microcontrollers would sometimes omit features of the model to lower cost and size.larger computers added features for higher performance.'], 'design limitation': ['=== von neumann bottleneck ===the shared bus between the program memory and data memory leads to the von neumann bottleneck, the limited throughput (data transfer rate) between the central processing unit (cpu) and memory compared to the amount of memory.  because the single bus can only access one of the two classes of memory at a time, throughput is lower than the rate at which the cpu can work.  this seriously limits the effective processing speed when the cpu is required to perform minimal processing on large amounts of data.  the cpu is continually forced to wait for needed data to move to or from memory.  since cpu speed and memory size have increased much faster than the throughput between them, the bottleneck has become more of a problem, a problem whose severity increases with every new generation of cpu.the von neumann bottleneck was described by john backus in his 1977 acm turing award lecture.  according to backus:surely there must be a less primitive way of making big changes in the store than by pushing vast numbers of words back and forth through the von neumann bottleneck. not only is this tube a literal bottleneck for the data traffic of a problem, but, more importantly, it is an intellectual bottleneck that has kept us tied to word-at-a-time thinking instead of encouraging us to think in terms of the larger conceptual units of the task at hand. thus programming is basically planning and detailing the enormous traffic of words through the von neumann bottleneck, and much of that traffic concerns not significant data itself, but where to find it.==== mitigations ====there are several known methods for mitigating the von neumann performance bottleneck.  for example, the following all can improve performance:providing a cache between the cpu and the main memoryproviding separate caches or separate access paths for data and instructions (the so-called modified harvard architecture)using branch predictor algorithms and logicproviding a limited cpu stack or other on-chip scratchpad memory to reduce memory accessimplementing the cpu and the memory hierarchy as a system on chip, providing greater locality of reference and thus reducing latency and increasing throughput between processor registers and main memorythe problem can also be sidestepped somewhat by using parallel computing, using for example the non-uniform memory access (numa) architecture—this approach is commonly employed by supercomputers. it is less clear whether the intellectual bottleneck that backus criticized has changed much since 1977. backus\\'s proposed solution has not had a major influence. modern functional programming and object-oriented programming are much less geared towards \"pushing vast numbers of words back and forth\" than earlier languages like fortran were, but internally, that is still what computers spend much of their time doing, even highly parallel supercomputers.as of 1996, a database benchmark study found that three out of four cpu cycles were spent waiting for memory. researchers expect that increasing the number of simultaneous instruction streams with multithreading or single-chip multiprocessing will make this bottleneck even worse.  in the context of multi-core processors, additional overhead is required to maintain cache coherence between processors and threads.=== self-modifying code ===aside from the von neumann bottleneck, program modifications can be quite harmful, either by accident or design.  in some simple stored-program computer designs, a malfunctioning program can damage itself, other programs, or the operating system, possibly leading to a computer crash. memory protection and other forms of access control can usually protect against both accidental and malicious program changes.'], 'further reading': ['', 'clements, alan (2013). \"8.3.7 predication\". computer organization & architecture: themes and variations. cengage learning. pp. 532–9. isbn 1-285-41542-6.'], 'advantage': ['the main purpose of predication is to avoid jumps over very small sections of program code, increasing the effectiveness of pipelined execution and avoiding problems with the cache. it also has a number of more subtle benefits:functions that are traditionally computed using simple arithmetic and bitwise operations may be quicker to compute using predicated instructions.predicated instructions with different predicates can be mixed with each other and with unconditional code, allowing better instruction scheduling and so even better performance.elimination of unnecessary branch instructions can make the execution of necessary branches, such as those that make up loops, faster by lessening the load on branch prediction mechanisms.elimination of the cost of a branch misprediction which can be high on deeply pipelined architectures.instruction sets that have comprehensive condition codes generated by instructions may reduce code size further by directly using the condition registers in or as predication.'], 'disadvantage': [\"predication's primary drawback is in increased encoding space. in typical implementations, every instruction reserves a bitfield for the predicate specifying under what conditions that instruction should have an effect. when available memory is limited, as on embedded devices, this space cost can be prohibitive. however, some architectures such as thumb-2 are able to avoid this issue (see below). other detriments are the following:predication complicates the hardware by adding levels of logic to critical paths and potentially degrades clock speed.a predicated block includes cycles for all operations, so shorter paths may take longer and be penalized.predication is not usually speculated and causes a longer dependency chain. for ordered data this translates to a performance loss compared to a predictable branch.predication is most effective when paths are balanced or when the longest path is the most frequently executed, but determining such a path is very difficult at compile time, even in the presence of profiling information.\"]})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['etymology', 'history', 'type', 'hardware', 'software', 'networking and the internet', 'unconventional computer', 'future', 'professions and organization', 'source']\n",
      "defaultdict(<class 'list'>, {'intro': ['in computer engineering, computer architecture is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. the architecture of a system refers to its structure in terms of separately specified components of that system and their interrelationships.some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation. in other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation.', 'in computing, a word is the natural unit of data used by a particular processor design. a word is a fixed-sized datum handled as a unit by the instruction set or the hardware of the processor. the number of bits or digits in a word (the word size, word width, or word length) is an important characteristic of any specific processor design or computer architecture.the size of a word is reflected in many aspects of a computer\\'s structure and operation; the majority of the registers in a processor are usually word sized and the largest datum that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. the largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used).documentation for computers with fixed word size commonly stated memory sizes in words rather than bytes or characters.  the documentation sometimes used metric prefixes correctly, sometimes with rounding, e.g., 65 kilowords (kw) meaning for 65536 words, and sometimes used them incorrectly, with kilowords (kw) meaning 1024 words (210) and megawords (mw) meaning 1,048,576 words (220). with standardization on 8-bit bytes and byte addressability, stating memory sizes in bytes, kilobytes, and megabytes with powers of 1024 rather than 1000 has become the norm, although there is some use of the iec binary prefixes.several of the earliest computers (and a few modern as well) used binary-coded decimal rather than plain binary, typically having a word size of 10 or 12 decimal digits, and some early decimal computers had no fixed word length at all. early binary systems tended to use word lengths that were some multiple of 6-bits, with the 36-bit word being especially common on mainframe computers. the introduction of ascii led to the move to systems with word lengths that were a multiple of 8-bits, with 16-bit machines being popular in the 1970s before the move to modern processors with 32 or 64 bits. special-purpose designs like digital signal processors, may have any word length from 4 to 80 bits.the size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. if multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see size families below).', 'in the domain of central processing unit (cpu) design, hazards are problems with the instruction pipeline in cpu microarchitectures when the next instruction cannot execute in the following clock cycle, and can potentially lead to incorrect computation results. three common types of hazards are data hazards, structural hazards, and control hazards (branching hazards).there are several methods used to deal with hazards, including pipeline stalls/pipeline bubbling, operand forwarding, and in the case of out-of-order execution, the scoreboarding method and the tomasulo algorithm.', 'in computer architecture, multithreading is the ability of a central processing unit (cpu) (or a single core in a multi-core processor) to provide multiple threads of execution concurrently, supported by the operating system. this approach differs from multiprocessing. in a multithreaded application, the threads share the resources of a single or multiple cores, which include the computing units, the cpu caches, and the translation lookaside buffer (tlb).where multiprocessing systems include multiple complete processing units in one or more cores, multithreading aims to increase utilization of a single core by using thread-level parallelism, as well as instruction-level parallelism. as the two techniques are complementary, they are combined in nearly all modern systems architectures with multiple multithreading cpus and with cpus with multiple multithreading cores.', 'the von neumann architecture — also known as the von neumann model or princeton architecture — is a computer architecture based on a 1945 description by john von neumann, and by others, in the first draft of a report on the edvac. the document describes a design architecture for an electronic digital computer with these components:a processing unit with both an arithmetic logic unit and processor registersa control unit that includes an instruction register and a program countermemory that stores data and instructionsexternal mass storageinput and output mechanismsthe term \"von neumann architecture\" has evolved to refer to any stored-program computer in which an instruction fetch and a data operation cannot occur at the same time (since they share a common bus). this is referred to as the von neumann bottleneck, which often limits the performance of the corresponding system.the design of a von neumann architecture machine is simpler than in a harvard architecture machine—which is also a stored-program system, yet has one dedicated set of address and data buses for reading and writing to memory, and another set of address and data buses to fetch instructions.a stored-program digital computer keeps both program instructions and data in read–write, random-access memory (ram).  stored-program computers were an advancement over the program-controlled computers of the 1940s, such as the colossus and the eniac. those were programmed by setting switches and inserting patch cables to route data and control signals between various functional units. the vast majority of modern computers use the same memory for both data and program instructions, but have caches between the cpu and memory, and, for the caches closest to the cpu, have separate caches for instructions and data, so that most instruction and data fetches use separate buses (split cache architecture).', 'in computer science, predication is an architectural feature that provides an alternative to conditional transfer of control, as implemented by conditional branch machine instructions. predication works by having conditional (predicated) non-branch instructions associated with a predicate, a boolean value used by the instruction to control whether the instruction is allowed to modify the architectural state or not.  if the predicate specified in the instruction is true, the instruction modifies the architectural state; otherwise, the architectural state is unchanged.  for example, a predicated move instruction (a conditional move) will only modify the destination if the predicate is true.  thus, instead of using a conditional branch to select an instruction or a sequence of instructions to execute based on the predicate that controls whether the branch occurs, the instructions to be executed are associated with that predicate, so that they will be executed, or not executed, based on whether that predicate is true or false.vector processors, some simd isas (such as avx2 and avx-512) and gpus in general make heavy use of predication, applying one bit of a conditional mask vector to the corresponding elements in the vector registers being processed, whereas scalar predication in scalar instruction sets only need the one predicate bit.  where predicate masks become particularly powerful in vector processing is if an array of condition codes, one per vector element, may feed back into predicate masks that are then applied to subsequent vector instructions.', 'a computer is a digital electronic machine that can be programmed to carry out sequences of arithmetic or logical operations (computation) automatically. modern computers can perform generic sets of operations known as programs. these programs enable computers to perform a wide range of tasks. a computer system is a \"complete\" computer that includes the hardware, operating system (main software), and peripheral equipment needed and used for \"full\" operation. this term may also refer to a group of computers that are linked and function together, such as a computer network or computer cluster.a broad range of industrial and consumer products use computers as control systems. simple special-purpose devices like microwave ovens and remote controls are included, as are factory devices like industrial robots and computer-aided design, as well as general-purpose devices like personal computers and mobile devices like smartphones. computers power the internet, which links billions of other computers and users.early computers were meant to be used only for calculations. simple manual instruments like the abacus have aided people in doing calculations since ancient times. early in the industrial revolution, some mechanical devices were built to automate long tedious tasks, such as guiding patterns for looms. more sophisticated electrical machines did specialized analog calculations in the early 20th century. the first digital electronic calculating machines were developed during world war ii. the first semiconductor transistors in the late 1940s were followed by the silicon-based mosfet (mos transistor) and monolithic integrated circuit (ic) chip technologies in the late 1950s, leading to the microprocessor and the microcomputer revolution in the 1970s. the speed, power and versatility of computers have been increasing dramatically ever since then, with transistor counts increasing at a rapid pace (as predicted by moore\\'s law), leading to the digital revolution during the late 20th to early 21st centuries.conventionally, a modern computer consists of at least one processing element, typically a central processing unit (cpu) in the form of a microprocessor, along with some type of computer memory, typically semiconductor memory chips. the processing element carries out arithmetic and logical operations, and a sequencing and control unit can change the order of operations in response to stored information. peripheral devices include input devices (keyboards, mice, joystick, etc.), output devices (monitor screens, printers, etc.), and input/output devices that perform both functions (e.g., the 2000s-era touchscreen). peripheral devices allow information to be retrieved from an external source and they enable the result of operations to be saved and retrieved.'], 'history': ['the first documented computer architecture was in the correspondence between charles babbage and ada lovelace, describing the analytical engine. when building the computer z1 in 1936, konrad zuse described in two patent applications for his future projects that machine instructions could be stored in the same storage used for data, i.e., the stored-program concept. two other early and important examples are:john von neumann\\'s 1945 paper, first draft of a report on the edvac, which described an organization of logical elements; andalan turing\\'s more detailed proposed electronic calculator for the automatic computing engine, also 1945 and which cited john von neumann\\'s paper.the term “architecture” in computer literature can be traced to the work of lyle r. johnson and frederick p. brooks, jr., members of the machine organization department in ibm\\'s main research center in 1959. johnson had the opportunity to write a proprietary research communication about the stretch, an ibm-developed supercomputer for los alamos national laboratory (at the time known as los alamos scientific laboratory). to describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that seemed more useful than “machine organization”.subsequently, brooks, a stretch designer, opened chapter 2 of a book called planning a computer system: project stretch by stating, “computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.”brooks went on to help develop the ibm system/360 (now called the ibm zseries) line of computers, in which “architecture” became a noun defining “what the user needs to know”. later, computer users came to use the term in many less explicit ways.the earliest computer architectures were designed on paper and then directly built into the final hardware form.later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (ttl) computer—such as the prototypes of the 6800 and the pa-risc—tested, and tweaked, before committing to the final hardware form.as of the 1990s, new computer architectures are typically \"built\", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a fpga as a soft microprocessor; or both—before committing to the final hardware form.', 'the earliest computing machines had fixed programs.  some very simple computers still use this design, either for simplicity or training purposes.  for example, a desk calculator (in principle) is a fixed program computer.  it can do basic mathematics, but it cannot run a word processor or games.  changing the program of a fixed-program machine requires rewiring, restructuring, or redesigning the machine.  the earliest computers were not so much \"programmed\" as  \"designed\" for a particular task.  \"reprogramming\" – when possible at all – was a laborious process that started with flowcharts and paper notes, followed by detailed engineering designs, and then the often-arduous process of physically rewiring and rebuilding the machine. it could take three weeks to set up and debug a program on eniac.with the proposal of the stored-program computer, this changed. a stored-program computer includes, by design, an instruction set, and can store in memory a set of instructions (a program) that details the computation.a stored-program design also allows for self-modifying code. one early motivation for such a facility was the need for a program to increment or otherwise modify the address portion of instructions, which operators had to do manually in early designs. this became less important when index registers and indirect addressing became usual features of machine architecture. another use was to embed frequently used data in the instruction stream using immediate addressing. self-modifying code has largely fallen out of favor, since it is usually hard to understand and debug, as well as being inefficient under modern processor pipelining and caching schemes.', 'predicated instructions were popular in european computer designs of the 1950s, including the mailüfterl (1955), the zuse z22 (1955), the zebra (1958), and the electrologica x1 (1958). the ibm acs-1 design of 1967 allocated a \"skip\" bit in its instruction formats, and the cdc flexible processor in 1976 allocated three conditional execution bits in its microinstruction formats.hewlett-packard\\'s pa-risc architecture (1986) had a feature called nullification, which allowed most instructions to be predicated by the previous instruction. ibm\\'s power architecture (1990) featured conditional move instructions. power\\'s successor, powerpc (1993), dropped these instructions. digital equipment corporation\\'s alpha architecture (1992) also featured conditional move instructions. mips gained conditional move instructions in 1994 with the mips iv version; and sparc was extended in version 9 (1994) with conditional move instructions for both integer and floating-point registers.in the hewlett-packard/intel ia-64 architecture, most instructions are predicated. the predicates are stored in 64 special-purpose predicate registers; and one of the predicate registers is always true so that unpredicated instructions are simply instructions predicated with the value true. the use of predication is essential in ia-64\\'s implementation of software pipelining because it avoids the need for writing separated code for prologs and epilogs.in the x86 architecture, a family of conditional move instructions (cmov and fcmov) were added to the architecture by the intel pentium pro (1995) processor. the cmov instructions copied the contents of the source register to the destination register depending on a predicate supplied by the value of the flag register.in the arm architecture, the original 32-bit instruction set provides a feature called conditional execution that allows most instructions to be predicated by one of 13 predicates that are based on some combination of the four condition codes set by the previous instruction. arm\\'s thumb instruction set (1994) dropped conditional execution to reduce the size of instructions so they could fit in 16 bits, but its successor, thumb-2 (2003) overcame this problem by using a special instruction which has no effect other than to supply predicates for the following four instructions. the 64-bit instruction set introduced in armv8-a (2011) replaced conditional execution with conditional selection instructions.== simd, simt and vector predication ==some simd instruction sets, like avx2, have the ability to use a logical mask to conditionally load/store values to memory, a parallel form of the conditional move, and may also apply individual mask bits to individual arithmetic units executing a parallel operation.  the technique is known in flynn\\'s taxonomy as \"associative processing\".this form of predication is also used in vector processors and single instruction, multiple threads gpu computing.  all the techniques, advantages and disadvantages of single scalar predication apply just as well to the parallel processing case.', '=== pre-20th century ===devices have been used to aid computation for thousands of years, mostly using one-to-one correspondence with fingers. the earliest counting device was probably a form of tally stick. later record keeping aids throughout the fertile crescent included calculi (clay spheres, cones, etc.) which represented counts of items, probably livestock or grains, sealed in hollow unbaked clay containers. the use of counting rods is one example.the abacus was initially used for arithmetic tasks. the roman abacus was developed from devices used in babylonia as early as 2400 bc. since then, many other forms of reckoning boards or tables have been invented. in a medieval european counting house, a checkered cloth would be placed on a table, and markers moved around on it according to certain rules, as an aid to calculating sums of money.the antikythera mechanism is believed to be the earliest known mechanical analog computer, according to derek j. de solla price. it was designed to calculate astronomical positions. it was discovered in 1901 in the antikythera wreck off the greek island of antikythera, between kythera and crete, and has been dated to approximately c.\\u2009100 bc. devices of comparable complexity to the antikythera mechanism would not reappear until the fourteenth century.many mechanical aids to calculation and measurement were constructed for astronomical and navigation use. the planisphere was a star chart invented by abū rayhān al-bīrūnī in the early 11th century. the astrolabe was invented in the hellenistic world in either the 1st or 2nd centuries bc and is often attributed to hipparchus. a combination of the planisphere and dioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems in spherical astronomy. an astrolabe incorporating a mechanical calendar computer and gear-wheels was invented by abi bakr of isfahan, persia in 1235. abū rayhān al-bīrūnī invented the first mechanical geared lunisolar calendar astrolabe, an early fixed-wired knowledge processing machine with a gear train and gear-wheels, c.\\u20091000 ad.the sector, a calculating instrument used for solving problems in proportion, trigonometry, multiplication and division, and for various functions, such as squares and cube roots, was developed in the late 16th century and found application in gunnery, surveying and navigation.the planimeter was a manual instrument to calculate the area of a closed figure by tracing over it with a mechanical linkage.the slide rule was invented around 1620–1630 by the english clergyman william oughtred, shortly after the publication of the concept of the logarithm. it is a hand-operated analog computer for doing multiplication and division. as slide rule development progressed, added scales provided reciprocals, squares and square roots, cubes and cube roots, as well as transcendental functions such as logarithms and exponentials, circular and hyperbolic trigonometry and other functions. slide rules with special scales are still used for quick performance of routine calculations, such as the e6b circular slide rule used for time and distance calculations on light aircraft.in the 1770s, pierre jaquet-droz, a swiss watchmaker, built a mechanical doll (automaton) that could write holding a quill pen. by switching the number and order of its internal wheels different letters, and hence different messages, could be produced. in effect, it could be mechanically \"programmed\" to read instructions. along with two other complex machines, the doll is at the musée d\\'art et d\\'histoire of neuchâtel, switzerland, and still operates.in 1831–1835, mathematician and engineer giovanni plana devised a perpetual calendar machine, which, through a system of pulleys and cylinders and over, could predict the perpetual calendar for every year from ad 0 (that is, 1 bc) to ad 4000, keeping track of leap years and varying day length. the tide-predicting machine invented by the scottish scientist sir william thomson in 1872 was of great utility to navigation in shallow waters. it used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location.the differential analyser, a mechanical analog computer designed to solve differential equations by integration, used wheel-and-disc mechanisms to perform the integration. in 1876, sir william thomson had already discussed the possible construction of such calculators, but he had been stymied by the limited output torque of the ball-and-disk integrators. in a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output. the torque amplifier was the advance that allowed these machines to work. starting in the 1920s, vannevar bush and others developed mechanical differential analyzers.=== first computer ===charles babbage, an english mechanical engineer and polymath, originated the concept of a programmable computer. considered the \"father of the computer\", he conceptualized and invented the first mechanical computer in the early 19th century. after working on his revolutionary difference engine, designed to aid in navigational calculations, in 1833 he realized that a much more general design, an analytical engine, was possible. the input of programs and data was to be provided to the machine via punched cards, a method being used at the time to direct mechanical looms such as the jacquard loom. for output, the machine would have a printer, a curve plotter and a bell. the machine would also be able to punch numbers onto cards to be read in later. the engine incorporated an arithmetic logic unit, control flow in the form of conditional branching and loops, and integrated memory, making it the first design for a general-purpose computer that could be described in modern terms as turing-complete.the machine was about a century ahead of its time. all the parts for his machine had to be made by hand – this was a major problem for a device with thousands of parts. eventually, the project was dissolved with the decision of the british government to cease funding. babbage\\'s failure to complete the analytical engine can be chiefly attributed to political and financial difficulties as well as his desire to develop an increasingly sophisticated computer and to move ahead faster than anyone else could follow. nevertheless, his son, henry babbage, completed a simplified version of the analytical engine\\'s computing unit (the mill) in 1888. he gave a successful demonstration of its use in computing tables in 1906.=== analog computers ===during the first half of the 20th century, many scientific computing needs were met by increasingly sophisticated analog computers, which used a direct mechanical or electrical model of the problem as a basis for computation. however, these were not programmable and generally lacked the versatility and accuracy of modern digital computers. the first modern analog computer was a tide-predicting machine, invented by sir william thomson (later to become lord kelvin) in 1872. the differential analyser, a mechanical analog computer designed to solve differential equations by integration using wheel-and-disc mechanisms, was conceptualized in 1876 by james thomson, the elder brother of the more famous sir william thomson.the art of mechanical analog computing reached its zenith with the differential analyzer, built by h. l. hazen and vannevar bush at mit starting in 1927. this built on the mechanical integrators of james thomson and the torque amplifiers invented by h. w. nieman. a dozen of these devices were built before their obsolescence became obvious. by the 1950s, the success of digital electronic computers had spelled the end for most analog computing machines, but analog computers remained in use during the 1950s in some specialized applications such as education (slide rule) and aircraft (control systems).=== digital computers ======= electromechanical ====by 1938, the united states navy had developed an electromechanical analog computer small enough to use aboard a submarine. this was the torpedo data computer, which used trigonometry to solve the problem of firing a torpedo at a moving target. during world war ii similar devices were developed in other countries as well.early digital computers were electromechanical; electric switches drove mechanical relays to perform the calculation. these devices had a low operating speed and were eventually superseded by much faster all-electric computers, originally using vacuum tubes. the z2, created by german engineer konrad zuse in 1939, was one of the earliest examples of an electromechanical relay computer.in 1941, zuse followed his earlier machine up with the z3, the world\\'s first working electromechanical programmable, fully automatic digital computer. the z3 was built with 2000 relays, implementing a 22 bit word length that operated at a clock frequency of about 5–10 hz. program code was supplied on punched film while data could be stored in 64 words of memory or supplied from the keyboard. it was quite similar to modern machines in some respects, pioneering numerous advances such as floating-point numbers. rather than the harder-to-implement decimal system (used in charles babbage\\'s earlier design), using a binary system meant that zuse\\'s machines were easier to build and potentially more reliable, given the technologies available at that time. the z3 was not itself a universal computer but could be extended to be turing complete.zuse\\'s next computer, the z4, became the world\\'s first commercial computer; after initial delay due to the second world war, it was completed in 1950 and delivered to the eth zurich. the computer was manufactured by zuse\\'s own company, zuse kg, which was founded in 1941 as the first company with the sole purpose of developing computers.==== vacuum tubes and digital electronic circuits ====purely electronic circuit elements soon replaced their mechanical and electromechanical equivalents, at the same time that digital calculation replaced analog. the engineer tommy flowers, working at the post office research station in london in the 1930s, began to explore the possible use of electronics for the telephone exchange. experimental equipment that he built in 1934 went into operation five years later, converting a portion of the telephone exchange network into an electronic data processing system, using thousands of vacuum tubes. in the us, john vincent atanasoff and clifford e. berry of iowa state university developed and tested the atanasoff–berry computer (abc) in 1942, the first \"automatic electronic digital computer\". this design was also all-electronic and used about 300 vacuum tubes, with capacitors fixed in a mechanically rotating drum for memory.during world war ii, the british code-breakers at bletchley park achieved a number of successes at breaking encrypted german military communications. the german encryption machine, enigma, was first attacked with the help of the electro-mechanical bombes which were often run by women. to crack the more sophisticated german lorenz sz 40/42 machine, used for high-level army communications, max newman and his colleagues commissioned flowers to build the colossus. he spent eleven months from early february 1943 designing and building the first colossus. after a functional test in december 1943, colossus was shipped to bletchley park, where it was delivered on 18 january 1944 and attacked its first message on 5 february.colossus was the world\\'s first electronic digital programmable computer. it used a large number of valves (vacuum tubes). it had paper-tape input and was capable of being configured to perform a variety of boolean logical operations on its data, but it was not turing-complete. nine mk ii colossi were built (the mk i was converted to a mk ii making ten machines in total). colossus mark i contained 1,500 thermionic valves (tubes), but mark ii with 2,400 valves, was both five times faster and simpler to operate than mark i, greatly speeding the decoding process.the eniac (electronic numerical integrator and computer) was the first electronic programmable computer built in the u.s. although the eniac was similar to the colossus, it was much faster, more flexible, and it was turing-complete. like the colossus, a \"program\" on the eniac was defined by the states of its patch cables and switches, a far cry from the stored program electronic machines that came later. once a program was written, it had to be mechanically set into the machine with manual resetting of plugs and switches. the programmers of the eniac were six women, often known collectively as the \"eniac girls\".it combined the high speed of electronics with the ability to be programmed for many complex problems. it could add or subtract 5000 times a second, a thousand times faster than any other machine. it also had modules to multiply, divide, and square root. high speed memory was limited to 20 words (about 80 bytes). built under the direction of john mauchly and j. presper eckert at the university of pennsylvania, eniac\\'s development and construction lasted from 1943 to full operation at the end of 1945. the machine was huge, weighing 30 tons, using 200 kilowatts of electric power and contained over 18,000 vacuum tubes, 1,500 relays, and hundreds of thousands of resistors, capacitors, and inductors.=== modern computers ======= concept of modern computer ====the principle of the modern computer was proposed by alan turing in his seminal 1936 paper, on computable numbers. turing proposed a simple device that he called \"universal computing machine\" and that is now known as a universal turing machine. he proved that such a machine is capable of computing anything that is computable by executing instructions (program) stored on tape, allowing the machine to be programmable. the fundamental concept of turing\\'s design is the stored program, where all the instructions for computing are stored in memory. von neumann acknowledged that the central concept of the modern computer was due to this paper. turing machines are to this day a central object of study in theory of computation. except for the limitations imposed by their finite memory stores, modern computers are said to be turing-complete, which is to say, they have algorithm execution capability equivalent to a universal turing machine.==== stored programs ====early computing machines had fixed programs. changing its function required the re-wiring and re-structuring of the machine. with the proposal of the stored-program computer this changed. a stored-program computer includes by design an instruction set and can store in memory a set of instructions (a program) that details the computation. the theoretical basis for the stored-program computer was laid by alan turing in his 1936 paper. in 1945, turing joined the national physical laboratory and began work on developing an electronic stored-program digital computer. his 1945 report \"proposed electronic calculator\" was the first specification for such a device. john von neumann at the university of pennsylvania also circulated his first draft of a report on the edvac in 1945.the manchester baby was the world\\'s first stored-program computer. it was built at the university of manchester in england by frederic c. williams, tom kilburn and geoff tootill, and ran its first program on 21 june 1948. it was designed as a testbed for the williams tube, the first random-access digital storage device. although the computer was considered \"small and primitive\" by the standards of its time, it was the first working machine to contain all of the elements essential to a modern electronic computer. as soon as the baby had demonstrated the feasibility of its design, a project was initiated at the university to develop it into a more usable computer, the manchester mark 1. grace hopper was the first person to develop a compiler for programming language.the mark 1 in turn quickly became the prototype for the ferranti mark 1, the world\\'s first commercially available general-purpose computer. built by ferranti, it was delivered to the university of manchester in february 1951. at least seven of these later machines were delivered between 1953 and 1957, one of them to shell labs in amsterdam. in october 1947, the directors of british catering company j. lyons & company decided to take an active role in promoting the commercial development of computers. the leo i computer became operational in april 1951 and ran the world\\'s first regular routine office computer job.==== transistors ====the concept of a field-effect transistor was proposed by julius edgar lilienfeld in 1925. john bardeen and walter brattain, while working under william shockley at bell labs, built the first working transistor, the point-contact transistor, in 1947, which was followed by shockley\\'s bipolar junction transistor in 1948. from 1955 onwards, transistors replaced vacuum tubes in computer designs, giving rise to the \"second generation\" of computers. compared to vacuum tubes, transistors have many advantages: they are smaller, and require less power than vacuum tubes, so give off less heat. junction transistors were much more reliable than vacuum tubes and had longer, indefinite, service life. transistorized computers could contain tens of thousands of binary logic circuits in a relatively compact space. however, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications.at the university of manchester, a team under the leadership of tom kilburn designed and built a machine using the newly developed transistors instead of valves. their first transistorised computer and the first in the world, was operational by 1953, and a second version was completed there in april 1955. however, the machine did make use of valves to generate its 125 khz clock waveforms and in the circuitry to read and write on its magnetic drum memory, so it was not the first completely transistorized computer. that distinction goes to the harwell cadet of 1955, built by the electronics division of the atomic energy research establishment at harwell.the metal–oxide–silicon field-effect transistor (mosfet), also known as the mos transistor, was invented by mohamed m. atalla and dawon kahng at bell labs in 1959. it was the first truly compact transistor that could be miniaturised and mass-produced for a wide range of uses. with its high scalability, and much lower power consumption and higher density than bipolar junction transistors, the mosfet made it possible to build high-density integrated circuits. in addition to data processing, it also enabled the practical use of mos transistors as memory cell storage elements, leading to the development of mos semiconductor memory, which replaced earlier magnetic-core memory in computers. the mosfet led to the microcomputer revolution, and became the driving force behind the computer revolution. the mosfet is the most widely used transistor in computers, and is the fundamental building block of digital electronics.==== integrated circuits ====the next great advance in computing power came with the advent of the integrated circuit (ic).the idea of the integrated circuit was first conceived by a radar scientist working for the royal radar establishment of the ministry of defence, geoffrey w.a. dummer. dummer presented the first public description of an integrated circuit at the symposium on progress in quality electronic components in washington, d.c. on 7 may 1952.the first working ics were invented by jack kilby at texas instruments and robert noyce at fairchild semiconductor. kilby recorded his initial ideas concerning the integrated circuit in july 1958, successfully demonstrating the first working integrated example on 12 september 1958. in his patent application of 6 february 1959, kilby described his new device as \"a body of semiconductor material ... wherein all the components of the electronic circuit are completely integrated\". however, kilby\\'s invention was a hybrid integrated circuit (hybrid ic), rather than a monolithic integrated circuit (ic) chip. kilby\\'s ic had external wire connections, which made it difficult to mass-produce.noyce also came up with his own idea of an integrated circuit half a year later than kilby. noyce\\'s invention was the first true monolithic ic chip. his chip solved many practical problems that kilby\\'s had not. produced at fairchild semiconductor, it was made of silicon, whereas kilby\\'s chip was made of germanium. noyce\\'s monolithic ic was fabricated using the planar process, developed by his colleague jean hoerni in early 1959. in turn, the planar process was based on mohamed m. atalla\\'s work on semiconductor surface passivation by silicon dioxide in the late 1950s.modern monolithic ics are predominantly mos (metal-oxide-semiconductor) integrated circuits, built from mosfets (mos transistors). the earliest experimental mos ic to be fabricated was a 16-transistor chip built by fred heiman and steven hofstein at rca in 1962. general microelectronics later introduced the first commercial mos ic in 1964, developed by robert norman. following the development of the self-aligned gate (silicon-gate) mos transistor by robert kerwin, donald klein and john sarace at bell labs in 1967, the first silicon-gate mos ic with self-aligned gates was developed by federico faggin at fairchild semiconductor in 1968. the mosfet has since become the most critical device component in modern ics.the development of the mos integrated circuit led to the invention of the microprocessor, and heralded an explosion in the commercial and personal use of computers. while the subject of exactly which device was the first microprocessor is contentious, partly due to lack of agreement on the exact definition of the term \"microprocessor\", it is largely undisputed that the first single-chip microprocessor was the intel 4004, designed and realized by federico faggin with his silicon-gate mos ic technology, along with ted hoff, masatoshi shima and stanley mazor at intel. in the early 1970s, mos ic technology enabled the integration of more than 10,000 transistors on a single chip.system on a chip (socs) are complete computers on a microchip (or chip) the size of a coin. they may or may not have integrated ram and flash memory. if not integrated, the ram is usually placed directly above (known as package on package) or below (on the opposite side of the circuit board) the soc, and the flash memory is usually placed right next to the soc, this all done to improve data transfer speeds, as the data signals don\\'t have to travel long distances. since eniac in 1945, computers have advanced enormously, with modern socs (such as the snapdragon 865) being the size of a coin while also being hundreds of thousands of times more powerful than eniac, integrating billions of transistors, and consuming only a few watts of power.=== mobile computers ===the first mobile computers were heavy and ran from mains power. the 50 lb (23 kg) ibm 5100 was an early example. later portables such as the osborne 1 and compaq portable were considerably lighter but still needed to be plugged in. the first laptops, such as the grid compass, removed this requirement by incorporating batteries – and with the continued miniaturization of computing resources and advancements in portable battery life, portable computers grew in popularity in the 2000s. the same developments allowed manufacturers to integrate computing resources into cellular mobile phones by the early 2000s.these smartphones and tablets run on a variety of operating systems and recently became the dominant computing device on the market. these are powered by system on a chip (socs), which are complete computers on a microchip the size of a coin.'], 'subcategorie': ['the discipline of computer architecture has three main subcategories:instruction set architecture (isa): defines the machine code that a processor reads and acts upon as well as the word size, memory address modes, processor registers, and data type.microarchitecture: also known as \"computer organization\", this describes how a particular processor will implement the isa. the size of a computer\\'s cpu cache for instance, is an issue that generally has nothing to do with the isa.systems design: includes all of the other hardware components within a computing system, such as data processing other than the cpu (e.g., direct memory access), virtualization, and multiprocessing.there are other technologies in computer architecture. the following technologies are used in bigger companies like intel, and were estimated in 2002 to count for 1% of all of computer architecture:macroarchitecture: architectural layers more abstract than microarchitectureassembly instruction set architecture: a smart assembler may convert an abstract assembly language common to a group of machines into slightly different machine language for different implementations.programmer-visible macroarchitecture: higher-level language tools such as compilers may define a consistent interface or contract to programmers using them, abstracting differences between underlying isa, uisa, and microarchitectures. for example, the c, c++, or java standards define different programmer-visible macroarchitectures.microcode: microcode is software that translates instructions to run on a chip. it acts like a wrapper around the hardware, presenting a preferred version of the hardware\\'s instruction set interface. this instruction translation facility gives chip designers flexible options: e.g. 1. a new improved version of the chip can use microcode to present the exact same instruction set as the old chip version, so all software targeting that instruction set will run on the new chip without needing changes. e.g. 2. microcode can present a variety of instruction sets for the same underlying chip, allowing it to run a wider variety of software.uisa: user instruction set architecture, refers to one of three subsets of the risc cpu instructions provided by powerpc risc processors. the uisa subset, are those risc instructions of interest to application developers. the other two subsets are vea (virtual environment architecture) instructions used by virtualization system developers, and oea (operating environment architecture) used by operation system developers.pin architecture: the hardware functions that a microprocessor should provide to a hardware platform, e.g., the x86 pins a20m, ferr/ignne or flush. also, messages that the processor should emit so that external caches can be invalidated (emptied). pin architecture functions are more flexible than isa functions because external hardware can adapt to new encodings, or change from a pin to a message. the term \"architecture\" fits, because the functions must be provided for compatible systems, even if the detailed method changes.'], 'role': [\"=== definition ===computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. the case of instruction set architecture can be used to illustrate the balance of these competing factors. more complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 loop instruction). however, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. the increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.the implementation involves integrated circuit design, packaging, power, and cooling. optimization of the design requires familiarity with compilers, operating systems to logic design, and packaging.=== instruction set architecture ===an instruction set architecture (isa) is the interface between the computer's software and hardware and also can be viewed as the programmer's view of the machine. computers do not understand high-level programming languages such as java, c++, or most programming languages used. a processor only understands instructions encoded in some numerical fashion, usually as binary numbers. software tools, such as compilers, translate those high level languages into instructions that the processor can understand.besides instructions, the isa defines items in the computer that are available to a program—e.g., data types, registers, addressing modes, and memory.  instructions locate these available items with register indexes (or names) and memory addressing modes.the isa of a computer is usually described in a small instruction manual, which describes how the instructions are encoded. also, it may define short (vaguely) mnemonic names for the instructions. the names can be recognized by a software development tool called an assembler.  an assembler is a computer program that translates a human-readable form of the isa into a computer-readable form.  disassemblers are also widely available, usually in debuggers and software programs to isolate and correct malfunctions in binary computer programs.isas vary in quality and completeness.  a good isa compromises between programmer convenience (how easy the code is to understand), size of the code (how much code is required to do a specific action), cost of the computer to interpret the instructions (more complexity means more hardware needed to decode and execute the instructions), and speed of the computer (with more complex decoding hardware comes longer decode time).  memory organization defines how instructions interact with the memory, and how memory interacts with itself.during design emulation, emulators can run programs written in a proposed instruction set. modern emulators can measure size, cost, and speed to determine whether a particular isa is meeting its goals.=== computer organization ===computer organization helps optimize performance-based products. for example, software engineers need to know the processing power of processors. they may need to optimize software in order to gain the most performance for the lowest price. this can require quite a detailed analysis of the computer's organization.  for example, in an sd card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.computer organization also helps plan the selection of a processor for a particular project. multimedia projects may need very rapid data access, while virtual machines may need fast interrupts. sometimes certain tasks need additional components as well.  for example, a computer capable of running a virtual machine needs virtual memory hardware so that the memory of different virtual computers can be kept separated. computer organization and features also affect power consumption and processor cost.=== implementation ===once an instruction set and micro-architecture have been designed, a practical machine must be developed. this design process is called the implementation. implementation is usually not considered architectural design, but rather hardware design engineering. implementation can be further broken down into several steps:logic implementation designs the circuits required at a logic-gate level.circuit implementation does transistor-level designs of basic elements (e.g., gates, multiplexers, latches) as well as of some larger blocks (alus, caches etc.) that may be implemented at the logic-gate level, or even at the physical level if the design calls for it.physical implementation draws physical circuits.  the different circuit components are placed in a chip floor plan or on a board and the wires connecting them are created.design validation tests the computer as a whole to see if it works in all situations and all timings. once the design validation process starts, the design at the logic level are tested using logic emulators. however, this is usually too slow to run a realistic test.  so, after making corrections based on the first test, prototypes are constructed using field-programmable gate-arrays (fpgas). most hobby projects stop at this stage.  the final step is to test prototype integrated circuits, which may require several redesigns.for cpus, the entire implementation process is organized differently and is often referred to as cpu design.\"], 'design goal': ['the exact form of a computer system depends on the constraints and goals. computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.the most common scheme does an in-depth power analysis and figures out how to keep power consumption low while maintaining adequate performance.=== performance ===modern computer performance is often described in instructions per cycle (ipc), which measures the efficiency of the architecture at any clock frequency; a faster ipc rate means the computer is faster. older computers had ipc counts as low as 0.1 while modern processors easily reach near 1. superscalar processors may reach three to five ipc by executing several instructions per clock cycle.counting machine-language instructions would be misleading because they can do varying amounts of work in different isas. the \"instruction\" in the standard measurements is not a count of the isa\\'s machine-language instructions, but a unit of measurement, usually based on the speed of the vax computer architecture.many people used to measure a computer\\'s speed by the clock rate (usually in mhz or ghz). this refers to the cycles per second of the main clock of the cpu. however, this metric is somewhat misleading, as a machine with a higher clock rate may not necessarily have greater performance. as a result, manufacturers have moved away from clock speed as a measure of performance.other factors influence speed, such as the mix of functional units, bus speeds, available memory, and the type and order of instructions in the programs.there are two main types of speed: latency and throughput. latency is the time between the start of a process and its completion. throughput is the amount of work done per unit time.  interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).performance is affected by a very wide range of design choices — for example, pipelining a processor usually makes latency worse, but makes throughput better. computers that control machinery usually need low interrupt latencies. these computers operate in a real-time environment and fail if an operation is not completed in a specified amount of time. for example, computer-controlled anti-lock brakes must begin braking within a predictable and limited time period after the brake pedal is sensed or else failure of the brake will occur.benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. although benchmarking shows strengths, it shouldn\\'t be how you choose a computer. often the measured machines split on different measures. for example, one system might handle scientific applications quickly, while another might render video games more smoothly. furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but don\\'t offer similar advantages to general tasks.=== power efficiency ===power efficiency is another important measurement in modern computers. a higher power efficiency can often be traded for lower speed or higher cost. the typical measurement when referring to power consumption in computer architecture is mips/w (millions of instructions per second per watt).modern circuits have less power required per transistor as the number of transistors per chip grows. this is because each transistor that is put in a new chip requires its own power supply and requires new pathways to be built to power it. however the number of transistors per chip is starting to increase at a slower rate. therefore, power efficiency is starting to become as important, if not more important than fitting more and more transistors into a single chip. recent processor designs have shown this emphasis as they put more focus on power efficiency rather than cramming as many transistors into a single chip as possible. in the world of embedded computers, power efficiency has long been an important goal next to throughput and latency.=== shifts in market demand ===increases in clock frequency have grown more slowly over the past few years, compared to power reduction improvements. this has been driven by the end of moore\\'s law and demand for longer battery life and reductions in size for mobile technology. this change in focus from higher clock rates to power consumption and miniaturization can be shown by the significant reductions in power consumption, as much as 50%, that were reported by intel in their release of the haswell microarchitecture; where they dropped their power consumption benchmark from 30 to 40 watts down to 10-20 watts. comparing this to the processing speed increase of 3 ghz to 4 ghz (2002 to 2006) it can be seen that the focus in research and development are shifting away from clock frequency and moving towards consuming less power and taking up less space.'], 'see also': ['', 'integer (computer science)', '', 'super-threadingspeculative multithreading', 'cardboard illustrative aid to computationinterconnect bottlenecklittle man computerrandom-access machineharvard architectureturing machineeckert architecture', '', ''], 'reference': ['', '', '=== general ===', '', '', '', ''], 'source': ['john l. hennessy and david patterson (2006). computer architecture: a quantitative approach (fourth ed.). morgan kaufmann. isbn 978-0-12-370490-0.barton, robert s., \"functional design of computers\", communications of the acm 4(9): 405 (1961).barton, robert s., \"a new approach to the functional design of a digital computer\", proceedings of the western joint computer conference, may 1961, pp. 393–396. about the design of the burroughs b5000 computer.bell, c. gordon; and newell, allen (1971). \"computer structures: readings and examples\", mcgraw-hill.blaauw, g.a., and brooks, f.p., jr., \"the structure of system/360, part i-outline of the logical structure\", ibm systems journal, vol. 3, no. 2, pp. 119–135, 1964.tanenbaum, andrew s. (1979). structured computer organization. englewood cliffs, new jersey: prentice-hall. isbn 0-13-148521-0.', ''], 'external link': ['isca: proceedings of the international symposium on computer architecturemicro: ieee/acm international symposium on microarchitecturehpca: international symposium on high performance computer architectureasplos: international conference on architectural support for programming languages and operating systemsacm transactions on architecture and code optimizationieee transactions on computersthe von neumann architecture of computer systems', '\"automatic pipelining from transactional datapath specifications\" (pdf). retrieved 23 july 2014.tulsen, dean (18 january 2005). \"pipeline hazards\" (pdf).', 'a survey of processors with explicit multithreading, acm, march 2003, by theo ungerer, borut robi and jurij silcoperating system | difference between multitasking, multithreading and multiprocessing geeksforgeeks, 6 sept. 2018.', 'harvard vs von neumanna tool that emulates the behavior of a von neumann machinejohnny: a simple open source simulator of a von neumann machine for educational purposes', ' media related to computers at wikimedia commons wikiversity has a quiz on this articlewarhol & the computer'], 'uses of word': ['depending on how a computer is organized, word-size units may be used for:fixed-point numbersholders for fixed point, usually integer, numerical values may be available in one or in several different sizes, but one of the sizes available will almost always be the word. the other sizes, if any, are likely to be multiples or fractions of the word size. the smaller sizes are normally used only for efficient use of memory; when loaded into the processor, their values usually go into a larger, word sized holder.floating-point numbersholders for floating-point numerical values are typically either a word or a multiple of a word.addressesholders for memory addresses must be of a size capable of expressing the needed range of values but not be excessively large, so often the size used is the word though it can also be a multiple or fraction of the word size.registersprocessor registers are designed with a size appropriate for the type of data they hold, e.g. integers, floating-point numbers, or addresses. many computer architectures use general-purpose registers that are capable of storing data in multiple representations.memory–processor transferwhen the processor reads from the memory subsystem into a register or writes a register\\'s value to memory, the amount of data transferred is often a word. historically, this amount of bits which could be transferred in one cycle was also called a catena in some environments (such as the bull gamma 60). in simple memory subsystems, the word is transferred over the memory data bus, which typically has a width of a word or half-word. in memory subsystems that use caches, the word-sized transfer is the one between the processor and the first level of cache; at lower levels of the memory hierarchy larger transfers (which are a multiple of the word size) are normally used.unit of address resolutionin a given architecture, successive address values designate successive units of memory; this unit is the unit of address resolution. in most computers, the unit is either a character (e.g. a byte) or a word. (a few computers have used bit resolution.) if the unit is a word, then a larger amount of memory can be accessed using an address of a given size at the cost of added complexity to access individual characters. on the other hand, if the unit is a byte, then individual characters can be addressed (i.e. selected during the memory operation).instructionsmachine instructions are normally the size of the architecture\\'s word, such as in risc architectures, or a multiple of the \"char\" size that is a fraction of it. this is a natural choice since instructions and data usually share the same memory subsystem. in harvard architectures the word sizes of instructions and data need not be related, as instructions and data are stored in different memories; for example, the processor in the 1ess electronic telephone switch had 37-bit instructions and 23-bit data words.'], 'word size choice': ['when a computer architecture is designed, the choice of a word size is of substantial importance.  there are design considerations which encourage particular bit-group sizes for particular uses (e.g. for addresses), and these considerations point to different sizes for different uses.  however, considerations of economy in design strongly push for one size, or a very few sizes related by multiples or fractions (submultiples) to a primary size.  that preferred size becomes the word size of the architecture.character size was in the past (pre-variable-sized character encoding) one of the influences on unit of address resolution and the choice of word size.  before the mid-1960s, characters were most often stored in six bits; this allowed no more than 64 characters, so the alphabet was limited to upper case.  since it is efficient in time and space to have the word size be a multiple of the character size, word sizes in this period were usually multiples of 6 bits (in binary machines).  a common choice then was the 36-bit word, which is also a good size for the numeric properties of a floating point format.after the introduction of the ibm system/360 design, which used eight-bit characters and supported lower-case letters, the standard size of a character (or more accurately, a byte) became eight bits.  word sizes thereafter were naturally multiples of eight bits, with 16, 32, and 64 bits being commonly used.=== variable-word architectures ===early machine designs included some that used what is often termed a variable word length.  in this type of organization, an operand had no fixed length. depending on the machine and the instruction, the length might be denoted by a count field, by a delimiting character, or by an additional bit called, e.g., flag, word mark.  such machines often used binary-coded decimal in 4-bit digits, or in 6-bit characters, for numbers.  this class of machines included the ibm 702, ibm 705, ibm 7080, ibm 7010, univac 1050, ibm 1401, ibm 1620, and rca 301.most of these machines work on one unit of memory at a time and since each instruction or datum is several units long, each instruction takes several cycles just to access memory.  these machines are often quite slow because of this.  for example, instruction fetches on an ibm 1620 model i take 8 cycles just to read the 12 digits of the instruction (the model ii reduced this to 6 cycles, or 4 cycles if the instruction did not need both address fields). instruction execution took a completely variable number of cycles, depending on the size of the operands.=== word, bit and byte addressing ===the memory model of an architecture is strongly influenced by the word size.  in particular, the resolution of a memory address, that is, the smallest unit that can be designated by an address, has often been chosen to be the word.  in this approach, the word-addressable machine approach, address values which differ by one designate adjacent memory words.  this is natural in machines which deal almost always in word (or multiple-word) units, and has the advantage of allowing instructions to use minimally sized fields to contain addresses, which can permit a smaller instruction size or a larger variety of instructions.when byte processing is to be a significant part of the workload, it is usually more advantageous to use the byte, rather than the word, as the unit of address resolution. address values which differ by one designate adjacent bytes in memory.  this allows an arbitrary character within a character string to be addressed straightforwardly.  a word can still be addressed, but the address to be used requires a few more bits than the word-resolution alternative.  the word size needs to be an integer multiple of the character size in this organization.  this addressing approach was used in the ibm 360, and has been the most common approach in machines designed since then.when the workload involves processing fields of different sizes, it can be advantageous to address to the bit. machines with bit addressing may have some instructions that use a programmer-defined byte size and other instructions that operate on fixed data sizes. as an example, on the ibm 7030 (\"stretch\"), a floating point instruction can only address words while an integer arithmetic instruction can specify a field length of 1-64 bits, a byte size of 1-8 bits and an accumulator offset of 0-127 bits. in at byte-addressable machine with storage-to-storage (ss) instructions, there are typically move instructions to copy one or multiple bytes from one arbitrary location to another. in a byte-oriented (byte-addressable) machine without ss instructions, moving a single byte from one arbitrary location to another is typically:load the source bytestore the result back in the target byteindividual bytes can be accessed on a word-oriented machine in one of two ways.  bytes can be manipulated by a combination of shift and mask operations in registers. moving a single byte from one arbitrary location to another may require the equivalent of the following:load the word containing the source byteshift the source word to align the desired byte to the correct position in the target wordand the source word with a mask to zero out all but the desired bitsload the word containing the target byteand the target word with a mask to zero out the target byteor the registers containing the source and target words to insert the source bytestore the result back in the target locationalternatively many word-oriented machines implement byte operations with instructions using special byte pointers in registers or memory.  for example, the pdp-10 byte pointer contained the size of the byte in bits (allowing different-sized bytes to be accessed), the bit position of the byte within the word, and the word address of the data.  instructions could automatically adjust the pointer to the next byte on, for example, load and deposit (store) operations.=== powers of two ===different amounts of memory are used to store data values with different degrees of precision. the commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word).  converting the index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. in some cases this relationship can also avoid the use of division operations. as a result, most modern computer designs have word sizes (and other operand sizes) that are a power of two times the size of a byte.'], 'size familie': ['as computer designs have grown more complex, the central importance of a single word size to an architecture has decreased.  although more capable hardware can use a wider variety of sizes of data, market forces exert pressure to maintain backward compatibility while extending processor capability.  as a result, what might have been the central word size in a fresh design has to coexist as an alternative size to the original word size in a backward compatible design. the original word size remains available in future designs, forming the basis of a size family.in the mid-1970s, dec designed the vax to be a 32-bit successor of the 16-bit pdp-11. they used word for a 16-bit quantity, while longword referred to a 32-bit quantity; this terminology is the same as the terminology used for the pdp-11. this was in contrast to earlier machines, where the natural unit of addressing memory would be called a word, while a quantity that is one half a word would be called a halfword. in fitting with this scheme, a vax quadword is 64 bits.  they continued this 16-bit word/32-bit longword/64-bit quadword terminology with the 64-bit alpha.another example is the x86 family, of which processors of three different word lengths (16-bit, later 32- and 64-bit) have been released, while word continues to designate a 16-bit quantity. as software is routinely ported from one word-length to the next, some apis and documentation define or refer to an older (and thus shorter) word-length than the full word length on the cpu that software may be compiled for. also, similar to how bytes are used for small numbers in many programs, a shorter word (16 or 32 bits) may be used in contexts where the range of a wider word is not needed (especially where this can save considerable stack space or cache memory space). for example, microsoft\\'s windows api maintains the programming language definition of word as 16 bits, despite the fact that the api may be used on a 32- or 64-bit x86 processor, where the standard word size would be 32 or 64 bits, respectively. data structures containing such different sized words refer to them as:word (16 bits/2 bytes)dword (32 bits/4 bytes)qword (64 bits/8 bytes)a similar phenomenon has developed in intel\\'s x86 assembly language – because of the support for various sizes (and backward compatibility) in the instruction set, some instruction mnemonics carry \"d\" or \"q\" identifiers denoting \"double-\", \"quad-\" or \"double-quad-\", which are in terms of the architecture\\'s original 16-bit word size.an example with a different word size is the ibm system/360 family. in the system/360 architecture, system/370 architecture and system/390 architecture, there are 8-bit bytes, 16-bit halfwords, 32-bit words and 64-bit doublewords. the z/architecture, which is the 64-bit member of that architecture family, continues to refer to 16-bit halfwords, 32-bit words, and 64-bit doublewords, and additionally features 128-bit quadwords.in general, new processors must use the same data word lengths and virtual address widths as an older processor to have binary compatibility with that older processor.often carefully written source code – written with source-code compatibility and software portability in mind – can be recompiled to run on a variety of processors, even ones with different data word lengths or different address widths or both.'], 'table of word size': [''], 'note': ['', ''], 'background': ['instructions in a pipelined processor are performed in several stages, so that at any given time several instructions are being processed in the various stages of the pipeline, such as fetch and execute. there are many different instruction pipeline microarchitectures, and instructions may be executed out-of-order. a hazard occurs when two or more of these simultaneous (possibly out of order) instructions conflict.'], 'type': ['=== data hazards ===data hazards occur when instructions that exhibit data dependence modify data in different stages of a pipeline. ignoring potential data hazards can result in race conditions (also termed race hazards). there are three situations in which a data hazard can occur:read after write (raw), a true dependencywrite after read (war), an anti-dependencywrite after write (waw), an output dependencyread after read (rar) is not a hazard case.consider two instructions i1 and i2, with i1 occurring before i2 in program order.==== read after write (raw) ====(i2 tries to read a source before i1 writes to it)a read after write (raw) data hazard refers to a situation where an instruction refers to a result that has not yet been calculated or retrieved. this can occur because even though an instruction is executed after a prior instruction, the prior instruction has been processed only partly through the pipeline.===== example =====for example:i1. r2 <- r5 + r3i2. r4 <- r2 + r3the first instruction is calculating a value to be saved in register r2, and the second is going to use this value to compute a result for register r4. however, in a pipeline, when operands are fetched for the 2nd operation, the results from the first have not yet been saved, and hence a data dependency occurs.a data dependency occurs with instruction i2, as it is dependent on the completion of instruction i1.==== write after read (war) ====(i2 tries to write a destination before it is read by i1)a write after read (war) data hazard represents a problem with concurrent execution.===== example =====for example:i1. r4 <- r1 + r5i2. r5 <- r1 + r2in any situation with a chance that i2 may finish before i1 (i.e., with concurrent execution), it must be ensured that the result of register r5 is not stored before i1 has had a chance to fetch the operands.==== write after write (waw) ====(i2 tries to write an operand before it is written by i1)a write after write (waw) data hazard may occur in a concurrent execution environment.===== example =====for example:i1. r2 <- r4 + r7i2. r2 <- r1 + r3the write back (wb) of i2 must be delayed until i1 finishes executing.=== structural hazards ===a structural hazard occurs when two (or more) instructions that are already in pipeline need the same resource. the result is that instruction must be executed in series rather than parallel for a portion of pipeline. structural hazards are sometime referred to as resource hazards.example:a situation in which multiple instructions are ready to enter the execute instruction phase and there is a single alu (arithmetic logic unit). one solution to such resource hazard is to increase available resources, such as having multiple ports into main memory and multiple alu (arithmetic logic unit) units.=== control hazards (branch hazards or instruction hazards) ===control hazard occurs when the pipeline makes wrong decisions on branch prediction and therefore brings instructions into the pipeline that must subsequently be discarded. the term branch hazard also refers to a control hazard.', 'computers can be classified in a number of different ways, including:=== by architecture ===analog computerdigital computerhybrid computerharvard architecturevon neumann architecturecomplex instruction set computerreduced instruction set computer=== by size, form-factor and purpose ===supercomputermainframe computerminicomputer (term no longer used)serverrackmount serverblade servertower serverpersonal computerworkstationmicrocomputer (term no longer used)home computerdesktop computertower desktopslimline desktopmultimedia computer (non-linear editing system computers, video editing pcs and the like)gaming computerall-in-one pcnettop (small form factor pcs, mini pcs)home theater pckeyboard computerportable computerthin clientinternet appliancelaptopdesktop replacement computergaming laptoprugged laptop2-in-1 pcultrabookchromebooksubnotebooknetbookmobile computers:tablet computersmartphoneultra-mobile pcpocket pcpalmtop pchandheld pcwearable computersmartwatchsmartglassessingle-board computerplug computerstick pcprogrammable logic controllercomputer-on-modulesystem on modulesystem in a packagesystem-on-chip (also known as an application processor or ap if it lacks circuitry such as radio circuitry)microcontroller'], 'eliminating hazard': ['=== generic ======= pipeline bubbling ====bubbling the pipeline, also termed a pipeline break or pipeline stall, is a method to preclude data, structural, and branch hazards. as instructions are fetched, control logic determines whether a hazard could/will occur. if this is true, then the control logic inserts no operations (nops) into the pipeline. thus, before the next instruction (which would cause the hazard) executes, the prior one will have had sufficient time to finish and prevent the hazard. if the number of nops equals the number of stages in the pipeline, the processor has been cleared of all instructions and can proceed free from hazards. all forms of stalling introduce a delay before the processor can resume execution.flushing the pipeline occurs when a branch instruction jumps to a new memory location, invalidating all prior stages in the pipeline.  these prior stages are cleared, allowing the pipeline to continue at the new instruction indicated by the branch.=== data hazards ===there are several main solutions and algorithms used to resolve data hazards:insert a pipeline bubble whenever a read after write (raw) dependency is encountered, guaranteed to increase latency, oruse out-of-order execution to potentially prevent the need for pipeline bubblesuse operand forwarding to use data from later stages in the pipelinein the case of out-of-order execution, the algorithm used can be:scoreboarding, in which case a pipeline bubble is needed only when there is no functional unit availablethe tomasulo algorithm, which uses register renaming, allowing continual issuing of instructionsthe task of removing data dependencies can be delegated to the compiler, which can fill in an appropriate number of nop instructions between dependent instructions to ensure correct operation, or re-order instructions where possible.==== operand forwarding ======== examples ====in the following examples, computed values are in bold, while register numbers are not.for example, to write the value 3 to register 1, (which already contains a 6), and then add 7 to register 1 and store the result in register 2, i.e.:i0: r1 = 6i1: r1 = 3i2: r2 = r1 + 7 = 10following execution, register 2 should contain the value 10. however, if i1 (write 3 to register 1) does not fully exit the pipeline before i2 starts executing, it means that r1 does not contain the value 3 when i2 performs its addition. in such an event, i2 adds 7 to the old value of register 1 (6), and so register 2 contains 13 instead, i.e.:i0: r1 = 6i2: r2 = r1 + 7 = 13i1: r1 = 3this error occurs because i2 reads register 1 before i1 has committed/stored the result of its write operation to register 1. so when i2 is reading the contents of register 1, register 1 still contains 6, not 3.forwarding (described below) helps correct such errors by depending on the fact that the output of i1 (which is 3) can be used by subsequent instructions before the value 3 is committed to/stored in register 1.forwarding applied to the example means that there is no wait to commit/store the output of i1 in register 1 (in this example, the output is 3) before making that output available to the subsequent instruction (in this case, i2). the effect is that i2 uses the correct (the more recent) value of register 1: the commit/store was made immediately and not pipelined.with forwarding enabled, the instruction decode/execution (id/ex) stage of the pipeline now has two inputs: the value read from the register specified (in this example, the value 6 from register 1), and the new value of register 1 (in this example, this value is 3) which is sent from the next stage instruction execute/memory access (ex/mem). added control logic is used to determine which input to use.=== control hazards (branch hazards) ===to avoid control hazards microarchitectures can:insert a pipeline bubble (discussed above), guaranteed to increase latency, oruse branch prediction and essentially make educated guesses about which instructions to insert, in which case a pipeline bubble will only be needed in the case of an incorrect predictionin the event that a branch causes a pipeline bubble after incorrect instructions have entered the pipeline, care must be taken to prevent any of the wrongly-loaded instructions from having any effect on the processor state excluding energy wasted processing them before they were discovered to be loaded incorrectly.=== other techniques ===memory latency is another factor that designers must attend to, because the delay could reduce performance. different types of memory have different accessing time to the memory. thus, by choosing a suitable type of memory, designers can improve the performance of the pipelined data path.'], 'overview': [\"the multithreading paradigm has become more popular as efforts to further exploit instruction-level parallelism have stalled since the late 1990s. this allowed the concept of throughput computing to re-emerge from the more specialized field of transaction processing. even though it is very difficult to further speed up a single thread or single program, most computer systems are actually multitasking among multiple threads or programs. thus, techniques that improve the throughput of all tasks result in overall performance gains.two major techniques for throughput computing are multithreading and multiprocessing.=== advantages ===if a thread gets a lot of cache misses, the other threads can continue taking advantage of the unused computing resources, which may lead to faster overall execution, as these resources would have been idle if only a single thread were executed. also, if a thread cannot use all the computing resources of the cpu (because instructions depend on each other's result), running another thread may prevent those resources from becoming idle.=== disadvantages ===multiple threads can interfere with each other when sharing hardware resources such as caches or translation lookaside buffers (tlbs). as a result, execution times of a single thread are not improved and can be degraded, even when only one thread is executing, due to lower frequencies or additional pipeline stages that are necessary to accommodate thread-switching hardware.overall efficiency varies; intel claims up to 30% improvement with its hyper-threading technology, while a synthetic program just performing a loop of non-optimized dependent floating-point operations actually gains a 100% speed improvement when run in parallel. on the other hand, hand-tuned assembly language programs using mmx or altivec extensions and performing data prefetches (as a good video encoder might) do not suffer from cache misses or idle computing resources. such programs therefore do not benefit from hardware multithreading and can indeed see degraded performance due to contention for shared resources.from the software standpoint, hardware support for multithreading is more visible to software, requiring more changes to both application programs and operating systems than multiprocessing. hardware techniques used to support multithreading often parallel the software techniques used for computer multitasking. thread scheduling is also a major problem in multithreading.\", \"most computer programs contain conditional code, which will be executed only under specific conditions depending on factors that cannot be determined beforehand, for example depending on user input. as the majority of processors simply execute the next instruction in a sequence, the traditional solution is to insert branch instructions that allow a program to conditionally branch to a different section of code, thus changing the next step in the sequence. this was sufficient until designers began improving performance by implementing instruction pipelining, a method which is slowed down by branches. for a more thorough description of the problems which arose, and a popular solution, see branch predictor.luckily, one of the more common patterns of code that normally relies on branching has a more elegant solution. consider the following pseudocode:on a system that uses conditional branching, this might translate to machine instructions looking similar to:with predication, all possible branch paths are coded inline, but some instructions execute while others do not. the basic idea is that each instruction is associated with a predicate (the word here used similarly to its usage in predicate logic) and that the instruction will only be executed if the predicate is true. the machine code for the above example using predication might look something like this:besides eliminating branches, less code is needed in total, provided the architecture provides predicated instructions. while this does not guarantee faster execution in general, it will if the dosomething and dosomethingelse blocks of code are short enough.predication's simplest form is partial predication, where the architecture has conditional move or conditional select instructions. conditional move instructions write the contents of one register over another only if the predicate's value is true, whereas conditional select instructions choose which of two registers has its contents written to a third based on the predicate's value. a more generalized and capable form is full predication. full predication has a set of predicate registers for storing predicates (which allows multiple nested or sequential branches to be simultaneously eliminated) and most instructions in the architecture have a register specifier field to specify which predicate register supplies the predicate.\"], 'types of multithreading': ['=== interleaved/temporal multithreading ======= coarse-grained multithreading ====the simplest type of multithreading occurs when one thread runs until it is blocked by an event that normally would create a long-latency stall. such a stall might be a cache miss that has to access off-chip memory, which might take hundreds of cpu cycles for the data to return. instead of waiting for the stall to resolve, a threaded processor would switch execution to another thread that was ready to run. only when the data for the previous thread had arrived, would the previous thread be placed back on the list of ready-to-run threads.for example:cycle i: instruction j from thread a is issued.cycle i + 1: instruction j + 1 from thread a is issued.cycle i + 2: instruction j + 2 from thread a is issued, which is a load instruction that misses in all caches.cycle i + 3: thread scheduler invoked, switches to thread b.cycle i + 4: instruction k from thread b is issued.cycle i + 5: instruction k + 1 from thread b is issued.conceptually, it is similar to cooperative multi-tasking used in real-time operating systems, in which tasks voluntarily give up execution time when they need to wait upon some type of the event. this type of multithreading is known as block, cooperative or coarse-grained multithreading.the goal of multithreading hardware support is to allow quick switching between a blocked thread and another thread ready to run. switching from one thread to another means the hardware switches from using one register set to another. to achieve this goal, the hardware for the program visible registers, as well as some processor control registers (such as the program counter), is replicated. for example, to quickly switch between two threads, the processor is built with two sets of registers.additional hardware support for multithreading allows thread switching to be done in one cpu cycle, bringing performance improvements. also, additional hardware allows each thread to behave as if it were executing alone and not sharing any hardware resources with other threads, minimizing the amount of software changes needed within the application and the operating system to support multithreading.many families of microcontrollers and embedded processors have multiple register banks to allow quick context switching for interrupts. such schemes can be considered a type of block multithreading among the user program thread and the interrupt threads.==== interleaved multithreading ====the purpose of interleaved multithreading is to remove all data dependency stalls from the execution pipeline. since one thread is relatively independent from other threads, there is less chance of one instruction in one pipelining stage needing an output from an older instruction in the pipeline. conceptually, it is similar to preemptive multitasking used in operating systems; an analogy would be that the time slice given to each active thread is one cpu cycle.for example:cycle i + 1: an instruction from thread b is issued.cycle i + 2: an instruction from thread c is issued.this type of multithreading was first called barrel processing, in which the staves of a barrel represent the pipeline stages and their executing threads. interleaved, preemptive, fine-grained or time-sliced multithreading are more modern terminology.in addition to the hardware costs discussed in the block type of multithreading, interleaved multithreading has an additional cost of each pipeline stage tracking the thread id of the instruction it is processing. also, since there are more threads being executed concurrently in the pipeline, shared resources such as caches and tlbs need to be larger to avoid thrashing between the different threads.=== simultaneous multithreading ===the most advanced type of multithreading applies to superscalar processors. whereas a normal superscalar processor issues multiple instructions from a single thread every cpu cycle, in simultaneous multithreading (smt) a superscalar processor can issue instructions from multiple threads every cpu cycle. recognizing that any single thread has a limited amount of instruction-level parallelism, this type of multithreading tries to exploit parallelism available across multiple threads to decrease the waste associated with unused issue slots.for example:cycle i: instructions j and j + 1 from thread a and instruction k from thread b are simultaneously issued.cycle i + 1: instruction j + 2 from thread a, instruction k + 1 from thread b, and instruction m from thread c are all simultaneously issued.cycle i + 2: instruction j + 3 from thread a and instructions m + 1 and m + 2 from thread c are all simultaneously issued.to distinguish the other types of multithreading from smt, the term \"temporal multithreading\" is used to denote when instructions from only one thread can be issued at a time.in addition to the hardware costs discussed for interleaved multithreading, smt has the additional cost of each pipeline stage tracking the thread id of each instruction being processed. again, shared resources such as caches and tlbs have to be sized for the large number of active threads being processed.implementations include dec (later compaq) ev8 (not completed), intel hyper-threading technology, ibm power5/power6/power7/power8/power9, ibm z13/z14/z15, sun microsystems ultrasparc t2, cray xmt, and amd bulldozer and zen microarchitectures.'], 'implementation specific': ['a major area of research is the thread scheduler that must quickly choose from among the list of ready-to-run threads to execute next, as well as maintain the ready-to-run and stalled thread lists. an important subtopic is the different thread priority schemes that can be used by the scheduler. the thread scheduler might be implemented totally in software, totally in hardware, or as a hardware/software combination.another area of research is what type of events should cause a thread switch: cache misses, inter-thread communication, dma completion, etc.if the multithreading scheme replicates all of the software-visible state, including privileged control registers and tlbs, then it enables virtual machines to be created for each thread. this allows each thread to run its own operating system on the same processor. on the other hand, if only user-mode state is saved, then less hardware is required, which would allow more threads to be active at one time for the same die area or cost.'], 'capabilitie': ['on a large scale, the ability to treat instructions as data is what makes assemblers, compilers, linkers, loaders, and other automated programming tools possible. it makes \"programs that write programs\" possible.  this has made a sophisticated self-hosting computing ecosystem flourish around von neumann architecture machines.some high level languages leverage the von neumann architecture by providing an abstract, machine-independent way to manipulate executable code at runtime (e.g., lisp), or by using runtime information to tune just-in-time compilation (e.g. languages hosted on the java virtual machine, or languages embedded in web browsers).on a smaller scale, some repetitive operations such as bitblt or pixel and vertex shaders can be accelerated on general purpose processors with just-in-time compilation techniques. this is one use of self-modifying code that has remained popular.== development of the stored-program concept ==the mathematician alan turing, who had been alerted to a problem of mathematical logic by the lectures of max newman at the university of cambridge, wrote a paper in 1936 entitled on computable numbers, with an application to the entscheidungsproblem, which was published in the proceedings of the london mathematical society. in it he described a hypothetical machine he called a universal computing machine, now known as the \"universal turing machine\". the hypothetical machine had an infinite store (memory in today\\'s terminology) that contained both instructions and data. john von neumann became acquainted with turing while he was a visiting professor at cambridge in 1935, and also during turing\\'s phd year at the institute for advanced study in princeton, new jersey during 1936–1937. whether he knew of turing\\'s paper of 1936 at that time is not clear.in 1936, konrad zuse also anticipated, in two patent applications, that machine instructions could be stored in the same storage used for data.independently, j. presper eckert and john mauchly, who were developing the eniac at the moore school of electrical engineering of the university of pennsylvania, wrote about the stored-program concept in december 1943. in planning a new machine, edvac, eckert wrote in january 1944 that they would store data and programs in a new addressable memory device, a mercury metal delay-line memory. this was the first time the construction of a practical stored-program machine was proposed.  at that time, he and mauchly were not aware of turing\\'s work.von neumann was involved in the manhattan project at the los alamos national laboratory. it required huge amounts of calculation, and thus drew him to the eniac project, during the summer of 1944. there he joined the ongoing discussions on the design of this stored-program computer, the edvac. as part of that group, he wrote up a description titled first draft of a report on the edvac based on the work of eckert and mauchly. it was unfinished when his colleague herman goldstine circulated it, and bore only von neumann\\'s name (to the consternation of eckert and mauchly). the paper was read by dozens of von neumann\\'s colleagues in america and europe, and influenced the next round of computer designs.jack copeland considers that it is \"historically inappropriate to refer to electronic stored-program digital computers as \\'von neumann machines\\'\". his los alamos colleague stan frankel said of von neumann\\'s regard for turing\\'s ideasi know that in or about 1943 or \\'44 von neumann was well aware of the fundamental importance of turing\\'s paper of 1936….von neumann introduced me to that paper and at his urging i studied it with care. many people have acclaimed von neumann as the \"father of the computer\" (in a modern sense of the term) but i am sure that he would never have made that mistake himself. he might well be called the midwife, perhaps, but he firmly emphasized to me, and to others i am sure, that the fundamental conception is owing to turing— in so far as not anticipated by babbage…. both turing and von neumann, of course, also made substantial contributions to the \"reduction to practice\" of these concepts but i would not regard these as comparable in importance with the introduction and explication of the concept of a computer able to store in its memory its program of activities and of modifying that program in the course of these activities.at the time that the \"first draft\" report was circulated, turing was producing a report entitled proposed electronic calculator. it described in engineering and programming detail, his idea of a machine he called the automatic computing engine (ace). he presented this to the executive committee of the british national physical laboratory on february 19, 1946. although turing knew from his wartime experience at bletchley park that what he proposed was feasible, the secrecy surrounding colossus, that was subsequently maintained for several decades, prevented him from saying so. various successful implementations of the ace design were produced.both von neumann\\'s and turing\\'s papers described stored-program computers, but von neumann\\'s earlier paper achieved greater circulation and the computer architecture it outlined became known as the \"von neumann architecture\". in the 1953 publication faster than thought: a symposium on digital computing machines (edited by b. v. bowden), a section in the chapter on computers in america reads as follows:the machine of the institute for advanced studies, princetonin 1945, professor j. von neumann, who was then working at the moore school of engineering in philadelphia, where the e.n.i.a.c. had been built, issued on behalf of a group of his co-workers, a report on the logical design of digital computers. the report contained a detailed proposal for the design of the machine that has since become known as the e.d.v.a.c. (electronic discrete variable automatic computer). this machine has only recently been completed in america, but the von neumann report inspired the construction of the e.d.s.a.c. (electronic delay-storage automatic calculator) in cambridge (see page 130).in 1947, burks, goldstine and von neumann published another report that outlined the design of another type of machine (a parallel machine this time) that would be exceedingly fast, capable perhaps of 20,000 operations per second. they pointed out that the outstanding problem in constructing such a machine was the development of suitable memory with instantaneously accessible contents. at first they suggested using a special vacuum tube—called the \"selectron\"—which the princeton laboratories of rca had invented. these tubes were expensive and difficult to make, so von neumann subsequently decided to build a machine based on the williams memory. this machine—completed in june, 1952 in princeton—has become popularly known as the maniac. the design of this machine inspired at least half a dozen machines now being built in america, all known affectionately as \"johniacs\".in the same book, the first two paragraphs of a chapter on ace read as follows:automatic computation at the national physical laboratoryone of the most modern digital computers which embodies developments and improvements in the technique of automatic electronic computing was recently demonstrated at the national physical laboratory, teddington, where it has been designed and built by a small team of mathematicians and electronics research engineers on the staff of the laboratory, assisted by a number of production engineers from the english electric company, limited. the equipment so far erected at the laboratory is only the pilot model of a much larger installation which will be known as the automatic computing engine, but although comparatively small in bulk and containing only about 800 thermionic valves, as can be judged from plates xii, xiii and xiv, it is an extremely rapid and versatile calculating machine.the basic concepts and abstract principles of computation by a machine were formulated by dr. a. m. turing, f.r.s., in a paper1. read before the london mathematical society in 1936, but work on such machines in britain was delayed by the war. in 1945, however, an examination of the problems was made at the national physical laboratory by mr. j. r. womersley, then superintendent of the mathematics division of the laboratory. he was joined by dr. turing and a small staff of specialists, and, by 1947, the preliminary planning was sufficiently advanced to warrant the establishment of the special group already mentioned. in april, 1948, the latter became the electronics section of the laboratory, under the charge of mr. f. m. colebrook.== early von neumann-architecture computers ==the first draft described a design that was used by many universities and corporations to construct their computers. among these various computers, only illiac and ordvac had compatible instruction sets.arc2 (birkbeck, university of london) officially came online on may 12, 1948.manchester baby (victoria university of manchester, england) made its first successful run of a stored program on june 21, 1948.edsac (university of cambridge, england) was the first practical stored-program electronic computer (may 1949)manchester mark 1 (university of manchester, england) developed from the baby (june 1949)csirac (council for scientific and industrial research) australia (november 1949)mesm in kyiv, ukraine (november 1950)edvac (ballistic research laboratory, computing laboratory at aberdeen proving ground 1951)ordvac (u-illinois) at aberdeen proving ground, maryland (completed november 1951)ias machine at princeton university (january 1952)maniac i at los alamos scientific laboratory (march 1952)illiac at the university of illinois, (september 1952)besm-1 in moscow (1952)avidac at argonne national laboratory (1953)oracle at oak ridge national laboratory (june 1953)besk in stockholm (1953)johnniac at rand corporation (january 1954)dask in denmark (1955)weizac at the weizmann institute of science in rehovot, israel (1955)perm in munich (1956)silliac in sydney (1956)== early stored-program computers ==the date information in the following chronology is difficult to put into proper order. some dates are for first running a test program, some dates are the first time the computer was demonstrated or completed, and some dates are for the first delivery or installation.the ibm ssec had the ability to treat instructions as data, and was publicly demonstrated on january 27, 1948. this ability was claimed in a us patent. however it was partially electromechanical, not fully electronic. in practice, instructions were read from paper tape due to its limited memory.the arc2 developed by andrew booth and kathleen booth at birkbeck, university of london officially came online on may 12, 1948. it featured the first rotating drum storage device.the manchester baby was the first fully electronic computer to run a stored program. it ran a factoring program for 52 minutes on june 21, 1948, after running a simple division program and a program to show that two numbers were relatively prime.the eniac was modified to run as a primitive read-only stored-program computer (using the function tables for program rom) and was demonstrated as such on september 16, 1948, running a program by adele goldstine for von neumann.the binac ran some test programs in february, march, and april 1949, although was not completed until september 1949.the manchester mark 1 developed from the baby project.  an intermediate version of the mark 1 was available to run programs in april 1949, but was not completed until october 1949.the edsac ran its first program on may 6, 1949.the edvac was delivered in august 1949, but it had problems that kept it from being put into regular operation until 1951.the csir mk i ran its first program in november 1949.the seac was demonstrated in april 1950.the pilot ace ran its first program on may 10, 1950, and was demonstrated in december 1950.the swac was completed in july 1950.the whirlwind was completed in december 1950 and was in actual use in april 1951.the first era atlas (later the commercial era 1101/univac 1101) was installed in december 1950.'], 'evolution': ['through the decades of the 1960s and 1970s computers generally became both smaller and faster, which led to evolutions in their architecture. for example, memory-mapped i/o lets input and output devices be treated the same as memory. a single system bus could be used to provide a modular system with lower cost. this is sometimes called a \"streamlining\" of the architecture.in subsequent decades, simple microcontrollers would sometimes omit features of the model to lower cost and size.larger computers added features for higher performance.'], 'design limitation': ['=== von neumann bottleneck ===the shared bus between the program memory and data memory leads to the von neumann bottleneck, the limited throughput (data transfer rate) between the central processing unit (cpu) and memory compared to the amount of memory.  because the single bus can only access one of the two classes of memory at a time, throughput is lower than the rate at which the cpu can work.  this seriously limits the effective processing speed when the cpu is required to perform minimal processing on large amounts of data.  the cpu is continually forced to wait for needed data to move to or from memory.  since cpu speed and memory size have increased much faster than the throughput between them, the bottleneck has become more of a problem, a problem whose severity increases with every new generation of cpu.the von neumann bottleneck was described by john backus in his 1977 acm turing award lecture.  according to backus:surely there must be a less primitive way of making big changes in the store than by pushing vast numbers of words back and forth through the von neumann bottleneck. not only is this tube a literal bottleneck for the data traffic of a problem, but, more importantly, it is an intellectual bottleneck that has kept us tied to word-at-a-time thinking instead of encouraging us to think in terms of the larger conceptual units of the task at hand. thus programming is basically planning and detailing the enormous traffic of words through the von neumann bottleneck, and much of that traffic concerns not significant data itself, but where to find it.==== mitigations ====there are several known methods for mitigating the von neumann performance bottleneck.  for example, the following all can improve performance:providing a cache between the cpu and the main memoryproviding separate caches or separate access paths for data and instructions (the so-called modified harvard architecture)using branch predictor algorithms and logicproviding a limited cpu stack or other on-chip scratchpad memory to reduce memory accessimplementing the cpu and the memory hierarchy as a system on chip, providing greater locality of reference and thus reducing latency and increasing throughput between processor registers and main memorythe problem can also be sidestepped somewhat by using parallel computing, using for example the non-uniform memory access (numa) architecture—this approach is commonly employed by supercomputers. it is less clear whether the intellectual bottleneck that backus criticized has changed much since 1977. backus\\'s proposed solution has not had a major influence. modern functional programming and object-oriented programming are much less geared towards \"pushing vast numbers of words back and forth\" than earlier languages like fortran were, but internally, that is still what computers spend much of their time doing, even highly parallel supercomputers.as of 1996, a database benchmark study found that three out of four cpu cycles were spent waiting for memory. researchers expect that increasing the number of simultaneous instruction streams with multithreading or single-chip multiprocessing will make this bottleneck even worse.  in the context of multi-core processors, additional overhead is required to maintain cache coherence between processors and threads.=== self-modifying code ===aside from the von neumann bottleneck, program modifications can be quite harmful, either by accident or design.  in some simple stored-program computer designs, a malfunctioning program can damage itself, other programs, or the operating system, possibly leading to a computer crash. memory protection and other forms of access control can usually protect against both accidental and malicious program changes.'], 'further reading': ['', 'clements, alan (2013). \"8.3.7 predication\". computer organization & architecture: themes and variations. cengage learning. pp. 532–9. isbn 1-285-41542-6.'], 'advantage': ['the main purpose of predication is to avoid jumps over very small sections of program code, increasing the effectiveness of pipelined execution and avoiding problems with the cache. it also has a number of more subtle benefits:functions that are traditionally computed using simple arithmetic and bitwise operations may be quicker to compute using predicated instructions.predicated instructions with different predicates can be mixed with each other and with unconditional code, allowing better instruction scheduling and so even better performance.elimination of unnecessary branch instructions can make the execution of necessary branches, such as those that make up loops, faster by lessening the load on branch prediction mechanisms.elimination of the cost of a branch misprediction which can be high on deeply pipelined architectures.instruction sets that have comprehensive condition codes generated by instructions may reduce code size further by directly using the condition registers in or as predication.'], 'disadvantage': [\"predication's primary drawback is in increased encoding space. in typical implementations, every instruction reserves a bitfield for the predicate specifying under what conditions that instruction should have an effect. when available memory is limited, as on embedded devices, this space cost can be prohibitive. however, some architectures such as thumb-2 are able to avoid this issue (see below). other detriments are the following:predication complicates the hardware by adding levels of logic to critical paths and potentially degrades clock speed.a predicated block includes cycles for all operations, so shorter paths may take longer and be penalized.predication is not usually speculated and causes a longer dependency chain. for ordered data this translates to a performance loss compared to a predictable branch.predication is most effective when paths are balanced or when the longest path is the most frequently executed, but determining such a path is very difficult at compile time, even in the presence of profiling information.\"], 'etymology': ['according to the oxford english dictionary, the first known use of computer was in a 1613 book called the yong mans gleanings by the english writer richard brathwait: \"i haue  [sic] read the truest computer of times, and the best arithmetician that euer [sic] breathed, and he reduceth thy dayes into a short number.\" this usage of the term referred to a human computer, a person who carried out calculations or computations. the word continued with the same meaning until the middle of the 20th century. during the latter part of this period women were often hired as computers because they could be paid less than their male counterparts. by 1943, most human computers were women.the online etymology dictionary gives the first attested use of computer in the 1640s, meaning \\'one who calculates\\'; this is an \"agent noun from compute (v.)\". the online etymology dictionary states that the use of the term to mean \"\\'calculating machine\\' (of any type) is from 1897.\"  the online etymology dictionary indicates that the \"modern use\" of the term, to mean \\'programmable digital electronic computer\\' dates from \"1945 under this name; [in a] theoretical [sense] from 1937, as turing machine\".'], 'hardware': ['the term hardware covers all of those parts of a computer that are tangible physical objects. circuits, computer chips, graphic cards, sound cards, memory (ram), motherboard, displays, power supplies, cables, keyboards, printers and \"mice\" input devices are all hardware.=== history of computing hardware ====== other hardware topics ===a general-purpose computer has four main components: the arithmetic logic unit (alu), the control unit, the memory, and the input and output devices (collectively termed i/o). these parts are interconnected by buses, often made of groups of wires. inside each of these parts are thousands to trillions of small electrical circuits which can be turned off or on by means of an electronic switch. each circuit represents a bit (binary digit) of information so that when the circuit is on it represents a \"1\", and when off it represents a \"0\" (in positive logic representation). the circuits are arranged in logic gates so that one or more of the circuits may control the state of one or more of the other circuits.=== input devices ===when unprocessed data is sent to the computer with the help of input devices, the data is processed and sent to output devices. the input devices may be hand-operated or automated. the act of processing is mainly regulated by the cpu. some examples of input devices are:computer keyboarddigital cameradigital videographics tabletimage scannerjoystickmicrophonemouseoverlay keyboardreal-time clocktrackballtouchscreenlight pen=== output devices ===the means through which computer gives output are known as output devices. some examples of output devices are:computer monitorprinterpc speakerprojectorsound cardvideo card=== control unit ===the control unit (often called a control system or central controller) manages the computer\\'s various components; it reads and interprets (decodes) the program instructions, transforming them into control signals that activate other parts of the computer. control systems in advanced computers may change the order of execution of some instructions to improve performance.a key component common to all cpus is the program counter, a special memory cell (a register) that keeps track of which location in memory the next instruction is to be read from.the control system\\'s function is as follows— this is a simplified description, and some of these steps may be performed concurrently or in a different order depending on the type of cpu:read the code for the next instruction from the cell indicated by the program counter.decode the numerical code for the instruction into a set of commands or signals for each of the other systems.increment the program counter so it points to the next instruction.read whatever data the instruction requires from cells in memory (or perhaps from an input device). the location of this required data is typically stored within the instruction code.provide the necessary data to an alu or register.if the instruction requires an alu or specialized hardware to complete, instruct the hardware to perform the requested operation.write the result from the alu back to a memory location or to a register or perhaps an output device.jump back to step (1).since the program counter is (conceptually) just another set of memory cells, it can be changed by calculations done in the alu. adding 100 to the program counter would cause the next instruction to be read from a place 100 locations further down the program. instructions that modify the program counter are often known as \"jumps\" and allow for loops (instructions that are repeated by the computer) and often conditional instruction execution (both examples of control flow).the sequence of operations that the control unit goes through to process an instruction is in itself like a short computer program, and indeed, in some more complex cpu designs, there is another yet smaller computer called a microsequencer, which runs a microcode program that causes all of these events to happen.=== central processing unit (cpu) ===the control unit, alu, and registers are collectively known as a central processing unit (cpu). early cpus were composed of many separate components. since the 1970s, cpus have typically been constructed on a single mos integrated circuit chip called a microprocessor.=== arithmetic logic unit (alu) ===the alu is capable of performing two classes of operations: arithmetic and logic. the set of arithmetic operations that a particular alu supports may be limited to addition and subtraction, or might include multiplication, division, trigonometry functions such as sine, cosine, etc., and square roots. some can operate only on whole numbers (integers) while others use floating point to represent real numbers, albeit with limited precision. however, any computer that is capable of performing just the simplest operations can be programmed to break down the more complex operations into simple steps that it can perform. therefore, any computer can be programmed to perform any arithmetic operation—although it will take more time to do so if its alu does not directly support the operation. an alu may also compare numbers and return boolean truth values (true or false) depending on whether one is equal to, greater than or less than the other (\"is 64 greater than 65?\"). logic operations involve boolean logic: and, or, xor, and not. these can be useful for creating complicated conditional statements and processing boolean logic.superscalar computers may contain multiple alus, allowing them to process several instructions simultaneously. graphics processors and computers with simd and mimd features often contain alus that can perform arithmetic on vectors and matrices.=== memory ===a computer\\'s memory can be viewed as a list of cells into which numbers can be placed or read. each cell has a numbered \"address\" and can store a single number. the computer can be instructed to \"put the number 123 into the cell numbered 1357\" or to \"add the number that is in cell 1357 to the number that is in cell 2468 and put the answer into cell 1595.\" the information stored in memory may represent practically anything. letters, numbers, even computer instructions can be placed into memory with equal ease. since the cpu does not differentiate between different types of information, it is the software\\'s responsibility to give significance to what the memory sees as nothing but a series of numbers.in almost all modern computers, each memory cell is set up to store binary numbers in groups of eight bits (called a byte). each byte is able to represent 256 different numbers (28 = 256); either from 0 to 255 or −128 to +127. to store larger numbers, several consecutive bytes may be used (typically, two, four or eight). when negative numbers are required, they are usually stored in two\\'s complement notation. other arrangements are possible, but are usually not seen outside of specialized applications or historical contexts. a computer can store any kind of information in memory if it can be represented numerically. modern computers have billions or even trillions of bytes of memory.the cpu contains a special set of memory cells called registers that can be read and written to much more rapidly than the main memory area. there are typically between two and one hundred registers depending on the type of cpu. registers are used for the most frequently needed data items to avoid having to access main memory every time data is needed. as data is constantly being worked on, reducing the need to access main memory (which is often slow compared to the alu and control units) greatly increases the computer\\'s speed.computer main memory comes in two principal varieties:random-access memory or ramread-only memory or romram can be read and written to anytime the cpu commands it, but rom is preloaded with data and software that never changes, therefore the cpu can only read from it. rom is typically used to store the computer\\'s initial start-up instructions. in general, the contents of ram are erased when the power to the computer is turned off, but rom retains its data indefinitely. in a pc, the rom contains a specialized program called the bios that orchestrates loading the computer\\'s operating system from the hard disk drive into ram whenever the computer is turned on or reset. in embedded computers, which frequently do not have disk drives, all of the required software may be stored in rom. software stored in rom is often called firmware, because it is notionally more like hardware than software. flash memory blurs the distinction between rom and ram, as it retains its data when turned off but is also rewritable. it is typically much slower than conventional rom and ram however, so its use is restricted to applications where high speed is unnecessary.in more sophisticated computers there may be one or more ram cache memories, which are slower than registers but faster than main memory. generally computers with this sort of cache are designed to move frequently needed data into the cache automatically, often without the need for any intervention on the programmer\\'s part.=== input/output (i/o) ===i/o is the means by which a computer exchanges information with the outside world. devices that provide input or output to the computer are called peripherals. on a typical personal computer, peripherals include input devices like the keyboard and mouse, and output devices such as the display and printer. hard disk drives, floppy disk drives and optical disc drives serve as both input and output devices. computer networking is another form of i/o.i/o devices are often complex computers in their own right, with their own cpu and memory. a graphics processing unit might contain fifty or more tiny computers that perform the calculations necessary to display 3d graphics. modern desktop computers contain many smaller computers that assist the main cpu in performing i/o. a 2016-era flat screen display contains its own computer circuitry.=== multitasking ===while a computer may be viewed as running one gigantic program stored in its main memory, in some systems it is necessary to give the appearance of running several programs simultaneously. this is achieved by multitasking i.e. having the computer switch rapidly between running each program in turn. one means by which this is done is with a special signal called an interrupt, which can periodically cause the computer to stop executing instructions where it was and do something else instead. by remembering where it was executing prior to the interrupt, the computer can return to that task later. if several programs are running \"at the same time\". then the interrupt generator might be causing several hundred interrupts per second, causing a program switch each time. since modern computers typically execute instructions several orders of magnitude faster than human perception, it may appear that many programs are running at the same time even though only one is ever executing in any given instant. this method of multitasking is sometimes termed \"time-sharing\" since each program is allocated a \"slice\" of time in turn.before the era of inexpensive computers, the principal use for multitasking was to allow many people to share the same computer. seemingly, multitasking would cause a computer that is switching between several programs to run more slowly, in direct proportion to the number of programs it is running, but most programs spend much of their time waiting for slow input/output devices to complete their tasks. if a program is waiting for the user to click on the mouse or press a key on the keyboard, then it will not take a \"time slice\" until the event it is waiting for has occurred. this frees up time for other programs to execute so that many programs may be run simultaneously without unacceptable speed loss.=== multiprocessing ===some computers are designed to distribute their work across several cpus in a multiprocessing configuration, a technique once employed in only large and powerful machines such as supercomputers, mainframe computers and servers. multiprocessor and multi-core (multiple cpus on a single integrated circuit) personal and laptop computers are now widely available, and are being increasingly used in lower-end markets as a result.supercomputers in particular often have highly unique architectures that differ significantly from the basic stored-program architecture and from general-purpose computers. they often feature thousands of cpus, customized high-speed interconnects, and specialized computing hardware. such designs tend to be useful for only specialized tasks due to the large scale of program organization required to successfully utilize most of the available resources at once. supercomputers usually see usage in large-scale simulation, graphics rendering, and cryptography applications, as well as with other so-called \"embarrassingly parallel\" tasks.'], 'software': ['software refers to parts of the computer which do not have a material form, such as programs, data, protocols, etc. software is that part of a computer system that consists of encoded information or computer instructions, in contrast to the physical hardware from which the system is built. computer software includes computer programs, libraries and related non-executable data, such as online documentation or digital media. it is often divided into system software and application software computer hardware and software require each other and neither can be realistically used on its own. when software is stored in hardware that cannot easily be modified, such as with bios rom in an ibm pc compatible computer, it is sometimes called \"firmware\".=== languages ===there are thousands of different programming languages—some intended for general purpose, others useful for only highly specialized applications.=== programs ===the defining feature of modern computers which distinguishes them from all other machines is that they can be programmed. that is to say that some type of instructions (the program) can be given to the computer, and it will process them. modern computers based on the von neumann architecture often have machine code in the form of an imperative programming language. in practical terms, a computer program may be just a few instructions or extend to many millions of instructions, as do the programs for word processors and web browsers for example. a typical modern computer can execute billions of instructions per second (gigaflops) and rarely makes a mistake over many years of operation. large computer programs consisting of several million instructions may take teams of programmers years to write, and due to the complexity of the task almost certainly contain errors.==== stored program architecture ====this section applies to most common ram machine–based computers.in most cases, computer instructions are simple: add one number to another, move some data from one location to another, send a message to some external device, etc. these instructions are read from the computer\\'s memory and are generally carried out (executed) in the order they were given. however, there are usually specialized instructions to tell the computer to jump ahead or backwards to some other place in the program and to carry on executing from there. these are called \"jump\" instructions (or branches). furthermore, jump instructions may be made to happen conditionally so that different sequences of instructions may be used depending on the result of some previous calculation or some external event. many computers directly support subroutines by providing a type of jump that \"remembers\" the location it jumped from and another instruction to return to the instruction following that jump instruction.program execution might be likened to reading a book. while a person will normally read each word and line in sequence, they may at times jump back to an earlier place in the text or skip sections that are not of interest. similarly, a computer may sometimes go back and repeat the instructions in some section of the program over and over again until some internal condition is met. this is called the flow of control within the program and it is what allows the computer to perform tasks repeatedly without human intervention.comparatively, a person using a pocket calculator can perform a basic arithmetic operation such as adding two numbers with just a few button presses. but to add together all of the numbers from 1 to 1,000 would take thousands of button presses and a lot of time, with a near certainty of making a mistake. on the other hand, a computer may be programmed to do this with just a few simple instructions. the following example is written in the mips assembly language:once told to run this program, the computer will perform the repetitive addition task without further human intervention. it will almost never make a mistake and a modern pc can complete the task in a fraction of a second.==== machine code ====in most computers, individual instructions are stored as machine code with each instruction being given a unique number (its operation code or opcode for short). the command to add two numbers together would have one opcode; the command to multiply them would have a different opcode, and so on. the simplest computers are able to perform any of a handful of different instructions; the more complex computers have several hundred to choose from, each with a unique numerical code. since the computer\\'s memory is able to store numbers, it can also store the instruction codes. this leads to the important fact that entire programs (which are just lists of these instructions) can be represented as lists of numbers and can themselves be manipulated inside the computer in the same way as numeric data. the fundamental concept of storing programs in the computer\\'s memory alongside the data they operate on is the crux of the von neumann, or stored program, architecture. in some cases, a computer might store some or all of its program in memory that is kept separate from the data it operates on. this is called the harvard architecture after the harvard mark i computer. modern von neumann computers display some traits of the harvard architecture in their designs, such as in cpu caches.while it is possible to write computer programs as long lists of numbers (machine language) and while this technique was used with many early computers, it is extremely tedious and potentially error-prone to do so in practice, especially for complicated programs. instead, each basic instruction can be given a short name that is indicative of its function and easy to remember – a mnemonic such as add, sub, mult or jump. these mnemonics are collectively known as a computer\\'s assembly language. converting programs written in assembly language into something the computer can actually understand (machine language) is usually done by a computer program called an assembler.==== programming language ====programming languages provide various ways of specifying programs for computers to run. unlike natural languages, programming languages are designed to permit no ambiguity and to be concise. they are purely written languages and are often difficult to read aloud. they are generally either translated into machine code by a compiler or an assembler before being run, or translated directly at run time by an interpreter. sometimes programs are executed by a hybrid method of the two techniques.===== low-level languages =====machine languages and the assembly languages that represent them (collectively termed low-level programming languages) are generally unique to the particular architecture of a computer\\'s central processing unit (cpu). for instance, an arm architecture cpu (such as may be found in a smartphone or a hand-held videogame) cannot understand the machine language of an x86 cpu that might be in a pc. historically a significant number of other cpu architectures were created and saw extensive use, notably including the mos technology 6502 and 6510 in addition to the zilog z80.===== high-level languages =====although considerably easier than in machine language, writing long programs in assembly language is often difficult and is also error prone. therefore, most practical programs are written in more abstract high-level programming languages that are able to express the needs of the programmer more conveniently (and thereby help reduce programmer error). high level languages are usually \"compiled\" into machine language (or sometimes into assembly language and then into machine language) using another computer program called a compiler. high level languages are less related to the workings of the target computer than assembly language, and more related to the language and structure of the problem(s) to be solved by the final program. it is therefore often possible to use different compilers to translate the same high level language program into the machine language of many different types of computer. this is part of the means by which software like video games may be made available for different computer architectures such as personal computers and various video game consoles.==== program design ====program design of small programs is relatively simple and involves the analysis of the problem, collection of inputs, using the programming constructs within languages, devising or using established procedures and algorithms, providing data for output devices and solutions to the problem as applicable. as problems become larger and more complex, features such as subprograms, modules, formal documentation, and new paradigms such as object-oriented programming are encountered. large programs involving thousands of line of code and more require formal software methodologies.the task of developing large software systems presents a significant intellectual challenge. producing software with an acceptably high reliability within a predictable schedule and budget has historically been difficult; the academic and professional discipline of software engineering concentrates specifically on this challenge.==== bugs ====errors in computer programs are called \"bugs\". they may be benign and not affect the usefulness of the program, or have only subtle effects. but in some cases, they may cause the program or the entire system to \"hang\", becoming unresponsive to input such as mouse clicks or keystrokes, to completely fail, or to crash. otherwise benign bugs may sometimes be harnessed for malicious intent by an unscrupulous user writing an exploit, code designed to take advantage of a bug and disrupt a computer\\'s proper execution. bugs are usually not the fault of the computer. since computers merely execute the instructions they are given, bugs are nearly always the result of programmer error or an oversight made in the program\\'s design. admiral grace hopper, an american computer scientist and developer of the first compiler, is credited for having first used the term \"bugs\" in computing after a dead moth was found shorting a relay in the harvard mark ii computer in september 1947.'], 'networking and the internet': ['computers have been used to coordinate information between multiple locations since the 1950s. the u.s. military\\'s sage system was the first large-scale example of such a system, which led to a number of special-purpose commercial systems such as sabre. in the 1970s, computer engineers at research institutions throughout the united states began to link their computers together using telecommunications technology. the effort was funded by arpa (now darpa), and the computer network that resulted was called the arpanet. the technologies that made the arpanet possible spread and evolved.in time, the network spread beyond academic and military institutions and became known as the internet. the emergence of networking involved a redefinition of the nature and boundaries of the computer. computer operating systems and applications were modified to include the ability to define and access the resources of other computers on the network, such as peripheral devices, stored information, and the like, as extensions of the resources of an individual computer. initially these facilities were available primarily to people working in high-tech environments, but in the 1990s the spread of applications like e-mail and the world wide web, combined with the development of cheap, fast networking technologies like ethernet and adsl saw computer networking become almost ubiquitous. in fact, the number of computers that are networked is growing phenomenally. a very large proportion of personal computers regularly connect to the internet to communicate and receive information. \"wireless\" networking, often utilizing mobile phone networks, has meant networking is becoming increasingly ubiquitous even in mobile computing environments.'], 'unconventional computer': ['a computer does not need to be electronic, nor even have a processor, nor ram, nor even a hard disk. while popular usage of the word \"computer\" is synonymous with a personal electronic computer, the modern definition of a computer is literally: \"a device that computes, especially a programmable [usually] electronic machine that performs high-speed mathematical or logical operations or that assembles, stores, correlates, or otherwise processes information.\" any device which processes information qualifies as a computer, especially if the processing is purposeful.'], 'future': ['there is active research to make computers out of many promising new types of technology, such as optical computers, dna computers, neural computers, and quantum computers. most computers are universal, and are able to calculate any computable function, and are limited only by their memory capacity and operating speed. however different designs of computers can give very different performance for particular problems; for example quantum computers can potentially break some modern encryption algorithms (by quantum factoring) very quickly.=== computer architecture paradigms ===there are many types of computer architectures:quantum computer vs. chemical computerscalar processor vs. vector processornon-uniform memory access (numa) computersregister machine vs. stack machineharvard architecture vs. von neumann architecturecellular architectureof all these abstract machines, a quantum computer holds the most promise for revolutionizing computing. logic gates are a common abstraction which can apply to most of the above digital or analog paradigms. the ability to store and execute lists of instructions called programs makes computers extremely versatile, distinguishing them from calculators. the church–turing thesis is a mathematical statement of this versatility: any computer with a minimum capability (being turing-complete) is, in principle, capable of performing the same tasks that any other computer can perform. therefore, any type of computer (netbook, supercomputer, cellular automaton, etc.) is able to perform the same computational tasks, given enough time and storage capacity.=== artificial intelligence ===a computer will solve problems in exactly the way it is programmed to, without regard to efficiency, alternative solutions, possible shortcuts, or possible errors in the code. computer programs that learn and adapt are part of the emerging field of artificial intelligence and machine learning. artificial intelligence based products generally fall into two major categories: rule-based systems and pattern recognition systems. rule-based systems attempt to represent the rules used by human experts and tend to be expensive to develop. pattern-based systems use data about a problem to generate conclusions. examples of pattern-based systems include voice recognition, font recognition, translation and the emerging field of on-line marketing.'], 'professions and organization': ['as the use of computers has spread throughout society, there are an increasing number of careers involving computers.the need for computers to work well together and to be able to exchange information has spawned the need for many standards organizations, clubs and societies of both a formal and informal nature.']})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['history', 'etymology', 'philosophy', 'field', 'discoverie', 'programming paradigm', 'academia', 'education', 'further reading']\n",
      "defaultdict(<class 'list'>, {'intro': ['in computer engineering, computer architecture is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. the architecture of a system refers to its structure in terms of separately specified components of that system and their interrelationships.some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation. in other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation.', 'in computing, a word is the natural unit of data used by a particular processor design. a word is a fixed-sized datum handled as a unit by the instruction set or the hardware of the processor. the number of bits or digits in a word (the word size, word width, or word length) is an important characteristic of any specific processor design or computer architecture.the size of a word is reflected in many aspects of a computer\\'s structure and operation; the majority of the registers in a processor are usually word sized and the largest datum that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. the largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used).documentation for computers with fixed word size commonly stated memory sizes in words rather than bytes or characters.  the documentation sometimes used metric prefixes correctly, sometimes with rounding, e.g., 65 kilowords (kw) meaning for 65536 words, and sometimes used them incorrectly, with kilowords (kw) meaning 1024 words (210) and megawords (mw) meaning 1,048,576 words (220). with standardization on 8-bit bytes and byte addressability, stating memory sizes in bytes, kilobytes, and megabytes with powers of 1024 rather than 1000 has become the norm, although there is some use of the iec binary prefixes.several of the earliest computers (and a few modern as well) used binary-coded decimal rather than plain binary, typically having a word size of 10 or 12 decimal digits, and some early decimal computers had no fixed word length at all. early binary systems tended to use word lengths that were some multiple of 6-bits, with the 36-bit word being especially common on mainframe computers. the introduction of ascii led to the move to systems with word lengths that were a multiple of 8-bits, with 16-bit machines being popular in the 1970s before the move to modern processors with 32 or 64 bits. special-purpose designs like digital signal processors, may have any word length from 4 to 80 bits.the size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. if multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see size families below).', 'in the domain of central processing unit (cpu) design, hazards are problems with the instruction pipeline in cpu microarchitectures when the next instruction cannot execute in the following clock cycle, and can potentially lead to incorrect computation results. three common types of hazards are data hazards, structural hazards, and control hazards (branching hazards).there are several methods used to deal with hazards, including pipeline stalls/pipeline bubbling, operand forwarding, and in the case of out-of-order execution, the scoreboarding method and the tomasulo algorithm.', 'in computer architecture, multithreading is the ability of a central processing unit (cpu) (or a single core in a multi-core processor) to provide multiple threads of execution concurrently, supported by the operating system. this approach differs from multiprocessing. in a multithreaded application, the threads share the resources of a single or multiple cores, which include the computing units, the cpu caches, and the translation lookaside buffer (tlb).where multiprocessing systems include multiple complete processing units in one or more cores, multithreading aims to increase utilization of a single core by using thread-level parallelism, as well as instruction-level parallelism. as the two techniques are complementary, they are combined in nearly all modern systems architectures with multiple multithreading cpus and with cpus with multiple multithreading cores.', 'the von neumann architecture — also known as the von neumann model or princeton architecture — is a computer architecture based on a 1945 description by john von neumann, and by others, in the first draft of a report on the edvac. the document describes a design architecture for an electronic digital computer with these components:a processing unit with both an arithmetic logic unit and processor registersa control unit that includes an instruction register and a program countermemory that stores data and instructionsexternal mass storageinput and output mechanismsthe term \"von neumann architecture\" has evolved to refer to any stored-program computer in which an instruction fetch and a data operation cannot occur at the same time (since they share a common bus). this is referred to as the von neumann bottleneck, which often limits the performance of the corresponding system.the design of a von neumann architecture machine is simpler than in a harvard architecture machine—which is also a stored-program system, yet has one dedicated set of address and data buses for reading and writing to memory, and another set of address and data buses to fetch instructions.a stored-program digital computer keeps both program instructions and data in read–write, random-access memory (ram).  stored-program computers were an advancement over the program-controlled computers of the 1940s, such as the colossus and the eniac. those were programmed by setting switches and inserting patch cables to route data and control signals between various functional units. the vast majority of modern computers use the same memory for both data and program instructions, but have caches between the cpu and memory, and, for the caches closest to the cpu, have separate caches for instructions and data, so that most instruction and data fetches use separate buses (split cache architecture).', 'in computer science, predication is an architectural feature that provides an alternative to conditional transfer of control, as implemented by conditional branch machine instructions. predication works by having conditional (predicated) non-branch instructions associated with a predicate, a boolean value used by the instruction to control whether the instruction is allowed to modify the architectural state or not.  if the predicate specified in the instruction is true, the instruction modifies the architectural state; otherwise, the architectural state is unchanged.  for example, a predicated move instruction (a conditional move) will only modify the destination if the predicate is true.  thus, instead of using a conditional branch to select an instruction or a sequence of instructions to execute based on the predicate that controls whether the branch occurs, the instructions to be executed are associated with that predicate, so that they will be executed, or not executed, based on whether that predicate is true or false.vector processors, some simd isas (such as avx2 and avx-512) and gpus in general make heavy use of predication, applying one bit of a conditional mask vector to the corresponding elements in the vector registers being processed, whereas scalar predication in scalar instruction sets only need the one predicate bit.  where predicate masks become particularly powerful in vector processing is if an array of condition codes, one per vector element, may feed back into predicate masks that are then applied to subsequent vector instructions.', 'a computer is a digital electronic machine that can be programmed to carry out sequences of arithmetic or logical operations (computation) automatically. modern computers can perform generic sets of operations known as programs. these programs enable computers to perform a wide range of tasks. a computer system is a \"complete\" computer that includes the hardware, operating system (main software), and peripheral equipment needed and used for \"full\" operation. this term may also refer to a group of computers that are linked and function together, such as a computer network or computer cluster.a broad range of industrial and consumer products use computers as control systems. simple special-purpose devices like microwave ovens and remote controls are included, as are factory devices like industrial robots and computer-aided design, as well as general-purpose devices like personal computers and mobile devices like smartphones. computers power the internet, which links billions of other computers and users.early computers were meant to be used only for calculations. simple manual instruments like the abacus have aided people in doing calculations since ancient times. early in the industrial revolution, some mechanical devices were built to automate long tedious tasks, such as guiding patterns for looms. more sophisticated electrical machines did specialized analog calculations in the early 20th century. the first digital electronic calculating machines were developed during world war ii. the first semiconductor transistors in the late 1940s were followed by the silicon-based mosfet (mos transistor) and monolithic integrated circuit (ic) chip technologies in the late 1950s, leading to the microprocessor and the microcomputer revolution in the 1970s. the speed, power and versatility of computers have been increasing dramatically ever since then, with transistor counts increasing at a rapid pace (as predicted by moore\\'s law), leading to the digital revolution during the late 20th to early 21st centuries.conventionally, a modern computer consists of at least one processing element, typically a central processing unit (cpu) in the form of a microprocessor, along with some type of computer memory, typically semiconductor memory chips. the processing element carries out arithmetic and logical operations, and a sequencing and control unit can change the order of operations in response to stored information. peripheral devices include input devices (keyboards, mice, joystick, etc.), output devices (monitor screens, printers, etc.), and input/output devices that perform both functions (e.g., the 2000s-era touchscreen). peripheral devices allow information to be retrieved from an external source and they enable the result of operations to be saved and retrieved.', 'computer science is the study of computation, automation, and information. computer science spans theoretical disciplines (such as algorithms, theory of computation, and information theory) to practical disciplines (including the design and implementation of hardware and software). computer science is generally considered an area of academic research and distinct from computer programming.algorithms and data structures are central to computer science.the theory of computation concerns abstract models of computation and general classes of problems that can be solved using them. the fields of cryptography and computer security involve studying the means for secure communication and for preventing security vulnerabilities. computer graphics and computational geometry address the generation of images. programming language theory considers approaches to the description of computational processes, and database theory concerns the management of repositories of data. human–computer interaction investigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. areas such as operating systems, networks and embedded systems investigate the principles and design behind complex systems. computer architecture describes the construction of computer components and computer-operated equipment. artificial intelligence and machine learning aim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. within artificial intelligence, computer vision aims to understand and process image and video data, while natural-language processing aims to understand and process textual and linguistic data.the fundamental concern of computer science is determining what can and cannot be automated. the turing award is generally recognized as the highest distinction in computer science.'], 'history': ['the first documented computer architecture was in the correspondence between charles babbage and ada lovelace, describing the analytical engine. when building the computer z1 in 1936, konrad zuse described in two patent applications for his future projects that machine instructions could be stored in the same storage used for data, i.e., the stored-program concept. two other early and important examples are:john von neumann\\'s 1945 paper, first draft of a report on the edvac, which described an organization of logical elements; andalan turing\\'s more detailed proposed electronic calculator for the automatic computing engine, also 1945 and which cited john von neumann\\'s paper.the term “architecture” in computer literature can be traced to the work of lyle r. johnson and frederick p. brooks, jr., members of the machine organization department in ibm\\'s main research center in 1959. johnson had the opportunity to write a proprietary research communication about the stretch, an ibm-developed supercomputer for los alamos national laboratory (at the time known as los alamos scientific laboratory). to describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that seemed more useful than “machine organization”.subsequently, brooks, a stretch designer, opened chapter 2 of a book called planning a computer system: project stretch by stating, “computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.”brooks went on to help develop the ibm system/360 (now called the ibm zseries) line of computers, in which “architecture” became a noun defining “what the user needs to know”. later, computer users came to use the term in many less explicit ways.the earliest computer architectures were designed on paper and then directly built into the final hardware form.later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (ttl) computer—such as the prototypes of the 6800 and the pa-risc—tested, and tweaked, before committing to the final hardware form.as of the 1990s, new computer architectures are typically \"built\", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a fpga as a soft microprocessor; or both—before committing to the final hardware form.', 'the earliest computing machines had fixed programs.  some very simple computers still use this design, either for simplicity or training purposes.  for example, a desk calculator (in principle) is a fixed program computer.  it can do basic mathematics, but it cannot run a word processor or games.  changing the program of a fixed-program machine requires rewiring, restructuring, or redesigning the machine.  the earliest computers were not so much \"programmed\" as  \"designed\" for a particular task.  \"reprogramming\" – when possible at all – was a laborious process that started with flowcharts and paper notes, followed by detailed engineering designs, and then the often-arduous process of physically rewiring and rebuilding the machine. it could take three weeks to set up and debug a program on eniac.with the proposal of the stored-program computer, this changed. a stored-program computer includes, by design, an instruction set, and can store in memory a set of instructions (a program) that details the computation.a stored-program design also allows for self-modifying code. one early motivation for such a facility was the need for a program to increment or otherwise modify the address portion of instructions, which operators had to do manually in early designs. this became less important when index registers and indirect addressing became usual features of machine architecture. another use was to embed frequently used data in the instruction stream using immediate addressing. self-modifying code has largely fallen out of favor, since it is usually hard to understand and debug, as well as being inefficient under modern processor pipelining and caching schemes.', 'predicated instructions were popular in european computer designs of the 1950s, including the mailüfterl (1955), the zuse z22 (1955), the zebra (1958), and the electrologica x1 (1958). the ibm acs-1 design of 1967 allocated a \"skip\" bit in its instruction formats, and the cdc flexible processor in 1976 allocated three conditional execution bits in its microinstruction formats.hewlett-packard\\'s pa-risc architecture (1986) had a feature called nullification, which allowed most instructions to be predicated by the previous instruction. ibm\\'s power architecture (1990) featured conditional move instructions. power\\'s successor, powerpc (1993), dropped these instructions. digital equipment corporation\\'s alpha architecture (1992) also featured conditional move instructions. mips gained conditional move instructions in 1994 with the mips iv version; and sparc was extended in version 9 (1994) with conditional move instructions for both integer and floating-point registers.in the hewlett-packard/intel ia-64 architecture, most instructions are predicated. the predicates are stored in 64 special-purpose predicate registers; and one of the predicate registers is always true so that unpredicated instructions are simply instructions predicated with the value true. the use of predication is essential in ia-64\\'s implementation of software pipelining because it avoids the need for writing separated code for prologs and epilogs.in the x86 architecture, a family of conditional move instructions (cmov and fcmov) were added to the architecture by the intel pentium pro (1995) processor. the cmov instructions copied the contents of the source register to the destination register depending on a predicate supplied by the value of the flag register.in the arm architecture, the original 32-bit instruction set provides a feature called conditional execution that allows most instructions to be predicated by one of 13 predicates that are based on some combination of the four condition codes set by the previous instruction. arm\\'s thumb instruction set (1994) dropped conditional execution to reduce the size of instructions so they could fit in 16 bits, but its successor, thumb-2 (2003) overcame this problem by using a special instruction which has no effect other than to supply predicates for the following four instructions. the 64-bit instruction set introduced in armv8-a (2011) replaced conditional execution with conditional selection instructions.== simd, simt and vector predication ==some simd instruction sets, like avx2, have the ability to use a logical mask to conditionally load/store values to memory, a parallel form of the conditional move, and may also apply individual mask bits to individual arithmetic units executing a parallel operation.  the technique is known in flynn\\'s taxonomy as \"associative processing\".this form of predication is also used in vector processors and single instruction, multiple threads gpu computing.  all the techniques, advantages and disadvantages of single scalar predication apply just as well to the parallel processing case.', '=== pre-20th century ===devices have been used to aid computation for thousands of years, mostly using one-to-one correspondence with fingers. the earliest counting device was probably a form of tally stick. later record keeping aids throughout the fertile crescent included calculi (clay spheres, cones, etc.) which represented counts of items, probably livestock or grains, sealed in hollow unbaked clay containers. the use of counting rods is one example.the abacus was initially used for arithmetic tasks. the roman abacus was developed from devices used in babylonia as early as 2400 bc. since then, many other forms of reckoning boards or tables have been invented. in a medieval european counting house, a checkered cloth would be placed on a table, and markers moved around on it according to certain rules, as an aid to calculating sums of money.the antikythera mechanism is believed to be the earliest known mechanical analog computer, according to derek j. de solla price. it was designed to calculate astronomical positions. it was discovered in 1901 in the antikythera wreck off the greek island of antikythera, between kythera and crete, and has been dated to approximately c.\\u2009100 bc. devices of comparable complexity to the antikythera mechanism would not reappear until the fourteenth century.many mechanical aids to calculation and measurement were constructed for astronomical and navigation use. the planisphere was a star chart invented by abū rayhān al-bīrūnī in the early 11th century. the astrolabe was invented in the hellenistic world in either the 1st or 2nd centuries bc and is often attributed to hipparchus. a combination of the planisphere and dioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems in spherical astronomy. an astrolabe incorporating a mechanical calendar computer and gear-wheels was invented by abi bakr of isfahan, persia in 1235. abū rayhān al-bīrūnī invented the first mechanical geared lunisolar calendar astrolabe, an early fixed-wired knowledge processing machine with a gear train and gear-wheels, c.\\u20091000 ad.the sector, a calculating instrument used for solving problems in proportion, trigonometry, multiplication and division, and for various functions, such as squares and cube roots, was developed in the late 16th century and found application in gunnery, surveying and navigation.the planimeter was a manual instrument to calculate the area of a closed figure by tracing over it with a mechanical linkage.the slide rule was invented around 1620–1630 by the english clergyman william oughtred, shortly after the publication of the concept of the logarithm. it is a hand-operated analog computer for doing multiplication and division. as slide rule development progressed, added scales provided reciprocals, squares and square roots, cubes and cube roots, as well as transcendental functions such as logarithms and exponentials, circular and hyperbolic trigonometry and other functions. slide rules with special scales are still used for quick performance of routine calculations, such as the e6b circular slide rule used for time and distance calculations on light aircraft.in the 1770s, pierre jaquet-droz, a swiss watchmaker, built a mechanical doll (automaton) that could write holding a quill pen. by switching the number and order of its internal wheels different letters, and hence different messages, could be produced. in effect, it could be mechanically \"programmed\" to read instructions. along with two other complex machines, the doll is at the musée d\\'art et d\\'histoire of neuchâtel, switzerland, and still operates.in 1831–1835, mathematician and engineer giovanni plana devised a perpetual calendar machine, which, through a system of pulleys and cylinders and over, could predict the perpetual calendar for every year from ad 0 (that is, 1 bc) to ad 4000, keeping track of leap years and varying day length. the tide-predicting machine invented by the scottish scientist sir william thomson in 1872 was of great utility to navigation in shallow waters. it used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location.the differential analyser, a mechanical analog computer designed to solve differential equations by integration, used wheel-and-disc mechanisms to perform the integration. in 1876, sir william thomson had already discussed the possible construction of such calculators, but he had been stymied by the limited output torque of the ball-and-disk integrators. in a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output. the torque amplifier was the advance that allowed these machines to work. starting in the 1920s, vannevar bush and others developed mechanical differential analyzers.=== first computer ===charles babbage, an english mechanical engineer and polymath, originated the concept of a programmable computer. considered the \"father of the computer\", he conceptualized and invented the first mechanical computer in the early 19th century. after working on his revolutionary difference engine, designed to aid in navigational calculations, in 1833 he realized that a much more general design, an analytical engine, was possible. the input of programs and data was to be provided to the machine via punched cards, a method being used at the time to direct mechanical looms such as the jacquard loom. for output, the machine would have a printer, a curve plotter and a bell. the machine would also be able to punch numbers onto cards to be read in later. the engine incorporated an arithmetic logic unit, control flow in the form of conditional branching and loops, and integrated memory, making it the first design for a general-purpose computer that could be described in modern terms as turing-complete.the machine was about a century ahead of its time. all the parts for his machine had to be made by hand – this was a major problem for a device with thousands of parts. eventually, the project was dissolved with the decision of the british government to cease funding. babbage\\'s failure to complete the analytical engine can be chiefly attributed to political and financial difficulties as well as his desire to develop an increasingly sophisticated computer and to move ahead faster than anyone else could follow. nevertheless, his son, henry babbage, completed a simplified version of the analytical engine\\'s computing unit (the mill) in 1888. he gave a successful demonstration of its use in computing tables in 1906.=== analog computers ===during the first half of the 20th century, many scientific computing needs were met by increasingly sophisticated analog computers, which used a direct mechanical or electrical model of the problem as a basis for computation. however, these were not programmable and generally lacked the versatility and accuracy of modern digital computers. the first modern analog computer was a tide-predicting machine, invented by sir william thomson (later to become lord kelvin) in 1872. the differential analyser, a mechanical analog computer designed to solve differential equations by integration using wheel-and-disc mechanisms, was conceptualized in 1876 by james thomson, the elder brother of the more famous sir william thomson.the art of mechanical analog computing reached its zenith with the differential analyzer, built by h. l. hazen and vannevar bush at mit starting in 1927. this built on the mechanical integrators of james thomson and the torque amplifiers invented by h. w. nieman. a dozen of these devices were built before their obsolescence became obvious. by the 1950s, the success of digital electronic computers had spelled the end for most analog computing machines, but analog computers remained in use during the 1950s in some specialized applications such as education (slide rule) and aircraft (control systems).=== digital computers ======= electromechanical ====by 1938, the united states navy had developed an electromechanical analog computer small enough to use aboard a submarine. this was the torpedo data computer, which used trigonometry to solve the problem of firing a torpedo at a moving target. during world war ii similar devices were developed in other countries as well.early digital computers were electromechanical; electric switches drove mechanical relays to perform the calculation. these devices had a low operating speed and were eventually superseded by much faster all-electric computers, originally using vacuum tubes. the z2, created by german engineer konrad zuse in 1939, was one of the earliest examples of an electromechanical relay computer.in 1941, zuse followed his earlier machine up with the z3, the world\\'s first working electromechanical programmable, fully automatic digital computer. the z3 was built with 2000 relays, implementing a 22 bit word length that operated at a clock frequency of about 5–10 hz. program code was supplied on punched film while data could be stored in 64 words of memory or supplied from the keyboard. it was quite similar to modern machines in some respects, pioneering numerous advances such as floating-point numbers. rather than the harder-to-implement decimal system (used in charles babbage\\'s earlier design), using a binary system meant that zuse\\'s machines were easier to build and potentially more reliable, given the technologies available at that time. the z3 was not itself a universal computer but could be extended to be turing complete.zuse\\'s next computer, the z4, became the world\\'s first commercial computer; after initial delay due to the second world war, it was completed in 1950 and delivered to the eth zurich. the computer was manufactured by zuse\\'s own company, zuse kg, which was founded in 1941 as the first company with the sole purpose of developing computers.==== vacuum tubes and digital electronic circuits ====purely electronic circuit elements soon replaced their mechanical and electromechanical equivalents, at the same time that digital calculation replaced analog. the engineer tommy flowers, working at the post office research station in london in the 1930s, began to explore the possible use of electronics for the telephone exchange. experimental equipment that he built in 1934 went into operation five years later, converting a portion of the telephone exchange network into an electronic data processing system, using thousands of vacuum tubes. in the us, john vincent atanasoff and clifford e. berry of iowa state university developed and tested the atanasoff–berry computer (abc) in 1942, the first \"automatic electronic digital computer\". this design was also all-electronic and used about 300 vacuum tubes, with capacitors fixed in a mechanically rotating drum for memory.during world war ii, the british code-breakers at bletchley park achieved a number of successes at breaking encrypted german military communications. the german encryption machine, enigma, was first attacked with the help of the electro-mechanical bombes which were often run by women. to crack the more sophisticated german lorenz sz 40/42 machine, used for high-level army communications, max newman and his colleagues commissioned flowers to build the colossus. he spent eleven months from early february 1943 designing and building the first colossus. after a functional test in december 1943, colossus was shipped to bletchley park, where it was delivered on 18 january 1944 and attacked its first message on 5 february.colossus was the world\\'s first electronic digital programmable computer. it used a large number of valves (vacuum tubes). it had paper-tape input and was capable of being configured to perform a variety of boolean logical operations on its data, but it was not turing-complete. nine mk ii colossi were built (the mk i was converted to a mk ii making ten machines in total). colossus mark i contained 1,500 thermionic valves (tubes), but mark ii with 2,400 valves, was both five times faster and simpler to operate than mark i, greatly speeding the decoding process.the eniac (electronic numerical integrator and computer) was the first electronic programmable computer built in the u.s. although the eniac was similar to the colossus, it was much faster, more flexible, and it was turing-complete. like the colossus, a \"program\" on the eniac was defined by the states of its patch cables and switches, a far cry from the stored program electronic machines that came later. once a program was written, it had to be mechanically set into the machine with manual resetting of plugs and switches. the programmers of the eniac were six women, often known collectively as the \"eniac girls\".it combined the high speed of electronics with the ability to be programmed for many complex problems. it could add or subtract 5000 times a second, a thousand times faster than any other machine. it also had modules to multiply, divide, and square root. high speed memory was limited to 20 words (about 80 bytes). built under the direction of john mauchly and j. presper eckert at the university of pennsylvania, eniac\\'s development and construction lasted from 1943 to full operation at the end of 1945. the machine was huge, weighing 30 tons, using 200 kilowatts of electric power and contained over 18,000 vacuum tubes, 1,500 relays, and hundreds of thousands of resistors, capacitors, and inductors.=== modern computers ======= concept of modern computer ====the principle of the modern computer was proposed by alan turing in his seminal 1936 paper, on computable numbers. turing proposed a simple device that he called \"universal computing machine\" and that is now known as a universal turing machine. he proved that such a machine is capable of computing anything that is computable by executing instructions (program) stored on tape, allowing the machine to be programmable. the fundamental concept of turing\\'s design is the stored program, where all the instructions for computing are stored in memory. von neumann acknowledged that the central concept of the modern computer was due to this paper. turing machines are to this day a central object of study in theory of computation. except for the limitations imposed by their finite memory stores, modern computers are said to be turing-complete, which is to say, they have algorithm execution capability equivalent to a universal turing machine.==== stored programs ====early computing machines had fixed programs. changing its function required the re-wiring and re-structuring of the machine. with the proposal of the stored-program computer this changed. a stored-program computer includes by design an instruction set and can store in memory a set of instructions (a program) that details the computation. the theoretical basis for the stored-program computer was laid by alan turing in his 1936 paper. in 1945, turing joined the national physical laboratory and began work on developing an electronic stored-program digital computer. his 1945 report \"proposed electronic calculator\" was the first specification for such a device. john von neumann at the university of pennsylvania also circulated his first draft of a report on the edvac in 1945.the manchester baby was the world\\'s first stored-program computer. it was built at the university of manchester in england by frederic c. williams, tom kilburn and geoff tootill, and ran its first program on 21 june 1948. it was designed as a testbed for the williams tube, the first random-access digital storage device. although the computer was considered \"small and primitive\" by the standards of its time, it was the first working machine to contain all of the elements essential to a modern electronic computer. as soon as the baby had demonstrated the feasibility of its design, a project was initiated at the university to develop it into a more usable computer, the manchester mark 1. grace hopper was the first person to develop a compiler for programming language.the mark 1 in turn quickly became the prototype for the ferranti mark 1, the world\\'s first commercially available general-purpose computer. built by ferranti, it was delivered to the university of manchester in february 1951. at least seven of these later machines were delivered between 1953 and 1957, one of them to shell labs in amsterdam. in october 1947, the directors of british catering company j. lyons & company decided to take an active role in promoting the commercial development of computers. the leo i computer became operational in april 1951 and ran the world\\'s first regular routine office computer job.==== transistors ====the concept of a field-effect transistor was proposed by julius edgar lilienfeld in 1925. john bardeen and walter brattain, while working under william shockley at bell labs, built the first working transistor, the point-contact transistor, in 1947, which was followed by shockley\\'s bipolar junction transistor in 1948. from 1955 onwards, transistors replaced vacuum tubes in computer designs, giving rise to the \"second generation\" of computers. compared to vacuum tubes, transistors have many advantages: they are smaller, and require less power than vacuum tubes, so give off less heat. junction transistors were much more reliable than vacuum tubes and had longer, indefinite, service life. transistorized computers could contain tens of thousands of binary logic circuits in a relatively compact space. however, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications.at the university of manchester, a team under the leadership of tom kilburn designed and built a machine using the newly developed transistors instead of valves. their first transistorised computer and the first in the world, was operational by 1953, and a second version was completed there in april 1955. however, the machine did make use of valves to generate its 125 khz clock waveforms and in the circuitry to read and write on its magnetic drum memory, so it was not the first completely transistorized computer. that distinction goes to the harwell cadet of 1955, built by the electronics division of the atomic energy research establishment at harwell.the metal–oxide–silicon field-effect transistor (mosfet), also known as the mos transistor, was invented by mohamed m. atalla and dawon kahng at bell labs in 1959. it was the first truly compact transistor that could be miniaturised and mass-produced for a wide range of uses. with its high scalability, and much lower power consumption and higher density than bipolar junction transistors, the mosfet made it possible to build high-density integrated circuits. in addition to data processing, it also enabled the practical use of mos transistors as memory cell storage elements, leading to the development of mos semiconductor memory, which replaced earlier magnetic-core memory in computers. the mosfet led to the microcomputer revolution, and became the driving force behind the computer revolution. the mosfet is the most widely used transistor in computers, and is the fundamental building block of digital electronics.==== integrated circuits ====the next great advance in computing power came with the advent of the integrated circuit (ic).the idea of the integrated circuit was first conceived by a radar scientist working for the royal radar establishment of the ministry of defence, geoffrey w.a. dummer. dummer presented the first public description of an integrated circuit at the symposium on progress in quality electronic components in washington, d.c. on 7 may 1952.the first working ics were invented by jack kilby at texas instruments and robert noyce at fairchild semiconductor. kilby recorded his initial ideas concerning the integrated circuit in july 1958, successfully demonstrating the first working integrated example on 12 september 1958. in his patent application of 6 february 1959, kilby described his new device as \"a body of semiconductor material ... wherein all the components of the electronic circuit are completely integrated\". however, kilby\\'s invention was a hybrid integrated circuit (hybrid ic), rather than a monolithic integrated circuit (ic) chip. kilby\\'s ic had external wire connections, which made it difficult to mass-produce.noyce also came up with his own idea of an integrated circuit half a year later than kilby. noyce\\'s invention was the first true monolithic ic chip. his chip solved many practical problems that kilby\\'s had not. produced at fairchild semiconductor, it was made of silicon, whereas kilby\\'s chip was made of germanium. noyce\\'s monolithic ic was fabricated using the planar process, developed by his colleague jean hoerni in early 1959. in turn, the planar process was based on mohamed m. atalla\\'s work on semiconductor surface passivation by silicon dioxide in the late 1950s.modern monolithic ics are predominantly mos (metal-oxide-semiconductor) integrated circuits, built from mosfets (mos transistors). the earliest experimental mos ic to be fabricated was a 16-transistor chip built by fred heiman and steven hofstein at rca in 1962. general microelectronics later introduced the first commercial mos ic in 1964, developed by robert norman. following the development of the self-aligned gate (silicon-gate) mos transistor by robert kerwin, donald klein and john sarace at bell labs in 1967, the first silicon-gate mos ic with self-aligned gates was developed by federico faggin at fairchild semiconductor in 1968. the mosfet has since become the most critical device component in modern ics.the development of the mos integrated circuit led to the invention of the microprocessor, and heralded an explosion in the commercial and personal use of computers. while the subject of exactly which device was the first microprocessor is contentious, partly due to lack of agreement on the exact definition of the term \"microprocessor\", it is largely undisputed that the first single-chip microprocessor was the intel 4004, designed and realized by federico faggin with his silicon-gate mos ic technology, along with ted hoff, masatoshi shima and stanley mazor at intel. in the early 1970s, mos ic technology enabled the integration of more than 10,000 transistors on a single chip.system on a chip (socs) are complete computers on a microchip (or chip) the size of a coin. they may or may not have integrated ram and flash memory. if not integrated, the ram is usually placed directly above (known as package on package) or below (on the opposite side of the circuit board) the soc, and the flash memory is usually placed right next to the soc, this all done to improve data transfer speeds, as the data signals don\\'t have to travel long distances. since eniac in 1945, computers have advanced enormously, with modern socs (such as the snapdragon 865) being the size of a coin while also being hundreds of thousands of times more powerful than eniac, integrating billions of transistors, and consuming only a few watts of power.=== mobile computers ===the first mobile computers were heavy and ran from mains power. the 50 lb (23 kg) ibm 5100 was an early example. later portables such as the osborne 1 and compaq portable were considerably lighter but still needed to be plugged in. the first laptops, such as the grid compass, removed this requirement by incorporating batteries – and with the continued miniaturization of computing resources and advancements in portable battery life, portable computers grew in popularity in the 2000s. the same developments allowed manufacturers to integrate computing resources into cellular mobile phones by the early 2000s.these smartphones and tablets run on a variety of operating systems and recently became the dominant computing device on the market. these are powered by system on a chip (socs), which are complete computers on a microchip the size of a coin.', 'the earliest foundations of what would become computer science predate the invention of the modern digital computer. machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment.wilhelm schickard designed and constructed the first working mechanical calculator in 1623. in 1673, gottfried leibniz demonstrated a digital mechanical calculator, called the stepped reckoner. leibniz may be considered the first computer scientist and information theorist, for, among other reasons, documenting the binary number system. in 1820, thomas de colmar launched the mechanical calculator industry when he invented his simplified arithmometer, the first calculating machine strong enough and reliable enough to be used daily in an office environment. charles babbage started the design of the first automatic mechanical calculator, his difference engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his analytical engine. he started developing this machine in 1834, and \"in less than two years, he had sketched out many of the salient features of the modern computer\". \"a crucial step was the adoption of a punched card system derived from the jacquard loom\" making it infinitely programmable. in 1843, during the translation of a french article on the analytical engine, ada lovelace wrote, in one of the many notes she included, an algorithm to compute the bernoulli numbers, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer. around 1885, herman hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of ibm. following babbage, although unaware of his earlier work, percy ludgate in 1909 published the 2nd of the only two designs for mechanical analytical engines in history. in 1937, one hundred years after babbage\\'s impossible dream, howard aiken convinced ibm, which was making all kinds of punched card equipment and was also in the calculator business to develop his giant programmable calculator, the ascc/harvard mark i, based on babbage\\'s analytical engine, which itself used cards and a central computing unit. when the machine was finished, some hailed it as \"babbage\\'s dream come true\".during the 1940s, with the development of new and more powerful computing machines such as the atanasoff–berry computer and eniac, the term computer came to refer to the machines rather than their human predecessors. as it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study computation in general. in 1945, ibm founded the watson scientific computing laboratory at columbia university in new york city. the renovated fraternity house on manhattan\\'s west side was ibm\\'s first laboratory devoted to pure science. the lab is the forerunner of ibm\\'s research division, which today operates research facilities around the world. ultimately, the close relationship between ibm and the university was instrumental in the emergence of a new scientific discipline, with columbia offering one of the first academic-credit courses in computer science in 1946. computer science began to be established as a distinct academic discipline in the 1950s and early 1960s. the world\\'s first computer science degree program, the cambridge diploma in computer science, began at the university of cambridge computer laboratory in 1953. the first computer science department in the united states was formed at purdue university in 1962. since practical computers became available, many applications of computing have become distinct areas of study in their own rights.'], 'subcategorie': ['the discipline of computer architecture has three main subcategories:instruction set architecture (isa): defines the machine code that a processor reads and acts upon as well as the word size, memory address modes, processor registers, and data type.microarchitecture: also known as \"computer organization\", this describes how a particular processor will implement the isa. the size of a computer\\'s cpu cache for instance, is an issue that generally has nothing to do with the isa.systems design: includes all of the other hardware components within a computing system, such as data processing other than the cpu (e.g., direct memory access), virtualization, and multiprocessing.there are other technologies in computer architecture. the following technologies are used in bigger companies like intel, and were estimated in 2002 to count for 1% of all of computer architecture:macroarchitecture: architectural layers more abstract than microarchitectureassembly instruction set architecture: a smart assembler may convert an abstract assembly language common to a group of machines into slightly different machine language for different implementations.programmer-visible macroarchitecture: higher-level language tools such as compilers may define a consistent interface or contract to programmers using them, abstracting differences between underlying isa, uisa, and microarchitectures. for example, the c, c++, or java standards define different programmer-visible macroarchitectures.microcode: microcode is software that translates instructions to run on a chip. it acts like a wrapper around the hardware, presenting a preferred version of the hardware\\'s instruction set interface. this instruction translation facility gives chip designers flexible options: e.g. 1. a new improved version of the chip can use microcode to present the exact same instruction set as the old chip version, so all software targeting that instruction set will run on the new chip without needing changes. e.g. 2. microcode can present a variety of instruction sets for the same underlying chip, allowing it to run a wider variety of software.uisa: user instruction set architecture, refers to one of three subsets of the risc cpu instructions provided by powerpc risc processors. the uisa subset, are those risc instructions of interest to application developers. the other two subsets are vea (virtual environment architecture) instructions used by virtualization system developers, and oea (operating environment architecture) used by operation system developers.pin architecture: the hardware functions that a microprocessor should provide to a hardware platform, e.g., the x86 pins a20m, ferr/ignne or flush. also, messages that the processor should emit so that external caches can be invalidated (emptied). pin architecture functions are more flexible than isa functions because external hardware can adapt to new encodings, or change from a pin to a message. the term \"architecture\" fits, because the functions must be provided for compatible systems, even if the detailed method changes.'], 'role': [\"=== definition ===computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. the case of instruction set architecture can be used to illustrate the balance of these competing factors. more complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 loop instruction). however, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. the increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.the implementation involves integrated circuit design, packaging, power, and cooling. optimization of the design requires familiarity with compilers, operating systems to logic design, and packaging.=== instruction set architecture ===an instruction set architecture (isa) is the interface between the computer's software and hardware and also can be viewed as the programmer's view of the machine. computers do not understand high-level programming languages such as java, c++, or most programming languages used. a processor only understands instructions encoded in some numerical fashion, usually as binary numbers. software tools, such as compilers, translate those high level languages into instructions that the processor can understand.besides instructions, the isa defines items in the computer that are available to a program—e.g., data types, registers, addressing modes, and memory.  instructions locate these available items with register indexes (or names) and memory addressing modes.the isa of a computer is usually described in a small instruction manual, which describes how the instructions are encoded. also, it may define short (vaguely) mnemonic names for the instructions. the names can be recognized by a software development tool called an assembler.  an assembler is a computer program that translates a human-readable form of the isa into a computer-readable form.  disassemblers are also widely available, usually in debuggers and software programs to isolate and correct malfunctions in binary computer programs.isas vary in quality and completeness.  a good isa compromises between programmer convenience (how easy the code is to understand), size of the code (how much code is required to do a specific action), cost of the computer to interpret the instructions (more complexity means more hardware needed to decode and execute the instructions), and speed of the computer (with more complex decoding hardware comes longer decode time).  memory organization defines how instructions interact with the memory, and how memory interacts with itself.during design emulation, emulators can run programs written in a proposed instruction set. modern emulators can measure size, cost, and speed to determine whether a particular isa is meeting its goals.=== computer organization ===computer organization helps optimize performance-based products. for example, software engineers need to know the processing power of processors. they may need to optimize software in order to gain the most performance for the lowest price. this can require quite a detailed analysis of the computer's organization.  for example, in an sd card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.computer organization also helps plan the selection of a processor for a particular project. multimedia projects may need very rapid data access, while virtual machines may need fast interrupts. sometimes certain tasks need additional components as well.  for example, a computer capable of running a virtual machine needs virtual memory hardware so that the memory of different virtual computers can be kept separated. computer organization and features also affect power consumption and processor cost.=== implementation ===once an instruction set and micro-architecture have been designed, a practical machine must be developed. this design process is called the implementation. implementation is usually not considered architectural design, but rather hardware design engineering. implementation can be further broken down into several steps:logic implementation designs the circuits required at a logic-gate level.circuit implementation does transistor-level designs of basic elements (e.g., gates, multiplexers, latches) as well as of some larger blocks (alus, caches etc.) that may be implemented at the logic-gate level, or even at the physical level if the design calls for it.physical implementation draws physical circuits.  the different circuit components are placed in a chip floor plan or on a board and the wires connecting them are created.design validation tests the computer as a whole to see if it works in all situations and all timings. once the design validation process starts, the design at the logic level are tested using logic emulators. however, this is usually too slow to run a realistic test.  so, after making corrections based on the first test, prototypes are constructed using field-programmable gate-arrays (fpgas). most hobby projects stop at this stage.  the final step is to test prototype integrated circuits, which may require several redesigns.for cpus, the entire implementation process is organized differently and is often referred to as cpu design.\"], 'design goal': ['the exact form of a computer system depends on the constraints and goals. computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.the most common scheme does an in-depth power analysis and figures out how to keep power consumption low while maintaining adequate performance.=== performance ===modern computer performance is often described in instructions per cycle (ipc), which measures the efficiency of the architecture at any clock frequency; a faster ipc rate means the computer is faster. older computers had ipc counts as low as 0.1 while modern processors easily reach near 1. superscalar processors may reach three to five ipc by executing several instructions per clock cycle.counting machine-language instructions would be misleading because they can do varying amounts of work in different isas. the \"instruction\" in the standard measurements is not a count of the isa\\'s machine-language instructions, but a unit of measurement, usually based on the speed of the vax computer architecture.many people used to measure a computer\\'s speed by the clock rate (usually in mhz or ghz). this refers to the cycles per second of the main clock of the cpu. however, this metric is somewhat misleading, as a machine with a higher clock rate may not necessarily have greater performance. as a result, manufacturers have moved away from clock speed as a measure of performance.other factors influence speed, such as the mix of functional units, bus speeds, available memory, and the type and order of instructions in the programs.there are two main types of speed: latency and throughput. latency is the time between the start of a process and its completion. throughput is the amount of work done per unit time.  interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).performance is affected by a very wide range of design choices — for example, pipelining a processor usually makes latency worse, but makes throughput better. computers that control machinery usually need low interrupt latencies. these computers operate in a real-time environment and fail if an operation is not completed in a specified amount of time. for example, computer-controlled anti-lock brakes must begin braking within a predictable and limited time period after the brake pedal is sensed or else failure of the brake will occur.benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. although benchmarking shows strengths, it shouldn\\'t be how you choose a computer. often the measured machines split on different measures. for example, one system might handle scientific applications quickly, while another might render video games more smoothly. furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but don\\'t offer similar advantages to general tasks.=== power efficiency ===power efficiency is another important measurement in modern computers. a higher power efficiency can often be traded for lower speed or higher cost. the typical measurement when referring to power consumption in computer architecture is mips/w (millions of instructions per second per watt).modern circuits have less power required per transistor as the number of transistors per chip grows. this is because each transistor that is put in a new chip requires its own power supply and requires new pathways to be built to power it. however the number of transistors per chip is starting to increase at a slower rate. therefore, power efficiency is starting to become as important, if not more important than fitting more and more transistors into a single chip. recent processor designs have shown this emphasis as they put more focus on power efficiency rather than cramming as many transistors into a single chip as possible. in the world of embedded computers, power efficiency has long been an important goal next to throughput and latency.=== shifts in market demand ===increases in clock frequency have grown more slowly over the past few years, compared to power reduction improvements. this has been driven by the end of moore\\'s law and demand for longer battery life and reductions in size for mobile technology. this change in focus from higher clock rates to power consumption and miniaturization can be shown by the significant reductions in power consumption, as much as 50%, that were reported by intel in their release of the haswell microarchitecture; where they dropped their power consumption benchmark from 30 to 40 watts down to 10-20 watts. comparing this to the processing speed increase of 3 ghz to 4 ghz (2002 to 2006) it can be seen that the focus in research and development are shifting away from clock frequency and moving towards consuming less power and taking up less space.'], 'see also': ['', 'integer (computer science)', '', 'super-threadingspeculative multithreading', 'cardboard illustrative aid to computationinterconnect bottlenecklittle man computerrandom-access machineharvard architectureturing machineeckert architecture', '', '', ''], 'reference': ['', '', '=== general ===', '', '', '', '', ''], 'source': ['john l. hennessy and david patterson (2006). computer architecture: a quantitative approach (fourth ed.). morgan kaufmann. isbn 978-0-12-370490-0.barton, robert s., \"functional design of computers\", communications of the acm 4(9): 405 (1961).barton, robert s., \"a new approach to the functional design of a digital computer\", proceedings of the western joint computer conference, may 1961, pp. 393–396. about the design of the burroughs b5000 computer.bell, c. gordon; and newell, allen (1971). \"computer structures: readings and examples\", mcgraw-hill.blaauw, g.a., and brooks, f.p., jr., \"the structure of system/360, part i-outline of the logical structure\", ibm systems journal, vol. 3, no. 2, pp. 119–135, 1964.tanenbaum, andrew s. (1979). structured computer organization. englewood cliffs, new jersey: prentice-hall. isbn 0-13-148521-0.', ''], 'external link': ['isca: proceedings of the international symposium on computer architecturemicro: ieee/acm international symposium on microarchitecturehpca: international symposium on high performance computer architectureasplos: international conference on architectural support for programming languages and operating systemsacm transactions on architecture and code optimizationieee transactions on computersthe von neumann architecture of computer systems', '\"automatic pipelining from transactional datapath specifications\" (pdf). retrieved 23 july 2014.tulsen, dean (18 january 2005). \"pipeline hazards\" (pdf).', 'a survey of processors with explicit multithreading, acm, march 2003, by theo ungerer, borut robi and jurij silcoperating system | difference between multitasking, multithreading and multiprocessing geeksforgeeks, 6 sept. 2018.', 'harvard vs von neumanna tool that emulates the behavior of a von neumann machinejohnny: a simple open source simulator of a von neumann machine for educational purposes', ' media related to computers at wikimedia commons wikiversity has a quiz on this articlewarhol & the computer', 'computer science at curliescholarly societies in computer science archived june 23, 2011, at the wayback machinewhat is computer science?best papers awards in computer science since 1996photographs of computer scientists by bertrand meyereecs.berkeley.edu=== bibliography and academic search engines ===citeseerx (article): search engine, digital library and repository for scientific and academic papers with a focus on computer and information science.dblp computer science bibliography (article): computer science bibliography website hosted at universität trier, in germany.the collection of computer science bibliographies (collection of computer science bibliographies)=== professional organizations ===association for computing machineryieee computer societyinformatics europeaaaiaaas computer science=== misc ===computer science—stack exchange: a community-run question-and-answer site for computer sciencewhat is computer science archived february 18, 2015, at the wayback machineis computer science science?computer science (software) must be considered as an independent discipline.'], 'uses of word': ['depending on how a computer is organized, word-size units may be used for:fixed-point numbersholders for fixed point, usually integer, numerical values may be available in one or in several different sizes, but one of the sizes available will almost always be the word. the other sizes, if any, are likely to be multiples or fractions of the word size. the smaller sizes are normally used only for efficient use of memory; when loaded into the processor, their values usually go into a larger, word sized holder.floating-point numbersholders for floating-point numerical values are typically either a word or a multiple of a word.addressesholders for memory addresses must be of a size capable of expressing the needed range of values but not be excessively large, so often the size used is the word though it can also be a multiple or fraction of the word size.registersprocessor registers are designed with a size appropriate for the type of data they hold, e.g. integers, floating-point numbers, or addresses. many computer architectures use general-purpose registers that are capable of storing data in multiple representations.memory–processor transferwhen the processor reads from the memory subsystem into a register or writes a register\\'s value to memory, the amount of data transferred is often a word. historically, this amount of bits which could be transferred in one cycle was also called a catena in some environments (such as the bull gamma 60). in simple memory subsystems, the word is transferred over the memory data bus, which typically has a width of a word or half-word. in memory subsystems that use caches, the word-sized transfer is the one between the processor and the first level of cache; at lower levels of the memory hierarchy larger transfers (which are a multiple of the word size) are normally used.unit of address resolutionin a given architecture, successive address values designate successive units of memory; this unit is the unit of address resolution. in most computers, the unit is either a character (e.g. a byte) or a word. (a few computers have used bit resolution.) if the unit is a word, then a larger amount of memory can be accessed using an address of a given size at the cost of added complexity to access individual characters. on the other hand, if the unit is a byte, then individual characters can be addressed (i.e. selected during the memory operation).instructionsmachine instructions are normally the size of the architecture\\'s word, such as in risc architectures, or a multiple of the \"char\" size that is a fraction of it. this is a natural choice since instructions and data usually share the same memory subsystem. in harvard architectures the word sizes of instructions and data need not be related, as instructions and data are stored in different memories; for example, the processor in the 1ess electronic telephone switch had 37-bit instructions and 23-bit data words.'], 'word size choice': ['when a computer architecture is designed, the choice of a word size is of substantial importance.  there are design considerations which encourage particular bit-group sizes for particular uses (e.g. for addresses), and these considerations point to different sizes for different uses.  however, considerations of economy in design strongly push for one size, or a very few sizes related by multiples or fractions (submultiples) to a primary size.  that preferred size becomes the word size of the architecture.character size was in the past (pre-variable-sized character encoding) one of the influences on unit of address resolution and the choice of word size.  before the mid-1960s, characters were most often stored in six bits; this allowed no more than 64 characters, so the alphabet was limited to upper case.  since it is efficient in time and space to have the word size be a multiple of the character size, word sizes in this period were usually multiples of 6 bits (in binary machines).  a common choice then was the 36-bit word, which is also a good size for the numeric properties of a floating point format.after the introduction of the ibm system/360 design, which used eight-bit characters and supported lower-case letters, the standard size of a character (or more accurately, a byte) became eight bits.  word sizes thereafter were naturally multiples of eight bits, with 16, 32, and 64 bits being commonly used.=== variable-word architectures ===early machine designs included some that used what is often termed a variable word length.  in this type of organization, an operand had no fixed length. depending on the machine and the instruction, the length might be denoted by a count field, by a delimiting character, or by an additional bit called, e.g., flag, word mark.  such machines often used binary-coded decimal in 4-bit digits, or in 6-bit characters, for numbers.  this class of machines included the ibm 702, ibm 705, ibm 7080, ibm 7010, univac 1050, ibm 1401, ibm 1620, and rca 301.most of these machines work on one unit of memory at a time and since each instruction or datum is several units long, each instruction takes several cycles just to access memory.  these machines are often quite slow because of this.  for example, instruction fetches on an ibm 1620 model i take 8 cycles just to read the 12 digits of the instruction (the model ii reduced this to 6 cycles, or 4 cycles if the instruction did not need both address fields). instruction execution took a completely variable number of cycles, depending on the size of the operands.=== word, bit and byte addressing ===the memory model of an architecture is strongly influenced by the word size.  in particular, the resolution of a memory address, that is, the smallest unit that can be designated by an address, has often been chosen to be the word.  in this approach, the word-addressable machine approach, address values which differ by one designate adjacent memory words.  this is natural in machines which deal almost always in word (or multiple-word) units, and has the advantage of allowing instructions to use minimally sized fields to contain addresses, which can permit a smaller instruction size or a larger variety of instructions.when byte processing is to be a significant part of the workload, it is usually more advantageous to use the byte, rather than the word, as the unit of address resolution. address values which differ by one designate adjacent bytes in memory.  this allows an arbitrary character within a character string to be addressed straightforwardly.  a word can still be addressed, but the address to be used requires a few more bits than the word-resolution alternative.  the word size needs to be an integer multiple of the character size in this organization.  this addressing approach was used in the ibm 360, and has been the most common approach in machines designed since then.when the workload involves processing fields of different sizes, it can be advantageous to address to the bit. machines with bit addressing may have some instructions that use a programmer-defined byte size and other instructions that operate on fixed data sizes. as an example, on the ibm 7030 (\"stretch\"), a floating point instruction can only address words while an integer arithmetic instruction can specify a field length of 1-64 bits, a byte size of 1-8 bits and an accumulator offset of 0-127 bits. in at byte-addressable machine with storage-to-storage (ss) instructions, there are typically move instructions to copy one or multiple bytes from one arbitrary location to another. in a byte-oriented (byte-addressable) machine without ss instructions, moving a single byte from one arbitrary location to another is typically:load the source bytestore the result back in the target byteindividual bytes can be accessed on a word-oriented machine in one of two ways.  bytes can be manipulated by a combination of shift and mask operations in registers. moving a single byte from one arbitrary location to another may require the equivalent of the following:load the word containing the source byteshift the source word to align the desired byte to the correct position in the target wordand the source word with a mask to zero out all but the desired bitsload the word containing the target byteand the target word with a mask to zero out the target byteor the registers containing the source and target words to insert the source bytestore the result back in the target locationalternatively many word-oriented machines implement byte operations with instructions using special byte pointers in registers or memory.  for example, the pdp-10 byte pointer contained the size of the byte in bits (allowing different-sized bytes to be accessed), the bit position of the byte within the word, and the word address of the data.  instructions could automatically adjust the pointer to the next byte on, for example, load and deposit (store) operations.=== powers of two ===different amounts of memory are used to store data values with different degrees of precision. the commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word).  converting the index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. in some cases this relationship can also avoid the use of division operations. as a result, most modern computer designs have word sizes (and other operand sizes) that are a power of two times the size of a byte.'], 'size familie': ['as computer designs have grown more complex, the central importance of a single word size to an architecture has decreased.  although more capable hardware can use a wider variety of sizes of data, market forces exert pressure to maintain backward compatibility while extending processor capability.  as a result, what might have been the central word size in a fresh design has to coexist as an alternative size to the original word size in a backward compatible design. the original word size remains available in future designs, forming the basis of a size family.in the mid-1970s, dec designed the vax to be a 32-bit successor of the 16-bit pdp-11. they used word for a 16-bit quantity, while longword referred to a 32-bit quantity; this terminology is the same as the terminology used for the pdp-11. this was in contrast to earlier machines, where the natural unit of addressing memory would be called a word, while a quantity that is one half a word would be called a halfword. in fitting with this scheme, a vax quadword is 64 bits.  they continued this 16-bit word/32-bit longword/64-bit quadword terminology with the 64-bit alpha.another example is the x86 family, of which processors of three different word lengths (16-bit, later 32- and 64-bit) have been released, while word continues to designate a 16-bit quantity. as software is routinely ported from one word-length to the next, some apis and documentation define or refer to an older (and thus shorter) word-length than the full word length on the cpu that software may be compiled for. also, similar to how bytes are used for small numbers in many programs, a shorter word (16 or 32 bits) may be used in contexts where the range of a wider word is not needed (especially where this can save considerable stack space or cache memory space). for example, microsoft\\'s windows api maintains the programming language definition of word as 16 bits, despite the fact that the api may be used on a 32- or 64-bit x86 processor, where the standard word size would be 32 or 64 bits, respectively. data structures containing such different sized words refer to them as:word (16 bits/2 bytes)dword (32 bits/4 bytes)qword (64 bits/8 bytes)a similar phenomenon has developed in intel\\'s x86 assembly language – because of the support for various sizes (and backward compatibility) in the instruction set, some instruction mnemonics carry \"d\" or \"q\" identifiers denoting \"double-\", \"quad-\" or \"double-quad-\", which are in terms of the architecture\\'s original 16-bit word size.an example with a different word size is the ibm system/360 family. in the system/360 architecture, system/370 architecture and system/390 architecture, there are 8-bit bytes, 16-bit halfwords, 32-bit words and 64-bit doublewords. the z/architecture, which is the 64-bit member of that architecture family, continues to refer to 16-bit halfwords, 32-bit words, and 64-bit doublewords, and additionally features 128-bit quadwords.in general, new processors must use the same data word lengths and virtual address widths as an older processor to have binary compatibility with that older processor.often carefully written source code – written with source-code compatibility and software portability in mind – can be recompiled to run on a variety of processors, even ones with different data word lengths or different address widths or both.'], 'table of word size': [''], 'note': ['', '', ''], 'background': ['instructions in a pipelined processor are performed in several stages, so that at any given time several instructions are being processed in the various stages of the pipeline, such as fetch and execute. there are many different instruction pipeline microarchitectures, and instructions may be executed out-of-order. a hazard occurs when two or more of these simultaneous (possibly out of order) instructions conflict.'], 'type': ['=== data hazards ===data hazards occur when instructions that exhibit data dependence modify data in different stages of a pipeline. ignoring potential data hazards can result in race conditions (also termed race hazards). there are three situations in which a data hazard can occur:read after write (raw), a true dependencywrite after read (war), an anti-dependencywrite after write (waw), an output dependencyread after read (rar) is not a hazard case.consider two instructions i1 and i2, with i1 occurring before i2 in program order.==== read after write (raw) ====(i2 tries to read a source before i1 writes to it)a read after write (raw) data hazard refers to a situation where an instruction refers to a result that has not yet been calculated or retrieved. this can occur because even though an instruction is executed after a prior instruction, the prior instruction has been processed only partly through the pipeline.===== example =====for example:i1. r2 <- r5 + r3i2. r4 <- r2 + r3the first instruction is calculating a value to be saved in register r2, and the second is going to use this value to compute a result for register r4. however, in a pipeline, when operands are fetched for the 2nd operation, the results from the first have not yet been saved, and hence a data dependency occurs.a data dependency occurs with instruction i2, as it is dependent on the completion of instruction i1.==== write after read (war) ====(i2 tries to write a destination before it is read by i1)a write after read (war) data hazard represents a problem with concurrent execution.===== example =====for example:i1. r4 <- r1 + r5i2. r5 <- r1 + r2in any situation with a chance that i2 may finish before i1 (i.e., with concurrent execution), it must be ensured that the result of register r5 is not stored before i1 has had a chance to fetch the operands.==== write after write (waw) ====(i2 tries to write an operand before it is written by i1)a write after write (waw) data hazard may occur in a concurrent execution environment.===== example =====for example:i1. r2 <- r4 + r7i2. r2 <- r1 + r3the write back (wb) of i2 must be delayed until i1 finishes executing.=== structural hazards ===a structural hazard occurs when two (or more) instructions that are already in pipeline need the same resource. the result is that instruction must be executed in series rather than parallel for a portion of pipeline. structural hazards are sometime referred to as resource hazards.example:a situation in which multiple instructions are ready to enter the execute instruction phase and there is a single alu (arithmetic logic unit). one solution to such resource hazard is to increase available resources, such as having multiple ports into main memory and multiple alu (arithmetic logic unit) units.=== control hazards (branch hazards or instruction hazards) ===control hazard occurs when the pipeline makes wrong decisions on branch prediction and therefore brings instructions into the pipeline that must subsequently be discarded. the term branch hazard also refers to a control hazard.', 'computers can be classified in a number of different ways, including:=== by architecture ===analog computerdigital computerhybrid computerharvard architecturevon neumann architecturecomplex instruction set computerreduced instruction set computer=== by size, form-factor and purpose ===supercomputermainframe computerminicomputer (term no longer used)serverrackmount serverblade servertower serverpersonal computerworkstationmicrocomputer (term no longer used)home computerdesktop computertower desktopslimline desktopmultimedia computer (non-linear editing system computers, video editing pcs and the like)gaming computerall-in-one pcnettop (small form factor pcs, mini pcs)home theater pckeyboard computerportable computerthin clientinternet appliancelaptopdesktop replacement computergaming laptoprugged laptop2-in-1 pcultrabookchromebooksubnotebooknetbookmobile computers:tablet computersmartphoneultra-mobile pcpocket pcpalmtop pchandheld pcwearable computersmartwatchsmartglassessingle-board computerplug computerstick pcprogrammable logic controllercomputer-on-modulesystem on modulesystem in a packagesystem-on-chip (also known as an application processor or ap if it lacks circuitry such as radio circuitry)microcontroller'], 'eliminating hazard': ['=== generic ======= pipeline bubbling ====bubbling the pipeline, also termed a pipeline break or pipeline stall, is a method to preclude data, structural, and branch hazards. as instructions are fetched, control logic determines whether a hazard could/will occur. if this is true, then the control logic inserts no operations (nops) into the pipeline. thus, before the next instruction (which would cause the hazard) executes, the prior one will have had sufficient time to finish and prevent the hazard. if the number of nops equals the number of stages in the pipeline, the processor has been cleared of all instructions and can proceed free from hazards. all forms of stalling introduce a delay before the processor can resume execution.flushing the pipeline occurs when a branch instruction jumps to a new memory location, invalidating all prior stages in the pipeline.  these prior stages are cleared, allowing the pipeline to continue at the new instruction indicated by the branch.=== data hazards ===there are several main solutions and algorithms used to resolve data hazards:insert a pipeline bubble whenever a read after write (raw) dependency is encountered, guaranteed to increase latency, oruse out-of-order execution to potentially prevent the need for pipeline bubblesuse operand forwarding to use data from later stages in the pipelinein the case of out-of-order execution, the algorithm used can be:scoreboarding, in which case a pipeline bubble is needed only when there is no functional unit availablethe tomasulo algorithm, which uses register renaming, allowing continual issuing of instructionsthe task of removing data dependencies can be delegated to the compiler, which can fill in an appropriate number of nop instructions between dependent instructions to ensure correct operation, or re-order instructions where possible.==== operand forwarding ======== examples ====in the following examples, computed values are in bold, while register numbers are not.for example, to write the value 3 to register 1, (which already contains a 6), and then add 7 to register 1 and store the result in register 2, i.e.:i0: r1 = 6i1: r1 = 3i2: r2 = r1 + 7 = 10following execution, register 2 should contain the value 10. however, if i1 (write 3 to register 1) does not fully exit the pipeline before i2 starts executing, it means that r1 does not contain the value 3 when i2 performs its addition. in such an event, i2 adds 7 to the old value of register 1 (6), and so register 2 contains 13 instead, i.e.:i0: r1 = 6i2: r2 = r1 + 7 = 13i1: r1 = 3this error occurs because i2 reads register 1 before i1 has committed/stored the result of its write operation to register 1. so when i2 is reading the contents of register 1, register 1 still contains 6, not 3.forwarding (described below) helps correct such errors by depending on the fact that the output of i1 (which is 3) can be used by subsequent instructions before the value 3 is committed to/stored in register 1.forwarding applied to the example means that there is no wait to commit/store the output of i1 in register 1 (in this example, the output is 3) before making that output available to the subsequent instruction (in this case, i2). the effect is that i2 uses the correct (the more recent) value of register 1: the commit/store was made immediately and not pipelined.with forwarding enabled, the instruction decode/execution (id/ex) stage of the pipeline now has two inputs: the value read from the register specified (in this example, the value 6 from register 1), and the new value of register 1 (in this example, this value is 3) which is sent from the next stage instruction execute/memory access (ex/mem). added control logic is used to determine which input to use.=== control hazards (branch hazards) ===to avoid control hazards microarchitectures can:insert a pipeline bubble (discussed above), guaranteed to increase latency, oruse branch prediction and essentially make educated guesses about which instructions to insert, in which case a pipeline bubble will only be needed in the case of an incorrect predictionin the event that a branch causes a pipeline bubble after incorrect instructions have entered the pipeline, care must be taken to prevent any of the wrongly-loaded instructions from having any effect on the processor state excluding energy wasted processing them before they were discovered to be loaded incorrectly.=== other techniques ===memory latency is another factor that designers must attend to, because the delay could reduce performance. different types of memory have different accessing time to the memory. thus, by choosing a suitable type of memory, designers can improve the performance of the pipelined data path.'], 'overview': [\"the multithreading paradigm has become more popular as efforts to further exploit instruction-level parallelism have stalled since the late 1990s. this allowed the concept of throughput computing to re-emerge from the more specialized field of transaction processing. even though it is very difficult to further speed up a single thread or single program, most computer systems are actually multitasking among multiple threads or programs. thus, techniques that improve the throughput of all tasks result in overall performance gains.two major techniques for throughput computing are multithreading and multiprocessing.=== advantages ===if a thread gets a lot of cache misses, the other threads can continue taking advantage of the unused computing resources, which may lead to faster overall execution, as these resources would have been idle if only a single thread were executed. also, if a thread cannot use all the computing resources of the cpu (because instructions depend on each other's result), running another thread may prevent those resources from becoming idle.=== disadvantages ===multiple threads can interfere with each other when sharing hardware resources such as caches or translation lookaside buffers (tlbs). as a result, execution times of a single thread are not improved and can be degraded, even when only one thread is executing, due to lower frequencies or additional pipeline stages that are necessary to accommodate thread-switching hardware.overall efficiency varies; intel claims up to 30% improvement with its hyper-threading technology, while a synthetic program just performing a loop of non-optimized dependent floating-point operations actually gains a 100% speed improvement when run in parallel. on the other hand, hand-tuned assembly language programs using mmx or altivec extensions and performing data prefetches (as a good video encoder might) do not suffer from cache misses or idle computing resources. such programs therefore do not benefit from hardware multithreading and can indeed see degraded performance due to contention for shared resources.from the software standpoint, hardware support for multithreading is more visible to software, requiring more changes to both application programs and operating systems than multiprocessing. hardware techniques used to support multithreading often parallel the software techniques used for computer multitasking. thread scheduling is also a major problem in multithreading.\", \"most computer programs contain conditional code, which will be executed only under specific conditions depending on factors that cannot be determined beforehand, for example depending on user input. as the majority of processors simply execute the next instruction in a sequence, the traditional solution is to insert branch instructions that allow a program to conditionally branch to a different section of code, thus changing the next step in the sequence. this was sufficient until designers began improving performance by implementing instruction pipelining, a method which is slowed down by branches. for a more thorough description of the problems which arose, and a popular solution, see branch predictor.luckily, one of the more common patterns of code that normally relies on branching has a more elegant solution. consider the following pseudocode:on a system that uses conditional branching, this might translate to machine instructions looking similar to:with predication, all possible branch paths are coded inline, but some instructions execute while others do not. the basic idea is that each instruction is associated with a predicate (the word here used similarly to its usage in predicate logic) and that the instruction will only be executed if the predicate is true. the machine code for the above example using predication might look something like this:besides eliminating branches, less code is needed in total, provided the architecture provides predicated instructions. while this does not guarantee faster execution in general, it will if the dosomething and dosomethingelse blocks of code are short enough.predication's simplest form is partial predication, where the architecture has conditional move or conditional select instructions. conditional move instructions write the contents of one register over another only if the predicate's value is true, whereas conditional select instructions choose which of two registers has its contents written to a third based on the predicate's value. a more generalized and capable form is full predication. full predication has a set of predicate registers for storing predicates (which allows multiple nested or sequential branches to be simultaneously eliminated) and most instructions in the architecture have a register specifier field to specify which predicate register supplies the predicate.\"], 'types of multithreading': ['=== interleaved/temporal multithreading ======= coarse-grained multithreading ====the simplest type of multithreading occurs when one thread runs until it is blocked by an event that normally would create a long-latency stall. such a stall might be a cache miss that has to access off-chip memory, which might take hundreds of cpu cycles for the data to return. instead of waiting for the stall to resolve, a threaded processor would switch execution to another thread that was ready to run. only when the data for the previous thread had arrived, would the previous thread be placed back on the list of ready-to-run threads.for example:cycle i: instruction j from thread a is issued.cycle i + 1: instruction j + 1 from thread a is issued.cycle i + 2: instruction j + 2 from thread a is issued, which is a load instruction that misses in all caches.cycle i + 3: thread scheduler invoked, switches to thread b.cycle i + 4: instruction k from thread b is issued.cycle i + 5: instruction k + 1 from thread b is issued.conceptually, it is similar to cooperative multi-tasking used in real-time operating systems, in which tasks voluntarily give up execution time when they need to wait upon some type of the event. this type of multithreading is known as block, cooperative or coarse-grained multithreading.the goal of multithreading hardware support is to allow quick switching between a blocked thread and another thread ready to run. switching from one thread to another means the hardware switches from using one register set to another. to achieve this goal, the hardware for the program visible registers, as well as some processor control registers (such as the program counter), is replicated. for example, to quickly switch between two threads, the processor is built with two sets of registers.additional hardware support for multithreading allows thread switching to be done in one cpu cycle, bringing performance improvements. also, additional hardware allows each thread to behave as if it were executing alone and not sharing any hardware resources with other threads, minimizing the amount of software changes needed within the application and the operating system to support multithreading.many families of microcontrollers and embedded processors have multiple register banks to allow quick context switching for interrupts. such schemes can be considered a type of block multithreading among the user program thread and the interrupt threads.==== interleaved multithreading ====the purpose of interleaved multithreading is to remove all data dependency stalls from the execution pipeline. since one thread is relatively independent from other threads, there is less chance of one instruction in one pipelining stage needing an output from an older instruction in the pipeline. conceptually, it is similar to preemptive multitasking used in operating systems; an analogy would be that the time slice given to each active thread is one cpu cycle.for example:cycle i + 1: an instruction from thread b is issued.cycle i + 2: an instruction from thread c is issued.this type of multithreading was first called barrel processing, in which the staves of a barrel represent the pipeline stages and their executing threads. interleaved, preemptive, fine-grained or time-sliced multithreading are more modern terminology.in addition to the hardware costs discussed in the block type of multithreading, interleaved multithreading has an additional cost of each pipeline stage tracking the thread id of the instruction it is processing. also, since there are more threads being executed concurrently in the pipeline, shared resources such as caches and tlbs need to be larger to avoid thrashing between the different threads.=== simultaneous multithreading ===the most advanced type of multithreading applies to superscalar processors. whereas a normal superscalar processor issues multiple instructions from a single thread every cpu cycle, in simultaneous multithreading (smt) a superscalar processor can issue instructions from multiple threads every cpu cycle. recognizing that any single thread has a limited amount of instruction-level parallelism, this type of multithreading tries to exploit parallelism available across multiple threads to decrease the waste associated with unused issue slots.for example:cycle i: instructions j and j + 1 from thread a and instruction k from thread b are simultaneously issued.cycle i + 1: instruction j + 2 from thread a, instruction k + 1 from thread b, and instruction m from thread c are all simultaneously issued.cycle i + 2: instruction j + 3 from thread a and instructions m + 1 and m + 2 from thread c are all simultaneously issued.to distinguish the other types of multithreading from smt, the term \"temporal multithreading\" is used to denote when instructions from only one thread can be issued at a time.in addition to the hardware costs discussed for interleaved multithreading, smt has the additional cost of each pipeline stage tracking the thread id of each instruction being processed. again, shared resources such as caches and tlbs have to be sized for the large number of active threads being processed.implementations include dec (later compaq) ev8 (not completed), intel hyper-threading technology, ibm power5/power6/power7/power8/power9, ibm z13/z14/z15, sun microsystems ultrasparc t2, cray xmt, and amd bulldozer and zen microarchitectures.'], 'implementation specific': ['a major area of research is the thread scheduler that must quickly choose from among the list of ready-to-run threads to execute next, as well as maintain the ready-to-run and stalled thread lists. an important subtopic is the different thread priority schemes that can be used by the scheduler. the thread scheduler might be implemented totally in software, totally in hardware, or as a hardware/software combination.another area of research is what type of events should cause a thread switch: cache misses, inter-thread communication, dma completion, etc.if the multithreading scheme replicates all of the software-visible state, including privileged control registers and tlbs, then it enables virtual machines to be created for each thread. this allows each thread to run its own operating system on the same processor. on the other hand, if only user-mode state is saved, then less hardware is required, which would allow more threads to be active at one time for the same die area or cost.'], 'capabilitie': ['on a large scale, the ability to treat instructions as data is what makes assemblers, compilers, linkers, loaders, and other automated programming tools possible. it makes \"programs that write programs\" possible.  this has made a sophisticated self-hosting computing ecosystem flourish around von neumann architecture machines.some high level languages leverage the von neumann architecture by providing an abstract, machine-independent way to manipulate executable code at runtime (e.g., lisp), or by using runtime information to tune just-in-time compilation (e.g. languages hosted on the java virtual machine, or languages embedded in web browsers).on a smaller scale, some repetitive operations such as bitblt or pixel and vertex shaders can be accelerated on general purpose processors with just-in-time compilation techniques. this is one use of self-modifying code that has remained popular.== development of the stored-program concept ==the mathematician alan turing, who had been alerted to a problem of mathematical logic by the lectures of max newman at the university of cambridge, wrote a paper in 1936 entitled on computable numbers, with an application to the entscheidungsproblem, which was published in the proceedings of the london mathematical society. in it he described a hypothetical machine he called a universal computing machine, now known as the \"universal turing machine\". the hypothetical machine had an infinite store (memory in today\\'s terminology) that contained both instructions and data. john von neumann became acquainted with turing while he was a visiting professor at cambridge in 1935, and also during turing\\'s phd year at the institute for advanced study in princeton, new jersey during 1936–1937. whether he knew of turing\\'s paper of 1936 at that time is not clear.in 1936, konrad zuse also anticipated, in two patent applications, that machine instructions could be stored in the same storage used for data.independently, j. presper eckert and john mauchly, who were developing the eniac at the moore school of electrical engineering of the university of pennsylvania, wrote about the stored-program concept in december 1943. in planning a new machine, edvac, eckert wrote in january 1944 that they would store data and programs in a new addressable memory device, a mercury metal delay-line memory. this was the first time the construction of a practical stored-program machine was proposed.  at that time, he and mauchly were not aware of turing\\'s work.von neumann was involved in the manhattan project at the los alamos national laboratory. it required huge amounts of calculation, and thus drew him to the eniac project, during the summer of 1944. there he joined the ongoing discussions on the design of this stored-program computer, the edvac. as part of that group, he wrote up a description titled first draft of a report on the edvac based on the work of eckert and mauchly. it was unfinished when his colleague herman goldstine circulated it, and bore only von neumann\\'s name (to the consternation of eckert and mauchly). the paper was read by dozens of von neumann\\'s colleagues in america and europe, and influenced the next round of computer designs.jack copeland considers that it is \"historically inappropriate to refer to electronic stored-program digital computers as \\'von neumann machines\\'\". his los alamos colleague stan frankel said of von neumann\\'s regard for turing\\'s ideasi know that in or about 1943 or \\'44 von neumann was well aware of the fundamental importance of turing\\'s paper of 1936….von neumann introduced me to that paper and at his urging i studied it with care. many people have acclaimed von neumann as the \"father of the computer\" (in a modern sense of the term) but i am sure that he would never have made that mistake himself. he might well be called the midwife, perhaps, but he firmly emphasized to me, and to others i am sure, that the fundamental conception is owing to turing— in so far as not anticipated by babbage…. both turing and von neumann, of course, also made substantial contributions to the \"reduction to practice\" of these concepts but i would not regard these as comparable in importance with the introduction and explication of the concept of a computer able to store in its memory its program of activities and of modifying that program in the course of these activities.at the time that the \"first draft\" report was circulated, turing was producing a report entitled proposed electronic calculator. it described in engineering and programming detail, his idea of a machine he called the automatic computing engine (ace). he presented this to the executive committee of the british national physical laboratory on february 19, 1946. although turing knew from his wartime experience at bletchley park that what he proposed was feasible, the secrecy surrounding colossus, that was subsequently maintained for several decades, prevented him from saying so. various successful implementations of the ace design were produced.both von neumann\\'s and turing\\'s papers described stored-program computers, but von neumann\\'s earlier paper achieved greater circulation and the computer architecture it outlined became known as the \"von neumann architecture\". in the 1953 publication faster than thought: a symposium on digital computing machines (edited by b. v. bowden), a section in the chapter on computers in america reads as follows:the machine of the institute for advanced studies, princetonin 1945, professor j. von neumann, who was then working at the moore school of engineering in philadelphia, where the e.n.i.a.c. had been built, issued on behalf of a group of his co-workers, a report on the logical design of digital computers. the report contained a detailed proposal for the design of the machine that has since become known as the e.d.v.a.c. (electronic discrete variable automatic computer). this machine has only recently been completed in america, but the von neumann report inspired the construction of the e.d.s.a.c. (electronic delay-storage automatic calculator) in cambridge (see page 130).in 1947, burks, goldstine and von neumann published another report that outlined the design of another type of machine (a parallel machine this time) that would be exceedingly fast, capable perhaps of 20,000 operations per second. they pointed out that the outstanding problem in constructing such a machine was the development of suitable memory with instantaneously accessible contents. at first they suggested using a special vacuum tube—called the \"selectron\"—which the princeton laboratories of rca had invented. these tubes were expensive and difficult to make, so von neumann subsequently decided to build a machine based on the williams memory. this machine—completed in june, 1952 in princeton—has become popularly known as the maniac. the design of this machine inspired at least half a dozen machines now being built in america, all known affectionately as \"johniacs\".in the same book, the first two paragraphs of a chapter on ace read as follows:automatic computation at the national physical laboratoryone of the most modern digital computers which embodies developments and improvements in the technique of automatic electronic computing was recently demonstrated at the national physical laboratory, teddington, where it has been designed and built by a small team of mathematicians and electronics research engineers on the staff of the laboratory, assisted by a number of production engineers from the english electric company, limited. the equipment so far erected at the laboratory is only the pilot model of a much larger installation which will be known as the automatic computing engine, but although comparatively small in bulk and containing only about 800 thermionic valves, as can be judged from plates xii, xiii and xiv, it is an extremely rapid and versatile calculating machine.the basic concepts and abstract principles of computation by a machine were formulated by dr. a. m. turing, f.r.s., in a paper1. read before the london mathematical society in 1936, but work on such machines in britain was delayed by the war. in 1945, however, an examination of the problems was made at the national physical laboratory by mr. j. r. womersley, then superintendent of the mathematics division of the laboratory. he was joined by dr. turing and a small staff of specialists, and, by 1947, the preliminary planning was sufficiently advanced to warrant the establishment of the special group already mentioned. in april, 1948, the latter became the electronics section of the laboratory, under the charge of mr. f. m. colebrook.== early von neumann-architecture computers ==the first draft described a design that was used by many universities and corporations to construct their computers. among these various computers, only illiac and ordvac had compatible instruction sets.arc2 (birkbeck, university of london) officially came online on may 12, 1948.manchester baby (victoria university of manchester, england) made its first successful run of a stored program on june 21, 1948.edsac (university of cambridge, england) was the first practical stored-program electronic computer (may 1949)manchester mark 1 (university of manchester, england) developed from the baby (june 1949)csirac (council for scientific and industrial research) australia (november 1949)mesm in kyiv, ukraine (november 1950)edvac (ballistic research laboratory, computing laboratory at aberdeen proving ground 1951)ordvac (u-illinois) at aberdeen proving ground, maryland (completed november 1951)ias machine at princeton university (january 1952)maniac i at los alamos scientific laboratory (march 1952)illiac at the university of illinois, (september 1952)besm-1 in moscow (1952)avidac at argonne national laboratory (1953)oracle at oak ridge national laboratory (june 1953)besk in stockholm (1953)johnniac at rand corporation (january 1954)dask in denmark (1955)weizac at the weizmann institute of science in rehovot, israel (1955)perm in munich (1956)silliac in sydney (1956)== early stored-program computers ==the date information in the following chronology is difficult to put into proper order. some dates are for first running a test program, some dates are the first time the computer was demonstrated or completed, and some dates are for the first delivery or installation.the ibm ssec had the ability to treat instructions as data, and was publicly demonstrated on january 27, 1948. this ability was claimed in a us patent. however it was partially electromechanical, not fully electronic. in practice, instructions were read from paper tape due to its limited memory.the arc2 developed by andrew booth and kathleen booth at birkbeck, university of london officially came online on may 12, 1948. it featured the first rotating drum storage device.the manchester baby was the first fully electronic computer to run a stored program. it ran a factoring program for 52 minutes on june 21, 1948, after running a simple division program and a program to show that two numbers were relatively prime.the eniac was modified to run as a primitive read-only stored-program computer (using the function tables for program rom) and was demonstrated as such on september 16, 1948, running a program by adele goldstine for von neumann.the binac ran some test programs in february, march, and april 1949, although was not completed until september 1949.the manchester mark 1 developed from the baby project.  an intermediate version of the mark 1 was available to run programs in april 1949, but was not completed until october 1949.the edsac ran its first program on may 6, 1949.the edvac was delivered in august 1949, but it had problems that kept it from being put into regular operation until 1951.the csir mk i ran its first program in november 1949.the seac was demonstrated in april 1950.the pilot ace ran its first program on may 10, 1950, and was demonstrated in december 1950.the swac was completed in july 1950.the whirlwind was completed in december 1950 and was in actual use in april 1951.the first era atlas (later the commercial era 1101/univac 1101) was installed in december 1950.'], 'evolution': ['through the decades of the 1960s and 1970s computers generally became both smaller and faster, which led to evolutions in their architecture. for example, memory-mapped i/o lets input and output devices be treated the same as memory. a single system bus could be used to provide a modular system with lower cost. this is sometimes called a \"streamlining\" of the architecture.in subsequent decades, simple microcontrollers would sometimes omit features of the model to lower cost and size.larger computers added features for higher performance.'], 'design limitation': ['=== von neumann bottleneck ===the shared bus between the program memory and data memory leads to the von neumann bottleneck, the limited throughput (data transfer rate) between the central processing unit (cpu) and memory compared to the amount of memory.  because the single bus can only access one of the two classes of memory at a time, throughput is lower than the rate at which the cpu can work.  this seriously limits the effective processing speed when the cpu is required to perform minimal processing on large amounts of data.  the cpu is continually forced to wait for needed data to move to or from memory.  since cpu speed and memory size have increased much faster than the throughput between them, the bottleneck has become more of a problem, a problem whose severity increases with every new generation of cpu.the von neumann bottleneck was described by john backus in his 1977 acm turing award lecture.  according to backus:surely there must be a less primitive way of making big changes in the store than by pushing vast numbers of words back and forth through the von neumann bottleneck. not only is this tube a literal bottleneck for the data traffic of a problem, but, more importantly, it is an intellectual bottleneck that has kept us tied to word-at-a-time thinking instead of encouraging us to think in terms of the larger conceptual units of the task at hand. thus programming is basically planning and detailing the enormous traffic of words through the von neumann bottleneck, and much of that traffic concerns not significant data itself, but where to find it.==== mitigations ====there are several known methods for mitigating the von neumann performance bottleneck.  for example, the following all can improve performance:providing a cache between the cpu and the main memoryproviding separate caches or separate access paths for data and instructions (the so-called modified harvard architecture)using branch predictor algorithms and logicproviding a limited cpu stack or other on-chip scratchpad memory to reduce memory accessimplementing the cpu and the memory hierarchy as a system on chip, providing greater locality of reference and thus reducing latency and increasing throughput between processor registers and main memorythe problem can also be sidestepped somewhat by using parallel computing, using for example the non-uniform memory access (numa) architecture—this approach is commonly employed by supercomputers. it is less clear whether the intellectual bottleneck that backus criticized has changed much since 1977. backus\\'s proposed solution has not had a major influence. modern functional programming and object-oriented programming are much less geared towards \"pushing vast numbers of words back and forth\" than earlier languages like fortran were, but internally, that is still what computers spend much of their time doing, even highly parallel supercomputers.as of 1996, a database benchmark study found that three out of four cpu cycles were spent waiting for memory. researchers expect that increasing the number of simultaneous instruction streams with multithreading or single-chip multiprocessing will make this bottleneck even worse.  in the context of multi-core processors, additional overhead is required to maintain cache coherence between processors and threads.=== self-modifying code ===aside from the von neumann bottleneck, program modifications can be quite harmful, either by accident or design.  in some simple stored-program computer designs, a malfunctioning program can damage itself, other programs, or the operating system, possibly leading to a computer crash. memory protection and other forms of access control can usually protect against both accidental and malicious program changes.'], 'further reading': ['', 'clements, alan (2013). \"8.3.7 predication\". computer organization & architecture: themes and variations. cengage learning. pp. 532–9. isbn 1-285-41542-6.', ''], 'advantage': ['the main purpose of predication is to avoid jumps over very small sections of program code, increasing the effectiveness of pipelined execution and avoiding problems with the cache. it also has a number of more subtle benefits:functions that are traditionally computed using simple arithmetic and bitwise operations may be quicker to compute using predicated instructions.predicated instructions with different predicates can be mixed with each other and with unconditional code, allowing better instruction scheduling and so even better performance.elimination of unnecessary branch instructions can make the execution of necessary branches, such as those that make up loops, faster by lessening the load on branch prediction mechanisms.elimination of the cost of a branch misprediction which can be high on deeply pipelined architectures.instruction sets that have comprehensive condition codes generated by instructions may reduce code size further by directly using the condition registers in or as predication.'], 'disadvantage': [\"predication's primary drawback is in increased encoding space. in typical implementations, every instruction reserves a bitfield for the predicate specifying under what conditions that instruction should have an effect. when available memory is limited, as on embedded devices, this space cost can be prohibitive. however, some architectures such as thumb-2 are able to avoid this issue (see below). other detriments are the following:predication complicates the hardware by adding levels of logic to critical paths and potentially degrades clock speed.a predicated block includes cycles for all operations, so shorter paths may take longer and be penalized.predication is not usually speculated and causes a longer dependency chain. for ordered data this translates to a performance loss compared to a predictable branch.predication is most effective when paths are balanced or when the longest path is the most frequently executed, but determining such a path is very difficult at compile time, even in the presence of profiling information.\"], 'etymology': ['according to the oxford english dictionary, the first known use of computer was in a 1613 book called the yong mans gleanings by the english writer richard brathwait: \"i haue  [sic] read the truest computer of times, and the best arithmetician that euer [sic] breathed, and he reduceth thy dayes into a short number.\" this usage of the term referred to a human computer, a person who carried out calculations or computations. the word continued with the same meaning until the middle of the 20th century. during the latter part of this period women were often hired as computers because they could be paid less than their male counterparts. by 1943, most human computers were women.the online etymology dictionary gives the first attested use of computer in the 1640s, meaning \\'one who calculates\\'; this is an \"agent noun from compute (v.)\". the online etymology dictionary states that the use of the term to mean \"\\'calculating machine\\' (of any type) is from 1897.\"  the online etymology dictionary indicates that the \"modern use\" of the term, to mean \\'programmable digital electronic computer\\' dates from \"1945 under this name; [in a] theoretical [sense] from 1937, as turing machine\".', 'although first proposed in 1956, the term \"computer science\" appears in a 1959 article in communications of the acm,in which louis fein argues for the creation of a graduate school in computer sciences analogous to the creation of harvard business school in 1921, justifying the name by arguing that, like management science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline.his efforts, and those of others such as numerical analyst george forsythe, were rewarded: universities went on to create such departments, starting with purdue in 1962. despite its name, a significant amount of computer science does not involve the study of computers themselves. because of this, several alternative names have been proposed. certain departments of major universities prefer the term computing science, to emphasize precisely that difference. danish scientist peter naur suggested the term datalogy, to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. the first scientific institution to use the term was the department of datalogy at the university of copenhagen, founded in 1969, with peter naur being the first professor in datalogy. the term is used mainly in the scandinavian countries. an alternative term, also proposed by naur, is data science; this is now used for a multi-disciplinary field of data analysis, including statistics and databases.in the early days of computing, a number of terms for the practitioners of the field of computing were suggested in the communications of the acm—turingineer, turologist, flow-charts-man, applied meta-mathematician, and applied epistemologist. three months later in the same journal, comptologist was suggested, followed next year by hypologist. the term computics has also been suggested. in europe, terms derived from contracted translations of the expression \"automatic information\" (e.g. \"informazione automatica\" in italian) or \"information and mathematics\" are often used, e.g. informatique (french), informatik (german), informatica (italian, dutch), informática (spanish, portuguese), informatika (slavic languages and hungarian) or pliroforiki (πληροφορική, which means informatics) in greek. similar words have also been adopted in the uk (as in the school of informatics, university of edinburgh). \"in the u.s., however, informatics is linked with applied computing, or computing in the context of another domain.\"a folkloric quotation, often attributed to—but almost certainly not first formulated by—edsger dijkstra, states that \"computer science is no more about computers than astronomy is about telescopes.\" the design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. for example, the study of computer hardware is usually considered part of computer engineering, while the study of commercial computer systems and their deployment is often called information technology or information systems. however, there has been much cross-fertilization of ideas between the various computer-related disciplines. computer science research also often intersects other disciplines, such as cognitive science, linguistics, mathematics, physics, biology, earth science, statistics, philosophy, and logic.computer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science. early computer science was strongly influenced by the work of mathematicians such as kurt gödel, alan turing, john von neumann, rózsa péter and alonzo church and there continues to be a useful interchange of ideas between the two fields in areas such as mathematical logic, category theory, domain theory, and algebra.the relationship between computer science and software engineering is a contentious issue, which is further muddied by disputes over what the term \"software engineering\" means, and how computer science is defined. david parnas, taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines.the academic, political, and funding aspects of computer science tend to depend on whether a department is formed with a mathematical emphasis or with an engineering emphasis. computer science departments with a mathematics emphasis and with a numerical orientation consider alignment with computational science. both types of departments tend to make efforts to bridge the field educationally if not across all research.'], 'hardware': ['the term hardware covers all of those parts of a computer that are tangible physical objects. circuits, computer chips, graphic cards, sound cards, memory (ram), motherboard, displays, power supplies, cables, keyboards, printers and \"mice\" input devices are all hardware.=== history of computing hardware ====== other hardware topics ===a general-purpose computer has four main components: the arithmetic logic unit (alu), the control unit, the memory, and the input and output devices (collectively termed i/o). these parts are interconnected by buses, often made of groups of wires. inside each of these parts are thousands to trillions of small electrical circuits which can be turned off or on by means of an electronic switch. each circuit represents a bit (binary digit) of information so that when the circuit is on it represents a \"1\", and when off it represents a \"0\" (in positive logic representation). the circuits are arranged in logic gates so that one or more of the circuits may control the state of one or more of the other circuits.=== input devices ===when unprocessed data is sent to the computer with the help of input devices, the data is processed and sent to output devices. the input devices may be hand-operated or automated. the act of processing is mainly regulated by the cpu. some examples of input devices are:computer keyboarddigital cameradigital videographics tabletimage scannerjoystickmicrophonemouseoverlay keyboardreal-time clocktrackballtouchscreenlight pen=== output devices ===the means through which computer gives output are known as output devices. some examples of output devices are:computer monitorprinterpc speakerprojectorsound cardvideo card=== control unit ===the control unit (often called a control system or central controller) manages the computer\\'s various components; it reads and interprets (decodes) the program instructions, transforming them into control signals that activate other parts of the computer. control systems in advanced computers may change the order of execution of some instructions to improve performance.a key component common to all cpus is the program counter, a special memory cell (a register) that keeps track of which location in memory the next instruction is to be read from.the control system\\'s function is as follows— this is a simplified description, and some of these steps may be performed concurrently or in a different order depending on the type of cpu:read the code for the next instruction from the cell indicated by the program counter.decode the numerical code for the instruction into a set of commands or signals for each of the other systems.increment the program counter so it points to the next instruction.read whatever data the instruction requires from cells in memory (or perhaps from an input device). the location of this required data is typically stored within the instruction code.provide the necessary data to an alu or register.if the instruction requires an alu or specialized hardware to complete, instruct the hardware to perform the requested operation.write the result from the alu back to a memory location or to a register or perhaps an output device.jump back to step (1).since the program counter is (conceptually) just another set of memory cells, it can be changed by calculations done in the alu. adding 100 to the program counter would cause the next instruction to be read from a place 100 locations further down the program. instructions that modify the program counter are often known as \"jumps\" and allow for loops (instructions that are repeated by the computer) and often conditional instruction execution (both examples of control flow).the sequence of operations that the control unit goes through to process an instruction is in itself like a short computer program, and indeed, in some more complex cpu designs, there is another yet smaller computer called a microsequencer, which runs a microcode program that causes all of these events to happen.=== central processing unit (cpu) ===the control unit, alu, and registers are collectively known as a central processing unit (cpu). early cpus were composed of many separate components. since the 1970s, cpus have typically been constructed on a single mos integrated circuit chip called a microprocessor.=== arithmetic logic unit (alu) ===the alu is capable of performing two classes of operations: arithmetic and logic. the set of arithmetic operations that a particular alu supports may be limited to addition and subtraction, or might include multiplication, division, trigonometry functions such as sine, cosine, etc., and square roots. some can operate only on whole numbers (integers) while others use floating point to represent real numbers, albeit with limited precision. however, any computer that is capable of performing just the simplest operations can be programmed to break down the more complex operations into simple steps that it can perform. therefore, any computer can be programmed to perform any arithmetic operation—although it will take more time to do so if its alu does not directly support the operation. an alu may also compare numbers and return boolean truth values (true or false) depending on whether one is equal to, greater than or less than the other (\"is 64 greater than 65?\"). logic operations involve boolean logic: and, or, xor, and not. these can be useful for creating complicated conditional statements and processing boolean logic.superscalar computers may contain multiple alus, allowing them to process several instructions simultaneously. graphics processors and computers with simd and mimd features often contain alus that can perform arithmetic on vectors and matrices.=== memory ===a computer\\'s memory can be viewed as a list of cells into which numbers can be placed or read. each cell has a numbered \"address\" and can store a single number. the computer can be instructed to \"put the number 123 into the cell numbered 1357\" or to \"add the number that is in cell 1357 to the number that is in cell 2468 and put the answer into cell 1595.\" the information stored in memory may represent practically anything. letters, numbers, even computer instructions can be placed into memory with equal ease. since the cpu does not differentiate between different types of information, it is the software\\'s responsibility to give significance to what the memory sees as nothing but a series of numbers.in almost all modern computers, each memory cell is set up to store binary numbers in groups of eight bits (called a byte). each byte is able to represent 256 different numbers (28 = 256); either from 0 to 255 or −128 to +127. to store larger numbers, several consecutive bytes may be used (typically, two, four or eight). when negative numbers are required, they are usually stored in two\\'s complement notation. other arrangements are possible, but are usually not seen outside of specialized applications or historical contexts. a computer can store any kind of information in memory if it can be represented numerically. modern computers have billions or even trillions of bytes of memory.the cpu contains a special set of memory cells called registers that can be read and written to much more rapidly than the main memory area. there are typically between two and one hundred registers depending on the type of cpu. registers are used for the most frequently needed data items to avoid having to access main memory every time data is needed. as data is constantly being worked on, reducing the need to access main memory (which is often slow compared to the alu and control units) greatly increases the computer\\'s speed.computer main memory comes in two principal varieties:random-access memory or ramread-only memory or romram can be read and written to anytime the cpu commands it, but rom is preloaded with data and software that never changes, therefore the cpu can only read from it. rom is typically used to store the computer\\'s initial start-up instructions. in general, the contents of ram are erased when the power to the computer is turned off, but rom retains its data indefinitely. in a pc, the rom contains a specialized program called the bios that orchestrates loading the computer\\'s operating system from the hard disk drive into ram whenever the computer is turned on or reset. in embedded computers, which frequently do not have disk drives, all of the required software may be stored in rom. software stored in rom is often called firmware, because it is notionally more like hardware than software. flash memory blurs the distinction between rom and ram, as it retains its data when turned off but is also rewritable. it is typically much slower than conventional rom and ram however, so its use is restricted to applications where high speed is unnecessary.in more sophisticated computers there may be one or more ram cache memories, which are slower than registers but faster than main memory. generally computers with this sort of cache are designed to move frequently needed data into the cache automatically, often without the need for any intervention on the programmer\\'s part.=== input/output (i/o) ===i/o is the means by which a computer exchanges information with the outside world. devices that provide input or output to the computer are called peripherals. on a typical personal computer, peripherals include input devices like the keyboard and mouse, and output devices such as the display and printer. hard disk drives, floppy disk drives and optical disc drives serve as both input and output devices. computer networking is another form of i/o.i/o devices are often complex computers in their own right, with their own cpu and memory. a graphics processing unit might contain fifty or more tiny computers that perform the calculations necessary to display 3d graphics. modern desktop computers contain many smaller computers that assist the main cpu in performing i/o. a 2016-era flat screen display contains its own computer circuitry.=== multitasking ===while a computer may be viewed as running one gigantic program stored in its main memory, in some systems it is necessary to give the appearance of running several programs simultaneously. this is achieved by multitasking i.e. having the computer switch rapidly between running each program in turn. one means by which this is done is with a special signal called an interrupt, which can periodically cause the computer to stop executing instructions where it was and do something else instead. by remembering where it was executing prior to the interrupt, the computer can return to that task later. if several programs are running \"at the same time\". then the interrupt generator might be causing several hundred interrupts per second, causing a program switch each time. since modern computers typically execute instructions several orders of magnitude faster than human perception, it may appear that many programs are running at the same time even though only one is ever executing in any given instant. this method of multitasking is sometimes termed \"time-sharing\" since each program is allocated a \"slice\" of time in turn.before the era of inexpensive computers, the principal use for multitasking was to allow many people to share the same computer. seemingly, multitasking would cause a computer that is switching between several programs to run more slowly, in direct proportion to the number of programs it is running, but most programs spend much of their time waiting for slow input/output devices to complete their tasks. if a program is waiting for the user to click on the mouse or press a key on the keyboard, then it will not take a \"time slice\" until the event it is waiting for has occurred. this frees up time for other programs to execute so that many programs may be run simultaneously without unacceptable speed loss.=== multiprocessing ===some computers are designed to distribute their work across several cpus in a multiprocessing configuration, a technique once employed in only large and powerful machines such as supercomputers, mainframe computers and servers. multiprocessor and multi-core (multiple cpus on a single integrated circuit) personal and laptop computers are now widely available, and are being increasingly used in lower-end markets as a result.supercomputers in particular often have highly unique architectures that differ significantly from the basic stored-program architecture and from general-purpose computers. they often feature thousands of cpus, customized high-speed interconnects, and specialized computing hardware. such designs tend to be useful for only specialized tasks due to the large scale of program organization required to successfully utilize most of the available resources at once. supercomputers usually see usage in large-scale simulation, graphics rendering, and cryptography applications, as well as with other so-called \"embarrassingly parallel\" tasks.'], 'software': ['software refers to parts of the computer which do not have a material form, such as programs, data, protocols, etc. software is that part of a computer system that consists of encoded information or computer instructions, in contrast to the physical hardware from which the system is built. computer software includes computer programs, libraries and related non-executable data, such as online documentation or digital media. it is often divided into system software and application software computer hardware and software require each other and neither can be realistically used on its own. when software is stored in hardware that cannot easily be modified, such as with bios rom in an ibm pc compatible computer, it is sometimes called \"firmware\".=== languages ===there are thousands of different programming languages—some intended for general purpose, others useful for only highly specialized applications.=== programs ===the defining feature of modern computers which distinguishes them from all other machines is that they can be programmed. that is to say that some type of instructions (the program) can be given to the computer, and it will process them. modern computers based on the von neumann architecture often have machine code in the form of an imperative programming language. in practical terms, a computer program may be just a few instructions or extend to many millions of instructions, as do the programs for word processors and web browsers for example. a typical modern computer can execute billions of instructions per second (gigaflops) and rarely makes a mistake over many years of operation. large computer programs consisting of several million instructions may take teams of programmers years to write, and due to the complexity of the task almost certainly contain errors.==== stored program architecture ====this section applies to most common ram machine–based computers.in most cases, computer instructions are simple: add one number to another, move some data from one location to another, send a message to some external device, etc. these instructions are read from the computer\\'s memory and are generally carried out (executed) in the order they were given. however, there are usually specialized instructions to tell the computer to jump ahead or backwards to some other place in the program and to carry on executing from there. these are called \"jump\" instructions (or branches). furthermore, jump instructions may be made to happen conditionally so that different sequences of instructions may be used depending on the result of some previous calculation or some external event. many computers directly support subroutines by providing a type of jump that \"remembers\" the location it jumped from and another instruction to return to the instruction following that jump instruction.program execution might be likened to reading a book. while a person will normally read each word and line in sequence, they may at times jump back to an earlier place in the text or skip sections that are not of interest. similarly, a computer may sometimes go back and repeat the instructions in some section of the program over and over again until some internal condition is met. this is called the flow of control within the program and it is what allows the computer to perform tasks repeatedly without human intervention.comparatively, a person using a pocket calculator can perform a basic arithmetic operation such as adding two numbers with just a few button presses. but to add together all of the numbers from 1 to 1,000 would take thousands of button presses and a lot of time, with a near certainty of making a mistake. on the other hand, a computer may be programmed to do this with just a few simple instructions. the following example is written in the mips assembly language:once told to run this program, the computer will perform the repetitive addition task without further human intervention. it will almost never make a mistake and a modern pc can complete the task in a fraction of a second.==== machine code ====in most computers, individual instructions are stored as machine code with each instruction being given a unique number (its operation code or opcode for short). the command to add two numbers together would have one opcode; the command to multiply them would have a different opcode, and so on. the simplest computers are able to perform any of a handful of different instructions; the more complex computers have several hundred to choose from, each with a unique numerical code. since the computer\\'s memory is able to store numbers, it can also store the instruction codes. this leads to the important fact that entire programs (which are just lists of these instructions) can be represented as lists of numbers and can themselves be manipulated inside the computer in the same way as numeric data. the fundamental concept of storing programs in the computer\\'s memory alongside the data they operate on is the crux of the von neumann, or stored program, architecture. in some cases, a computer might store some or all of its program in memory that is kept separate from the data it operates on. this is called the harvard architecture after the harvard mark i computer. modern von neumann computers display some traits of the harvard architecture in their designs, such as in cpu caches.while it is possible to write computer programs as long lists of numbers (machine language) and while this technique was used with many early computers, it is extremely tedious and potentially error-prone to do so in practice, especially for complicated programs. instead, each basic instruction can be given a short name that is indicative of its function and easy to remember – a mnemonic such as add, sub, mult or jump. these mnemonics are collectively known as a computer\\'s assembly language. converting programs written in assembly language into something the computer can actually understand (machine language) is usually done by a computer program called an assembler.==== programming language ====programming languages provide various ways of specifying programs for computers to run. unlike natural languages, programming languages are designed to permit no ambiguity and to be concise. they are purely written languages and are often difficult to read aloud. they are generally either translated into machine code by a compiler or an assembler before being run, or translated directly at run time by an interpreter. sometimes programs are executed by a hybrid method of the two techniques.===== low-level languages =====machine languages and the assembly languages that represent them (collectively termed low-level programming languages) are generally unique to the particular architecture of a computer\\'s central processing unit (cpu). for instance, an arm architecture cpu (such as may be found in a smartphone or a hand-held videogame) cannot understand the machine language of an x86 cpu that might be in a pc. historically a significant number of other cpu architectures were created and saw extensive use, notably including the mos technology 6502 and 6510 in addition to the zilog z80.===== high-level languages =====although considerably easier than in machine language, writing long programs in assembly language is often difficult and is also error prone. therefore, most practical programs are written in more abstract high-level programming languages that are able to express the needs of the programmer more conveniently (and thereby help reduce programmer error). high level languages are usually \"compiled\" into machine language (or sometimes into assembly language and then into machine language) using another computer program called a compiler. high level languages are less related to the workings of the target computer than assembly language, and more related to the language and structure of the problem(s) to be solved by the final program. it is therefore often possible to use different compilers to translate the same high level language program into the machine language of many different types of computer. this is part of the means by which software like video games may be made available for different computer architectures such as personal computers and various video game consoles.==== program design ====program design of small programs is relatively simple and involves the analysis of the problem, collection of inputs, using the programming constructs within languages, devising or using established procedures and algorithms, providing data for output devices and solutions to the problem as applicable. as problems become larger and more complex, features such as subprograms, modules, formal documentation, and new paradigms such as object-oriented programming are encountered. large programs involving thousands of line of code and more require formal software methodologies.the task of developing large software systems presents a significant intellectual challenge. producing software with an acceptably high reliability within a predictable schedule and budget has historically been difficult; the academic and professional discipline of software engineering concentrates specifically on this challenge.==== bugs ====errors in computer programs are called \"bugs\". they may be benign and not affect the usefulness of the program, or have only subtle effects. but in some cases, they may cause the program or the entire system to \"hang\", becoming unresponsive to input such as mouse clicks or keystrokes, to completely fail, or to crash. otherwise benign bugs may sometimes be harnessed for malicious intent by an unscrupulous user writing an exploit, code designed to take advantage of a bug and disrupt a computer\\'s proper execution. bugs are usually not the fault of the computer. since computers merely execute the instructions they are given, bugs are nearly always the result of programmer error or an oversight made in the program\\'s design. admiral grace hopper, an american computer scientist and developer of the first compiler, is credited for having first used the term \"bugs\" in computing after a dead moth was found shorting a relay in the harvard mark ii computer in september 1947.'], 'networking and the internet': ['computers have been used to coordinate information between multiple locations since the 1950s. the u.s. military\\'s sage system was the first large-scale example of such a system, which led to a number of special-purpose commercial systems such as sabre. in the 1970s, computer engineers at research institutions throughout the united states began to link their computers together using telecommunications technology. the effort was funded by arpa (now darpa), and the computer network that resulted was called the arpanet. the technologies that made the arpanet possible spread and evolved.in time, the network spread beyond academic and military institutions and became known as the internet. the emergence of networking involved a redefinition of the nature and boundaries of the computer. computer operating systems and applications were modified to include the ability to define and access the resources of other computers on the network, such as peripheral devices, stored information, and the like, as extensions of the resources of an individual computer. initially these facilities were available primarily to people working in high-tech environments, but in the 1990s the spread of applications like e-mail and the world wide web, combined with the development of cheap, fast networking technologies like ethernet and adsl saw computer networking become almost ubiquitous. in fact, the number of computers that are networked is growing phenomenally. a very large proportion of personal computers regularly connect to the internet to communicate and receive information. \"wireless\" networking, often utilizing mobile phone networks, has meant networking is becoming increasingly ubiquitous even in mobile computing environments.'], 'unconventional computer': ['a computer does not need to be electronic, nor even have a processor, nor ram, nor even a hard disk. while popular usage of the word \"computer\" is synonymous with a personal electronic computer, the modern definition of a computer is literally: \"a device that computes, especially a programmable [usually] electronic machine that performs high-speed mathematical or logical operations or that assembles, stores, correlates, or otherwise processes information.\" any device which processes information qualifies as a computer, especially if the processing is purposeful.'], 'future': ['there is active research to make computers out of many promising new types of technology, such as optical computers, dna computers, neural computers, and quantum computers. most computers are universal, and are able to calculate any computable function, and are limited only by their memory capacity and operating speed. however different designs of computers can give very different performance for particular problems; for example quantum computers can potentially break some modern encryption algorithms (by quantum factoring) very quickly.=== computer architecture paradigms ===there are many types of computer architectures:quantum computer vs. chemical computerscalar processor vs. vector processornon-uniform memory access (numa) computersregister machine vs. stack machineharvard architecture vs. von neumann architecturecellular architectureof all these abstract machines, a quantum computer holds the most promise for revolutionizing computing. logic gates are a common abstraction which can apply to most of the above digital or analog paradigms. the ability to store and execute lists of instructions called programs makes computers extremely versatile, distinguishing them from calculators. the church–turing thesis is a mathematical statement of this versatility: any computer with a minimum capability (being turing-complete) is, in principle, capable of performing the same tasks that any other computer can perform. therefore, any type of computer (netbook, supercomputer, cellular automaton, etc.) is able to perform the same computational tasks, given enough time and storage capacity.=== artificial intelligence ===a computer will solve problems in exactly the way it is programmed to, without regard to efficiency, alternative solutions, possible shortcuts, or possible errors in the code. computer programs that learn and adapt are part of the emerging field of artificial intelligence and machine learning. artificial intelligence based products generally fall into two major categories: rule-based systems and pattern recognition systems. rule-based systems attempt to represent the rules used by human experts and tend to be expensive to develop. pattern-based systems use data about a problem to generate conclusions. examples of pattern-based systems include voice recognition, font recognition, translation and the emerging field of on-line marketing.'], 'professions and organization': ['as the use of computers has spread throughout society, there are an increasing number of careers involving computers.the need for computers to work well together and to be able to exchange information has spawned the need for many standards organizations, clubs and societies of both a formal and informal nature.'], 'philosophy': ['=== epistemology of computer science ===despite the word \"science\" in its name, there is debate over whether or not computer science is a discipline of science, mathematics, or engineering. allen newell and herbert a. simon argued in 1975, computer science is an empirical discipline. we would have called it an experimental science, but like astronomy, economics, and geology, some of its unique forms of observation and experience do not fit a narrow stereotype of the experimental method. nonetheless, they are experiments. each new machine that is built is an experiment. actually constructing the machine poses a question to nature; and we listen for the answer by observing the machine in operation and analyzing it by all analytical and measurement means available. it has since been argued that computer science can be classified as an empirical science since it makes use of empirical testing to evaluate the correctness of programs, but a problem remains in defining the laws and theorems of computer science (if any exist) and defining the nature of experiments in computer science. proponents of classifying computer science as an engineering discipline argue that the reliability of computational systems is investigated in the same way as bridges in civil engineering and airplanes in aerospace engineering. they also argue that while empirical sciences observe what presently exists, computer science observes what is possible to exist and while scientists discover laws from observation, no proper laws have been found in computer science and it is instead concerned with creating phenomena.proponents of classifying computer science as a mathematical discipline argue that computer programs are physical realizations of mathematical entities and programs can be deductively reasoned through mathematical formal methods. computer scientists edsger w. dijkstra and tony hoare regard instructions for computer programs as mathematical sentences and interpret formal semantics for programming languages as mathematical axiomatic systems.=== paradigms of computer science ===a number of computer scientists have argued for the distinction of three separate paradigms in computer science. peter wegner argued that those paradigms are science, technology, and mathematics. peter denning\\'s working group argued that they are theory, abstraction (modeling), and design. amnon h. eden described them as the \"rationalist paradigm\" (which treats computer science as a branch of mathematics, which is prevalent in theoretical computer science, and mainly employs deductive reasoning), the \"technocratic paradigm\" (which might be found in engineering approaches, most prominently in software engineering), and the \"scientific paradigm\" (which approaches computer-related artifacts from the empirical perspective of natural sciences, identifiable in some branches of artificial intelligence).computer science focuses on methods involved in design, specification, programming, verification, implementation and testing of human-made computing systems.'], 'field': ['computer science is no more about computers than astronomy is about telescopes.as a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.csab, formerly called computing sciences accreditation board—which is made up of representatives of the association for computing machinery (acm), and the ieee computer society (ieee cs)—identifies four areas that it considers crucial to the discipline of computer science: theory of computation, algorithms and data structures, programming methodology and languages, and computer elements and architecture. in addition to these four areas, csab also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical and symbolic computation as being important areas of computer science.=== theoretical computer science ===theoretical computer science is mathematical and abstract in spirit, but it derives its motivation from the practical and everyday computation. its aim is to understand the nature of computation and, as a consequence of this understanding, provide more efficient methodologies.==== theory of computation ====according to peter denning, the fundamental question underlying computer science is, \"what can be automated?\" theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. in an effort to answer the first question, computability theory examines which computational problems are solvable on various theoretical models of computation. the second question is addressed by computational complexity theory, which studies the time and space costs associated with different approaches to solving a multitude of computational problems.the famous p = np? problem, one of the millennium prize problems, is an open problem in the theory of computation.==== information and coding theory ====information theory, closely related to probability and statistics, is related to the quantification of information. this was developed by claude shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data.coding theory is the study of the properties of codes (systems for converting information from one form to another) and their fitness for a specific application. codes are used for data compression, cryptography, error detection and correction, and more recently also for network coding. codes are studied for the purpose of designing efficient and reliable data transmission methods.==== data structures and algorithms ====data structures and algorithms are the studies of commonly used computational methods and their computational efficiency.==== programming language theory and formal methods ====programming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and their individual features. it falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, and linguistics. it is an active research area, with numerous dedicated academic journals.formal methods are a particular kind of mathematically based technique for the specification, development and verification of software and hardware systems. the use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. they form an important theoretical underpinning for software engineering, especially where safety or security is involved. formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. for industrial use, tool support is required. however, the high cost of using formal methods means that they are usually only used in the development of high-integrity and life-critical systems, where safety or security is of utmost importance. formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification.=== computer systems and computational processes ======= artificial intelligence ====artificial intelligence (ai) aims to or is required to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, learning, and communication found in humans and animals. from its origins in cybernetics and in the dartmouth conference (1956), artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such as applied mathematics, symbolic logic, semiotics, electrical engineering, philosophy of mind, neurophysiology, and social intelligence. ai is associated in the popular mind with robotic development, but the main field of practical application has been as an embedded component in areas of software development, which require computational understanding. the starting point in the late 1940s was alan turing\\'s question \"can computers think?\", and the question remains effectively unanswered, although the turing test is still used to assess computer output on the scale of human intelligence. but the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data.==== computer architecture and organization ====computer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. it focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory. computer engineers study computational logic and design of computer hardware, from individual processor components, microcontrollers, personal computers to supercomputers and embedded systems. the term “architecture” in computer literature can be traced to the work of lyle r. johnson and frederick p. brooks, jr., members of the machine organization department in ibm\\'s main research center in 1959.==== concurrent, parallel and distributed computing ====concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. a number of mathematical models have been developed for general concurrent computation including petri nets, process calculi and the parallel random access machine model. when multiple computers are connected in a network while using concurrency, this is known as a distributed system. computers within that distributed system have their own private memory, and information can be exchanged to achieve common goals.==== computer networks ====this branch of computer science aims to manage networks between computers worldwide.==== computer security and cryptography ====computer security is a branch of computer technology with the objective of protecting information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users.historical cryptography is the art of writing and deciphering secret messages. modern cryptography is the scientific study of problems relating to distributed computations that can be attacked. technologies studied in modern cryptography include symmetric and asymmetric encryption, digital signatures, cryptographic hash functions, key-agreement protocols, blockchain, zero-knowledge proofs, and garbled circuits.==== databases and data mining ====a database is intended to organize, store, and retrieve large amounts of data easily. digital databases are managed using database management systems to store, create, maintain, and search data, through database models and query languages. data mining is a process of discovering patterns in large data sets.==== computer graphics and visualization ====computer graphics is the study of digital visual contents and involves the synthesis and manipulation of image data. the study is connected to many other fields in computer science, including computer vision, image processing, and computational geometry, and is heavily applied in the fields of special effects and video games.==== image and sound processing ====information can take the form of images, sound, video or other multimedia. bits of information can be streamed via signals. its processing is the central notion of informatics, the european view on computing, which studies information processing algorithms independently of the type of information carrier - whether it is electrical, mechanical or biological. this field plays important role in information theory, telecommunications, information engineering and has applications in medical image computing and speech synthesis, among others. what is the lower bound on the complexity of fast fourier transform algorithms? is one of unsolved problems in theoretical computer science.=== applied computer science ======= computational science, finance and engineering ====scientific computing (or computational science) is the field of study concerned with constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems. a major usage of scientific computing is simulation of various processes, including computational fluid dynamics, physical, electrical, and electronic systems and circuits, as well as societies and social situations (notably war games) along with their habitats, among many others. modern computers enable optimization of such designs as complete aircraft. notable in electrical and electronic circuit design are spice, as well as software for physical realization of new (or modified) designs. the latter includes essential design software for integrated circuits.==== social computing and human–computer interaction ====social computing is an area that is concerned with the intersection of social behavior and computational systems. human–computer interaction research develops theories, principles, and guidelines for user interface designers.==== software engineering ====software engineering is the study of designing, implementing, and modifying the software in order to ensure it is of high quality, affordable, maintainable, and fast to build. it is a systematic approach to software design, involving the application of engineering practices to software. software engineering deals with the organizing and analyzing of software—it doesn\\'t just deal with the creation or manufacture of new software, but its internal arrangement and maintenance. for example software testing, systems engineering, technical debt and software development processes.'], 'discoverie': ['the philosopher of computing bill rapaport noted three great insights of computer science:gottfried wilhelm leibniz\\'s, george boole\\'s, alan turing\\'s, claude shannon\\'s, and samuel morse\\'s insight: there are only two objects that a computer has to deal with in order to represent \"anything\".all the information about any computable problem can be represented using only 0 and 1 (or any other bistable pair that can flip-flop between two easily distinguishable states, such as \"on/off\", \"magnetized/de-magnetized\", \"high-voltage/low-voltage\", etc.).alan turing\\'s insight: there are only five actions that a computer has to perform in order to do \"anything\".every algorithm can be expressed in a language for a computer consisting of only five basic instructions:move left one location;move right one location;read symbol at current location;print 0 at current location;print 1 at current location.corrado böhm and giuseppe jacopini\\'s insight: there are only three ways of combining these actions (into more complex ones) that are needed in order for a computer to do \"anything\".only three rules are needed to combine any set of basic instructions into more complex ones:sequence: first do this, then do that; selection: if such-and-such is the case, then do this, else do that;repetition: while such-and-such is the case, do this.note that the three rules of boehm\\'s and jacopini\\'s insight can be further simplified with the use of goto (which means it is more elementary than structured programming).'], 'programming paradigm': ['programming languages can be used to accomplish different tasks in different ways. common programming paradigms include:functional programming, a style of building the structure and elements of computer programs that treats computation as the evaluation of mathematical functions and avoids state and mutable data. it is a declarative programming paradigm, which means programming is done with expressions or declarations instead of statements.imperative programming, a programming paradigm that uses statements that change a program\\'s state. in much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. imperative programming focuses on describing how a program operates.object-oriented programming, a programming paradigm based on the concept of \"objects\", which may contain data, in the form of fields, often known as attributes; and code, in the form of procedures, often known as methods. a feature of objects is that an object\\'s procedures can access and often modify the data fields of the object with which they are associated. thus object-oriented computer programs are made out of objects that interact with one another.service-oriented programming, a programming paradigm that uses \"services\" as the unit of computer work, to design and implement integrated business applications and mission critical software programsmany languages offer support for multiple paradigms, making the distinction more a matter of style than of technical capabilities.'], 'academia': ['conferences are important events for computer science research. during these conferences, researchers from the public and private sectors present their recent work and meet. unlike in most other academic fields, in computer science, the prestige of conference papers is greater than that of journal publications. one proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.'], 'education': ['computer science, known by its near synonyms, computing, computer studies, has been taught in uk schools since the days of batch processing, mark sensitive cards and paper tape but usually to a select few students. in 1981, the bbc produced a micro-computer and classroom network and computer studies became common for gce o level students (11–16-year-old), and computer science to a level students. its importance was recognised, and it became a compulsory part of the national curriculum, for key stage 3 & 4. in september 2014 it became an entitlement for all pupils over the age of 4.in the us, with 14,000 school districts deciding the curriculum, provision was fractured. according to a 2010 report by the association for computing machinery (acm) and computer science teachers association (csta), only 14 out of 50 states have adopted significant education standards for high school computer science.israel, new zealand, and south korea have included computer science in their national secondary education curricula, and several others are following.']})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['relation to instruction set architecture', 'aspect', 'microarchitectural concept', 'further reading']\n",
      "defaultdict(<class 'list'>, {'intro': ['in computer engineering, computer architecture is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. the architecture of a system refers to its structure in terms of separately specified components of that system and their interrelationships.some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation. in other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation.', 'in computing, a word is the natural unit of data used by a particular processor design. a word is a fixed-sized datum handled as a unit by the instruction set or the hardware of the processor. the number of bits or digits in a word (the word size, word width, or word length) is an important characteristic of any specific processor design or computer architecture.the size of a word is reflected in many aspects of a computer\\'s structure and operation; the majority of the registers in a processor are usually word sized and the largest datum that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. the largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used).documentation for computers with fixed word size commonly stated memory sizes in words rather than bytes or characters.  the documentation sometimes used metric prefixes correctly, sometimes with rounding, e.g., 65 kilowords (kw) meaning for 65536 words, and sometimes used them incorrectly, with kilowords (kw) meaning 1024 words (210) and megawords (mw) meaning 1,048,576 words (220). with standardization on 8-bit bytes and byte addressability, stating memory sizes in bytes, kilobytes, and megabytes with powers of 1024 rather than 1000 has become the norm, although there is some use of the iec binary prefixes.several of the earliest computers (and a few modern as well) used binary-coded decimal rather than plain binary, typically having a word size of 10 or 12 decimal digits, and some early decimal computers had no fixed word length at all. early binary systems tended to use word lengths that were some multiple of 6-bits, with the 36-bit word being especially common on mainframe computers. the introduction of ascii led to the move to systems with word lengths that were a multiple of 8-bits, with 16-bit machines being popular in the 1970s before the move to modern processors with 32 or 64 bits. special-purpose designs like digital signal processors, may have any word length from 4 to 80 bits.the size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. if multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see size families below).', 'in the domain of central processing unit (cpu) design, hazards are problems with the instruction pipeline in cpu microarchitectures when the next instruction cannot execute in the following clock cycle, and can potentially lead to incorrect computation results. three common types of hazards are data hazards, structural hazards, and control hazards (branching hazards).there are several methods used to deal with hazards, including pipeline stalls/pipeline bubbling, operand forwarding, and in the case of out-of-order execution, the scoreboarding method and the tomasulo algorithm.', 'in computer architecture, multithreading is the ability of a central processing unit (cpu) (or a single core in a multi-core processor) to provide multiple threads of execution concurrently, supported by the operating system. this approach differs from multiprocessing. in a multithreaded application, the threads share the resources of a single or multiple cores, which include the computing units, the cpu caches, and the translation lookaside buffer (tlb).where multiprocessing systems include multiple complete processing units in one or more cores, multithreading aims to increase utilization of a single core by using thread-level parallelism, as well as instruction-level parallelism. as the two techniques are complementary, they are combined in nearly all modern systems architectures with multiple multithreading cpus and with cpus with multiple multithreading cores.', 'the von neumann architecture — also known as the von neumann model or princeton architecture — is a computer architecture based on a 1945 description by john von neumann, and by others, in the first draft of a report on the edvac. the document describes a design architecture for an electronic digital computer with these components:a processing unit with both an arithmetic logic unit and processor registersa control unit that includes an instruction register and a program countermemory that stores data and instructionsexternal mass storageinput and output mechanismsthe term \"von neumann architecture\" has evolved to refer to any stored-program computer in which an instruction fetch and a data operation cannot occur at the same time (since they share a common bus). this is referred to as the von neumann bottleneck, which often limits the performance of the corresponding system.the design of a von neumann architecture machine is simpler than in a harvard architecture machine—which is also a stored-program system, yet has one dedicated set of address and data buses for reading and writing to memory, and another set of address and data buses to fetch instructions.a stored-program digital computer keeps both program instructions and data in read–write, random-access memory (ram).  stored-program computers were an advancement over the program-controlled computers of the 1940s, such as the colossus and the eniac. those were programmed by setting switches and inserting patch cables to route data and control signals between various functional units. the vast majority of modern computers use the same memory for both data and program instructions, but have caches between the cpu and memory, and, for the caches closest to the cpu, have separate caches for instructions and data, so that most instruction and data fetches use separate buses (split cache architecture).', 'in computer science, predication is an architectural feature that provides an alternative to conditional transfer of control, as implemented by conditional branch machine instructions. predication works by having conditional (predicated) non-branch instructions associated with a predicate, a boolean value used by the instruction to control whether the instruction is allowed to modify the architectural state or not.  if the predicate specified in the instruction is true, the instruction modifies the architectural state; otherwise, the architectural state is unchanged.  for example, a predicated move instruction (a conditional move) will only modify the destination if the predicate is true.  thus, instead of using a conditional branch to select an instruction or a sequence of instructions to execute based on the predicate that controls whether the branch occurs, the instructions to be executed are associated with that predicate, so that they will be executed, or not executed, based on whether that predicate is true or false.vector processors, some simd isas (such as avx2 and avx-512) and gpus in general make heavy use of predication, applying one bit of a conditional mask vector to the corresponding elements in the vector registers being processed, whereas scalar predication in scalar instruction sets only need the one predicate bit.  where predicate masks become particularly powerful in vector processing is if an array of condition codes, one per vector element, may feed back into predicate masks that are then applied to subsequent vector instructions.', 'a computer is a digital electronic machine that can be programmed to carry out sequences of arithmetic or logical operations (computation) automatically. modern computers can perform generic sets of operations known as programs. these programs enable computers to perform a wide range of tasks. a computer system is a \"complete\" computer that includes the hardware, operating system (main software), and peripheral equipment needed and used for \"full\" operation. this term may also refer to a group of computers that are linked and function together, such as a computer network or computer cluster.a broad range of industrial and consumer products use computers as control systems. simple special-purpose devices like microwave ovens and remote controls are included, as are factory devices like industrial robots and computer-aided design, as well as general-purpose devices like personal computers and mobile devices like smartphones. computers power the internet, which links billions of other computers and users.early computers were meant to be used only for calculations. simple manual instruments like the abacus have aided people in doing calculations since ancient times. early in the industrial revolution, some mechanical devices were built to automate long tedious tasks, such as guiding patterns for looms. more sophisticated electrical machines did specialized analog calculations in the early 20th century. the first digital electronic calculating machines were developed during world war ii. the first semiconductor transistors in the late 1940s were followed by the silicon-based mosfet (mos transistor) and monolithic integrated circuit (ic) chip technologies in the late 1950s, leading to the microprocessor and the microcomputer revolution in the 1970s. the speed, power and versatility of computers have been increasing dramatically ever since then, with transistor counts increasing at a rapid pace (as predicted by moore\\'s law), leading to the digital revolution during the late 20th to early 21st centuries.conventionally, a modern computer consists of at least one processing element, typically a central processing unit (cpu) in the form of a microprocessor, along with some type of computer memory, typically semiconductor memory chips. the processing element carries out arithmetic and logical operations, and a sequencing and control unit can change the order of operations in response to stored information. peripheral devices include input devices (keyboards, mice, joystick, etc.), output devices (monitor screens, printers, etc.), and input/output devices that perform both functions (e.g., the 2000s-era touchscreen). peripheral devices allow information to be retrieved from an external source and they enable the result of operations to be saved and retrieved.', 'computer science is the study of computation, automation, and information. computer science spans theoretical disciplines (such as algorithms, theory of computation, and information theory) to practical disciplines (including the design and implementation of hardware and software). computer science is generally considered an area of academic research and distinct from computer programming.algorithms and data structures are central to computer science.the theory of computation concerns abstract models of computation and general classes of problems that can be solved using them. the fields of cryptography and computer security involve studying the means for secure communication and for preventing security vulnerabilities. computer graphics and computational geometry address the generation of images. programming language theory considers approaches to the description of computational processes, and database theory concerns the management of repositories of data. human–computer interaction investigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. areas such as operating systems, networks and embedded systems investigate the principles and design behind complex systems. computer architecture describes the construction of computer components and computer-operated equipment. artificial intelligence and machine learning aim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. within artificial intelligence, computer vision aims to understand and process image and video data, while natural-language processing aims to understand and process textual and linguistic data.the fundamental concern of computer science is determining what can and cannot be automated. the turing award is generally recognized as the highest distinction in computer science.', 'in computer engineering, microarchitecture, also called computer organization and sometimes abbreviated as µarch or uarch, is the way a given instruction set architecture (isa) is implemented in a particular processor. a given isa may be implemented with different microarchitectures; implementations may vary due to different goals of a given design or due to shifts in technology.computer architecture is the combination of microarchitecture and instruction set architecture.'], 'history': ['the first documented computer architecture was in the correspondence between charles babbage and ada lovelace, describing the analytical engine. when building the computer z1 in 1936, konrad zuse described in two patent applications for his future projects that machine instructions could be stored in the same storage used for data, i.e., the stored-program concept. two other early and important examples are:john von neumann\\'s 1945 paper, first draft of a report on the edvac, which described an organization of logical elements; andalan turing\\'s more detailed proposed electronic calculator for the automatic computing engine, also 1945 and which cited john von neumann\\'s paper.the term “architecture” in computer literature can be traced to the work of lyle r. johnson and frederick p. brooks, jr., members of the machine organization department in ibm\\'s main research center in 1959. johnson had the opportunity to write a proprietary research communication about the stretch, an ibm-developed supercomputer for los alamos national laboratory (at the time known as los alamos scientific laboratory). to describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that seemed more useful than “machine organization”.subsequently, brooks, a stretch designer, opened chapter 2 of a book called planning a computer system: project stretch by stating, “computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.”brooks went on to help develop the ibm system/360 (now called the ibm zseries) line of computers, in which “architecture” became a noun defining “what the user needs to know”. later, computer users came to use the term in many less explicit ways.the earliest computer architectures were designed on paper and then directly built into the final hardware form.later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (ttl) computer—such as the prototypes of the 6800 and the pa-risc—tested, and tweaked, before committing to the final hardware form.as of the 1990s, new computer architectures are typically \"built\", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a fpga as a soft microprocessor; or both—before committing to the final hardware form.', 'the earliest computing machines had fixed programs.  some very simple computers still use this design, either for simplicity or training purposes.  for example, a desk calculator (in principle) is a fixed program computer.  it can do basic mathematics, but it cannot run a word processor or games.  changing the program of a fixed-program machine requires rewiring, restructuring, or redesigning the machine.  the earliest computers were not so much \"programmed\" as  \"designed\" for a particular task.  \"reprogramming\" – when possible at all – was a laborious process that started with flowcharts and paper notes, followed by detailed engineering designs, and then the often-arduous process of physically rewiring and rebuilding the machine. it could take three weeks to set up and debug a program on eniac.with the proposal of the stored-program computer, this changed. a stored-program computer includes, by design, an instruction set, and can store in memory a set of instructions (a program) that details the computation.a stored-program design also allows for self-modifying code. one early motivation for such a facility was the need for a program to increment or otherwise modify the address portion of instructions, which operators had to do manually in early designs. this became less important when index registers and indirect addressing became usual features of machine architecture. another use was to embed frequently used data in the instruction stream using immediate addressing. self-modifying code has largely fallen out of favor, since it is usually hard to understand and debug, as well as being inefficient under modern processor pipelining and caching schemes.', 'predicated instructions were popular in european computer designs of the 1950s, including the mailüfterl (1955), the zuse z22 (1955), the zebra (1958), and the electrologica x1 (1958). the ibm acs-1 design of 1967 allocated a \"skip\" bit in its instruction formats, and the cdc flexible processor in 1976 allocated three conditional execution bits in its microinstruction formats.hewlett-packard\\'s pa-risc architecture (1986) had a feature called nullification, which allowed most instructions to be predicated by the previous instruction. ibm\\'s power architecture (1990) featured conditional move instructions. power\\'s successor, powerpc (1993), dropped these instructions. digital equipment corporation\\'s alpha architecture (1992) also featured conditional move instructions. mips gained conditional move instructions in 1994 with the mips iv version; and sparc was extended in version 9 (1994) with conditional move instructions for both integer and floating-point registers.in the hewlett-packard/intel ia-64 architecture, most instructions are predicated. the predicates are stored in 64 special-purpose predicate registers; and one of the predicate registers is always true so that unpredicated instructions are simply instructions predicated with the value true. the use of predication is essential in ia-64\\'s implementation of software pipelining because it avoids the need for writing separated code for prologs and epilogs.in the x86 architecture, a family of conditional move instructions (cmov and fcmov) were added to the architecture by the intel pentium pro (1995) processor. the cmov instructions copied the contents of the source register to the destination register depending on a predicate supplied by the value of the flag register.in the arm architecture, the original 32-bit instruction set provides a feature called conditional execution that allows most instructions to be predicated by one of 13 predicates that are based on some combination of the four condition codes set by the previous instruction. arm\\'s thumb instruction set (1994) dropped conditional execution to reduce the size of instructions so they could fit in 16 bits, but its successor, thumb-2 (2003) overcame this problem by using a special instruction which has no effect other than to supply predicates for the following four instructions. the 64-bit instruction set introduced in armv8-a (2011) replaced conditional execution with conditional selection instructions.== simd, simt and vector predication ==some simd instruction sets, like avx2, have the ability to use a logical mask to conditionally load/store values to memory, a parallel form of the conditional move, and may also apply individual mask bits to individual arithmetic units executing a parallel operation.  the technique is known in flynn\\'s taxonomy as \"associative processing\".this form of predication is also used in vector processors and single instruction, multiple threads gpu computing.  all the techniques, advantages and disadvantages of single scalar predication apply just as well to the parallel processing case.', '=== pre-20th century ===devices have been used to aid computation for thousands of years, mostly using one-to-one correspondence with fingers. the earliest counting device was probably a form of tally stick. later record keeping aids throughout the fertile crescent included calculi (clay spheres, cones, etc.) which represented counts of items, probably livestock or grains, sealed in hollow unbaked clay containers. the use of counting rods is one example.the abacus was initially used for arithmetic tasks. the roman abacus was developed from devices used in babylonia as early as 2400 bc. since then, many other forms of reckoning boards or tables have been invented. in a medieval european counting house, a checkered cloth would be placed on a table, and markers moved around on it according to certain rules, as an aid to calculating sums of money.the antikythera mechanism is believed to be the earliest known mechanical analog computer, according to derek j. de solla price. it was designed to calculate astronomical positions. it was discovered in 1901 in the antikythera wreck off the greek island of antikythera, between kythera and crete, and has been dated to approximately c.\\u2009100 bc. devices of comparable complexity to the antikythera mechanism would not reappear until the fourteenth century.many mechanical aids to calculation and measurement were constructed for astronomical and navigation use. the planisphere was a star chart invented by abū rayhān al-bīrūnī in the early 11th century. the astrolabe was invented in the hellenistic world in either the 1st or 2nd centuries bc and is often attributed to hipparchus. a combination of the planisphere and dioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems in spherical astronomy. an astrolabe incorporating a mechanical calendar computer and gear-wheels was invented by abi bakr of isfahan, persia in 1235. abū rayhān al-bīrūnī invented the first mechanical geared lunisolar calendar astrolabe, an early fixed-wired knowledge processing machine with a gear train and gear-wheels, c.\\u20091000 ad.the sector, a calculating instrument used for solving problems in proportion, trigonometry, multiplication and division, and for various functions, such as squares and cube roots, was developed in the late 16th century and found application in gunnery, surveying and navigation.the planimeter was a manual instrument to calculate the area of a closed figure by tracing over it with a mechanical linkage.the slide rule was invented around 1620–1630 by the english clergyman william oughtred, shortly after the publication of the concept of the logarithm. it is a hand-operated analog computer for doing multiplication and division. as slide rule development progressed, added scales provided reciprocals, squares and square roots, cubes and cube roots, as well as transcendental functions such as logarithms and exponentials, circular and hyperbolic trigonometry and other functions. slide rules with special scales are still used for quick performance of routine calculations, such as the e6b circular slide rule used for time and distance calculations on light aircraft.in the 1770s, pierre jaquet-droz, a swiss watchmaker, built a mechanical doll (automaton) that could write holding a quill pen. by switching the number and order of its internal wheels different letters, and hence different messages, could be produced. in effect, it could be mechanically \"programmed\" to read instructions. along with two other complex machines, the doll is at the musée d\\'art et d\\'histoire of neuchâtel, switzerland, and still operates.in 1831–1835, mathematician and engineer giovanni plana devised a perpetual calendar machine, which, through a system of pulleys and cylinders and over, could predict the perpetual calendar for every year from ad 0 (that is, 1 bc) to ad 4000, keeping track of leap years and varying day length. the tide-predicting machine invented by the scottish scientist sir william thomson in 1872 was of great utility to navigation in shallow waters. it used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location.the differential analyser, a mechanical analog computer designed to solve differential equations by integration, used wheel-and-disc mechanisms to perform the integration. in 1876, sir william thomson had already discussed the possible construction of such calculators, but he had been stymied by the limited output torque of the ball-and-disk integrators. in a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output. the torque amplifier was the advance that allowed these machines to work. starting in the 1920s, vannevar bush and others developed mechanical differential analyzers.=== first computer ===charles babbage, an english mechanical engineer and polymath, originated the concept of a programmable computer. considered the \"father of the computer\", he conceptualized and invented the first mechanical computer in the early 19th century. after working on his revolutionary difference engine, designed to aid in navigational calculations, in 1833 he realized that a much more general design, an analytical engine, was possible. the input of programs and data was to be provided to the machine via punched cards, a method being used at the time to direct mechanical looms such as the jacquard loom. for output, the machine would have a printer, a curve plotter and a bell. the machine would also be able to punch numbers onto cards to be read in later. the engine incorporated an arithmetic logic unit, control flow in the form of conditional branching and loops, and integrated memory, making it the first design for a general-purpose computer that could be described in modern terms as turing-complete.the machine was about a century ahead of its time. all the parts for his machine had to be made by hand – this was a major problem for a device with thousands of parts. eventually, the project was dissolved with the decision of the british government to cease funding. babbage\\'s failure to complete the analytical engine can be chiefly attributed to political and financial difficulties as well as his desire to develop an increasingly sophisticated computer and to move ahead faster than anyone else could follow. nevertheless, his son, henry babbage, completed a simplified version of the analytical engine\\'s computing unit (the mill) in 1888. he gave a successful demonstration of its use in computing tables in 1906.=== analog computers ===during the first half of the 20th century, many scientific computing needs were met by increasingly sophisticated analog computers, which used a direct mechanical or electrical model of the problem as a basis for computation. however, these were not programmable and generally lacked the versatility and accuracy of modern digital computers. the first modern analog computer was a tide-predicting machine, invented by sir william thomson (later to become lord kelvin) in 1872. the differential analyser, a mechanical analog computer designed to solve differential equations by integration using wheel-and-disc mechanisms, was conceptualized in 1876 by james thomson, the elder brother of the more famous sir william thomson.the art of mechanical analog computing reached its zenith with the differential analyzer, built by h. l. hazen and vannevar bush at mit starting in 1927. this built on the mechanical integrators of james thomson and the torque amplifiers invented by h. w. nieman. a dozen of these devices were built before their obsolescence became obvious. by the 1950s, the success of digital electronic computers had spelled the end for most analog computing machines, but analog computers remained in use during the 1950s in some specialized applications such as education (slide rule) and aircraft (control systems).=== digital computers ======= electromechanical ====by 1938, the united states navy had developed an electromechanical analog computer small enough to use aboard a submarine. this was the torpedo data computer, which used trigonometry to solve the problem of firing a torpedo at a moving target. during world war ii similar devices were developed in other countries as well.early digital computers were electromechanical; electric switches drove mechanical relays to perform the calculation. these devices had a low operating speed and were eventually superseded by much faster all-electric computers, originally using vacuum tubes. the z2, created by german engineer konrad zuse in 1939, was one of the earliest examples of an electromechanical relay computer.in 1941, zuse followed his earlier machine up with the z3, the world\\'s first working electromechanical programmable, fully automatic digital computer. the z3 was built with 2000 relays, implementing a 22 bit word length that operated at a clock frequency of about 5–10 hz. program code was supplied on punched film while data could be stored in 64 words of memory or supplied from the keyboard. it was quite similar to modern machines in some respects, pioneering numerous advances such as floating-point numbers. rather than the harder-to-implement decimal system (used in charles babbage\\'s earlier design), using a binary system meant that zuse\\'s machines were easier to build and potentially more reliable, given the technologies available at that time. the z3 was not itself a universal computer but could be extended to be turing complete.zuse\\'s next computer, the z4, became the world\\'s first commercial computer; after initial delay due to the second world war, it was completed in 1950 and delivered to the eth zurich. the computer was manufactured by zuse\\'s own company, zuse kg, which was founded in 1941 as the first company with the sole purpose of developing computers.==== vacuum tubes and digital electronic circuits ====purely electronic circuit elements soon replaced their mechanical and electromechanical equivalents, at the same time that digital calculation replaced analog. the engineer tommy flowers, working at the post office research station in london in the 1930s, began to explore the possible use of electronics for the telephone exchange. experimental equipment that he built in 1934 went into operation five years later, converting a portion of the telephone exchange network into an electronic data processing system, using thousands of vacuum tubes. in the us, john vincent atanasoff and clifford e. berry of iowa state university developed and tested the atanasoff–berry computer (abc) in 1942, the first \"automatic electronic digital computer\". this design was also all-electronic and used about 300 vacuum tubes, with capacitors fixed in a mechanically rotating drum for memory.during world war ii, the british code-breakers at bletchley park achieved a number of successes at breaking encrypted german military communications. the german encryption machine, enigma, was first attacked with the help of the electro-mechanical bombes which were often run by women. to crack the more sophisticated german lorenz sz 40/42 machine, used for high-level army communications, max newman and his colleagues commissioned flowers to build the colossus. he spent eleven months from early february 1943 designing and building the first colossus. after a functional test in december 1943, colossus was shipped to bletchley park, where it was delivered on 18 january 1944 and attacked its first message on 5 february.colossus was the world\\'s first electronic digital programmable computer. it used a large number of valves (vacuum tubes). it had paper-tape input and was capable of being configured to perform a variety of boolean logical operations on its data, but it was not turing-complete. nine mk ii colossi were built (the mk i was converted to a mk ii making ten machines in total). colossus mark i contained 1,500 thermionic valves (tubes), but mark ii with 2,400 valves, was both five times faster and simpler to operate than mark i, greatly speeding the decoding process.the eniac (electronic numerical integrator and computer) was the first electronic programmable computer built in the u.s. although the eniac was similar to the colossus, it was much faster, more flexible, and it was turing-complete. like the colossus, a \"program\" on the eniac was defined by the states of its patch cables and switches, a far cry from the stored program electronic machines that came later. once a program was written, it had to be mechanically set into the machine with manual resetting of plugs and switches. the programmers of the eniac were six women, often known collectively as the \"eniac girls\".it combined the high speed of electronics with the ability to be programmed for many complex problems. it could add or subtract 5000 times a second, a thousand times faster than any other machine. it also had modules to multiply, divide, and square root. high speed memory was limited to 20 words (about 80 bytes). built under the direction of john mauchly and j. presper eckert at the university of pennsylvania, eniac\\'s development and construction lasted from 1943 to full operation at the end of 1945. the machine was huge, weighing 30 tons, using 200 kilowatts of electric power and contained over 18,000 vacuum tubes, 1,500 relays, and hundreds of thousands of resistors, capacitors, and inductors.=== modern computers ======= concept of modern computer ====the principle of the modern computer was proposed by alan turing in his seminal 1936 paper, on computable numbers. turing proposed a simple device that he called \"universal computing machine\" and that is now known as a universal turing machine. he proved that such a machine is capable of computing anything that is computable by executing instructions (program) stored on tape, allowing the machine to be programmable. the fundamental concept of turing\\'s design is the stored program, where all the instructions for computing are stored in memory. von neumann acknowledged that the central concept of the modern computer was due to this paper. turing machines are to this day a central object of study in theory of computation. except for the limitations imposed by their finite memory stores, modern computers are said to be turing-complete, which is to say, they have algorithm execution capability equivalent to a universal turing machine.==== stored programs ====early computing machines had fixed programs. changing its function required the re-wiring and re-structuring of the machine. with the proposal of the stored-program computer this changed. a stored-program computer includes by design an instruction set and can store in memory a set of instructions (a program) that details the computation. the theoretical basis for the stored-program computer was laid by alan turing in his 1936 paper. in 1945, turing joined the national physical laboratory and began work on developing an electronic stored-program digital computer. his 1945 report \"proposed electronic calculator\" was the first specification for such a device. john von neumann at the university of pennsylvania also circulated his first draft of a report on the edvac in 1945.the manchester baby was the world\\'s first stored-program computer. it was built at the university of manchester in england by frederic c. williams, tom kilburn and geoff tootill, and ran its first program on 21 june 1948. it was designed as a testbed for the williams tube, the first random-access digital storage device. although the computer was considered \"small and primitive\" by the standards of its time, it was the first working machine to contain all of the elements essential to a modern electronic computer. as soon as the baby had demonstrated the feasibility of its design, a project was initiated at the university to develop it into a more usable computer, the manchester mark 1. grace hopper was the first person to develop a compiler for programming language.the mark 1 in turn quickly became the prototype for the ferranti mark 1, the world\\'s first commercially available general-purpose computer. built by ferranti, it was delivered to the university of manchester in february 1951. at least seven of these later machines were delivered between 1953 and 1957, one of them to shell labs in amsterdam. in october 1947, the directors of british catering company j. lyons & company decided to take an active role in promoting the commercial development of computers. the leo i computer became operational in april 1951 and ran the world\\'s first regular routine office computer job.==== transistors ====the concept of a field-effect transistor was proposed by julius edgar lilienfeld in 1925. john bardeen and walter brattain, while working under william shockley at bell labs, built the first working transistor, the point-contact transistor, in 1947, which was followed by shockley\\'s bipolar junction transistor in 1948. from 1955 onwards, transistors replaced vacuum tubes in computer designs, giving rise to the \"second generation\" of computers. compared to vacuum tubes, transistors have many advantages: they are smaller, and require less power than vacuum tubes, so give off less heat. junction transistors were much more reliable than vacuum tubes and had longer, indefinite, service life. transistorized computers could contain tens of thousands of binary logic circuits in a relatively compact space. however, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications.at the university of manchester, a team under the leadership of tom kilburn designed and built a machine using the newly developed transistors instead of valves. their first transistorised computer and the first in the world, was operational by 1953, and a second version was completed there in april 1955. however, the machine did make use of valves to generate its 125 khz clock waveforms and in the circuitry to read and write on its magnetic drum memory, so it was not the first completely transistorized computer. that distinction goes to the harwell cadet of 1955, built by the electronics division of the atomic energy research establishment at harwell.the metal–oxide–silicon field-effect transistor (mosfet), also known as the mos transistor, was invented by mohamed m. atalla and dawon kahng at bell labs in 1959. it was the first truly compact transistor that could be miniaturised and mass-produced for a wide range of uses. with its high scalability, and much lower power consumption and higher density than bipolar junction transistors, the mosfet made it possible to build high-density integrated circuits. in addition to data processing, it also enabled the practical use of mos transistors as memory cell storage elements, leading to the development of mos semiconductor memory, which replaced earlier magnetic-core memory in computers. the mosfet led to the microcomputer revolution, and became the driving force behind the computer revolution. the mosfet is the most widely used transistor in computers, and is the fundamental building block of digital electronics.==== integrated circuits ====the next great advance in computing power came with the advent of the integrated circuit (ic).the idea of the integrated circuit was first conceived by a radar scientist working for the royal radar establishment of the ministry of defence, geoffrey w.a. dummer. dummer presented the first public description of an integrated circuit at the symposium on progress in quality electronic components in washington, d.c. on 7 may 1952.the first working ics were invented by jack kilby at texas instruments and robert noyce at fairchild semiconductor. kilby recorded his initial ideas concerning the integrated circuit in july 1958, successfully demonstrating the first working integrated example on 12 september 1958. in his patent application of 6 february 1959, kilby described his new device as \"a body of semiconductor material ... wherein all the components of the electronic circuit are completely integrated\". however, kilby\\'s invention was a hybrid integrated circuit (hybrid ic), rather than a monolithic integrated circuit (ic) chip. kilby\\'s ic had external wire connections, which made it difficult to mass-produce.noyce also came up with his own idea of an integrated circuit half a year later than kilby. noyce\\'s invention was the first true monolithic ic chip. his chip solved many practical problems that kilby\\'s had not. produced at fairchild semiconductor, it was made of silicon, whereas kilby\\'s chip was made of germanium. noyce\\'s monolithic ic was fabricated using the planar process, developed by his colleague jean hoerni in early 1959. in turn, the planar process was based on mohamed m. atalla\\'s work on semiconductor surface passivation by silicon dioxide in the late 1950s.modern monolithic ics are predominantly mos (metal-oxide-semiconductor) integrated circuits, built from mosfets (mos transistors). the earliest experimental mos ic to be fabricated was a 16-transistor chip built by fred heiman and steven hofstein at rca in 1962. general microelectronics later introduced the first commercial mos ic in 1964, developed by robert norman. following the development of the self-aligned gate (silicon-gate) mos transistor by robert kerwin, donald klein and john sarace at bell labs in 1967, the first silicon-gate mos ic with self-aligned gates was developed by federico faggin at fairchild semiconductor in 1968. the mosfet has since become the most critical device component in modern ics.the development of the mos integrated circuit led to the invention of the microprocessor, and heralded an explosion in the commercial and personal use of computers. while the subject of exactly which device was the first microprocessor is contentious, partly due to lack of agreement on the exact definition of the term \"microprocessor\", it is largely undisputed that the first single-chip microprocessor was the intel 4004, designed and realized by federico faggin with his silicon-gate mos ic technology, along with ted hoff, masatoshi shima and stanley mazor at intel. in the early 1970s, mos ic technology enabled the integration of more than 10,000 transistors on a single chip.system on a chip (socs) are complete computers on a microchip (or chip) the size of a coin. they may or may not have integrated ram and flash memory. if not integrated, the ram is usually placed directly above (known as package on package) or below (on the opposite side of the circuit board) the soc, and the flash memory is usually placed right next to the soc, this all done to improve data transfer speeds, as the data signals don\\'t have to travel long distances. since eniac in 1945, computers have advanced enormously, with modern socs (such as the snapdragon 865) being the size of a coin while also being hundreds of thousands of times more powerful than eniac, integrating billions of transistors, and consuming only a few watts of power.=== mobile computers ===the first mobile computers were heavy and ran from mains power. the 50 lb (23 kg) ibm 5100 was an early example. later portables such as the osborne 1 and compaq portable were considerably lighter but still needed to be plugged in. the first laptops, such as the grid compass, removed this requirement by incorporating batteries – and with the continued miniaturization of computing resources and advancements in portable battery life, portable computers grew in popularity in the 2000s. the same developments allowed manufacturers to integrate computing resources into cellular mobile phones by the early 2000s.these smartphones and tablets run on a variety of operating systems and recently became the dominant computing device on the market. these are powered by system on a chip (socs), which are complete computers on a microchip the size of a coin.', 'the earliest foundations of what would become computer science predate the invention of the modern digital computer. machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment.wilhelm schickard designed and constructed the first working mechanical calculator in 1623. in 1673, gottfried leibniz demonstrated a digital mechanical calculator, called the stepped reckoner. leibniz may be considered the first computer scientist and information theorist, for, among other reasons, documenting the binary number system. in 1820, thomas de colmar launched the mechanical calculator industry when he invented his simplified arithmometer, the first calculating machine strong enough and reliable enough to be used daily in an office environment. charles babbage started the design of the first automatic mechanical calculator, his difference engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his analytical engine. he started developing this machine in 1834, and \"in less than two years, he had sketched out many of the salient features of the modern computer\". \"a crucial step was the adoption of a punched card system derived from the jacquard loom\" making it infinitely programmable. in 1843, during the translation of a french article on the analytical engine, ada lovelace wrote, in one of the many notes she included, an algorithm to compute the bernoulli numbers, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer. around 1885, herman hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of ibm. following babbage, although unaware of his earlier work, percy ludgate in 1909 published the 2nd of the only two designs for mechanical analytical engines in history. in 1937, one hundred years after babbage\\'s impossible dream, howard aiken convinced ibm, which was making all kinds of punched card equipment and was also in the calculator business to develop his giant programmable calculator, the ascc/harvard mark i, based on babbage\\'s analytical engine, which itself used cards and a central computing unit. when the machine was finished, some hailed it as \"babbage\\'s dream come true\".during the 1940s, with the development of new and more powerful computing machines such as the atanasoff–berry computer and eniac, the term computer came to refer to the machines rather than their human predecessors. as it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study computation in general. in 1945, ibm founded the watson scientific computing laboratory at columbia university in new york city. the renovated fraternity house on manhattan\\'s west side was ibm\\'s first laboratory devoted to pure science. the lab is the forerunner of ibm\\'s research division, which today operates research facilities around the world. ultimately, the close relationship between ibm and the university was instrumental in the emergence of a new scientific discipline, with columbia offering one of the first academic-credit courses in computer science in 1946. computer science began to be established as a distinct academic discipline in the 1950s and early 1960s. the world\\'s first computer science degree program, the cambridge diploma in computer science, began at the university of cambridge computer laboratory in 1953. the first computer science department in the united states was formed at purdue university in 1962. since practical computers became available, many applications of computing have become distinct areas of study in their own rights.'], 'subcategorie': ['the discipline of computer architecture has three main subcategories:instruction set architecture (isa): defines the machine code that a processor reads and acts upon as well as the word size, memory address modes, processor registers, and data type.microarchitecture: also known as \"computer organization\", this describes how a particular processor will implement the isa. the size of a computer\\'s cpu cache for instance, is an issue that generally has nothing to do with the isa.systems design: includes all of the other hardware components within a computing system, such as data processing other than the cpu (e.g., direct memory access), virtualization, and multiprocessing.there are other technologies in computer architecture. the following technologies are used in bigger companies like intel, and were estimated in 2002 to count for 1% of all of computer architecture:macroarchitecture: architectural layers more abstract than microarchitectureassembly instruction set architecture: a smart assembler may convert an abstract assembly language common to a group of machines into slightly different machine language for different implementations.programmer-visible macroarchitecture: higher-level language tools such as compilers may define a consistent interface or contract to programmers using them, abstracting differences between underlying isa, uisa, and microarchitectures. for example, the c, c++, or java standards define different programmer-visible macroarchitectures.microcode: microcode is software that translates instructions to run on a chip. it acts like a wrapper around the hardware, presenting a preferred version of the hardware\\'s instruction set interface. this instruction translation facility gives chip designers flexible options: e.g. 1. a new improved version of the chip can use microcode to present the exact same instruction set as the old chip version, so all software targeting that instruction set will run on the new chip without needing changes. e.g. 2. microcode can present a variety of instruction sets for the same underlying chip, allowing it to run a wider variety of software.uisa: user instruction set architecture, refers to one of three subsets of the risc cpu instructions provided by powerpc risc processors. the uisa subset, are those risc instructions of interest to application developers. the other two subsets are vea (virtual environment architecture) instructions used by virtualization system developers, and oea (operating environment architecture) used by operation system developers.pin architecture: the hardware functions that a microprocessor should provide to a hardware platform, e.g., the x86 pins a20m, ferr/ignne or flush. also, messages that the processor should emit so that external caches can be invalidated (emptied). pin architecture functions are more flexible than isa functions because external hardware can adapt to new encodings, or change from a pin to a message. the term \"architecture\" fits, because the functions must be provided for compatible systems, even if the detailed method changes.'], 'role': [\"=== definition ===computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. the case of instruction set architecture can be used to illustrate the balance of these competing factors. more complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 loop instruction). however, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. the increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.the implementation involves integrated circuit design, packaging, power, and cooling. optimization of the design requires familiarity with compilers, operating systems to logic design, and packaging.=== instruction set architecture ===an instruction set architecture (isa) is the interface between the computer's software and hardware and also can be viewed as the programmer's view of the machine. computers do not understand high-level programming languages such as java, c++, or most programming languages used. a processor only understands instructions encoded in some numerical fashion, usually as binary numbers. software tools, such as compilers, translate those high level languages into instructions that the processor can understand.besides instructions, the isa defines items in the computer that are available to a program—e.g., data types, registers, addressing modes, and memory.  instructions locate these available items with register indexes (or names) and memory addressing modes.the isa of a computer is usually described in a small instruction manual, which describes how the instructions are encoded. also, it may define short (vaguely) mnemonic names for the instructions. the names can be recognized by a software development tool called an assembler.  an assembler is a computer program that translates a human-readable form of the isa into a computer-readable form.  disassemblers are also widely available, usually in debuggers and software programs to isolate and correct malfunctions in binary computer programs.isas vary in quality and completeness.  a good isa compromises between programmer convenience (how easy the code is to understand), size of the code (how much code is required to do a specific action), cost of the computer to interpret the instructions (more complexity means more hardware needed to decode and execute the instructions), and speed of the computer (with more complex decoding hardware comes longer decode time).  memory organization defines how instructions interact with the memory, and how memory interacts with itself.during design emulation, emulators can run programs written in a proposed instruction set. modern emulators can measure size, cost, and speed to determine whether a particular isa is meeting its goals.=== computer organization ===computer organization helps optimize performance-based products. for example, software engineers need to know the processing power of processors. they may need to optimize software in order to gain the most performance for the lowest price. this can require quite a detailed analysis of the computer's organization.  for example, in an sd card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.computer organization also helps plan the selection of a processor for a particular project. multimedia projects may need very rapid data access, while virtual machines may need fast interrupts. sometimes certain tasks need additional components as well.  for example, a computer capable of running a virtual machine needs virtual memory hardware so that the memory of different virtual computers can be kept separated. computer organization and features also affect power consumption and processor cost.=== implementation ===once an instruction set and micro-architecture have been designed, a practical machine must be developed. this design process is called the implementation. implementation is usually not considered architectural design, but rather hardware design engineering. implementation can be further broken down into several steps:logic implementation designs the circuits required at a logic-gate level.circuit implementation does transistor-level designs of basic elements (e.g., gates, multiplexers, latches) as well as of some larger blocks (alus, caches etc.) that may be implemented at the logic-gate level, or even at the physical level if the design calls for it.physical implementation draws physical circuits.  the different circuit components are placed in a chip floor plan or on a board and the wires connecting them are created.design validation tests the computer as a whole to see if it works in all situations and all timings. once the design validation process starts, the design at the logic level are tested using logic emulators. however, this is usually too slow to run a realistic test.  so, after making corrections based on the first test, prototypes are constructed using field-programmable gate-arrays (fpgas). most hobby projects stop at this stage.  the final step is to test prototype integrated circuits, which may require several redesigns.for cpus, the entire implementation process is organized differently and is often referred to as cpu design.\"], 'design goal': ['the exact form of a computer system depends on the constraints and goals. computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.the most common scheme does an in-depth power analysis and figures out how to keep power consumption low while maintaining adequate performance.=== performance ===modern computer performance is often described in instructions per cycle (ipc), which measures the efficiency of the architecture at any clock frequency; a faster ipc rate means the computer is faster. older computers had ipc counts as low as 0.1 while modern processors easily reach near 1. superscalar processors may reach three to five ipc by executing several instructions per clock cycle.counting machine-language instructions would be misleading because they can do varying amounts of work in different isas. the \"instruction\" in the standard measurements is not a count of the isa\\'s machine-language instructions, but a unit of measurement, usually based on the speed of the vax computer architecture.many people used to measure a computer\\'s speed by the clock rate (usually in mhz or ghz). this refers to the cycles per second of the main clock of the cpu. however, this metric is somewhat misleading, as a machine with a higher clock rate may not necessarily have greater performance. as a result, manufacturers have moved away from clock speed as a measure of performance.other factors influence speed, such as the mix of functional units, bus speeds, available memory, and the type and order of instructions in the programs.there are two main types of speed: latency and throughput. latency is the time between the start of a process and its completion. throughput is the amount of work done per unit time.  interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).performance is affected by a very wide range of design choices — for example, pipelining a processor usually makes latency worse, but makes throughput better. computers that control machinery usually need low interrupt latencies. these computers operate in a real-time environment and fail if an operation is not completed in a specified amount of time. for example, computer-controlled anti-lock brakes must begin braking within a predictable and limited time period after the brake pedal is sensed or else failure of the brake will occur.benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. although benchmarking shows strengths, it shouldn\\'t be how you choose a computer. often the measured machines split on different measures. for example, one system might handle scientific applications quickly, while another might render video games more smoothly. furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but don\\'t offer similar advantages to general tasks.=== power efficiency ===power efficiency is another important measurement in modern computers. a higher power efficiency can often be traded for lower speed or higher cost. the typical measurement when referring to power consumption in computer architecture is mips/w (millions of instructions per second per watt).modern circuits have less power required per transistor as the number of transistors per chip grows. this is because each transistor that is put in a new chip requires its own power supply and requires new pathways to be built to power it. however the number of transistors per chip is starting to increase at a slower rate. therefore, power efficiency is starting to become as important, if not more important than fitting more and more transistors into a single chip. recent processor designs have shown this emphasis as they put more focus on power efficiency rather than cramming as many transistors into a single chip as possible. in the world of embedded computers, power efficiency has long been an important goal next to throughput and latency.=== shifts in market demand ===increases in clock frequency have grown more slowly over the past few years, compared to power reduction improvements. this has been driven by the end of moore\\'s law and demand for longer battery life and reductions in size for mobile technology. this change in focus from higher clock rates to power consumption and miniaturization can be shown by the significant reductions in power consumption, as much as 50%, that were reported by intel in their release of the haswell microarchitecture; where they dropped their power consumption benchmark from 30 to 40 watts down to 10-20 watts. comparing this to the processing speed increase of 3 ghz to 4 ghz (2002 to 2006) it can be seen that the focus in research and development are shifting away from clock frequency and moving towards consuming less power and taking up less space.'], 'see also': ['', 'integer (computer science)', '', 'super-threadingspeculative multithreading', 'cardboard illustrative aid to computationinterconnect bottlenecklittle man computerrandom-access machineharvard architectureturing machineeckert architecture', '', '', '', 'control unithardware architecturehardware description language (hdl)instruction-level parallelism (ilp)list of amd cpu microarchitectureslist of intel cpu microarchitecturesprocessor designstream processingvhdlvery large-scale integration (vlsi)verilog'], 'reference': ['', '', '=== general ===', '', '', '', '', '', ''], 'source': ['john l. hennessy and david patterson (2006). computer architecture: a quantitative approach (fourth ed.). morgan kaufmann. isbn 978-0-12-370490-0.barton, robert s., \"functional design of computers\", communications of the acm 4(9): 405 (1961).barton, robert s., \"a new approach to the functional design of a digital computer\", proceedings of the western joint computer conference, may 1961, pp. 393–396. about the design of the burroughs b5000 computer.bell, c. gordon; and newell, allen (1971). \"computer structures: readings and examples\", mcgraw-hill.blaauw, g.a., and brooks, f.p., jr., \"the structure of system/360, part i-outline of the logical structure\", ibm systems journal, vol. 3, no. 2, pp. 119–135, 1964.tanenbaum, andrew s. (1979). structured computer organization. englewood cliffs, new jersey: prentice-hall. isbn 0-13-148521-0.', ''], 'external link': ['isca: proceedings of the international symposium on computer architecturemicro: ieee/acm international symposium on microarchitecturehpca: international symposium on high performance computer architectureasplos: international conference on architectural support for programming languages and operating systemsacm transactions on architecture and code optimizationieee transactions on computersthe von neumann architecture of computer systems', '\"automatic pipelining from transactional datapath specifications\" (pdf). retrieved 23 july 2014.tulsen, dean (18 january 2005). \"pipeline hazards\" (pdf).', 'a survey of processors with explicit multithreading, acm, march 2003, by theo ungerer, borut robi and jurij silcoperating system | difference between multitasking, multithreading and multiprocessing geeksforgeeks, 6 sept. 2018.', 'harvard vs von neumanna tool that emulates the behavior of a von neumann machinejohnny: a simple open source simulator of a von neumann machine for educational purposes', ' media related to computers at wikimedia commons wikiversity has a quiz on this articlewarhol & the computer', 'computer science at curliescholarly societies in computer science archived june 23, 2011, at the wayback machinewhat is computer science?best papers awards in computer science since 1996photographs of computer scientists by bertrand meyereecs.berkeley.edu=== bibliography and academic search engines ===citeseerx (article): search engine, digital library and repository for scientific and academic papers with a focus on computer and information science.dblp computer science bibliography (article): computer science bibliography website hosted at universität trier, in germany.the collection of computer science bibliographies (collection of computer science bibliographies)=== professional organizations ===association for computing machineryieee computer societyinformatics europeaaaiaaas computer science=== misc ===computer science—stack exchange: a community-run question-and-answer site for computer sciencewhat is computer science archived february 18, 2015, at the wayback machineis computer science science?computer science (software) must be considered as an independent discipline.'], 'uses of word': ['depending on how a computer is organized, word-size units may be used for:fixed-point numbersholders for fixed point, usually integer, numerical values may be available in one or in several different sizes, but one of the sizes available will almost always be the word. the other sizes, if any, are likely to be multiples or fractions of the word size. the smaller sizes are normally used only for efficient use of memory; when loaded into the processor, their values usually go into a larger, word sized holder.floating-point numbersholders for floating-point numerical values are typically either a word or a multiple of a word.addressesholders for memory addresses must be of a size capable of expressing the needed range of values but not be excessively large, so often the size used is the word though it can also be a multiple or fraction of the word size.registersprocessor registers are designed with a size appropriate for the type of data they hold, e.g. integers, floating-point numbers, or addresses. many computer architectures use general-purpose registers that are capable of storing data in multiple representations.memory–processor transferwhen the processor reads from the memory subsystem into a register or writes a register\\'s value to memory, the amount of data transferred is often a word. historically, this amount of bits which could be transferred in one cycle was also called a catena in some environments (such as the bull gamma 60). in simple memory subsystems, the word is transferred over the memory data bus, which typically has a width of a word or half-word. in memory subsystems that use caches, the word-sized transfer is the one between the processor and the first level of cache; at lower levels of the memory hierarchy larger transfers (which are a multiple of the word size) are normally used.unit of address resolutionin a given architecture, successive address values designate successive units of memory; this unit is the unit of address resolution. in most computers, the unit is either a character (e.g. a byte) or a word. (a few computers have used bit resolution.) if the unit is a word, then a larger amount of memory can be accessed using an address of a given size at the cost of added complexity to access individual characters. on the other hand, if the unit is a byte, then individual characters can be addressed (i.e. selected during the memory operation).instructionsmachine instructions are normally the size of the architecture\\'s word, such as in risc architectures, or a multiple of the \"char\" size that is a fraction of it. this is a natural choice since instructions and data usually share the same memory subsystem. in harvard architectures the word sizes of instructions and data need not be related, as instructions and data are stored in different memories; for example, the processor in the 1ess electronic telephone switch had 37-bit instructions and 23-bit data words.'], 'word size choice': ['when a computer architecture is designed, the choice of a word size is of substantial importance.  there are design considerations which encourage particular bit-group sizes for particular uses (e.g. for addresses), and these considerations point to different sizes for different uses.  however, considerations of economy in design strongly push for one size, or a very few sizes related by multiples or fractions (submultiples) to a primary size.  that preferred size becomes the word size of the architecture.character size was in the past (pre-variable-sized character encoding) one of the influences on unit of address resolution and the choice of word size.  before the mid-1960s, characters were most often stored in six bits; this allowed no more than 64 characters, so the alphabet was limited to upper case.  since it is efficient in time and space to have the word size be a multiple of the character size, word sizes in this period were usually multiples of 6 bits (in binary machines).  a common choice then was the 36-bit word, which is also a good size for the numeric properties of a floating point format.after the introduction of the ibm system/360 design, which used eight-bit characters and supported lower-case letters, the standard size of a character (or more accurately, a byte) became eight bits.  word sizes thereafter were naturally multiples of eight bits, with 16, 32, and 64 bits being commonly used.=== variable-word architectures ===early machine designs included some that used what is often termed a variable word length.  in this type of organization, an operand had no fixed length. depending on the machine and the instruction, the length might be denoted by a count field, by a delimiting character, or by an additional bit called, e.g., flag, word mark.  such machines often used binary-coded decimal in 4-bit digits, or in 6-bit characters, for numbers.  this class of machines included the ibm 702, ibm 705, ibm 7080, ibm 7010, univac 1050, ibm 1401, ibm 1620, and rca 301.most of these machines work on one unit of memory at a time and since each instruction or datum is several units long, each instruction takes several cycles just to access memory.  these machines are often quite slow because of this.  for example, instruction fetches on an ibm 1620 model i take 8 cycles just to read the 12 digits of the instruction (the model ii reduced this to 6 cycles, or 4 cycles if the instruction did not need both address fields). instruction execution took a completely variable number of cycles, depending on the size of the operands.=== word, bit and byte addressing ===the memory model of an architecture is strongly influenced by the word size.  in particular, the resolution of a memory address, that is, the smallest unit that can be designated by an address, has often been chosen to be the word.  in this approach, the word-addressable machine approach, address values which differ by one designate adjacent memory words.  this is natural in machines which deal almost always in word (or multiple-word) units, and has the advantage of allowing instructions to use minimally sized fields to contain addresses, which can permit a smaller instruction size or a larger variety of instructions.when byte processing is to be a significant part of the workload, it is usually more advantageous to use the byte, rather than the word, as the unit of address resolution. address values which differ by one designate adjacent bytes in memory.  this allows an arbitrary character within a character string to be addressed straightforwardly.  a word can still be addressed, but the address to be used requires a few more bits than the word-resolution alternative.  the word size needs to be an integer multiple of the character size in this organization.  this addressing approach was used in the ibm 360, and has been the most common approach in machines designed since then.when the workload involves processing fields of different sizes, it can be advantageous to address to the bit. machines with bit addressing may have some instructions that use a programmer-defined byte size and other instructions that operate on fixed data sizes. as an example, on the ibm 7030 (\"stretch\"), a floating point instruction can only address words while an integer arithmetic instruction can specify a field length of 1-64 bits, a byte size of 1-8 bits and an accumulator offset of 0-127 bits. in at byte-addressable machine with storage-to-storage (ss) instructions, there are typically move instructions to copy one or multiple bytes from one arbitrary location to another. in a byte-oriented (byte-addressable) machine without ss instructions, moving a single byte from one arbitrary location to another is typically:load the source bytestore the result back in the target byteindividual bytes can be accessed on a word-oriented machine in one of two ways.  bytes can be manipulated by a combination of shift and mask operations in registers. moving a single byte from one arbitrary location to another may require the equivalent of the following:load the word containing the source byteshift the source word to align the desired byte to the correct position in the target wordand the source word with a mask to zero out all but the desired bitsload the word containing the target byteand the target word with a mask to zero out the target byteor the registers containing the source and target words to insert the source bytestore the result back in the target locationalternatively many word-oriented machines implement byte operations with instructions using special byte pointers in registers or memory.  for example, the pdp-10 byte pointer contained the size of the byte in bits (allowing different-sized bytes to be accessed), the bit position of the byte within the word, and the word address of the data.  instructions could automatically adjust the pointer to the next byte on, for example, load and deposit (store) operations.=== powers of two ===different amounts of memory are used to store data values with different degrees of precision. the commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word).  converting the index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. in some cases this relationship can also avoid the use of division operations. as a result, most modern computer designs have word sizes (and other operand sizes) that are a power of two times the size of a byte.'], 'size familie': ['as computer designs have grown more complex, the central importance of a single word size to an architecture has decreased.  although more capable hardware can use a wider variety of sizes of data, market forces exert pressure to maintain backward compatibility while extending processor capability.  as a result, what might have been the central word size in a fresh design has to coexist as an alternative size to the original word size in a backward compatible design. the original word size remains available in future designs, forming the basis of a size family.in the mid-1970s, dec designed the vax to be a 32-bit successor of the 16-bit pdp-11. they used word for a 16-bit quantity, while longword referred to a 32-bit quantity; this terminology is the same as the terminology used for the pdp-11. this was in contrast to earlier machines, where the natural unit of addressing memory would be called a word, while a quantity that is one half a word would be called a halfword. in fitting with this scheme, a vax quadword is 64 bits.  they continued this 16-bit word/32-bit longword/64-bit quadword terminology with the 64-bit alpha.another example is the x86 family, of which processors of three different word lengths (16-bit, later 32- and 64-bit) have been released, while word continues to designate a 16-bit quantity. as software is routinely ported from one word-length to the next, some apis and documentation define or refer to an older (and thus shorter) word-length than the full word length on the cpu that software may be compiled for. also, similar to how bytes are used for small numbers in many programs, a shorter word (16 or 32 bits) may be used in contexts where the range of a wider word is not needed (especially where this can save considerable stack space or cache memory space). for example, microsoft\\'s windows api maintains the programming language definition of word as 16 bits, despite the fact that the api may be used on a 32- or 64-bit x86 processor, where the standard word size would be 32 or 64 bits, respectively. data structures containing such different sized words refer to them as:word (16 bits/2 bytes)dword (32 bits/4 bytes)qword (64 bits/8 bytes)a similar phenomenon has developed in intel\\'s x86 assembly language – because of the support for various sizes (and backward compatibility) in the instruction set, some instruction mnemonics carry \"d\" or \"q\" identifiers denoting \"double-\", \"quad-\" or \"double-quad-\", which are in terms of the architecture\\'s original 16-bit word size.an example with a different word size is the ibm system/360 family. in the system/360 architecture, system/370 architecture and system/390 architecture, there are 8-bit bytes, 16-bit halfwords, 32-bit words and 64-bit doublewords. the z/architecture, which is the 64-bit member of that architecture family, continues to refer to 16-bit halfwords, 32-bit words, and 64-bit doublewords, and additionally features 128-bit quadwords.in general, new processors must use the same data word lengths and virtual address widths as an older processor to have binary compatibility with that older processor.often carefully written source code – written with source-code compatibility and software portability in mind – can be recompiled to run on a variety of processors, even ones with different data word lengths or different address widths or both.'], 'table of word size': [''], 'note': ['', '', ''], 'background': ['instructions in a pipelined processor are performed in several stages, so that at any given time several instructions are being processed in the various stages of the pipeline, such as fetch and execute. there are many different instruction pipeline microarchitectures, and instructions may be executed out-of-order. a hazard occurs when two or more of these simultaneous (possibly out of order) instructions conflict.'], 'type': ['=== data hazards ===data hazards occur when instructions that exhibit data dependence modify data in different stages of a pipeline. ignoring potential data hazards can result in race conditions (also termed race hazards). there are three situations in which a data hazard can occur:read after write (raw), a true dependencywrite after read (war), an anti-dependencywrite after write (waw), an output dependencyread after read (rar) is not a hazard case.consider two instructions i1 and i2, with i1 occurring before i2 in program order.==== read after write (raw) ====(i2 tries to read a source before i1 writes to it)a read after write (raw) data hazard refers to a situation where an instruction refers to a result that has not yet been calculated or retrieved. this can occur because even though an instruction is executed after a prior instruction, the prior instruction has been processed only partly through the pipeline.===== example =====for example:i1. r2 <- r5 + r3i2. r4 <- r2 + r3the first instruction is calculating a value to be saved in register r2, and the second is going to use this value to compute a result for register r4. however, in a pipeline, when operands are fetched for the 2nd operation, the results from the first have not yet been saved, and hence a data dependency occurs.a data dependency occurs with instruction i2, as it is dependent on the completion of instruction i1.==== write after read (war) ====(i2 tries to write a destination before it is read by i1)a write after read (war) data hazard represents a problem with concurrent execution.===== example =====for example:i1. r4 <- r1 + r5i2. r5 <- r1 + r2in any situation with a chance that i2 may finish before i1 (i.e., with concurrent execution), it must be ensured that the result of register r5 is not stored before i1 has had a chance to fetch the operands.==== write after write (waw) ====(i2 tries to write an operand before it is written by i1)a write after write (waw) data hazard may occur in a concurrent execution environment.===== example =====for example:i1. r2 <- r4 + r7i2. r2 <- r1 + r3the write back (wb) of i2 must be delayed until i1 finishes executing.=== structural hazards ===a structural hazard occurs when two (or more) instructions that are already in pipeline need the same resource. the result is that instruction must be executed in series rather than parallel for a portion of pipeline. structural hazards are sometime referred to as resource hazards.example:a situation in which multiple instructions are ready to enter the execute instruction phase and there is a single alu (arithmetic logic unit). one solution to such resource hazard is to increase available resources, such as having multiple ports into main memory and multiple alu (arithmetic logic unit) units.=== control hazards (branch hazards or instruction hazards) ===control hazard occurs when the pipeline makes wrong decisions on branch prediction and therefore brings instructions into the pipeline that must subsequently be discarded. the term branch hazard also refers to a control hazard.', 'computers can be classified in a number of different ways, including:=== by architecture ===analog computerdigital computerhybrid computerharvard architecturevon neumann architecturecomplex instruction set computerreduced instruction set computer=== by size, form-factor and purpose ===supercomputermainframe computerminicomputer (term no longer used)serverrackmount serverblade servertower serverpersonal computerworkstationmicrocomputer (term no longer used)home computerdesktop computertower desktopslimline desktopmultimedia computer (non-linear editing system computers, video editing pcs and the like)gaming computerall-in-one pcnettop (small form factor pcs, mini pcs)home theater pckeyboard computerportable computerthin clientinternet appliancelaptopdesktop replacement computergaming laptoprugged laptop2-in-1 pcultrabookchromebooksubnotebooknetbookmobile computers:tablet computersmartphoneultra-mobile pcpocket pcpalmtop pchandheld pcwearable computersmartwatchsmartglassessingle-board computerplug computerstick pcprogrammable logic controllercomputer-on-modulesystem on modulesystem in a packagesystem-on-chip (also known as an application processor or ap if it lacks circuitry such as radio circuitry)microcontroller'], 'eliminating hazard': ['=== generic ======= pipeline bubbling ====bubbling the pipeline, also termed a pipeline break or pipeline stall, is a method to preclude data, structural, and branch hazards. as instructions are fetched, control logic determines whether a hazard could/will occur. if this is true, then the control logic inserts no operations (nops) into the pipeline. thus, before the next instruction (which would cause the hazard) executes, the prior one will have had sufficient time to finish and prevent the hazard. if the number of nops equals the number of stages in the pipeline, the processor has been cleared of all instructions and can proceed free from hazards. all forms of stalling introduce a delay before the processor can resume execution.flushing the pipeline occurs when a branch instruction jumps to a new memory location, invalidating all prior stages in the pipeline.  these prior stages are cleared, allowing the pipeline to continue at the new instruction indicated by the branch.=== data hazards ===there are several main solutions and algorithms used to resolve data hazards:insert a pipeline bubble whenever a read after write (raw) dependency is encountered, guaranteed to increase latency, oruse out-of-order execution to potentially prevent the need for pipeline bubblesuse operand forwarding to use data from later stages in the pipelinein the case of out-of-order execution, the algorithm used can be:scoreboarding, in which case a pipeline bubble is needed only when there is no functional unit availablethe tomasulo algorithm, which uses register renaming, allowing continual issuing of instructionsthe task of removing data dependencies can be delegated to the compiler, which can fill in an appropriate number of nop instructions between dependent instructions to ensure correct operation, or re-order instructions where possible.==== operand forwarding ======== examples ====in the following examples, computed values are in bold, while register numbers are not.for example, to write the value 3 to register 1, (which already contains a 6), and then add 7 to register 1 and store the result in register 2, i.e.:i0: r1 = 6i1: r1 = 3i2: r2 = r1 + 7 = 10following execution, register 2 should contain the value 10. however, if i1 (write 3 to register 1) does not fully exit the pipeline before i2 starts executing, it means that r1 does not contain the value 3 when i2 performs its addition. in such an event, i2 adds 7 to the old value of register 1 (6), and so register 2 contains 13 instead, i.e.:i0: r1 = 6i2: r2 = r1 + 7 = 13i1: r1 = 3this error occurs because i2 reads register 1 before i1 has committed/stored the result of its write operation to register 1. so when i2 is reading the contents of register 1, register 1 still contains 6, not 3.forwarding (described below) helps correct such errors by depending on the fact that the output of i1 (which is 3) can be used by subsequent instructions before the value 3 is committed to/stored in register 1.forwarding applied to the example means that there is no wait to commit/store the output of i1 in register 1 (in this example, the output is 3) before making that output available to the subsequent instruction (in this case, i2). the effect is that i2 uses the correct (the more recent) value of register 1: the commit/store was made immediately and not pipelined.with forwarding enabled, the instruction decode/execution (id/ex) stage of the pipeline now has two inputs: the value read from the register specified (in this example, the value 6 from register 1), and the new value of register 1 (in this example, this value is 3) which is sent from the next stage instruction execute/memory access (ex/mem). added control logic is used to determine which input to use.=== control hazards (branch hazards) ===to avoid control hazards microarchitectures can:insert a pipeline bubble (discussed above), guaranteed to increase latency, oruse branch prediction and essentially make educated guesses about which instructions to insert, in which case a pipeline bubble will only be needed in the case of an incorrect predictionin the event that a branch causes a pipeline bubble after incorrect instructions have entered the pipeline, care must be taken to prevent any of the wrongly-loaded instructions from having any effect on the processor state excluding energy wasted processing them before they were discovered to be loaded incorrectly.=== other techniques ===memory latency is another factor that designers must attend to, because the delay could reduce performance. different types of memory have different accessing time to the memory. thus, by choosing a suitable type of memory, designers can improve the performance of the pipelined data path.'], 'overview': [\"the multithreading paradigm has become more popular as efforts to further exploit instruction-level parallelism have stalled since the late 1990s. this allowed the concept of throughput computing to re-emerge from the more specialized field of transaction processing. even though it is very difficult to further speed up a single thread or single program, most computer systems are actually multitasking among multiple threads or programs. thus, techniques that improve the throughput of all tasks result in overall performance gains.two major techniques for throughput computing are multithreading and multiprocessing.=== advantages ===if a thread gets a lot of cache misses, the other threads can continue taking advantage of the unused computing resources, which may lead to faster overall execution, as these resources would have been idle if only a single thread were executed. also, if a thread cannot use all the computing resources of the cpu (because instructions depend on each other's result), running another thread may prevent those resources from becoming idle.=== disadvantages ===multiple threads can interfere with each other when sharing hardware resources such as caches or translation lookaside buffers (tlbs). as a result, execution times of a single thread are not improved and can be degraded, even when only one thread is executing, due to lower frequencies or additional pipeline stages that are necessary to accommodate thread-switching hardware.overall efficiency varies; intel claims up to 30% improvement with its hyper-threading technology, while a synthetic program just performing a loop of non-optimized dependent floating-point operations actually gains a 100% speed improvement when run in parallel. on the other hand, hand-tuned assembly language programs using mmx or altivec extensions and performing data prefetches (as a good video encoder might) do not suffer from cache misses or idle computing resources. such programs therefore do not benefit from hardware multithreading and can indeed see degraded performance due to contention for shared resources.from the software standpoint, hardware support for multithreading is more visible to software, requiring more changes to both application programs and operating systems than multiprocessing. hardware techniques used to support multithreading often parallel the software techniques used for computer multitasking. thread scheduling is also a major problem in multithreading.\", \"most computer programs contain conditional code, which will be executed only under specific conditions depending on factors that cannot be determined beforehand, for example depending on user input. as the majority of processors simply execute the next instruction in a sequence, the traditional solution is to insert branch instructions that allow a program to conditionally branch to a different section of code, thus changing the next step in the sequence. this was sufficient until designers began improving performance by implementing instruction pipelining, a method which is slowed down by branches. for a more thorough description of the problems which arose, and a popular solution, see branch predictor.luckily, one of the more common patterns of code that normally relies on branching has a more elegant solution. consider the following pseudocode:on a system that uses conditional branching, this might translate to machine instructions looking similar to:with predication, all possible branch paths are coded inline, but some instructions execute while others do not. the basic idea is that each instruction is associated with a predicate (the word here used similarly to its usage in predicate logic) and that the instruction will only be executed if the predicate is true. the machine code for the above example using predication might look something like this:besides eliminating branches, less code is needed in total, provided the architecture provides predicated instructions. while this does not guarantee faster execution in general, it will if the dosomething and dosomethingelse blocks of code are short enough.predication's simplest form is partial predication, where the architecture has conditional move or conditional select instructions. conditional move instructions write the contents of one register over another only if the predicate's value is true, whereas conditional select instructions choose which of two registers has its contents written to a third based on the predicate's value. a more generalized and capable form is full predication. full predication has a set of predicate registers for storing predicates (which allows multiple nested or sequential branches to be simultaneously eliminated) and most instructions in the architecture have a register specifier field to specify which predicate register supplies the predicate.\"], 'types of multithreading': ['=== interleaved/temporal multithreading ======= coarse-grained multithreading ====the simplest type of multithreading occurs when one thread runs until it is blocked by an event that normally would create a long-latency stall. such a stall might be a cache miss that has to access off-chip memory, which might take hundreds of cpu cycles for the data to return. instead of waiting for the stall to resolve, a threaded processor would switch execution to another thread that was ready to run. only when the data for the previous thread had arrived, would the previous thread be placed back on the list of ready-to-run threads.for example:cycle i: instruction j from thread a is issued.cycle i + 1: instruction j + 1 from thread a is issued.cycle i + 2: instruction j + 2 from thread a is issued, which is a load instruction that misses in all caches.cycle i + 3: thread scheduler invoked, switches to thread b.cycle i + 4: instruction k from thread b is issued.cycle i + 5: instruction k + 1 from thread b is issued.conceptually, it is similar to cooperative multi-tasking used in real-time operating systems, in which tasks voluntarily give up execution time when they need to wait upon some type of the event. this type of multithreading is known as block, cooperative or coarse-grained multithreading.the goal of multithreading hardware support is to allow quick switching between a blocked thread and another thread ready to run. switching from one thread to another means the hardware switches from using one register set to another. to achieve this goal, the hardware for the program visible registers, as well as some processor control registers (such as the program counter), is replicated. for example, to quickly switch between two threads, the processor is built with two sets of registers.additional hardware support for multithreading allows thread switching to be done in one cpu cycle, bringing performance improvements. also, additional hardware allows each thread to behave as if it were executing alone and not sharing any hardware resources with other threads, minimizing the amount of software changes needed within the application and the operating system to support multithreading.many families of microcontrollers and embedded processors have multiple register banks to allow quick context switching for interrupts. such schemes can be considered a type of block multithreading among the user program thread and the interrupt threads.==== interleaved multithreading ====the purpose of interleaved multithreading is to remove all data dependency stalls from the execution pipeline. since one thread is relatively independent from other threads, there is less chance of one instruction in one pipelining stage needing an output from an older instruction in the pipeline. conceptually, it is similar to preemptive multitasking used in operating systems; an analogy would be that the time slice given to each active thread is one cpu cycle.for example:cycle i + 1: an instruction from thread b is issued.cycle i + 2: an instruction from thread c is issued.this type of multithreading was first called barrel processing, in which the staves of a barrel represent the pipeline stages and their executing threads. interleaved, preemptive, fine-grained or time-sliced multithreading are more modern terminology.in addition to the hardware costs discussed in the block type of multithreading, interleaved multithreading has an additional cost of each pipeline stage tracking the thread id of the instruction it is processing. also, since there are more threads being executed concurrently in the pipeline, shared resources such as caches and tlbs need to be larger to avoid thrashing between the different threads.=== simultaneous multithreading ===the most advanced type of multithreading applies to superscalar processors. whereas a normal superscalar processor issues multiple instructions from a single thread every cpu cycle, in simultaneous multithreading (smt) a superscalar processor can issue instructions from multiple threads every cpu cycle. recognizing that any single thread has a limited amount of instruction-level parallelism, this type of multithreading tries to exploit parallelism available across multiple threads to decrease the waste associated with unused issue slots.for example:cycle i: instructions j and j + 1 from thread a and instruction k from thread b are simultaneously issued.cycle i + 1: instruction j + 2 from thread a, instruction k + 1 from thread b, and instruction m from thread c are all simultaneously issued.cycle i + 2: instruction j + 3 from thread a and instructions m + 1 and m + 2 from thread c are all simultaneously issued.to distinguish the other types of multithreading from smt, the term \"temporal multithreading\" is used to denote when instructions from only one thread can be issued at a time.in addition to the hardware costs discussed for interleaved multithreading, smt has the additional cost of each pipeline stage tracking the thread id of each instruction being processed. again, shared resources such as caches and tlbs have to be sized for the large number of active threads being processed.implementations include dec (later compaq) ev8 (not completed), intel hyper-threading technology, ibm power5/power6/power7/power8/power9, ibm z13/z14/z15, sun microsystems ultrasparc t2, cray xmt, and amd bulldozer and zen microarchitectures.'], 'implementation specific': ['a major area of research is the thread scheduler that must quickly choose from among the list of ready-to-run threads to execute next, as well as maintain the ready-to-run and stalled thread lists. an important subtopic is the different thread priority schemes that can be used by the scheduler. the thread scheduler might be implemented totally in software, totally in hardware, or as a hardware/software combination.another area of research is what type of events should cause a thread switch: cache misses, inter-thread communication, dma completion, etc.if the multithreading scheme replicates all of the software-visible state, including privileged control registers and tlbs, then it enables virtual machines to be created for each thread. this allows each thread to run its own operating system on the same processor. on the other hand, if only user-mode state is saved, then less hardware is required, which would allow more threads to be active at one time for the same die area or cost.'], 'capabilitie': ['on a large scale, the ability to treat instructions as data is what makes assemblers, compilers, linkers, loaders, and other automated programming tools possible. it makes \"programs that write programs\" possible.  this has made a sophisticated self-hosting computing ecosystem flourish around von neumann architecture machines.some high level languages leverage the von neumann architecture by providing an abstract, machine-independent way to manipulate executable code at runtime (e.g., lisp), or by using runtime information to tune just-in-time compilation (e.g. languages hosted on the java virtual machine, or languages embedded in web browsers).on a smaller scale, some repetitive operations such as bitblt or pixel and vertex shaders can be accelerated on general purpose processors with just-in-time compilation techniques. this is one use of self-modifying code that has remained popular.== development of the stored-program concept ==the mathematician alan turing, who had been alerted to a problem of mathematical logic by the lectures of max newman at the university of cambridge, wrote a paper in 1936 entitled on computable numbers, with an application to the entscheidungsproblem, which was published in the proceedings of the london mathematical society. in it he described a hypothetical machine he called a universal computing machine, now known as the \"universal turing machine\". the hypothetical machine had an infinite store (memory in today\\'s terminology) that contained both instructions and data. john von neumann became acquainted with turing while he was a visiting professor at cambridge in 1935, and also during turing\\'s phd year at the institute for advanced study in princeton, new jersey during 1936–1937. whether he knew of turing\\'s paper of 1936 at that time is not clear.in 1936, konrad zuse also anticipated, in two patent applications, that machine instructions could be stored in the same storage used for data.independently, j. presper eckert and john mauchly, who were developing the eniac at the moore school of electrical engineering of the university of pennsylvania, wrote about the stored-program concept in december 1943. in planning a new machine, edvac, eckert wrote in january 1944 that they would store data and programs in a new addressable memory device, a mercury metal delay-line memory. this was the first time the construction of a practical stored-program machine was proposed.  at that time, he and mauchly were not aware of turing\\'s work.von neumann was involved in the manhattan project at the los alamos national laboratory. it required huge amounts of calculation, and thus drew him to the eniac project, during the summer of 1944. there he joined the ongoing discussions on the design of this stored-program computer, the edvac. as part of that group, he wrote up a description titled first draft of a report on the edvac based on the work of eckert and mauchly. it was unfinished when his colleague herman goldstine circulated it, and bore only von neumann\\'s name (to the consternation of eckert and mauchly). the paper was read by dozens of von neumann\\'s colleagues in america and europe, and influenced the next round of computer designs.jack copeland considers that it is \"historically inappropriate to refer to electronic stored-program digital computers as \\'von neumann machines\\'\". his los alamos colleague stan frankel said of von neumann\\'s regard for turing\\'s ideasi know that in or about 1943 or \\'44 von neumann was well aware of the fundamental importance of turing\\'s paper of 1936….von neumann introduced me to that paper and at his urging i studied it with care. many people have acclaimed von neumann as the \"father of the computer\" (in a modern sense of the term) but i am sure that he would never have made that mistake himself. he might well be called the midwife, perhaps, but he firmly emphasized to me, and to others i am sure, that the fundamental conception is owing to turing— in so far as not anticipated by babbage…. both turing and von neumann, of course, also made substantial contributions to the \"reduction to practice\" of these concepts but i would not regard these as comparable in importance with the introduction and explication of the concept of a computer able to store in its memory its program of activities and of modifying that program in the course of these activities.at the time that the \"first draft\" report was circulated, turing was producing a report entitled proposed electronic calculator. it described in engineering and programming detail, his idea of a machine he called the automatic computing engine (ace). he presented this to the executive committee of the british national physical laboratory on february 19, 1946. although turing knew from his wartime experience at bletchley park that what he proposed was feasible, the secrecy surrounding colossus, that was subsequently maintained for several decades, prevented him from saying so. various successful implementations of the ace design were produced.both von neumann\\'s and turing\\'s papers described stored-program computers, but von neumann\\'s earlier paper achieved greater circulation and the computer architecture it outlined became known as the \"von neumann architecture\". in the 1953 publication faster than thought: a symposium on digital computing machines (edited by b. v. bowden), a section in the chapter on computers in america reads as follows:the machine of the institute for advanced studies, princetonin 1945, professor j. von neumann, who was then working at the moore school of engineering in philadelphia, where the e.n.i.a.c. had been built, issued on behalf of a group of his co-workers, a report on the logical design of digital computers. the report contained a detailed proposal for the design of the machine that has since become known as the e.d.v.a.c. (electronic discrete variable automatic computer). this machine has only recently been completed in america, but the von neumann report inspired the construction of the e.d.s.a.c. (electronic delay-storage automatic calculator) in cambridge (see page 130).in 1947, burks, goldstine and von neumann published another report that outlined the design of another type of machine (a parallel machine this time) that would be exceedingly fast, capable perhaps of 20,000 operations per second. they pointed out that the outstanding problem in constructing such a machine was the development of suitable memory with instantaneously accessible contents. at first they suggested using a special vacuum tube—called the \"selectron\"—which the princeton laboratories of rca had invented. these tubes were expensive and difficult to make, so von neumann subsequently decided to build a machine based on the williams memory. this machine—completed in june, 1952 in princeton—has become popularly known as the maniac. the design of this machine inspired at least half a dozen machines now being built in america, all known affectionately as \"johniacs\".in the same book, the first two paragraphs of a chapter on ace read as follows:automatic computation at the national physical laboratoryone of the most modern digital computers which embodies developments and improvements in the technique of automatic electronic computing was recently demonstrated at the national physical laboratory, teddington, where it has been designed and built by a small team of mathematicians and electronics research engineers on the staff of the laboratory, assisted by a number of production engineers from the english electric company, limited. the equipment so far erected at the laboratory is only the pilot model of a much larger installation which will be known as the automatic computing engine, but although comparatively small in bulk and containing only about 800 thermionic valves, as can be judged from plates xii, xiii and xiv, it is an extremely rapid and versatile calculating machine.the basic concepts and abstract principles of computation by a machine were formulated by dr. a. m. turing, f.r.s., in a paper1. read before the london mathematical society in 1936, but work on such machines in britain was delayed by the war. in 1945, however, an examination of the problems was made at the national physical laboratory by mr. j. r. womersley, then superintendent of the mathematics division of the laboratory. he was joined by dr. turing and a small staff of specialists, and, by 1947, the preliminary planning was sufficiently advanced to warrant the establishment of the special group already mentioned. in april, 1948, the latter became the electronics section of the laboratory, under the charge of mr. f. m. colebrook.== early von neumann-architecture computers ==the first draft described a design that was used by many universities and corporations to construct their computers. among these various computers, only illiac and ordvac had compatible instruction sets.arc2 (birkbeck, university of london) officially came online on may 12, 1948.manchester baby (victoria university of manchester, england) made its first successful run of a stored program on june 21, 1948.edsac (university of cambridge, england) was the first practical stored-program electronic computer (may 1949)manchester mark 1 (university of manchester, england) developed from the baby (june 1949)csirac (council for scientific and industrial research) australia (november 1949)mesm in kyiv, ukraine (november 1950)edvac (ballistic research laboratory, computing laboratory at aberdeen proving ground 1951)ordvac (u-illinois) at aberdeen proving ground, maryland (completed november 1951)ias machine at princeton university (january 1952)maniac i at los alamos scientific laboratory (march 1952)illiac at the university of illinois, (september 1952)besm-1 in moscow (1952)avidac at argonne national laboratory (1953)oracle at oak ridge national laboratory (june 1953)besk in stockholm (1953)johnniac at rand corporation (january 1954)dask in denmark (1955)weizac at the weizmann institute of science in rehovot, israel (1955)perm in munich (1956)silliac in sydney (1956)== early stored-program computers ==the date information in the following chronology is difficult to put into proper order. some dates are for first running a test program, some dates are the first time the computer was demonstrated or completed, and some dates are for the first delivery or installation.the ibm ssec had the ability to treat instructions as data, and was publicly demonstrated on january 27, 1948. this ability was claimed in a us patent. however it was partially electromechanical, not fully electronic. in practice, instructions were read from paper tape due to its limited memory.the arc2 developed by andrew booth and kathleen booth at birkbeck, university of london officially came online on may 12, 1948. it featured the first rotating drum storage device.the manchester baby was the first fully electronic computer to run a stored program. it ran a factoring program for 52 minutes on june 21, 1948, after running a simple division program and a program to show that two numbers were relatively prime.the eniac was modified to run as a primitive read-only stored-program computer (using the function tables for program rom) and was demonstrated as such on september 16, 1948, running a program by adele goldstine for von neumann.the binac ran some test programs in february, march, and april 1949, although was not completed until september 1949.the manchester mark 1 developed from the baby project.  an intermediate version of the mark 1 was available to run programs in april 1949, but was not completed until october 1949.the edsac ran its first program on may 6, 1949.the edvac was delivered in august 1949, but it had problems that kept it from being put into regular operation until 1951.the csir mk i ran its first program in november 1949.the seac was demonstrated in april 1950.the pilot ace ran its first program on may 10, 1950, and was demonstrated in december 1950.the swac was completed in july 1950.the whirlwind was completed in december 1950 and was in actual use in april 1951.the first era atlas (later the commercial era 1101/univac 1101) was installed in december 1950.'], 'evolution': ['through the decades of the 1960s and 1970s computers generally became both smaller and faster, which led to evolutions in their architecture. for example, memory-mapped i/o lets input and output devices be treated the same as memory. a single system bus could be used to provide a modular system with lower cost. this is sometimes called a \"streamlining\" of the architecture.in subsequent decades, simple microcontrollers would sometimes omit features of the model to lower cost and size.larger computers added features for higher performance.'], 'design limitation': ['=== von neumann bottleneck ===the shared bus between the program memory and data memory leads to the von neumann bottleneck, the limited throughput (data transfer rate) between the central processing unit (cpu) and memory compared to the amount of memory.  because the single bus can only access one of the two classes of memory at a time, throughput is lower than the rate at which the cpu can work.  this seriously limits the effective processing speed when the cpu is required to perform minimal processing on large amounts of data.  the cpu is continually forced to wait for needed data to move to or from memory.  since cpu speed and memory size have increased much faster than the throughput between them, the bottleneck has become more of a problem, a problem whose severity increases with every new generation of cpu.the von neumann bottleneck was described by john backus in his 1977 acm turing award lecture.  according to backus:surely there must be a less primitive way of making big changes in the store than by pushing vast numbers of words back and forth through the von neumann bottleneck. not only is this tube a literal bottleneck for the data traffic of a problem, but, more importantly, it is an intellectual bottleneck that has kept us tied to word-at-a-time thinking instead of encouraging us to think in terms of the larger conceptual units of the task at hand. thus programming is basically planning and detailing the enormous traffic of words through the von neumann bottleneck, and much of that traffic concerns not significant data itself, but where to find it.==== mitigations ====there are several known methods for mitigating the von neumann performance bottleneck.  for example, the following all can improve performance:providing a cache between the cpu and the main memoryproviding separate caches or separate access paths for data and instructions (the so-called modified harvard architecture)using branch predictor algorithms and logicproviding a limited cpu stack or other on-chip scratchpad memory to reduce memory accessimplementing the cpu and the memory hierarchy as a system on chip, providing greater locality of reference and thus reducing latency and increasing throughput between processor registers and main memorythe problem can also be sidestepped somewhat by using parallel computing, using for example the non-uniform memory access (numa) architecture—this approach is commonly employed by supercomputers. it is less clear whether the intellectual bottleneck that backus criticized has changed much since 1977. backus\\'s proposed solution has not had a major influence. modern functional programming and object-oriented programming are much less geared towards \"pushing vast numbers of words back and forth\" than earlier languages like fortran were, but internally, that is still what computers spend much of their time doing, even highly parallel supercomputers.as of 1996, a database benchmark study found that three out of four cpu cycles were spent waiting for memory. researchers expect that increasing the number of simultaneous instruction streams with multithreading or single-chip multiprocessing will make this bottleneck even worse.  in the context of multi-core processors, additional overhead is required to maintain cache coherence between processors and threads.=== self-modifying code ===aside from the von neumann bottleneck, program modifications can be quite harmful, either by accident or design.  in some simple stored-program computer designs, a malfunctioning program can damage itself, other programs, or the operating system, possibly leading to a computer crash. memory protection and other forms of access control can usually protect against both accidental and malicious program changes.'], 'further reading': ['', 'clements, alan (2013). \"8.3.7 predication\". computer organization & architecture: themes and variations. cengage learning. pp. 532–9. isbn 1-285-41542-6.', '', 'patterson, d.; hennessy, j. (2004). computer organization and design: the hardware/software interface. morgan kaufmann. isbn 1-55860-604-1.hamacher, v. c.; vrasenic, z. g.; zaky, s. g. (2001). computer organization. mcgraw-hill. isbn 0-07-232086-9.stallings, william (2002). computer organization and architecture. prentice hall. isbn 0-13-035119-9.hayes, j. p. (2002). computer architecture and organization. mcgraw-hill. isbn 0-07-286198-3.schneider, gary michael (1985). the principles of computer organization. wiley. pp. 6–7. isbn 0-471-88552-5.mano, m. morris (1992). computer system architecture. prentice hall. p. 3. isbn 0-13-175563-3.abd-el-barr, mostafa; el-rewini, hesham (2004). fundamentals of computer organization and architecture. wiley. p. 1. isbn 0-471-46741-3.gardner, j (2001). \"pc processor microarchitecture\". extremetech.gilreath, william f.; laplante, phillip a. (2012) [2003]. computer architecture: a minimalist perspective. springer. isbn 978-1-4615-0237-1.patterson, david a. (10 october 2018). a new golden age for computer architecture. us berkeley acm a.m. turing laureate colloquium. ctwj53r07yi.'], 'advantage': ['the main purpose of predication is to avoid jumps over very small sections of program code, increasing the effectiveness of pipelined execution and avoiding problems with the cache. it also has a number of more subtle benefits:functions that are traditionally computed using simple arithmetic and bitwise operations may be quicker to compute using predicated instructions.predicated instructions with different predicates can be mixed with each other and with unconditional code, allowing better instruction scheduling and so even better performance.elimination of unnecessary branch instructions can make the execution of necessary branches, such as those that make up loops, faster by lessening the load on branch prediction mechanisms.elimination of the cost of a branch misprediction which can be high on deeply pipelined architectures.instruction sets that have comprehensive condition codes generated by instructions may reduce code size further by directly using the condition registers in or as predication.'], 'disadvantage': [\"predication's primary drawback is in increased encoding space. in typical implementations, every instruction reserves a bitfield for the predicate specifying under what conditions that instruction should have an effect. when available memory is limited, as on embedded devices, this space cost can be prohibitive. however, some architectures such as thumb-2 are able to avoid this issue (see below). other detriments are the following:predication complicates the hardware by adding levels of logic to critical paths and potentially degrades clock speed.a predicated block includes cycles for all operations, so shorter paths may take longer and be penalized.predication is not usually speculated and causes a longer dependency chain. for ordered data this translates to a performance loss compared to a predictable branch.predication is most effective when paths are balanced or when the longest path is the most frequently executed, but determining such a path is very difficult at compile time, even in the presence of profiling information.\"], 'etymology': ['according to the oxford english dictionary, the first known use of computer was in a 1613 book called the yong mans gleanings by the english writer richard brathwait: \"i haue  [sic] read the truest computer of times, and the best arithmetician that euer [sic] breathed, and he reduceth thy dayes into a short number.\" this usage of the term referred to a human computer, a person who carried out calculations or computations. the word continued with the same meaning until the middle of the 20th century. during the latter part of this period women were often hired as computers because they could be paid less than their male counterparts. by 1943, most human computers were women.the online etymology dictionary gives the first attested use of computer in the 1640s, meaning \\'one who calculates\\'; this is an \"agent noun from compute (v.)\". the online etymology dictionary states that the use of the term to mean \"\\'calculating machine\\' (of any type) is from 1897.\"  the online etymology dictionary indicates that the \"modern use\" of the term, to mean \\'programmable digital electronic computer\\' dates from \"1945 under this name; [in a] theoretical [sense] from 1937, as turing machine\".', 'although first proposed in 1956, the term \"computer science\" appears in a 1959 article in communications of the acm,in which louis fein argues for the creation of a graduate school in computer sciences analogous to the creation of harvard business school in 1921, justifying the name by arguing that, like management science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline.his efforts, and those of others such as numerical analyst george forsythe, were rewarded: universities went on to create such departments, starting with purdue in 1962. despite its name, a significant amount of computer science does not involve the study of computers themselves. because of this, several alternative names have been proposed. certain departments of major universities prefer the term computing science, to emphasize precisely that difference. danish scientist peter naur suggested the term datalogy, to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. the first scientific institution to use the term was the department of datalogy at the university of copenhagen, founded in 1969, with peter naur being the first professor in datalogy. the term is used mainly in the scandinavian countries. an alternative term, also proposed by naur, is data science; this is now used for a multi-disciplinary field of data analysis, including statistics and databases.in the early days of computing, a number of terms for the practitioners of the field of computing were suggested in the communications of the acm—turingineer, turologist, flow-charts-man, applied meta-mathematician, and applied epistemologist. three months later in the same journal, comptologist was suggested, followed next year by hypologist. the term computics has also been suggested. in europe, terms derived from contracted translations of the expression \"automatic information\" (e.g. \"informazione automatica\" in italian) or \"information and mathematics\" are often used, e.g. informatique (french), informatik (german), informatica (italian, dutch), informática (spanish, portuguese), informatika (slavic languages and hungarian) or pliroforiki (πληροφορική, which means informatics) in greek. similar words have also been adopted in the uk (as in the school of informatics, university of edinburgh). \"in the u.s., however, informatics is linked with applied computing, or computing in the context of another domain.\"a folkloric quotation, often attributed to—but almost certainly not first formulated by—edsger dijkstra, states that \"computer science is no more about computers than astronomy is about telescopes.\" the design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. for example, the study of computer hardware is usually considered part of computer engineering, while the study of commercial computer systems and their deployment is often called information technology or information systems. however, there has been much cross-fertilization of ideas between the various computer-related disciplines. computer science research also often intersects other disciplines, such as cognitive science, linguistics, mathematics, physics, biology, earth science, statistics, philosophy, and logic.computer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science. early computer science was strongly influenced by the work of mathematicians such as kurt gödel, alan turing, john von neumann, rózsa péter and alonzo church and there continues to be a useful interchange of ideas between the two fields in areas such as mathematical logic, category theory, domain theory, and algebra.the relationship between computer science and software engineering is a contentious issue, which is further muddied by disputes over what the term \"software engineering\" means, and how computer science is defined. david parnas, taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines.the academic, political, and funding aspects of computer science tend to depend on whether a department is formed with a mathematical emphasis or with an engineering emphasis. computer science departments with a mathematics emphasis and with a numerical orientation consider alignment with computational science. both types of departments tend to make efforts to bridge the field educationally if not across all research.'], 'hardware': ['the term hardware covers all of those parts of a computer that are tangible physical objects. circuits, computer chips, graphic cards, sound cards, memory (ram), motherboard, displays, power supplies, cables, keyboards, printers and \"mice\" input devices are all hardware.=== history of computing hardware ====== other hardware topics ===a general-purpose computer has four main components: the arithmetic logic unit (alu), the control unit, the memory, and the input and output devices (collectively termed i/o). these parts are interconnected by buses, often made of groups of wires. inside each of these parts are thousands to trillions of small electrical circuits which can be turned off or on by means of an electronic switch. each circuit represents a bit (binary digit) of information so that when the circuit is on it represents a \"1\", and when off it represents a \"0\" (in positive logic representation). the circuits are arranged in logic gates so that one or more of the circuits may control the state of one or more of the other circuits.=== input devices ===when unprocessed data is sent to the computer with the help of input devices, the data is processed and sent to output devices. the input devices may be hand-operated or automated. the act of processing is mainly regulated by the cpu. some examples of input devices are:computer keyboarddigital cameradigital videographics tabletimage scannerjoystickmicrophonemouseoverlay keyboardreal-time clocktrackballtouchscreenlight pen=== output devices ===the means through which computer gives output are known as output devices. some examples of output devices are:computer monitorprinterpc speakerprojectorsound cardvideo card=== control unit ===the control unit (often called a control system or central controller) manages the computer\\'s various components; it reads and interprets (decodes) the program instructions, transforming them into control signals that activate other parts of the computer. control systems in advanced computers may change the order of execution of some instructions to improve performance.a key component common to all cpus is the program counter, a special memory cell (a register) that keeps track of which location in memory the next instruction is to be read from.the control system\\'s function is as follows— this is a simplified description, and some of these steps may be performed concurrently or in a different order depending on the type of cpu:read the code for the next instruction from the cell indicated by the program counter.decode the numerical code for the instruction into a set of commands or signals for each of the other systems.increment the program counter so it points to the next instruction.read whatever data the instruction requires from cells in memory (or perhaps from an input device). the location of this required data is typically stored within the instruction code.provide the necessary data to an alu or register.if the instruction requires an alu or specialized hardware to complete, instruct the hardware to perform the requested operation.write the result from the alu back to a memory location or to a register or perhaps an output device.jump back to step (1).since the program counter is (conceptually) just another set of memory cells, it can be changed by calculations done in the alu. adding 100 to the program counter would cause the next instruction to be read from a place 100 locations further down the program. instructions that modify the program counter are often known as \"jumps\" and allow for loops (instructions that are repeated by the computer) and often conditional instruction execution (both examples of control flow).the sequence of operations that the control unit goes through to process an instruction is in itself like a short computer program, and indeed, in some more complex cpu designs, there is another yet smaller computer called a microsequencer, which runs a microcode program that causes all of these events to happen.=== central processing unit (cpu) ===the control unit, alu, and registers are collectively known as a central processing unit (cpu). early cpus were composed of many separate components. since the 1970s, cpus have typically been constructed on a single mos integrated circuit chip called a microprocessor.=== arithmetic logic unit (alu) ===the alu is capable of performing two classes of operations: arithmetic and logic. the set of arithmetic operations that a particular alu supports may be limited to addition and subtraction, or might include multiplication, division, trigonometry functions such as sine, cosine, etc., and square roots. some can operate only on whole numbers (integers) while others use floating point to represent real numbers, albeit with limited precision. however, any computer that is capable of performing just the simplest operations can be programmed to break down the more complex operations into simple steps that it can perform. therefore, any computer can be programmed to perform any arithmetic operation—although it will take more time to do so if its alu does not directly support the operation. an alu may also compare numbers and return boolean truth values (true or false) depending on whether one is equal to, greater than or less than the other (\"is 64 greater than 65?\"). logic operations involve boolean logic: and, or, xor, and not. these can be useful for creating complicated conditional statements and processing boolean logic.superscalar computers may contain multiple alus, allowing them to process several instructions simultaneously. graphics processors and computers with simd and mimd features often contain alus that can perform arithmetic on vectors and matrices.=== memory ===a computer\\'s memory can be viewed as a list of cells into which numbers can be placed or read. each cell has a numbered \"address\" and can store a single number. the computer can be instructed to \"put the number 123 into the cell numbered 1357\" or to \"add the number that is in cell 1357 to the number that is in cell 2468 and put the answer into cell 1595.\" the information stored in memory may represent practically anything. letters, numbers, even computer instructions can be placed into memory with equal ease. since the cpu does not differentiate between different types of information, it is the software\\'s responsibility to give significance to what the memory sees as nothing but a series of numbers.in almost all modern computers, each memory cell is set up to store binary numbers in groups of eight bits (called a byte). each byte is able to represent 256 different numbers (28 = 256); either from 0 to 255 or −128 to +127. to store larger numbers, several consecutive bytes may be used (typically, two, four or eight). when negative numbers are required, they are usually stored in two\\'s complement notation. other arrangements are possible, but are usually not seen outside of specialized applications or historical contexts. a computer can store any kind of information in memory if it can be represented numerically. modern computers have billions or even trillions of bytes of memory.the cpu contains a special set of memory cells called registers that can be read and written to much more rapidly than the main memory area. there are typically between two and one hundred registers depending on the type of cpu. registers are used for the most frequently needed data items to avoid having to access main memory every time data is needed. as data is constantly being worked on, reducing the need to access main memory (which is often slow compared to the alu and control units) greatly increases the computer\\'s speed.computer main memory comes in two principal varieties:random-access memory or ramread-only memory or romram can be read and written to anytime the cpu commands it, but rom is preloaded with data and software that never changes, therefore the cpu can only read from it. rom is typically used to store the computer\\'s initial start-up instructions. in general, the contents of ram are erased when the power to the computer is turned off, but rom retains its data indefinitely. in a pc, the rom contains a specialized program called the bios that orchestrates loading the computer\\'s operating system from the hard disk drive into ram whenever the computer is turned on or reset. in embedded computers, which frequently do not have disk drives, all of the required software may be stored in rom. software stored in rom is often called firmware, because it is notionally more like hardware than software. flash memory blurs the distinction between rom and ram, as it retains its data when turned off but is also rewritable. it is typically much slower than conventional rom and ram however, so its use is restricted to applications where high speed is unnecessary.in more sophisticated computers there may be one or more ram cache memories, which are slower than registers but faster than main memory. generally computers with this sort of cache are designed to move frequently needed data into the cache automatically, often without the need for any intervention on the programmer\\'s part.=== input/output (i/o) ===i/o is the means by which a computer exchanges information with the outside world. devices that provide input or output to the computer are called peripherals. on a typical personal computer, peripherals include input devices like the keyboard and mouse, and output devices such as the display and printer. hard disk drives, floppy disk drives and optical disc drives serve as both input and output devices. computer networking is another form of i/o.i/o devices are often complex computers in their own right, with their own cpu and memory. a graphics processing unit might contain fifty or more tiny computers that perform the calculations necessary to display 3d graphics. modern desktop computers contain many smaller computers that assist the main cpu in performing i/o. a 2016-era flat screen display contains its own computer circuitry.=== multitasking ===while a computer may be viewed as running one gigantic program stored in its main memory, in some systems it is necessary to give the appearance of running several programs simultaneously. this is achieved by multitasking i.e. having the computer switch rapidly between running each program in turn. one means by which this is done is with a special signal called an interrupt, which can periodically cause the computer to stop executing instructions where it was and do something else instead. by remembering where it was executing prior to the interrupt, the computer can return to that task later. if several programs are running \"at the same time\". then the interrupt generator might be causing several hundred interrupts per second, causing a program switch each time. since modern computers typically execute instructions several orders of magnitude faster than human perception, it may appear that many programs are running at the same time even though only one is ever executing in any given instant. this method of multitasking is sometimes termed \"time-sharing\" since each program is allocated a \"slice\" of time in turn.before the era of inexpensive computers, the principal use for multitasking was to allow many people to share the same computer. seemingly, multitasking would cause a computer that is switching between several programs to run more slowly, in direct proportion to the number of programs it is running, but most programs spend much of their time waiting for slow input/output devices to complete their tasks. if a program is waiting for the user to click on the mouse or press a key on the keyboard, then it will not take a \"time slice\" until the event it is waiting for has occurred. this frees up time for other programs to execute so that many programs may be run simultaneously without unacceptable speed loss.=== multiprocessing ===some computers are designed to distribute their work across several cpus in a multiprocessing configuration, a technique once employed in only large and powerful machines such as supercomputers, mainframe computers and servers. multiprocessor and multi-core (multiple cpus on a single integrated circuit) personal and laptop computers are now widely available, and are being increasingly used in lower-end markets as a result.supercomputers in particular often have highly unique architectures that differ significantly from the basic stored-program architecture and from general-purpose computers. they often feature thousands of cpus, customized high-speed interconnects, and specialized computing hardware. such designs tend to be useful for only specialized tasks due to the large scale of program organization required to successfully utilize most of the available resources at once. supercomputers usually see usage in large-scale simulation, graphics rendering, and cryptography applications, as well as with other so-called \"embarrassingly parallel\" tasks.'], 'software': ['software refers to parts of the computer which do not have a material form, such as programs, data, protocols, etc. software is that part of a computer system that consists of encoded information or computer instructions, in contrast to the physical hardware from which the system is built. computer software includes computer programs, libraries and related non-executable data, such as online documentation or digital media. it is often divided into system software and application software computer hardware and software require each other and neither can be realistically used on its own. when software is stored in hardware that cannot easily be modified, such as with bios rom in an ibm pc compatible computer, it is sometimes called \"firmware\".=== languages ===there are thousands of different programming languages—some intended for general purpose, others useful for only highly specialized applications.=== programs ===the defining feature of modern computers which distinguishes them from all other machines is that they can be programmed. that is to say that some type of instructions (the program) can be given to the computer, and it will process them. modern computers based on the von neumann architecture often have machine code in the form of an imperative programming language. in practical terms, a computer program may be just a few instructions or extend to many millions of instructions, as do the programs for word processors and web browsers for example. a typical modern computer can execute billions of instructions per second (gigaflops) and rarely makes a mistake over many years of operation. large computer programs consisting of several million instructions may take teams of programmers years to write, and due to the complexity of the task almost certainly contain errors.==== stored program architecture ====this section applies to most common ram machine–based computers.in most cases, computer instructions are simple: add one number to another, move some data from one location to another, send a message to some external device, etc. these instructions are read from the computer\\'s memory and are generally carried out (executed) in the order they were given. however, there are usually specialized instructions to tell the computer to jump ahead or backwards to some other place in the program and to carry on executing from there. these are called \"jump\" instructions (or branches). furthermore, jump instructions may be made to happen conditionally so that different sequences of instructions may be used depending on the result of some previous calculation or some external event. many computers directly support subroutines by providing a type of jump that \"remembers\" the location it jumped from and another instruction to return to the instruction following that jump instruction.program execution might be likened to reading a book. while a person will normally read each word and line in sequence, they may at times jump back to an earlier place in the text or skip sections that are not of interest. similarly, a computer may sometimes go back and repeat the instructions in some section of the program over and over again until some internal condition is met. this is called the flow of control within the program and it is what allows the computer to perform tasks repeatedly without human intervention.comparatively, a person using a pocket calculator can perform a basic arithmetic operation such as adding two numbers with just a few button presses. but to add together all of the numbers from 1 to 1,000 would take thousands of button presses and a lot of time, with a near certainty of making a mistake. on the other hand, a computer may be programmed to do this with just a few simple instructions. the following example is written in the mips assembly language:once told to run this program, the computer will perform the repetitive addition task without further human intervention. it will almost never make a mistake and a modern pc can complete the task in a fraction of a second.==== machine code ====in most computers, individual instructions are stored as machine code with each instruction being given a unique number (its operation code or opcode for short). the command to add two numbers together would have one opcode; the command to multiply them would have a different opcode, and so on. the simplest computers are able to perform any of a handful of different instructions; the more complex computers have several hundred to choose from, each with a unique numerical code. since the computer\\'s memory is able to store numbers, it can also store the instruction codes. this leads to the important fact that entire programs (which are just lists of these instructions) can be represented as lists of numbers and can themselves be manipulated inside the computer in the same way as numeric data. the fundamental concept of storing programs in the computer\\'s memory alongside the data they operate on is the crux of the von neumann, or stored program, architecture. in some cases, a computer might store some or all of its program in memory that is kept separate from the data it operates on. this is called the harvard architecture after the harvard mark i computer. modern von neumann computers display some traits of the harvard architecture in their designs, such as in cpu caches.while it is possible to write computer programs as long lists of numbers (machine language) and while this technique was used with many early computers, it is extremely tedious and potentially error-prone to do so in practice, especially for complicated programs. instead, each basic instruction can be given a short name that is indicative of its function and easy to remember – a mnemonic such as add, sub, mult or jump. these mnemonics are collectively known as a computer\\'s assembly language. converting programs written in assembly language into something the computer can actually understand (machine language) is usually done by a computer program called an assembler.==== programming language ====programming languages provide various ways of specifying programs for computers to run. unlike natural languages, programming languages are designed to permit no ambiguity and to be concise. they are purely written languages and are often difficult to read aloud. they are generally either translated into machine code by a compiler or an assembler before being run, or translated directly at run time by an interpreter. sometimes programs are executed by a hybrid method of the two techniques.===== low-level languages =====machine languages and the assembly languages that represent them (collectively termed low-level programming languages) are generally unique to the particular architecture of a computer\\'s central processing unit (cpu). for instance, an arm architecture cpu (such as may be found in a smartphone or a hand-held videogame) cannot understand the machine language of an x86 cpu that might be in a pc. historically a significant number of other cpu architectures were created and saw extensive use, notably including the mos technology 6502 and 6510 in addition to the zilog z80.===== high-level languages =====although considerably easier than in machine language, writing long programs in assembly language is often difficult and is also error prone. therefore, most practical programs are written in more abstract high-level programming languages that are able to express the needs of the programmer more conveniently (and thereby help reduce programmer error). high level languages are usually \"compiled\" into machine language (or sometimes into assembly language and then into machine language) using another computer program called a compiler. high level languages are less related to the workings of the target computer than assembly language, and more related to the language and structure of the problem(s) to be solved by the final program. it is therefore often possible to use different compilers to translate the same high level language program into the machine language of many different types of computer. this is part of the means by which software like video games may be made available for different computer architectures such as personal computers and various video game consoles.==== program design ====program design of small programs is relatively simple and involves the analysis of the problem, collection of inputs, using the programming constructs within languages, devising or using established procedures and algorithms, providing data for output devices and solutions to the problem as applicable. as problems become larger and more complex, features such as subprograms, modules, formal documentation, and new paradigms such as object-oriented programming are encountered. large programs involving thousands of line of code and more require formal software methodologies.the task of developing large software systems presents a significant intellectual challenge. producing software with an acceptably high reliability within a predictable schedule and budget has historically been difficult; the academic and professional discipline of software engineering concentrates specifically on this challenge.==== bugs ====errors in computer programs are called \"bugs\". they may be benign and not affect the usefulness of the program, or have only subtle effects. but in some cases, they may cause the program or the entire system to \"hang\", becoming unresponsive to input such as mouse clicks or keystrokes, to completely fail, or to crash. otherwise benign bugs may sometimes be harnessed for malicious intent by an unscrupulous user writing an exploit, code designed to take advantage of a bug and disrupt a computer\\'s proper execution. bugs are usually not the fault of the computer. since computers merely execute the instructions they are given, bugs are nearly always the result of programmer error or an oversight made in the program\\'s design. admiral grace hopper, an american computer scientist and developer of the first compiler, is credited for having first used the term \"bugs\" in computing after a dead moth was found shorting a relay in the harvard mark ii computer in september 1947.'], 'networking and the internet': ['computers have been used to coordinate information between multiple locations since the 1950s. the u.s. military\\'s sage system was the first large-scale example of such a system, which led to a number of special-purpose commercial systems such as sabre. in the 1970s, computer engineers at research institutions throughout the united states began to link their computers together using telecommunications technology. the effort was funded by arpa (now darpa), and the computer network that resulted was called the arpanet. the technologies that made the arpanet possible spread and evolved.in time, the network spread beyond academic and military institutions and became known as the internet. the emergence of networking involved a redefinition of the nature and boundaries of the computer. computer operating systems and applications were modified to include the ability to define and access the resources of other computers on the network, such as peripheral devices, stored information, and the like, as extensions of the resources of an individual computer. initially these facilities were available primarily to people working in high-tech environments, but in the 1990s the spread of applications like e-mail and the world wide web, combined with the development of cheap, fast networking technologies like ethernet and adsl saw computer networking become almost ubiquitous. in fact, the number of computers that are networked is growing phenomenally. a very large proportion of personal computers regularly connect to the internet to communicate and receive information. \"wireless\" networking, often utilizing mobile phone networks, has meant networking is becoming increasingly ubiquitous even in mobile computing environments.'], 'unconventional computer': ['a computer does not need to be electronic, nor even have a processor, nor ram, nor even a hard disk. while popular usage of the word \"computer\" is synonymous with a personal electronic computer, the modern definition of a computer is literally: \"a device that computes, especially a programmable [usually] electronic machine that performs high-speed mathematical or logical operations or that assembles, stores, correlates, or otherwise processes information.\" any device which processes information qualifies as a computer, especially if the processing is purposeful.'], 'future': ['there is active research to make computers out of many promising new types of technology, such as optical computers, dna computers, neural computers, and quantum computers. most computers are universal, and are able to calculate any computable function, and are limited only by their memory capacity and operating speed. however different designs of computers can give very different performance for particular problems; for example quantum computers can potentially break some modern encryption algorithms (by quantum factoring) very quickly.=== computer architecture paradigms ===there are many types of computer architectures:quantum computer vs. chemical computerscalar processor vs. vector processornon-uniform memory access (numa) computersregister machine vs. stack machineharvard architecture vs. von neumann architecturecellular architectureof all these abstract machines, a quantum computer holds the most promise for revolutionizing computing. logic gates are a common abstraction which can apply to most of the above digital or analog paradigms. the ability to store and execute lists of instructions called programs makes computers extremely versatile, distinguishing them from calculators. the church–turing thesis is a mathematical statement of this versatility: any computer with a minimum capability (being turing-complete) is, in principle, capable of performing the same tasks that any other computer can perform. therefore, any type of computer (netbook, supercomputer, cellular automaton, etc.) is able to perform the same computational tasks, given enough time and storage capacity.=== artificial intelligence ===a computer will solve problems in exactly the way it is programmed to, without regard to efficiency, alternative solutions, possible shortcuts, or possible errors in the code. computer programs that learn and adapt are part of the emerging field of artificial intelligence and machine learning. artificial intelligence based products generally fall into two major categories: rule-based systems and pattern recognition systems. rule-based systems attempt to represent the rules used by human experts and tend to be expensive to develop. pattern-based systems use data about a problem to generate conclusions. examples of pattern-based systems include voice recognition, font recognition, translation and the emerging field of on-line marketing.'], 'professions and organization': ['as the use of computers has spread throughout society, there are an increasing number of careers involving computers.the need for computers to work well together and to be able to exchange information has spawned the need for many standards organizations, clubs and societies of both a formal and informal nature.'], 'philosophy': ['=== epistemology of computer science ===despite the word \"science\" in its name, there is debate over whether or not computer science is a discipline of science, mathematics, or engineering. allen newell and herbert a. simon argued in 1975, computer science is an empirical discipline. we would have called it an experimental science, but like astronomy, economics, and geology, some of its unique forms of observation and experience do not fit a narrow stereotype of the experimental method. nonetheless, they are experiments. each new machine that is built is an experiment. actually constructing the machine poses a question to nature; and we listen for the answer by observing the machine in operation and analyzing it by all analytical and measurement means available. it has since been argued that computer science can be classified as an empirical science since it makes use of empirical testing to evaluate the correctness of programs, but a problem remains in defining the laws and theorems of computer science (if any exist) and defining the nature of experiments in computer science. proponents of classifying computer science as an engineering discipline argue that the reliability of computational systems is investigated in the same way as bridges in civil engineering and airplanes in aerospace engineering. they also argue that while empirical sciences observe what presently exists, computer science observes what is possible to exist and while scientists discover laws from observation, no proper laws have been found in computer science and it is instead concerned with creating phenomena.proponents of classifying computer science as a mathematical discipline argue that computer programs are physical realizations of mathematical entities and programs can be deductively reasoned through mathematical formal methods. computer scientists edsger w. dijkstra and tony hoare regard instructions for computer programs as mathematical sentences and interpret formal semantics for programming languages as mathematical axiomatic systems.=== paradigms of computer science ===a number of computer scientists have argued for the distinction of three separate paradigms in computer science. peter wegner argued that those paradigms are science, technology, and mathematics. peter denning\\'s working group argued that they are theory, abstraction (modeling), and design. amnon h. eden described them as the \"rationalist paradigm\" (which treats computer science as a branch of mathematics, which is prevalent in theoretical computer science, and mainly employs deductive reasoning), the \"technocratic paradigm\" (which might be found in engineering approaches, most prominently in software engineering), and the \"scientific paradigm\" (which approaches computer-related artifacts from the empirical perspective of natural sciences, identifiable in some branches of artificial intelligence).computer science focuses on methods involved in design, specification, programming, verification, implementation and testing of human-made computing systems.'], 'field': ['computer science is no more about computers than astronomy is about telescopes.as a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.csab, formerly called computing sciences accreditation board—which is made up of representatives of the association for computing machinery (acm), and the ieee computer society (ieee cs)—identifies four areas that it considers crucial to the discipline of computer science: theory of computation, algorithms and data structures, programming methodology and languages, and computer elements and architecture. in addition to these four areas, csab also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical and symbolic computation as being important areas of computer science.=== theoretical computer science ===theoretical computer science is mathematical and abstract in spirit, but it derives its motivation from the practical and everyday computation. its aim is to understand the nature of computation and, as a consequence of this understanding, provide more efficient methodologies.==== theory of computation ====according to peter denning, the fundamental question underlying computer science is, \"what can be automated?\" theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. in an effort to answer the first question, computability theory examines which computational problems are solvable on various theoretical models of computation. the second question is addressed by computational complexity theory, which studies the time and space costs associated with different approaches to solving a multitude of computational problems.the famous p = np? problem, one of the millennium prize problems, is an open problem in the theory of computation.==== information and coding theory ====information theory, closely related to probability and statistics, is related to the quantification of information. this was developed by claude shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data.coding theory is the study of the properties of codes (systems for converting information from one form to another) and their fitness for a specific application. codes are used for data compression, cryptography, error detection and correction, and more recently also for network coding. codes are studied for the purpose of designing efficient and reliable data transmission methods.==== data structures and algorithms ====data structures and algorithms are the studies of commonly used computational methods and their computational efficiency.==== programming language theory and formal methods ====programming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and their individual features. it falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, and linguistics. it is an active research area, with numerous dedicated academic journals.formal methods are a particular kind of mathematically based technique for the specification, development and verification of software and hardware systems. the use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. they form an important theoretical underpinning for software engineering, especially where safety or security is involved. formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. for industrial use, tool support is required. however, the high cost of using formal methods means that they are usually only used in the development of high-integrity and life-critical systems, where safety or security is of utmost importance. formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification.=== computer systems and computational processes ======= artificial intelligence ====artificial intelligence (ai) aims to or is required to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, learning, and communication found in humans and animals. from its origins in cybernetics and in the dartmouth conference (1956), artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such as applied mathematics, symbolic logic, semiotics, electrical engineering, philosophy of mind, neurophysiology, and social intelligence. ai is associated in the popular mind with robotic development, but the main field of practical application has been as an embedded component in areas of software development, which require computational understanding. the starting point in the late 1940s was alan turing\\'s question \"can computers think?\", and the question remains effectively unanswered, although the turing test is still used to assess computer output on the scale of human intelligence. but the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data.==== computer architecture and organization ====computer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. it focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory. computer engineers study computational logic and design of computer hardware, from individual processor components, microcontrollers, personal computers to supercomputers and embedded systems. the term “architecture” in computer literature can be traced to the work of lyle r. johnson and frederick p. brooks, jr., members of the machine organization department in ibm\\'s main research center in 1959.==== concurrent, parallel and distributed computing ====concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. a number of mathematical models have been developed for general concurrent computation including petri nets, process calculi and the parallel random access machine model. when multiple computers are connected in a network while using concurrency, this is known as a distributed system. computers within that distributed system have their own private memory, and information can be exchanged to achieve common goals.==== computer networks ====this branch of computer science aims to manage networks between computers worldwide.==== computer security and cryptography ====computer security is a branch of computer technology with the objective of protecting information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users.historical cryptography is the art of writing and deciphering secret messages. modern cryptography is the scientific study of problems relating to distributed computations that can be attacked. technologies studied in modern cryptography include symmetric and asymmetric encryption, digital signatures, cryptographic hash functions, key-agreement protocols, blockchain, zero-knowledge proofs, and garbled circuits.==== databases and data mining ====a database is intended to organize, store, and retrieve large amounts of data easily. digital databases are managed using database management systems to store, create, maintain, and search data, through database models and query languages. data mining is a process of discovering patterns in large data sets.==== computer graphics and visualization ====computer graphics is the study of digital visual contents and involves the synthesis and manipulation of image data. the study is connected to many other fields in computer science, including computer vision, image processing, and computational geometry, and is heavily applied in the fields of special effects and video games.==== image and sound processing ====information can take the form of images, sound, video or other multimedia. bits of information can be streamed via signals. its processing is the central notion of informatics, the european view on computing, which studies information processing algorithms independently of the type of information carrier - whether it is electrical, mechanical or biological. this field plays important role in information theory, telecommunications, information engineering and has applications in medical image computing and speech synthesis, among others. what is the lower bound on the complexity of fast fourier transform algorithms? is one of unsolved problems in theoretical computer science.=== applied computer science ======= computational science, finance and engineering ====scientific computing (or computational science) is the field of study concerned with constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems. a major usage of scientific computing is simulation of various processes, including computational fluid dynamics, physical, electrical, and electronic systems and circuits, as well as societies and social situations (notably war games) along with their habitats, among many others. modern computers enable optimization of such designs as complete aircraft. notable in electrical and electronic circuit design are spice, as well as software for physical realization of new (or modified) designs. the latter includes essential design software for integrated circuits.==== social computing and human–computer interaction ====social computing is an area that is concerned with the intersection of social behavior and computational systems. human–computer interaction research develops theories, principles, and guidelines for user interface designers.==== software engineering ====software engineering is the study of designing, implementing, and modifying the software in order to ensure it is of high quality, affordable, maintainable, and fast to build. it is a systematic approach to software design, involving the application of engineering practices to software. software engineering deals with the organizing and analyzing of software—it doesn\\'t just deal with the creation or manufacture of new software, but its internal arrangement and maintenance. for example software testing, systems engineering, technical debt and software development processes.'], 'discoverie': ['the philosopher of computing bill rapaport noted three great insights of computer science:gottfried wilhelm leibniz\\'s, george boole\\'s, alan turing\\'s, claude shannon\\'s, and samuel morse\\'s insight: there are only two objects that a computer has to deal with in order to represent \"anything\".all the information about any computable problem can be represented using only 0 and 1 (or any other bistable pair that can flip-flop between two easily distinguishable states, such as \"on/off\", \"magnetized/de-magnetized\", \"high-voltage/low-voltage\", etc.).alan turing\\'s insight: there are only five actions that a computer has to perform in order to do \"anything\".every algorithm can be expressed in a language for a computer consisting of only five basic instructions:move left one location;move right one location;read symbol at current location;print 0 at current location;print 1 at current location.corrado böhm and giuseppe jacopini\\'s insight: there are only three ways of combining these actions (into more complex ones) that are needed in order for a computer to do \"anything\".only three rules are needed to combine any set of basic instructions into more complex ones:sequence: first do this, then do that; selection: if such-and-such is the case, then do this, else do that;repetition: while such-and-such is the case, do this.note that the three rules of boehm\\'s and jacopini\\'s insight can be further simplified with the use of goto (which means it is more elementary than structured programming).'], 'programming paradigm': ['programming languages can be used to accomplish different tasks in different ways. common programming paradigms include:functional programming, a style of building the structure and elements of computer programs that treats computation as the evaluation of mathematical functions and avoids state and mutable data. it is a declarative programming paradigm, which means programming is done with expressions or declarations instead of statements.imperative programming, a programming paradigm that uses statements that change a program\\'s state. in much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. imperative programming focuses on describing how a program operates.object-oriented programming, a programming paradigm based on the concept of \"objects\", which may contain data, in the form of fields, often known as attributes; and code, in the form of procedures, often known as methods. a feature of objects is that an object\\'s procedures can access and often modify the data fields of the object with which they are associated. thus object-oriented computer programs are made out of objects that interact with one another.service-oriented programming, a programming paradigm that uses \"services\" as the unit of computer work, to design and implement integrated business applications and mission critical software programsmany languages offer support for multiple paradigms, making the distinction more a matter of style than of technical capabilities.'], 'academia': ['conferences are important events for computer science research. during these conferences, researchers from the public and private sectors present their recent work and meet. unlike in most other academic fields, in computer science, the prestige of conference papers is greater than that of journal publications. one proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.'], 'education': ['computer science, known by its near synonyms, computing, computer studies, has been taught in uk schools since the days of batch processing, mark sensitive cards and paper tape but usually to a select few students. in 1981, the bbc produced a micro-computer and classroom network and computer studies became common for gce o level students (11–16-year-old), and computer science to a level students. its importance was recognised, and it became a compulsory part of the national curriculum, for key stage 3 & 4. in september 2014 it became an entitlement for all pupils over the age of 4.in the us, with 14,000 school districts deciding the curriculum, provision was fractured. according to a 2010 report by the association for computing machinery (acm) and computer science teachers association (csta), only 14 out of 50 states have adopted significant education standards for high school computer science.israel, new zealand, and south korea have included computer science in their national secondary education curricula, and several others are following.'], 'relation to instruction set architecture': ['the isa is roughly the same as the programming model of a processor as seen by an assembly language programmer or compiler writer. the isa includes the instructions, execution model, processor registers, address and data formats among other things. the microarchitecture includes the constituent parts of the processor and how these interconnect and interoperate to implement the isa.the microarchitecture of a machine is usually represented as (more or less detailed) diagrams that describe the interconnections of the various microarchitectural elements of the machine, which may be anything from single gates and registers, to complete arithmetic logic units (alus) and even larger elements. these diagrams generally separate the datapath (where data is placed) and the control path (which can be said to steer the data).the person designing a system usually draws the specific microarchitecture as a kind of data flow diagram. like a block diagram, the microarchitecture diagram shows microarchitectural elements such as the arithmetic and logic unit and the register file as a single schematic symbol. typically, the diagram connects those elements with arrows, thick lines and thin lines to distinguish between three-state buses (which require a three-state buffer for each device that drives the bus), unidirectional buses (always driven by a single source, such as the way the address bus on simpler computers is always driven by the memory address register), and individual control lines. very simple computers have a single data bus organization –  they have a single three-state bus. the diagram of more complex computers usually shows multiple three-state buses, which help the machine do more operations simultaneously.each microarchitectural element is in turn represented by a schematic describing the interconnections of logic gates used to implement it. each logic gate is in turn represented by a circuit diagram describing the connections of the transistors used to implement it in some particular logic family. machines with different microarchitectures may have the same instruction set architecture, and thus be capable of executing the same programs. new microarchitectures and/or circuitry solutions, along with advances in semiconductor manufacturing, are what allows newer generations of processors to achieve higher performance while using the same isa.in principle, a single microarchitecture could execute several different isas with only minor changes to the microcode.'], 'aspect': ['the pipelined datapath is the most commonly used datapath design in microarchitecture today. this technique is used in most modern microprocessors, microcontrollers, and dsps. the pipelined architecture allows multiple instructions to overlap in execution, much like an assembly line. the pipeline includes several different stages which are fundamental in microarchitecture designs. some of these stages include instruction fetch, instruction decode, execute, and write back. some architectures include other stages such as memory access. the design of pipelines is one of the central microarchitectural tasks.execution units are also essential to microarchitecture. execution units include arithmetic logic units (alu), floating point units (fpu), load/store units, branch prediction, and simd. these units perform the operations or calculations of the processor. the choice of the number of execution units, their latency and throughput is a central microarchitectural design task. the size, latency, throughput and connectivity of memories within the system are also microarchitectural decisions.system-level design decisions such as whether or not to include peripherals, such as memory controllers, can be considered part of the microarchitectural design process. this includes decisions on the performance-level and connectivity of these peripherals.unlike architectural design, where achieving a specific performance level is the main goal, microarchitectural design pays closer attention to other constraints. since microarchitecture design decisions directly affect what goes into a system, attention must be paid to issues such as chip area/cost, power consumption, logic complexity, ease of connectivity, manufacturability, ease of debugging, and testability.'], 'microarchitectural concept': ['=== instruction cycles ===to run programs, all single- or multi-chip cpus:read an instruction and decode itfind any associated data that is needed to process the instructionprocess the instructionwrite the results outthe instruction cycle is repeated continuously until the power is turned off.=== multicycle microarchitecture ===historically, the earliest computers were multicycle designs. the smallest, least-expensive computers often still use this technique. multicycle architectures often use the least total number of logic elements and reasonable amounts of power. they can be designed to have deterministic timing and high reliability. in particular, they have no pipeline to stall when taking conditional branches or interrupts.  however, other microarchitectures often perform more instructions per unit time, using the same logic family.  when discussing \"improved performance,\" an improvement is often relative to a multicycle design.in a multicycle computer, the computer does the four steps in sequence, over several cycles of the clock. some designs can perform the sequence in two clock cycles by completing successive stages on alternate clock edges, possibly with longer operations occurring outside the main cycle. for example, stage one on the rising edge of the first cycle, stage two on the falling edge of the first cycle, etc.in the control logic, the combination of cycle counter, cycle state (high or low) and the bits of the instruction decode register determine exactly what each part of the computer should be doing. to design the control logic, one can create a table of bits describing the control signals to each part of the computer in each cycle of each instruction. then, this logic table can be tested in a software simulation running test code.  if the logic table is placed in a memory and used to actually run a real computer, it is called a microprogram. in some computer designs, the logic table is optimized into the form of combinational logic made from logic gates, usually using a computer program that optimizes logic. early computers used ad-hoc logic design for control until maurice wilkes invented this tabular approach and called it microprogramming.=== increasing execution speed ===complicating this simple-looking series of steps is the fact that the memory hierarchy, which includes caching, main memory and non-volatile storage like hard disks (where the program instructions and data reside), has always been slower than the processor itself. step (2) often introduces a lengthy (in cpu terms) delay while the data arrives over the computer bus. a considerable amount of research has been put into designs that avoid these delays as much as possible. over the years, a central goal was to execute more instructions in parallel, thus increasing the effective execution speed of a program. these efforts introduced complicated logic and circuit structures. initially, these techniques could only be implemented on expensive mainframes or supercomputers due to the amount of circuitry needed for these techniques. as semiconductor manufacturing progressed, more and more of these techniques could be implemented on a single semiconductor chip. see moore\\'s law.=== instruction set choice ===instruction sets have shifted over the years, from originally very simple to sometimes very complex (in various respects). in recent years, load–store architectures, vliw and epic types have been in fashion. architectures that are dealing with data parallelism include simd and vectors. some labels used to denote classes of cpu architectures are not particularly descriptive, especially so the cisc label; many early designs retroactively denoted \"cisc\" are in fact significantly simpler than modern risc processors (in several respects).however, the choice of instruction set architecture may greatly affect the complexity of implementing high-performance devices. the prominent strategy, used to develop the first risc processors, was to simplify instructions to a minimum of individual semantic complexity combined with high encoding regularity and simplicity. such uniform instructions were easily fetched, decoded and executed in a pipelined fashion and a simple strategy to reduce the number of logic levels in order to reach high operating frequencies; instruction cache-memories compensated for the higher operating frequency and inherently low code density while large register sets were used to factor out as much of the (slow) memory accesses as possible.=== instruction pipelining ===one of the first, and most powerful, techniques to improve performance is the use of instruction pipelining. early processor designs would carry out all of the steps above for one instruction before moving onto the next. large portions of the circuitry were left idle at any one step; for instance, the instruction decoding circuitry would be idle during execution and so on.pipelining improves performance by allowing a number of instructions to work their way through the processor at the same time. in the same basic example, the processor would start to decode (step 1) a new instruction while the last one was waiting for results. this would allow up to four instructions to be \"in flight\" at one time, making the processor look four times as fast. although any one instruction takes just as long to complete (there are still four steps) the cpu as a whole \"retires\" instructions much faster.risc makes pipelines smaller and much easier to construct by cleanly separating each stage of the instruction process and making them take the same amount of time—one cycle. the processor as a whole operates in an assembly line fashion, with instructions coming in one side and results out the other. due to the reduced complexity of the classic risc pipeline, the pipelined core and an instruction cache could be placed on the same size die that would otherwise fit the core alone on a cisc design. this was the real reason that risc was faster. early designs like the sparc and mips often ran over 10 times as fast as intel and motorola cisc solutions at the same clock speed and price.pipelines are by no means limited to risc designs. by 1986 the top-of-the-line vax implementation (vax 8800) was a heavily pipelined design, slightly predating the first commercial mips and sparc designs. most modern cpus (even embedded cpus) are now pipelined, and microcoded cpus with no pipelining are seen only in the most area-constrained embedded processors. large cisc machines, from the vax 8800 to the modern pentium 4 and athlon, are implemented with both microcode and pipelines. improvements in pipelining and caching are the two major microarchitectural advances that have enabled processor performance to keep pace with the circuit technology on which they are based.=== cache ===it was not long before improvements in chip manufacturing allowed for even more circuitry to be placed on the die, and designers started looking for ways to use it. one of the most common was to add an ever-increasing amount of cache memory on-die. cache is very fast and expensive memory. it can be accessed in a few cycles as opposed to many needed to \"talk\" to main memory. the cpu includes a cache controller which automates reading and writing from the cache. if the data is already in the cache it is accessed from there – at considerable time savings, whereas if it is not the processor is \"stalled\" while the cache controller reads it in.risc designs started adding cache in the mid-to-late 1980s, often only 4 kb in total. this number grew over time, and typical cpus now have at least 2 mb, while more powerful cpus come with 4 or 6 or 12mb or even 32mb or more, with the most being 768mb in the newly released epyc milan-x line, organized in multiple levels of a memory hierarchy. generally speaking, more cache means more performance, due to reduced stalling.caches and pipelines were a perfect match for each other. previously, it didn\\'t make much sense to build a pipeline that could run faster than the access latency of off-chip memory. using on-chip cache memory instead, meant that a pipeline could run at the speed of the cache access latency, a much smaller length of time. this allowed the operating frequencies of processors to increase at a much faster rate than that of off-chip memory.=== branch prediction ===one barrier to achieving higher performance through instruction-level parallelism stems from pipeline stalls and flushes due to branches. normally, whether a conditional branch will be taken isn\\'t known until late in the pipeline as conditional branches depend on results coming from a register. from the time that the processor\\'s instruction decoder has figured out that it has encountered a conditional branch instruction to the time that the deciding register value can be read out, the pipeline needs to be stalled for several cycles, or if it\\'s not and the branch is taken, the pipeline needs to be flushed. as clock speeds increase the depth of the pipeline increases with it, and some modern processors may have 20 stages or more. on average, every fifth instruction executed is a branch, so without any intervention, that\\'s a high amount of stalling.techniques such as branch prediction and speculative execution are used to lessen these branch penalties. branch prediction is where the hardware makes educated guesses on whether a particular branch will be taken. in reality one side or the other of the branch will be called much more often than the other. modern designs have rather complex statistical prediction systems, which watch the results of past branches to predict the future with greater accuracy. the guess allows the hardware to prefetch instructions without waiting for the register read. speculative execution is a further enhancement in which the code along the predicted path is not just prefetched but also executed before it is known whether the branch should be taken or not. this can yield better performance when the guess is good, with the risk of a huge penalty when the guess is bad because instructions need to be undone.=== superscalar ===even with all of the added complexity and gates needed to support the concepts outlined above, improvements in semiconductor manufacturing soon allowed even more logic gates to be used.in the outline above the processor processes parts of a single instruction at a time. computer programs could be executed faster if multiple instructions were processed simultaneously. this is what superscalar processors achieve, by replicating functional units such as alus. the replication of functional units was only made possible when the die area of a single-issue processor no longer stretched the limits of what could be reliably manufactured. by the late 1980s, superscalar designs started to enter the market place.in modern designs it is common to find two load units, one store (many instructions have no results to store), two or more integer math units, two or more floating point units, and often a simd unit of some sort. the instruction issue logic grows in complexity by reading in a huge list of instructions from memory and handing them off to the different execution units that are idle at that point. the results are then collected and re-ordered at the end.=== out-of-order execution ===the addition of caches reduces the frequency or duration of stalls due to waiting for data to be fetched from the memory hierarchy, but does not get rid of these stalls entirely. in early designs a cache miss would force the cache controller to stall the processor and wait. of course there may be some other instruction in the program whose data is available in the cache at that point. out-of-order execution allows that ready instruction to be processed while an older instruction waits on the cache, then re-orders the results to make it appear that everything happened in the programmed order. this technique is also used to avoid other operand dependency stalls, such as an instruction awaiting a result from a long latency floating-point operation or other multi-cycle operations.=== register renaming ===register renaming refers to a technique used to avoid unnecessary serialized execution of program instructions because of the reuse of the same registers by those instructions. suppose we have two groups of instruction that will use the same register. one set of instructions is executed first to leave the register to the other set, but if the other set is assigned to a different similar register, both sets of instructions can be executed in parallel (or) in series.=== multiprocessing and multithreading ===computer architects have become stymied by the growing mismatch in cpu operating frequencies and dram access times. none of the techniques that exploited instruction-level parallelism (ilp) within one program could make up for the long stalls that occurred when data had to be fetched from main memory. additionally, the large transistor counts and high operating frequencies needed for the more advanced ilp techniques required power dissipation levels that could no longer be cheaply cooled. for these reasons, newer generations of computers have started to exploit higher levels of parallelism that exist outside of a single program or program thread.this trend is sometimes known as throughput computing. this idea originated in the mainframe market where online transaction processing emphasized not just the execution speed of one transaction, but the capacity to deal with massive numbers of transactions. with transaction-based applications such as network routing and web-site serving greatly increasing in the last decade, the computer industry has re-emphasized capacity and throughput issues.one technique of how this parallelism is achieved is through multiprocessing systems, computer systems with multiple cpus. once reserved for high-end mainframes and supercomputers, small-scale (2–8) multiprocessors servers have become commonplace for the small business market. for large corporations, large scale (16–256) multiprocessors are common. even personal computers with multiple cpus have appeared since the 1990s.with further transistor size reductions made available with semiconductor technology advances, multi-core cpus have appeared where multiple cpus are implemented on the same silicon chip. initially used in chips targeting embedded markets, where simpler and smaller cpus would allow multiple instantiations to fit on one piece of silicon. by 2005, semiconductor technology allowed dual high-end desktop cpus cmp chips to be manufactured in volume. some designs, such as sun microsystems\\' ultrasparc t1 have reverted to simpler (scalar, in-order) designs in order to fit more processors on one piece of silicon.another technique that has become more popular recently is multithreading. in multithreading, when the processor has to fetch data from slow system memory, instead of stalling for the data to arrive, the processor switches to another program or program thread which is ready to execute. though this does not speed up a particular program/thread, it increases the overall system throughput by reducing the time the cpu is idle.conceptually, multithreading is equivalent to a context switch at the operating system level. the difference is that a multithreaded cpu can do a thread switch in one cpu cycle instead of the hundreds or thousands of cpu cycles a context switch normally requires. this is achieved by replicating the state hardware (such as the register file and program counter) for each active thread.a further enhancement is simultaneous multithreading. this technique allows superscalar cpus to execute instructions from different programs/threads simultaneously in the same cycle.']})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['categorie']\n",
      "defaultdict(<class 'list'>, {'intro': ['in computer engineering, computer architecture is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. the architecture of a system refers to its structure in terms of separately specified components of that system and their interrelationships.some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation. in other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation.', 'in computing, a word is the natural unit of data used by a particular processor design. a word is a fixed-sized datum handled as a unit by the instruction set or the hardware of the processor. the number of bits or digits in a word (the word size, word width, or word length) is an important characteristic of any specific processor design or computer architecture.the size of a word is reflected in many aspects of a computer\\'s structure and operation; the majority of the registers in a processor are usually word sized and the largest datum that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. the largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used).documentation for computers with fixed word size commonly stated memory sizes in words rather than bytes or characters.  the documentation sometimes used metric prefixes correctly, sometimes with rounding, e.g., 65 kilowords (kw) meaning for 65536 words, and sometimes used them incorrectly, with kilowords (kw) meaning 1024 words (210) and megawords (mw) meaning 1,048,576 words (220). with standardization on 8-bit bytes and byte addressability, stating memory sizes in bytes, kilobytes, and megabytes with powers of 1024 rather than 1000 has become the norm, although there is some use of the iec binary prefixes.several of the earliest computers (and a few modern as well) used binary-coded decimal rather than plain binary, typically having a word size of 10 or 12 decimal digits, and some early decimal computers had no fixed word length at all. early binary systems tended to use word lengths that were some multiple of 6-bits, with the 36-bit word being especially common on mainframe computers. the introduction of ascii led to the move to systems with word lengths that were a multiple of 8-bits, with 16-bit machines being popular in the 1970s before the move to modern processors with 32 or 64 bits. special-purpose designs like digital signal processors, may have any word length from 4 to 80 bits.the size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. if multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see size families below).', 'in the domain of central processing unit (cpu) design, hazards are problems with the instruction pipeline in cpu microarchitectures when the next instruction cannot execute in the following clock cycle, and can potentially lead to incorrect computation results. three common types of hazards are data hazards, structural hazards, and control hazards (branching hazards).there are several methods used to deal with hazards, including pipeline stalls/pipeline bubbling, operand forwarding, and in the case of out-of-order execution, the scoreboarding method and the tomasulo algorithm.', 'in computer architecture, multithreading is the ability of a central processing unit (cpu) (or a single core in a multi-core processor) to provide multiple threads of execution concurrently, supported by the operating system. this approach differs from multiprocessing. in a multithreaded application, the threads share the resources of a single or multiple cores, which include the computing units, the cpu caches, and the translation lookaside buffer (tlb).where multiprocessing systems include multiple complete processing units in one or more cores, multithreading aims to increase utilization of a single core by using thread-level parallelism, as well as instruction-level parallelism. as the two techniques are complementary, they are combined in nearly all modern systems architectures with multiple multithreading cpus and with cpus with multiple multithreading cores.', 'the von neumann architecture — also known as the von neumann model or princeton architecture — is a computer architecture based on a 1945 description by john von neumann, and by others, in the first draft of a report on the edvac. the document describes a design architecture for an electronic digital computer with these components:a processing unit with both an arithmetic logic unit and processor registersa control unit that includes an instruction register and a program countermemory that stores data and instructionsexternal mass storageinput and output mechanismsthe term \"von neumann architecture\" has evolved to refer to any stored-program computer in which an instruction fetch and a data operation cannot occur at the same time (since they share a common bus). this is referred to as the von neumann bottleneck, which often limits the performance of the corresponding system.the design of a von neumann architecture machine is simpler than in a harvard architecture machine—which is also a stored-program system, yet has one dedicated set of address and data buses for reading and writing to memory, and another set of address and data buses to fetch instructions.a stored-program digital computer keeps both program instructions and data in read–write, random-access memory (ram).  stored-program computers were an advancement over the program-controlled computers of the 1940s, such as the colossus and the eniac. those were programmed by setting switches and inserting patch cables to route data and control signals between various functional units. the vast majority of modern computers use the same memory for both data and program instructions, but have caches between the cpu and memory, and, for the caches closest to the cpu, have separate caches for instructions and data, so that most instruction and data fetches use separate buses (split cache architecture).', 'in computer science, predication is an architectural feature that provides an alternative to conditional transfer of control, as implemented by conditional branch machine instructions. predication works by having conditional (predicated) non-branch instructions associated with a predicate, a boolean value used by the instruction to control whether the instruction is allowed to modify the architectural state or not.  if the predicate specified in the instruction is true, the instruction modifies the architectural state; otherwise, the architectural state is unchanged.  for example, a predicated move instruction (a conditional move) will only modify the destination if the predicate is true.  thus, instead of using a conditional branch to select an instruction or a sequence of instructions to execute based on the predicate that controls whether the branch occurs, the instructions to be executed are associated with that predicate, so that they will be executed, or not executed, based on whether that predicate is true or false.vector processors, some simd isas (such as avx2 and avx-512) and gpus in general make heavy use of predication, applying one bit of a conditional mask vector to the corresponding elements in the vector registers being processed, whereas scalar predication in scalar instruction sets only need the one predicate bit.  where predicate masks become particularly powerful in vector processing is if an array of condition codes, one per vector element, may feed back into predicate masks that are then applied to subsequent vector instructions.', 'a computer is a digital electronic machine that can be programmed to carry out sequences of arithmetic or logical operations (computation) automatically. modern computers can perform generic sets of operations known as programs. these programs enable computers to perform a wide range of tasks. a computer system is a \"complete\" computer that includes the hardware, operating system (main software), and peripheral equipment needed and used for \"full\" operation. this term may also refer to a group of computers that are linked and function together, such as a computer network or computer cluster.a broad range of industrial and consumer products use computers as control systems. simple special-purpose devices like microwave ovens and remote controls are included, as are factory devices like industrial robots and computer-aided design, as well as general-purpose devices like personal computers and mobile devices like smartphones. computers power the internet, which links billions of other computers and users.early computers were meant to be used only for calculations. simple manual instruments like the abacus have aided people in doing calculations since ancient times. early in the industrial revolution, some mechanical devices were built to automate long tedious tasks, such as guiding patterns for looms. more sophisticated electrical machines did specialized analog calculations in the early 20th century. the first digital electronic calculating machines were developed during world war ii. the first semiconductor transistors in the late 1940s were followed by the silicon-based mosfet (mos transistor) and monolithic integrated circuit (ic) chip technologies in the late 1950s, leading to the microprocessor and the microcomputer revolution in the 1970s. the speed, power and versatility of computers have been increasing dramatically ever since then, with transistor counts increasing at a rapid pace (as predicted by moore\\'s law), leading to the digital revolution during the late 20th to early 21st centuries.conventionally, a modern computer consists of at least one processing element, typically a central processing unit (cpu) in the form of a microprocessor, along with some type of computer memory, typically semiconductor memory chips. the processing element carries out arithmetic and logical operations, and a sequencing and control unit can change the order of operations in response to stored information. peripheral devices include input devices (keyboards, mice, joystick, etc.), output devices (monitor screens, printers, etc.), and input/output devices that perform both functions (e.g., the 2000s-era touchscreen). peripheral devices allow information to be retrieved from an external source and they enable the result of operations to be saved and retrieved.', 'computer science is the study of computation, automation, and information. computer science spans theoretical disciplines (such as algorithms, theory of computation, and information theory) to practical disciplines (including the design and implementation of hardware and software). computer science is generally considered an area of academic research and distinct from computer programming.algorithms and data structures are central to computer science.the theory of computation concerns abstract models of computation and general classes of problems that can be solved using them. the fields of cryptography and computer security involve studying the means for secure communication and for preventing security vulnerabilities. computer graphics and computational geometry address the generation of images. programming language theory considers approaches to the description of computational processes, and database theory concerns the management of repositories of data. human–computer interaction investigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. areas such as operating systems, networks and embedded systems investigate the principles and design behind complex systems. computer architecture describes the construction of computer components and computer-operated equipment. artificial intelligence and machine learning aim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. within artificial intelligence, computer vision aims to understand and process image and video data, while natural-language processing aims to understand and process textual and linguistic data.the fundamental concern of computer science is determining what can and cannot be automated. the turing award is generally recognized as the highest distinction in computer science.', 'in computer engineering, microarchitecture, also called computer organization and sometimes abbreviated as µarch or uarch, is the way a given instruction set architecture (isa) is implemented in a particular processor. a given isa may be implemented with different microarchitectures; implementations may vary due to different goals of a given design or due to shifts in technology.computer architecture is the combination of microarchitecture and instruction set architecture.', 'a computer architecture simulator is a program that simulates the execution of computer architecture.computer architecture simulators are used for the following purposes:lowering cost by evaluating hardware designs without building physical hardware systems.enabling access to unobtainable hardware.increasing the precision and volume of computer performance data.introducing abilities that are not normally possible on real hardware such as running code backwards when an error is detected or running in faster-than-real time.'], 'history': ['the first documented computer architecture was in the correspondence between charles babbage and ada lovelace, describing the analytical engine. when building the computer z1 in 1936, konrad zuse described in two patent applications for his future projects that machine instructions could be stored in the same storage used for data, i.e., the stored-program concept. two other early and important examples are:john von neumann\\'s 1945 paper, first draft of a report on the edvac, which described an organization of logical elements; andalan turing\\'s more detailed proposed electronic calculator for the automatic computing engine, also 1945 and which cited john von neumann\\'s paper.the term “architecture” in computer literature can be traced to the work of lyle r. johnson and frederick p. brooks, jr., members of the machine organization department in ibm\\'s main research center in 1959. johnson had the opportunity to write a proprietary research communication about the stretch, an ibm-developed supercomputer for los alamos national laboratory (at the time known as los alamos scientific laboratory). to describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that seemed more useful than “machine organization”.subsequently, brooks, a stretch designer, opened chapter 2 of a book called planning a computer system: project stretch by stating, “computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.”brooks went on to help develop the ibm system/360 (now called the ibm zseries) line of computers, in which “architecture” became a noun defining “what the user needs to know”. later, computer users came to use the term in many less explicit ways.the earliest computer architectures were designed on paper and then directly built into the final hardware form.later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (ttl) computer—such as the prototypes of the 6800 and the pa-risc—tested, and tweaked, before committing to the final hardware form.as of the 1990s, new computer architectures are typically \"built\", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a fpga as a soft microprocessor; or both—before committing to the final hardware form.', 'the earliest computing machines had fixed programs.  some very simple computers still use this design, either for simplicity or training purposes.  for example, a desk calculator (in principle) is a fixed program computer.  it can do basic mathematics, but it cannot run a word processor or games.  changing the program of a fixed-program machine requires rewiring, restructuring, or redesigning the machine.  the earliest computers were not so much \"programmed\" as  \"designed\" for a particular task.  \"reprogramming\" – when possible at all – was a laborious process that started with flowcharts and paper notes, followed by detailed engineering designs, and then the often-arduous process of physically rewiring and rebuilding the machine. it could take three weeks to set up and debug a program on eniac.with the proposal of the stored-program computer, this changed. a stored-program computer includes, by design, an instruction set, and can store in memory a set of instructions (a program) that details the computation.a stored-program design also allows for self-modifying code. one early motivation for such a facility was the need for a program to increment or otherwise modify the address portion of instructions, which operators had to do manually in early designs. this became less important when index registers and indirect addressing became usual features of machine architecture. another use was to embed frequently used data in the instruction stream using immediate addressing. self-modifying code has largely fallen out of favor, since it is usually hard to understand and debug, as well as being inefficient under modern processor pipelining and caching schemes.', 'predicated instructions were popular in european computer designs of the 1950s, including the mailüfterl (1955), the zuse z22 (1955), the zebra (1958), and the electrologica x1 (1958). the ibm acs-1 design of 1967 allocated a \"skip\" bit in its instruction formats, and the cdc flexible processor in 1976 allocated three conditional execution bits in its microinstruction formats.hewlett-packard\\'s pa-risc architecture (1986) had a feature called nullification, which allowed most instructions to be predicated by the previous instruction. ibm\\'s power architecture (1990) featured conditional move instructions. power\\'s successor, powerpc (1993), dropped these instructions. digital equipment corporation\\'s alpha architecture (1992) also featured conditional move instructions. mips gained conditional move instructions in 1994 with the mips iv version; and sparc was extended in version 9 (1994) with conditional move instructions for both integer and floating-point registers.in the hewlett-packard/intel ia-64 architecture, most instructions are predicated. the predicates are stored in 64 special-purpose predicate registers; and one of the predicate registers is always true so that unpredicated instructions are simply instructions predicated with the value true. the use of predication is essential in ia-64\\'s implementation of software pipelining because it avoids the need for writing separated code for prologs and epilogs.in the x86 architecture, a family of conditional move instructions (cmov and fcmov) were added to the architecture by the intel pentium pro (1995) processor. the cmov instructions copied the contents of the source register to the destination register depending on a predicate supplied by the value of the flag register.in the arm architecture, the original 32-bit instruction set provides a feature called conditional execution that allows most instructions to be predicated by one of 13 predicates that are based on some combination of the four condition codes set by the previous instruction. arm\\'s thumb instruction set (1994) dropped conditional execution to reduce the size of instructions so they could fit in 16 bits, but its successor, thumb-2 (2003) overcame this problem by using a special instruction which has no effect other than to supply predicates for the following four instructions. the 64-bit instruction set introduced in armv8-a (2011) replaced conditional execution with conditional selection instructions.== simd, simt and vector predication ==some simd instruction sets, like avx2, have the ability to use a logical mask to conditionally load/store values to memory, a parallel form of the conditional move, and may also apply individual mask bits to individual arithmetic units executing a parallel operation.  the technique is known in flynn\\'s taxonomy as \"associative processing\".this form of predication is also used in vector processors and single instruction, multiple threads gpu computing.  all the techniques, advantages and disadvantages of single scalar predication apply just as well to the parallel processing case.', '=== pre-20th century ===devices have been used to aid computation for thousands of years, mostly using one-to-one correspondence with fingers. the earliest counting device was probably a form of tally stick. later record keeping aids throughout the fertile crescent included calculi (clay spheres, cones, etc.) which represented counts of items, probably livestock or grains, sealed in hollow unbaked clay containers. the use of counting rods is one example.the abacus was initially used for arithmetic tasks. the roman abacus was developed from devices used in babylonia as early as 2400 bc. since then, many other forms of reckoning boards or tables have been invented. in a medieval european counting house, a checkered cloth would be placed on a table, and markers moved around on it according to certain rules, as an aid to calculating sums of money.the antikythera mechanism is believed to be the earliest known mechanical analog computer, according to derek j. de solla price. it was designed to calculate astronomical positions. it was discovered in 1901 in the antikythera wreck off the greek island of antikythera, between kythera and crete, and has been dated to approximately c.\\u2009100 bc. devices of comparable complexity to the antikythera mechanism would not reappear until the fourteenth century.many mechanical aids to calculation and measurement were constructed for astronomical and navigation use. the planisphere was a star chart invented by abū rayhān al-bīrūnī in the early 11th century. the astrolabe was invented in the hellenistic world in either the 1st or 2nd centuries bc and is often attributed to hipparchus. a combination of the planisphere and dioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems in spherical astronomy. an astrolabe incorporating a mechanical calendar computer and gear-wheels was invented by abi bakr of isfahan, persia in 1235. abū rayhān al-bīrūnī invented the first mechanical geared lunisolar calendar astrolabe, an early fixed-wired knowledge processing machine with a gear train and gear-wheels, c.\\u20091000 ad.the sector, a calculating instrument used for solving problems in proportion, trigonometry, multiplication and division, and for various functions, such as squares and cube roots, was developed in the late 16th century and found application in gunnery, surveying and navigation.the planimeter was a manual instrument to calculate the area of a closed figure by tracing over it with a mechanical linkage.the slide rule was invented around 1620–1630 by the english clergyman william oughtred, shortly after the publication of the concept of the logarithm. it is a hand-operated analog computer for doing multiplication and division. as slide rule development progressed, added scales provided reciprocals, squares and square roots, cubes and cube roots, as well as transcendental functions such as logarithms and exponentials, circular and hyperbolic trigonometry and other functions. slide rules with special scales are still used for quick performance of routine calculations, such as the e6b circular slide rule used for time and distance calculations on light aircraft.in the 1770s, pierre jaquet-droz, a swiss watchmaker, built a mechanical doll (automaton) that could write holding a quill pen. by switching the number and order of its internal wheels different letters, and hence different messages, could be produced. in effect, it could be mechanically \"programmed\" to read instructions. along with two other complex machines, the doll is at the musée d\\'art et d\\'histoire of neuchâtel, switzerland, and still operates.in 1831–1835, mathematician and engineer giovanni plana devised a perpetual calendar machine, which, through a system of pulleys and cylinders and over, could predict the perpetual calendar for every year from ad 0 (that is, 1 bc) to ad 4000, keeping track of leap years and varying day length. the tide-predicting machine invented by the scottish scientist sir william thomson in 1872 was of great utility to navigation in shallow waters. it used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location.the differential analyser, a mechanical analog computer designed to solve differential equations by integration, used wheel-and-disc mechanisms to perform the integration. in 1876, sir william thomson had already discussed the possible construction of such calculators, but he had been stymied by the limited output torque of the ball-and-disk integrators. in a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output. the torque amplifier was the advance that allowed these machines to work. starting in the 1920s, vannevar bush and others developed mechanical differential analyzers.=== first computer ===charles babbage, an english mechanical engineer and polymath, originated the concept of a programmable computer. considered the \"father of the computer\", he conceptualized and invented the first mechanical computer in the early 19th century. after working on his revolutionary difference engine, designed to aid in navigational calculations, in 1833 he realized that a much more general design, an analytical engine, was possible. the input of programs and data was to be provided to the machine via punched cards, a method being used at the time to direct mechanical looms such as the jacquard loom. for output, the machine would have a printer, a curve plotter and a bell. the machine would also be able to punch numbers onto cards to be read in later. the engine incorporated an arithmetic logic unit, control flow in the form of conditional branching and loops, and integrated memory, making it the first design for a general-purpose computer that could be described in modern terms as turing-complete.the machine was about a century ahead of its time. all the parts for his machine had to be made by hand – this was a major problem for a device with thousands of parts. eventually, the project was dissolved with the decision of the british government to cease funding. babbage\\'s failure to complete the analytical engine can be chiefly attributed to political and financial difficulties as well as his desire to develop an increasingly sophisticated computer and to move ahead faster than anyone else could follow. nevertheless, his son, henry babbage, completed a simplified version of the analytical engine\\'s computing unit (the mill) in 1888. he gave a successful demonstration of its use in computing tables in 1906.=== analog computers ===during the first half of the 20th century, many scientific computing needs were met by increasingly sophisticated analog computers, which used a direct mechanical or electrical model of the problem as a basis for computation. however, these were not programmable and generally lacked the versatility and accuracy of modern digital computers. the first modern analog computer was a tide-predicting machine, invented by sir william thomson (later to become lord kelvin) in 1872. the differential analyser, a mechanical analog computer designed to solve differential equations by integration using wheel-and-disc mechanisms, was conceptualized in 1876 by james thomson, the elder brother of the more famous sir william thomson.the art of mechanical analog computing reached its zenith with the differential analyzer, built by h. l. hazen and vannevar bush at mit starting in 1927. this built on the mechanical integrators of james thomson and the torque amplifiers invented by h. w. nieman. a dozen of these devices were built before their obsolescence became obvious. by the 1950s, the success of digital electronic computers had spelled the end for most analog computing machines, but analog computers remained in use during the 1950s in some specialized applications such as education (slide rule) and aircraft (control systems).=== digital computers ======= electromechanical ====by 1938, the united states navy had developed an electromechanical analog computer small enough to use aboard a submarine. this was the torpedo data computer, which used trigonometry to solve the problem of firing a torpedo at a moving target. during world war ii similar devices were developed in other countries as well.early digital computers were electromechanical; electric switches drove mechanical relays to perform the calculation. these devices had a low operating speed and were eventually superseded by much faster all-electric computers, originally using vacuum tubes. the z2, created by german engineer konrad zuse in 1939, was one of the earliest examples of an electromechanical relay computer.in 1941, zuse followed his earlier machine up with the z3, the world\\'s first working electromechanical programmable, fully automatic digital computer. the z3 was built with 2000 relays, implementing a 22 bit word length that operated at a clock frequency of about 5–10 hz. program code was supplied on punched film while data could be stored in 64 words of memory or supplied from the keyboard. it was quite similar to modern machines in some respects, pioneering numerous advances such as floating-point numbers. rather than the harder-to-implement decimal system (used in charles babbage\\'s earlier design), using a binary system meant that zuse\\'s machines were easier to build and potentially more reliable, given the technologies available at that time. the z3 was not itself a universal computer but could be extended to be turing complete.zuse\\'s next computer, the z4, became the world\\'s first commercial computer; after initial delay due to the second world war, it was completed in 1950 and delivered to the eth zurich. the computer was manufactured by zuse\\'s own company, zuse kg, which was founded in 1941 as the first company with the sole purpose of developing computers.==== vacuum tubes and digital electronic circuits ====purely electronic circuit elements soon replaced their mechanical and electromechanical equivalents, at the same time that digital calculation replaced analog. the engineer tommy flowers, working at the post office research station in london in the 1930s, began to explore the possible use of electronics for the telephone exchange. experimental equipment that he built in 1934 went into operation five years later, converting a portion of the telephone exchange network into an electronic data processing system, using thousands of vacuum tubes. in the us, john vincent atanasoff and clifford e. berry of iowa state university developed and tested the atanasoff–berry computer (abc) in 1942, the first \"automatic electronic digital computer\". this design was also all-electronic and used about 300 vacuum tubes, with capacitors fixed in a mechanically rotating drum for memory.during world war ii, the british code-breakers at bletchley park achieved a number of successes at breaking encrypted german military communications. the german encryption machine, enigma, was first attacked with the help of the electro-mechanical bombes which were often run by women. to crack the more sophisticated german lorenz sz 40/42 machine, used for high-level army communications, max newman and his colleagues commissioned flowers to build the colossus. he spent eleven months from early february 1943 designing and building the first colossus. after a functional test in december 1943, colossus was shipped to bletchley park, where it was delivered on 18 january 1944 and attacked its first message on 5 february.colossus was the world\\'s first electronic digital programmable computer. it used a large number of valves (vacuum tubes). it had paper-tape input and was capable of being configured to perform a variety of boolean logical operations on its data, but it was not turing-complete. nine mk ii colossi were built (the mk i was converted to a mk ii making ten machines in total). colossus mark i contained 1,500 thermionic valves (tubes), but mark ii with 2,400 valves, was both five times faster and simpler to operate than mark i, greatly speeding the decoding process.the eniac (electronic numerical integrator and computer) was the first electronic programmable computer built in the u.s. although the eniac was similar to the colossus, it was much faster, more flexible, and it was turing-complete. like the colossus, a \"program\" on the eniac was defined by the states of its patch cables and switches, a far cry from the stored program electronic machines that came later. once a program was written, it had to be mechanically set into the machine with manual resetting of plugs and switches. the programmers of the eniac were six women, often known collectively as the \"eniac girls\".it combined the high speed of electronics with the ability to be programmed for many complex problems. it could add or subtract 5000 times a second, a thousand times faster than any other machine. it also had modules to multiply, divide, and square root. high speed memory was limited to 20 words (about 80 bytes). built under the direction of john mauchly and j. presper eckert at the university of pennsylvania, eniac\\'s development and construction lasted from 1943 to full operation at the end of 1945. the machine was huge, weighing 30 tons, using 200 kilowatts of electric power and contained over 18,000 vacuum tubes, 1,500 relays, and hundreds of thousands of resistors, capacitors, and inductors.=== modern computers ======= concept of modern computer ====the principle of the modern computer was proposed by alan turing in his seminal 1936 paper, on computable numbers. turing proposed a simple device that he called \"universal computing machine\" and that is now known as a universal turing machine. he proved that such a machine is capable of computing anything that is computable by executing instructions (program) stored on tape, allowing the machine to be programmable. the fundamental concept of turing\\'s design is the stored program, where all the instructions for computing are stored in memory. von neumann acknowledged that the central concept of the modern computer was due to this paper. turing machines are to this day a central object of study in theory of computation. except for the limitations imposed by their finite memory stores, modern computers are said to be turing-complete, which is to say, they have algorithm execution capability equivalent to a universal turing machine.==== stored programs ====early computing machines had fixed programs. changing its function required the re-wiring and re-structuring of the machine. with the proposal of the stored-program computer this changed. a stored-program computer includes by design an instruction set and can store in memory a set of instructions (a program) that details the computation. the theoretical basis for the stored-program computer was laid by alan turing in his 1936 paper. in 1945, turing joined the national physical laboratory and began work on developing an electronic stored-program digital computer. his 1945 report \"proposed electronic calculator\" was the first specification for such a device. john von neumann at the university of pennsylvania also circulated his first draft of a report on the edvac in 1945.the manchester baby was the world\\'s first stored-program computer. it was built at the university of manchester in england by frederic c. williams, tom kilburn and geoff tootill, and ran its first program on 21 june 1948. it was designed as a testbed for the williams tube, the first random-access digital storage device. although the computer was considered \"small and primitive\" by the standards of its time, it was the first working machine to contain all of the elements essential to a modern electronic computer. as soon as the baby had demonstrated the feasibility of its design, a project was initiated at the university to develop it into a more usable computer, the manchester mark 1. grace hopper was the first person to develop a compiler for programming language.the mark 1 in turn quickly became the prototype for the ferranti mark 1, the world\\'s first commercially available general-purpose computer. built by ferranti, it was delivered to the university of manchester in february 1951. at least seven of these later machines were delivered between 1953 and 1957, one of them to shell labs in amsterdam. in october 1947, the directors of british catering company j. lyons & company decided to take an active role in promoting the commercial development of computers. the leo i computer became operational in april 1951 and ran the world\\'s first regular routine office computer job.==== transistors ====the concept of a field-effect transistor was proposed by julius edgar lilienfeld in 1925. john bardeen and walter brattain, while working under william shockley at bell labs, built the first working transistor, the point-contact transistor, in 1947, which was followed by shockley\\'s bipolar junction transistor in 1948. from 1955 onwards, transistors replaced vacuum tubes in computer designs, giving rise to the \"second generation\" of computers. compared to vacuum tubes, transistors have many advantages: they are smaller, and require less power than vacuum tubes, so give off less heat. junction transistors were much more reliable than vacuum tubes and had longer, indefinite, service life. transistorized computers could contain tens of thousands of binary logic circuits in a relatively compact space. however, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications.at the university of manchester, a team under the leadership of tom kilburn designed and built a machine using the newly developed transistors instead of valves. their first transistorised computer and the first in the world, was operational by 1953, and a second version was completed there in april 1955. however, the machine did make use of valves to generate its 125 khz clock waveforms and in the circuitry to read and write on its magnetic drum memory, so it was not the first completely transistorized computer. that distinction goes to the harwell cadet of 1955, built by the electronics division of the atomic energy research establishment at harwell.the metal–oxide–silicon field-effect transistor (mosfet), also known as the mos transistor, was invented by mohamed m. atalla and dawon kahng at bell labs in 1959. it was the first truly compact transistor that could be miniaturised and mass-produced for a wide range of uses. with its high scalability, and much lower power consumption and higher density than bipolar junction transistors, the mosfet made it possible to build high-density integrated circuits. in addition to data processing, it also enabled the practical use of mos transistors as memory cell storage elements, leading to the development of mos semiconductor memory, which replaced earlier magnetic-core memory in computers. the mosfet led to the microcomputer revolution, and became the driving force behind the computer revolution. the mosfet is the most widely used transistor in computers, and is the fundamental building block of digital electronics.==== integrated circuits ====the next great advance in computing power came with the advent of the integrated circuit (ic).the idea of the integrated circuit was first conceived by a radar scientist working for the royal radar establishment of the ministry of defence, geoffrey w.a. dummer. dummer presented the first public description of an integrated circuit at the symposium on progress in quality electronic components in washington, d.c. on 7 may 1952.the first working ics were invented by jack kilby at texas instruments and robert noyce at fairchild semiconductor. kilby recorded his initial ideas concerning the integrated circuit in july 1958, successfully demonstrating the first working integrated example on 12 september 1958. in his patent application of 6 february 1959, kilby described his new device as \"a body of semiconductor material ... wherein all the components of the electronic circuit are completely integrated\". however, kilby\\'s invention was a hybrid integrated circuit (hybrid ic), rather than a monolithic integrated circuit (ic) chip. kilby\\'s ic had external wire connections, which made it difficult to mass-produce.noyce also came up with his own idea of an integrated circuit half a year later than kilby. noyce\\'s invention was the first true monolithic ic chip. his chip solved many practical problems that kilby\\'s had not. produced at fairchild semiconductor, it was made of silicon, whereas kilby\\'s chip was made of germanium. noyce\\'s monolithic ic was fabricated using the planar process, developed by his colleague jean hoerni in early 1959. in turn, the planar process was based on mohamed m. atalla\\'s work on semiconductor surface passivation by silicon dioxide in the late 1950s.modern monolithic ics are predominantly mos (metal-oxide-semiconductor) integrated circuits, built from mosfets (mos transistors). the earliest experimental mos ic to be fabricated was a 16-transistor chip built by fred heiman and steven hofstein at rca in 1962. general microelectronics later introduced the first commercial mos ic in 1964, developed by robert norman. following the development of the self-aligned gate (silicon-gate) mos transistor by robert kerwin, donald klein and john sarace at bell labs in 1967, the first silicon-gate mos ic with self-aligned gates was developed by federico faggin at fairchild semiconductor in 1968. the mosfet has since become the most critical device component in modern ics.the development of the mos integrated circuit led to the invention of the microprocessor, and heralded an explosion in the commercial and personal use of computers. while the subject of exactly which device was the first microprocessor is contentious, partly due to lack of agreement on the exact definition of the term \"microprocessor\", it is largely undisputed that the first single-chip microprocessor was the intel 4004, designed and realized by federico faggin with his silicon-gate mos ic technology, along with ted hoff, masatoshi shima and stanley mazor at intel. in the early 1970s, mos ic technology enabled the integration of more than 10,000 transistors on a single chip.system on a chip (socs) are complete computers on a microchip (or chip) the size of a coin. they may or may not have integrated ram and flash memory. if not integrated, the ram is usually placed directly above (known as package on package) or below (on the opposite side of the circuit board) the soc, and the flash memory is usually placed right next to the soc, this all done to improve data transfer speeds, as the data signals don\\'t have to travel long distances. since eniac in 1945, computers have advanced enormously, with modern socs (such as the snapdragon 865) being the size of a coin while also being hundreds of thousands of times more powerful than eniac, integrating billions of transistors, and consuming only a few watts of power.=== mobile computers ===the first mobile computers were heavy and ran from mains power. the 50 lb (23 kg) ibm 5100 was an early example. later portables such as the osborne 1 and compaq portable were considerably lighter but still needed to be plugged in. the first laptops, such as the grid compass, removed this requirement by incorporating batteries – and with the continued miniaturization of computing resources and advancements in portable battery life, portable computers grew in popularity in the 2000s. the same developments allowed manufacturers to integrate computing resources into cellular mobile phones by the early 2000s.these smartphones and tablets run on a variety of operating systems and recently became the dominant computing device on the market. these are powered by system on a chip (socs), which are complete computers on a microchip the size of a coin.', 'the earliest foundations of what would become computer science predate the invention of the modern digital computer. machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment.wilhelm schickard designed and constructed the first working mechanical calculator in 1623. in 1673, gottfried leibniz demonstrated a digital mechanical calculator, called the stepped reckoner. leibniz may be considered the first computer scientist and information theorist, for, among other reasons, documenting the binary number system. in 1820, thomas de colmar launched the mechanical calculator industry when he invented his simplified arithmometer, the first calculating machine strong enough and reliable enough to be used daily in an office environment. charles babbage started the design of the first automatic mechanical calculator, his difference engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his analytical engine. he started developing this machine in 1834, and \"in less than two years, he had sketched out many of the salient features of the modern computer\". \"a crucial step was the adoption of a punched card system derived from the jacquard loom\" making it infinitely programmable. in 1843, during the translation of a french article on the analytical engine, ada lovelace wrote, in one of the many notes she included, an algorithm to compute the bernoulli numbers, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer. around 1885, herman hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of ibm. following babbage, although unaware of his earlier work, percy ludgate in 1909 published the 2nd of the only two designs for mechanical analytical engines in history. in 1937, one hundred years after babbage\\'s impossible dream, howard aiken convinced ibm, which was making all kinds of punched card equipment and was also in the calculator business to develop his giant programmable calculator, the ascc/harvard mark i, based on babbage\\'s analytical engine, which itself used cards and a central computing unit. when the machine was finished, some hailed it as \"babbage\\'s dream come true\".during the 1940s, with the development of new and more powerful computing machines such as the atanasoff–berry computer and eniac, the term computer came to refer to the machines rather than their human predecessors. as it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study computation in general. in 1945, ibm founded the watson scientific computing laboratory at columbia university in new york city. the renovated fraternity house on manhattan\\'s west side was ibm\\'s first laboratory devoted to pure science. the lab is the forerunner of ibm\\'s research division, which today operates research facilities around the world. ultimately, the close relationship between ibm and the university was instrumental in the emergence of a new scientific discipline, with columbia offering one of the first academic-credit courses in computer science in 1946. computer science began to be established as a distinct academic discipline in the 1950s and early 1960s. the world\\'s first computer science degree program, the cambridge diploma in computer science, began at the university of cambridge computer laboratory in 1953. the first computer science department in the united states was formed at purdue university in 1962. since practical computers became available, many applications of computing have become distinct areas of study in their own rights.'], 'subcategorie': ['the discipline of computer architecture has three main subcategories:instruction set architecture (isa): defines the machine code that a processor reads and acts upon as well as the word size, memory address modes, processor registers, and data type.microarchitecture: also known as \"computer organization\", this describes how a particular processor will implement the isa. the size of a computer\\'s cpu cache for instance, is an issue that generally has nothing to do with the isa.systems design: includes all of the other hardware components within a computing system, such as data processing other than the cpu (e.g., direct memory access), virtualization, and multiprocessing.there are other technologies in computer architecture. the following technologies are used in bigger companies like intel, and were estimated in 2002 to count for 1% of all of computer architecture:macroarchitecture: architectural layers more abstract than microarchitectureassembly instruction set architecture: a smart assembler may convert an abstract assembly language common to a group of machines into slightly different machine language for different implementations.programmer-visible macroarchitecture: higher-level language tools such as compilers may define a consistent interface or contract to programmers using them, abstracting differences between underlying isa, uisa, and microarchitectures. for example, the c, c++, or java standards define different programmer-visible macroarchitectures.microcode: microcode is software that translates instructions to run on a chip. it acts like a wrapper around the hardware, presenting a preferred version of the hardware\\'s instruction set interface. this instruction translation facility gives chip designers flexible options: e.g. 1. a new improved version of the chip can use microcode to present the exact same instruction set as the old chip version, so all software targeting that instruction set will run on the new chip without needing changes. e.g. 2. microcode can present a variety of instruction sets for the same underlying chip, allowing it to run a wider variety of software.uisa: user instruction set architecture, refers to one of three subsets of the risc cpu instructions provided by powerpc risc processors. the uisa subset, are those risc instructions of interest to application developers. the other two subsets are vea (virtual environment architecture) instructions used by virtualization system developers, and oea (operating environment architecture) used by operation system developers.pin architecture: the hardware functions that a microprocessor should provide to a hardware platform, e.g., the x86 pins a20m, ferr/ignne or flush. also, messages that the processor should emit so that external caches can be invalidated (emptied). pin architecture functions are more flexible than isa functions because external hardware can adapt to new encodings, or change from a pin to a message. the term \"architecture\" fits, because the functions must be provided for compatible systems, even if the detailed method changes.'], 'role': [\"=== definition ===computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. the case of instruction set architecture can be used to illustrate the balance of these competing factors. more complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 loop instruction). however, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. the increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.the implementation involves integrated circuit design, packaging, power, and cooling. optimization of the design requires familiarity with compilers, operating systems to logic design, and packaging.=== instruction set architecture ===an instruction set architecture (isa) is the interface between the computer's software and hardware and also can be viewed as the programmer's view of the machine. computers do not understand high-level programming languages such as java, c++, or most programming languages used. a processor only understands instructions encoded in some numerical fashion, usually as binary numbers. software tools, such as compilers, translate those high level languages into instructions that the processor can understand.besides instructions, the isa defines items in the computer that are available to a program—e.g., data types, registers, addressing modes, and memory.  instructions locate these available items with register indexes (or names) and memory addressing modes.the isa of a computer is usually described in a small instruction manual, which describes how the instructions are encoded. also, it may define short (vaguely) mnemonic names for the instructions. the names can be recognized by a software development tool called an assembler.  an assembler is a computer program that translates a human-readable form of the isa into a computer-readable form.  disassemblers are also widely available, usually in debuggers and software programs to isolate and correct malfunctions in binary computer programs.isas vary in quality and completeness.  a good isa compromises between programmer convenience (how easy the code is to understand), size of the code (how much code is required to do a specific action), cost of the computer to interpret the instructions (more complexity means more hardware needed to decode and execute the instructions), and speed of the computer (with more complex decoding hardware comes longer decode time).  memory organization defines how instructions interact with the memory, and how memory interacts with itself.during design emulation, emulators can run programs written in a proposed instruction set. modern emulators can measure size, cost, and speed to determine whether a particular isa is meeting its goals.=== computer organization ===computer organization helps optimize performance-based products. for example, software engineers need to know the processing power of processors. they may need to optimize software in order to gain the most performance for the lowest price. this can require quite a detailed analysis of the computer's organization.  for example, in an sd card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.computer organization also helps plan the selection of a processor for a particular project. multimedia projects may need very rapid data access, while virtual machines may need fast interrupts. sometimes certain tasks need additional components as well.  for example, a computer capable of running a virtual machine needs virtual memory hardware so that the memory of different virtual computers can be kept separated. computer organization and features also affect power consumption and processor cost.=== implementation ===once an instruction set and micro-architecture have been designed, a practical machine must be developed. this design process is called the implementation. implementation is usually not considered architectural design, but rather hardware design engineering. implementation can be further broken down into several steps:logic implementation designs the circuits required at a logic-gate level.circuit implementation does transistor-level designs of basic elements (e.g., gates, multiplexers, latches) as well as of some larger blocks (alus, caches etc.) that may be implemented at the logic-gate level, or even at the physical level if the design calls for it.physical implementation draws physical circuits.  the different circuit components are placed in a chip floor plan or on a board and the wires connecting them are created.design validation tests the computer as a whole to see if it works in all situations and all timings. once the design validation process starts, the design at the logic level are tested using logic emulators. however, this is usually too slow to run a realistic test.  so, after making corrections based on the first test, prototypes are constructed using field-programmable gate-arrays (fpgas). most hobby projects stop at this stage.  the final step is to test prototype integrated circuits, which may require several redesigns.for cpus, the entire implementation process is organized differently and is often referred to as cpu design.\"], 'design goal': ['the exact form of a computer system depends on the constraints and goals. computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.the most common scheme does an in-depth power analysis and figures out how to keep power consumption low while maintaining adequate performance.=== performance ===modern computer performance is often described in instructions per cycle (ipc), which measures the efficiency of the architecture at any clock frequency; a faster ipc rate means the computer is faster. older computers had ipc counts as low as 0.1 while modern processors easily reach near 1. superscalar processors may reach three to five ipc by executing several instructions per clock cycle.counting machine-language instructions would be misleading because they can do varying amounts of work in different isas. the \"instruction\" in the standard measurements is not a count of the isa\\'s machine-language instructions, but a unit of measurement, usually based on the speed of the vax computer architecture.many people used to measure a computer\\'s speed by the clock rate (usually in mhz or ghz). this refers to the cycles per second of the main clock of the cpu. however, this metric is somewhat misleading, as a machine with a higher clock rate may not necessarily have greater performance. as a result, manufacturers have moved away from clock speed as a measure of performance.other factors influence speed, such as the mix of functional units, bus speeds, available memory, and the type and order of instructions in the programs.there are two main types of speed: latency and throughput. latency is the time between the start of a process and its completion. throughput is the amount of work done per unit time.  interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).performance is affected by a very wide range of design choices — for example, pipelining a processor usually makes latency worse, but makes throughput better. computers that control machinery usually need low interrupt latencies. these computers operate in a real-time environment and fail if an operation is not completed in a specified amount of time. for example, computer-controlled anti-lock brakes must begin braking within a predictable and limited time period after the brake pedal is sensed or else failure of the brake will occur.benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. although benchmarking shows strengths, it shouldn\\'t be how you choose a computer. often the measured machines split on different measures. for example, one system might handle scientific applications quickly, while another might render video games more smoothly. furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but don\\'t offer similar advantages to general tasks.=== power efficiency ===power efficiency is another important measurement in modern computers. a higher power efficiency can often be traded for lower speed or higher cost. the typical measurement when referring to power consumption in computer architecture is mips/w (millions of instructions per second per watt).modern circuits have less power required per transistor as the number of transistors per chip grows. this is because each transistor that is put in a new chip requires its own power supply and requires new pathways to be built to power it. however the number of transistors per chip is starting to increase at a slower rate. therefore, power efficiency is starting to become as important, if not more important than fitting more and more transistors into a single chip. recent processor designs have shown this emphasis as they put more focus on power efficiency rather than cramming as many transistors into a single chip as possible. in the world of embedded computers, power efficiency has long been an important goal next to throughput and latency.=== shifts in market demand ===increases in clock frequency have grown more slowly over the past few years, compared to power reduction improvements. this has been driven by the end of moore\\'s law and demand for longer battery life and reductions in size for mobile technology. this change in focus from higher clock rates to power consumption and miniaturization can be shown by the significant reductions in power consumption, as much as 50%, that were reported by intel in their release of the haswell microarchitecture; where they dropped their power consumption benchmark from 30 to 40 watts down to 10-20 watts. comparing this to the processing speed increase of 3 ghz to 4 ghz (2002 to 2006) it can be seen that the focus in research and development are shifting away from clock frequency and moving towards consuming less power and taking up less space.'], 'see also': ['', 'integer (computer science)', '', 'super-threadingspeculative multithreading', 'cardboard illustrative aid to computationinterconnect bottlenecklittle man computerrandom-access machineharvard architectureturing machineeckert architecture', '', '', '', 'control unithardware architecturehardware description language (hdl)instruction-level parallelism (ilp)list of amd cpu microarchitectureslist of intel cpu microarchitecturesprocessor designstream processingvhdlvery large-scale integration (vlsi)verilog', 'instruction set simulator'], 'reference': ['', '', '=== general ===', '', '', '', '', '', '', ''], 'source': ['john l. hennessy and david patterson (2006). computer architecture: a quantitative approach (fourth ed.). morgan kaufmann. isbn 978-0-12-370490-0.barton, robert s., \"functional design of computers\", communications of the acm 4(9): 405 (1961).barton, robert s., \"a new approach to the functional design of a digital computer\", proceedings of the western joint computer conference, may 1961, pp. 393–396. about the design of the burroughs b5000 computer.bell, c. gordon; and newell, allen (1971). \"computer structures: readings and examples\", mcgraw-hill.blaauw, g.a., and brooks, f.p., jr., \"the structure of system/360, part i-outline of the logical structure\", ibm systems journal, vol. 3, no. 2, pp. 119–135, 1964.tanenbaum, andrew s. (1979). structured computer organization. englewood cliffs, new jersey: prentice-hall. isbn 0-13-148521-0.', ''], 'external link': ['isca: proceedings of the international symposium on computer architecturemicro: ieee/acm international symposium on microarchitecturehpca: international symposium on high performance computer architectureasplos: international conference on architectural support for programming languages and operating systemsacm transactions on architecture and code optimizationieee transactions on computersthe von neumann architecture of computer systems', '\"automatic pipelining from transactional datapath specifications\" (pdf). retrieved 23 july 2014.tulsen, dean (18 january 2005). \"pipeline hazards\" (pdf).', 'a survey of processors with explicit multithreading, acm, march 2003, by theo ungerer, borut robi and jurij silcoperating system | difference between multitasking, multithreading and multiprocessing geeksforgeeks, 6 sept. 2018.', 'harvard vs von neumanna tool that emulates the behavior of a von neumann machinejohnny: a simple open source simulator of a von neumann machine for educational purposes', ' media related to computers at wikimedia commons wikiversity has a quiz on this articlewarhol & the computer', 'computer science at curliescholarly societies in computer science archived june 23, 2011, at the wayback machinewhat is computer science?best papers awards in computer science since 1996photographs of computer scientists by bertrand meyereecs.berkeley.edu=== bibliography and academic search engines ===citeseerx (article): search engine, digital library and repository for scientific and academic papers with a focus on computer and information science.dblp computer science bibliography (article): computer science bibliography website hosted at universität trier, in germany.the collection of computer science bibliographies (collection of computer science bibliographies)=== professional organizations ===association for computing machineryieee computer societyinformatics europeaaaiaaas computer science=== misc ===computer science—stack exchange: a community-run question-and-answer site for computer sciencewhat is computer science archived february 18, 2015, at the wayback machineis computer science science?computer science (software) must be considered as an independent discipline.', 'the archer virtual infrastructure for computer architecture simulation\"mikrocodesimulator mikrosim 2010\". 0/1-simware. retrieved 2010-12-06.'], 'uses of word': ['depending on how a computer is organized, word-size units may be used for:fixed-point numbersholders for fixed point, usually integer, numerical values may be available in one or in several different sizes, but one of the sizes available will almost always be the word. the other sizes, if any, are likely to be multiples or fractions of the word size. the smaller sizes are normally used only for efficient use of memory; when loaded into the processor, their values usually go into a larger, word sized holder.floating-point numbersholders for floating-point numerical values are typically either a word or a multiple of a word.addressesholders for memory addresses must be of a size capable of expressing the needed range of values but not be excessively large, so often the size used is the word though it can also be a multiple or fraction of the word size.registersprocessor registers are designed with a size appropriate for the type of data they hold, e.g. integers, floating-point numbers, or addresses. many computer architectures use general-purpose registers that are capable of storing data in multiple representations.memory–processor transferwhen the processor reads from the memory subsystem into a register or writes a register\\'s value to memory, the amount of data transferred is often a word. historically, this amount of bits which could be transferred in one cycle was also called a catena in some environments (such as the bull gamma 60). in simple memory subsystems, the word is transferred over the memory data bus, which typically has a width of a word or half-word. in memory subsystems that use caches, the word-sized transfer is the one between the processor and the first level of cache; at lower levels of the memory hierarchy larger transfers (which are a multiple of the word size) are normally used.unit of address resolutionin a given architecture, successive address values designate successive units of memory; this unit is the unit of address resolution. in most computers, the unit is either a character (e.g. a byte) or a word. (a few computers have used bit resolution.) if the unit is a word, then a larger amount of memory can be accessed using an address of a given size at the cost of added complexity to access individual characters. on the other hand, if the unit is a byte, then individual characters can be addressed (i.e. selected during the memory operation).instructionsmachine instructions are normally the size of the architecture\\'s word, such as in risc architectures, or a multiple of the \"char\" size that is a fraction of it. this is a natural choice since instructions and data usually share the same memory subsystem. in harvard architectures the word sizes of instructions and data need not be related, as instructions and data are stored in different memories; for example, the processor in the 1ess electronic telephone switch had 37-bit instructions and 23-bit data words.'], 'word size choice': ['when a computer architecture is designed, the choice of a word size is of substantial importance.  there are design considerations which encourage particular bit-group sizes for particular uses (e.g. for addresses), and these considerations point to different sizes for different uses.  however, considerations of economy in design strongly push for one size, or a very few sizes related by multiples or fractions (submultiples) to a primary size.  that preferred size becomes the word size of the architecture.character size was in the past (pre-variable-sized character encoding) one of the influences on unit of address resolution and the choice of word size.  before the mid-1960s, characters were most often stored in six bits; this allowed no more than 64 characters, so the alphabet was limited to upper case.  since it is efficient in time and space to have the word size be a multiple of the character size, word sizes in this period were usually multiples of 6 bits (in binary machines).  a common choice then was the 36-bit word, which is also a good size for the numeric properties of a floating point format.after the introduction of the ibm system/360 design, which used eight-bit characters and supported lower-case letters, the standard size of a character (or more accurately, a byte) became eight bits.  word sizes thereafter were naturally multiples of eight bits, with 16, 32, and 64 bits being commonly used.=== variable-word architectures ===early machine designs included some that used what is often termed a variable word length.  in this type of organization, an operand had no fixed length. depending on the machine and the instruction, the length might be denoted by a count field, by a delimiting character, or by an additional bit called, e.g., flag, word mark.  such machines often used binary-coded decimal in 4-bit digits, or in 6-bit characters, for numbers.  this class of machines included the ibm 702, ibm 705, ibm 7080, ibm 7010, univac 1050, ibm 1401, ibm 1620, and rca 301.most of these machines work on one unit of memory at a time and since each instruction or datum is several units long, each instruction takes several cycles just to access memory.  these machines are often quite slow because of this.  for example, instruction fetches on an ibm 1620 model i take 8 cycles just to read the 12 digits of the instruction (the model ii reduced this to 6 cycles, or 4 cycles if the instruction did not need both address fields). instruction execution took a completely variable number of cycles, depending on the size of the operands.=== word, bit and byte addressing ===the memory model of an architecture is strongly influenced by the word size.  in particular, the resolution of a memory address, that is, the smallest unit that can be designated by an address, has often been chosen to be the word.  in this approach, the word-addressable machine approach, address values which differ by one designate adjacent memory words.  this is natural in machines which deal almost always in word (or multiple-word) units, and has the advantage of allowing instructions to use minimally sized fields to contain addresses, which can permit a smaller instruction size or a larger variety of instructions.when byte processing is to be a significant part of the workload, it is usually more advantageous to use the byte, rather than the word, as the unit of address resolution. address values which differ by one designate adjacent bytes in memory.  this allows an arbitrary character within a character string to be addressed straightforwardly.  a word can still be addressed, but the address to be used requires a few more bits than the word-resolution alternative.  the word size needs to be an integer multiple of the character size in this organization.  this addressing approach was used in the ibm 360, and has been the most common approach in machines designed since then.when the workload involves processing fields of different sizes, it can be advantageous to address to the bit. machines with bit addressing may have some instructions that use a programmer-defined byte size and other instructions that operate on fixed data sizes. as an example, on the ibm 7030 (\"stretch\"), a floating point instruction can only address words while an integer arithmetic instruction can specify a field length of 1-64 bits, a byte size of 1-8 bits and an accumulator offset of 0-127 bits. in at byte-addressable machine with storage-to-storage (ss) instructions, there are typically move instructions to copy one or multiple bytes from one arbitrary location to another. in a byte-oriented (byte-addressable) machine without ss instructions, moving a single byte from one arbitrary location to another is typically:load the source bytestore the result back in the target byteindividual bytes can be accessed on a word-oriented machine in one of two ways.  bytes can be manipulated by a combination of shift and mask operations in registers. moving a single byte from one arbitrary location to another may require the equivalent of the following:load the word containing the source byteshift the source word to align the desired byte to the correct position in the target wordand the source word with a mask to zero out all but the desired bitsload the word containing the target byteand the target word with a mask to zero out the target byteor the registers containing the source and target words to insert the source bytestore the result back in the target locationalternatively many word-oriented machines implement byte operations with instructions using special byte pointers in registers or memory.  for example, the pdp-10 byte pointer contained the size of the byte in bits (allowing different-sized bytes to be accessed), the bit position of the byte within the word, and the word address of the data.  instructions could automatically adjust the pointer to the next byte on, for example, load and deposit (store) operations.=== powers of two ===different amounts of memory are used to store data values with different degrees of precision. the commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word).  converting the index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. in some cases this relationship can also avoid the use of division operations. as a result, most modern computer designs have word sizes (and other operand sizes) that are a power of two times the size of a byte.'], 'size familie': ['as computer designs have grown more complex, the central importance of a single word size to an architecture has decreased.  although more capable hardware can use a wider variety of sizes of data, market forces exert pressure to maintain backward compatibility while extending processor capability.  as a result, what might have been the central word size in a fresh design has to coexist as an alternative size to the original word size in a backward compatible design. the original word size remains available in future designs, forming the basis of a size family.in the mid-1970s, dec designed the vax to be a 32-bit successor of the 16-bit pdp-11. they used word for a 16-bit quantity, while longword referred to a 32-bit quantity; this terminology is the same as the terminology used for the pdp-11. this was in contrast to earlier machines, where the natural unit of addressing memory would be called a word, while a quantity that is one half a word would be called a halfword. in fitting with this scheme, a vax quadword is 64 bits.  they continued this 16-bit word/32-bit longword/64-bit quadword terminology with the 64-bit alpha.another example is the x86 family, of which processors of three different word lengths (16-bit, later 32- and 64-bit) have been released, while word continues to designate a 16-bit quantity. as software is routinely ported from one word-length to the next, some apis and documentation define or refer to an older (and thus shorter) word-length than the full word length on the cpu that software may be compiled for. also, similar to how bytes are used for small numbers in many programs, a shorter word (16 or 32 bits) may be used in contexts where the range of a wider word is not needed (especially where this can save considerable stack space or cache memory space). for example, microsoft\\'s windows api maintains the programming language definition of word as 16 bits, despite the fact that the api may be used on a 32- or 64-bit x86 processor, where the standard word size would be 32 or 64 bits, respectively. data structures containing such different sized words refer to them as:word (16 bits/2 bytes)dword (32 bits/4 bytes)qword (64 bits/8 bytes)a similar phenomenon has developed in intel\\'s x86 assembly language – because of the support for various sizes (and backward compatibility) in the instruction set, some instruction mnemonics carry \"d\" or \"q\" identifiers denoting \"double-\", \"quad-\" or \"double-quad-\", which are in terms of the architecture\\'s original 16-bit word size.an example with a different word size is the ibm system/360 family. in the system/360 architecture, system/370 architecture and system/390 architecture, there are 8-bit bytes, 16-bit halfwords, 32-bit words and 64-bit doublewords. the z/architecture, which is the 64-bit member of that architecture family, continues to refer to 16-bit halfwords, 32-bit words, and 64-bit doublewords, and additionally features 128-bit quadwords.in general, new processors must use the same data word lengths and virtual address widths as an older processor to have binary compatibility with that older processor.often carefully written source code – written with source-code compatibility and software portability in mind – can be recompiled to run on a variety of processors, even ones with different data word lengths or different address widths or both.'], 'table of word size': [''], 'note': ['', '', ''], 'background': ['instructions in a pipelined processor are performed in several stages, so that at any given time several instructions are being processed in the various stages of the pipeline, such as fetch and execute. there are many different instruction pipeline microarchitectures, and instructions may be executed out-of-order. a hazard occurs when two or more of these simultaneous (possibly out of order) instructions conflict.'], 'type': ['=== data hazards ===data hazards occur when instructions that exhibit data dependence modify data in different stages of a pipeline. ignoring potential data hazards can result in race conditions (also termed race hazards). there are three situations in which a data hazard can occur:read after write (raw), a true dependencywrite after read (war), an anti-dependencywrite after write (waw), an output dependencyread after read (rar) is not a hazard case.consider two instructions i1 and i2, with i1 occurring before i2 in program order.==== read after write (raw) ====(i2 tries to read a source before i1 writes to it)a read after write (raw) data hazard refers to a situation where an instruction refers to a result that has not yet been calculated or retrieved. this can occur because even though an instruction is executed after a prior instruction, the prior instruction has been processed only partly through the pipeline.===== example =====for example:i1. r2 <- r5 + r3i2. r4 <- r2 + r3the first instruction is calculating a value to be saved in register r2, and the second is going to use this value to compute a result for register r4. however, in a pipeline, when operands are fetched for the 2nd operation, the results from the first have not yet been saved, and hence a data dependency occurs.a data dependency occurs with instruction i2, as it is dependent on the completion of instruction i1.==== write after read (war) ====(i2 tries to write a destination before it is read by i1)a write after read (war) data hazard represents a problem with concurrent execution.===== example =====for example:i1. r4 <- r1 + r5i2. r5 <- r1 + r2in any situation with a chance that i2 may finish before i1 (i.e., with concurrent execution), it must be ensured that the result of register r5 is not stored before i1 has had a chance to fetch the operands.==== write after write (waw) ====(i2 tries to write an operand before it is written by i1)a write after write (waw) data hazard may occur in a concurrent execution environment.===== example =====for example:i1. r2 <- r4 + r7i2. r2 <- r1 + r3the write back (wb) of i2 must be delayed until i1 finishes executing.=== structural hazards ===a structural hazard occurs when two (or more) instructions that are already in pipeline need the same resource. the result is that instruction must be executed in series rather than parallel for a portion of pipeline. structural hazards are sometime referred to as resource hazards.example:a situation in which multiple instructions are ready to enter the execute instruction phase and there is a single alu (arithmetic logic unit). one solution to such resource hazard is to increase available resources, such as having multiple ports into main memory and multiple alu (arithmetic logic unit) units.=== control hazards (branch hazards or instruction hazards) ===control hazard occurs when the pipeline makes wrong decisions on branch prediction and therefore brings instructions into the pipeline that must subsequently be discarded. the term branch hazard also refers to a control hazard.', 'computers can be classified in a number of different ways, including:=== by architecture ===analog computerdigital computerhybrid computerharvard architecturevon neumann architecturecomplex instruction set computerreduced instruction set computer=== by size, form-factor and purpose ===supercomputermainframe computerminicomputer (term no longer used)serverrackmount serverblade servertower serverpersonal computerworkstationmicrocomputer (term no longer used)home computerdesktop computertower desktopslimline desktopmultimedia computer (non-linear editing system computers, video editing pcs and the like)gaming computerall-in-one pcnettop (small form factor pcs, mini pcs)home theater pckeyboard computerportable computerthin clientinternet appliancelaptopdesktop replacement computergaming laptoprugged laptop2-in-1 pcultrabookchromebooksubnotebooknetbookmobile computers:tablet computersmartphoneultra-mobile pcpocket pcpalmtop pchandheld pcwearable computersmartwatchsmartglassessingle-board computerplug computerstick pcprogrammable logic controllercomputer-on-modulesystem on modulesystem in a packagesystem-on-chip (also known as an application processor or ap if it lacks circuitry such as radio circuitry)microcontroller'], 'eliminating hazard': ['=== generic ======= pipeline bubbling ====bubbling the pipeline, also termed a pipeline break or pipeline stall, is a method to preclude data, structural, and branch hazards. as instructions are fetched, control logic determines whether a hazard could/will occur. if this is true, then the control logic inserts no operations (nops) into the pipeline. thus, before the next instruction (which would cause the hazard) executes, the prior one will have had sufficient time to finish and prevent the hazard. if the number of nops equals the number of stages in the pipeline, the processor has been cleared of all instructions and can proceed free from hazards. all forms of stalling introduce a delay before the processor can resume execution.flushing the pipeline occurs when a branch instruction jumps to a new memory location, invalidating all prior stages in the pipeline.  these prior stages are cleared, allowing the pipeline to continue at the new instruction indicated by the branch.=== data hazards ===there are several main solutions and algorithms used to resolve data hazards:insert a pipeline bubble whenever a read after write (raw) dependency is encountered, guaranteed to increase latency, oruse out-of-order execution to potentially prevent the need for pipeline bubblesuse operand forwarding to use data from later stages in the pipelinein the case of out-of-order execution, the algorithm used can be:scoreboarding, in which case a pipeline bubble is needed only when there is no functional unit availablethe tomasulo algorithm, which uses register renaming, allowing continual issuing of instructionsthe task of removing data dependencies can be delegated to the compiler, which can fill in an appropriate number of nop instructions between dependent instructions to ensure correct operation, or re-order instructions where possible.==== operand forwarding ======== examples ====in the following examples, computed values are in bold, while register numbers are not.for example, to write the value 3 to register 1, (which already contains a 6), and then add 7 to register 1 and store the result in register 2, i.e.:i0: r1 = 6i1: r1 = 3i2: r2 = r1 + 7 = 10following execution, register 2 should contain the value 10. however, if i1 (write 3 to register 1) does not fully exit the pipeline before i2 starts executing, it means that r1 does not contain the value 3 when i2 performs its addition. in such an event, i2 adds 7 to the old value of register 1 (6), and so register 2 contains 13 instead, i.e.:i0: r1 = 6i2: r2 = r1 + 7 = 13i1: r1 = 3this error occurs because i2 reads register 1 before i1 has committed/stored the result of its write operation to register 1. so when i2 is reading the contents of register 1, register 1 still contains 6, not 3.forwarding (described below) helps correct such errors by depending on the fact that the output of i1 (which is 3) can be used by subsequent instructions before the value 3 is committed to/stored in register 1.forwarding applied to the example means that there is no wait to commit/store the output of i1 in register 1 (in this example, the output is 3) before making that output available to the subsequent instruction (in this case, i2). the effect is that i2 uses the correct (the more recent) value of register 1: the commit/store was made immediately and not pipelined.with forwarding enabled, the instruction decode/execution (id/ex) stage of the pipeline now has two inputs: the value read from the register specified (in this example, the value 6 from register 1), and the new value of register 1 (in this example, this value is 3) which is sent from the next stage instruction execute/memory access (ex/mem). added control logic is used to determine which input to use.=== control hazards (branch hazards) ===to avoid control hazards microarchitectures can:insert a pipeline bubble (discussed above), guaranteed to increase latency, oruse branch prediction and essentially make educated guesses about which instructions to insert, in which case a pipeline bubble will only be needed in the case of an incorrect predictionin the event that a branch causes a pipeline bubble after incorrect instructions have entered the pipeline, care must be taken to prevent any of the wrongly-loaded instructions from having any effect on the processor state excluding energy wasted processing them before they were discovered to be loaded incorrectly.=== other techniques ===memory latency is another factor that designers must attend to, because the delay could reduce performance. different types of memory have different accessing time to the memory. thus, by choosing a suitable type of memory, designers can improve the performance of the pipelined data path.'], 'overview': [\"the multithreading paradigm has become more popular as efforts to further exploit instruction-level parallelism have stalled since the late 1990s. this allowed the concept of throughput computing to re-emerge from the more specialized field of transaction processing. even though it is very difficult to further speed up a single thread or single program, most computer systems are actually multitasking among multiple threads or programs. thus, techniques that improve the throughput of all tasks result in overall performance gains.two major techniques for throughput computing are multithreading and multiprocessing.=== advantages ===if a thread gets a lot of cache misses, the other threads can continue taking advantage of the unused computing resources, which may lead to faster overall execution, as these resources would have been idle if only a single thread were executed. also, if a thread cannot use all the computing resources of the cpu (because instructions depend on each other's result), running another thread may prevent those resources from becoming idle.=== disadvantages ===multiple threads can interfere with each other when sharing hardware resources such as caches or translation lookaside buffers (tlbs). as a result, execution times of a single thread are not improved and can be degraded, even when only one thread is executing, due to lower frequencies or additional pipeline stages that are necessary to accommodate thread-switching hardware.overall efficiency varies; intel claims up to 30% improvement with its hyper-threading technology, while a synthetic program just performing a loop of non-optimized dependent floating-point operations actually gains a 100% speed improvement when run in parallel. on the other hand, hand-tuned assembly language programs using mmx or altivec extensions and performing data prefetches (as a good video encoder might) do not suffer from cache misses or idle computing resources. such programs therefore do not benefit from hardware multithreading and can indeed see degraded performance due to contention for shared resources.from the software standpoint, hardware support for multithreading is more visible to software, requiring more changes to both application programs and operating systems than multiprocessing. hardware techniques used to support multithreading often parallel the software techniques used for computer multitasking. thread scheduling is also a major problem in multithreading.\", \"most computer programs contain conditional code, which will be executed only under specific conditions depending on factors that cannot be determined beforehand, for example depending on user input. as the majority of processors simply execute the next instruction in a sequence, the traditional solution is to insert branch instructions that allow a program to conditionally branch to a different section of code, thus changing the next step in the sequence. this was sufficient until designers began improving performance by implementing instruction pipelining, a method which is slowed down by branches. for a more thorough description of the problems which arose, and a popular solution, see branch predictor.luckily, one of the more common patterns of code that normally relies on branching has a more elegant solution. consider the following pseudocode:on a system that uses conditional branching, this might translate to machine instructions looking similar to:with predication, all possible branch paths are coded inline, but some instructions execute while others do not. the basic idea is that each instruction is associated with a predicate (the word here used similarly to its usage in predicate logic) and that the instruction will only be executed if the predicate is true. the machine code for the above example using predication might look something like this:besides eliminating branches, less code is needed in total, provided the architecture provides predicated instructions. while this does not guarantee faster execution in general, it will if the dosomething and dosomethingelse blocks of code are short enough.predication's simplest form is partial predication, where the architecture has conditional move or conditional select instructions. conditional move instructions write the contents of one register over another only if the predicate's value is true, whereas conditional select instructions choose which of two registers has its contents written to a third based on the predicate's value. a more generalized and capable form is full predication. full predication has a set of predicate registers for storing predicates (which allows multiple nested or sequential branches to be simultaneously eliminated) and most instructions in the architecture have a register specifier field to specify which predicate register supplies the predicate.\"], 'types of multithreading': ['=== interleaved/temporal multithreading ======= coarse-grained multithreading ====the simplest type of multithreading occurs when one thread runs until it is blocked by an event that normally would create a long-latency stall. such a stall might be a cache miss that has to access off-chip memory, which might take hundreds of cpu cycles for the data to return. instead of waiting for the stall to resolve, a threaded processor would switch execution to another thread that was ready to run. only when the data for the previous thread had arrived, would the previous thread be placed back on the list of ready-to-run threads.for example:cycle i: instruction j from thread a is issued.cycle i + 1: instruction j + 1 from thread a is issued.cycle i + 2: instruction j + 2 from thread a is issued, which is a load instruction that misses in all caches.cycle i + 3: thread scheduler invoked, switches to thread b.cycle i + 4: instruction k from thread b is issued.cycle i + 5: instruction k + 1 from thread b is issued.conceptually, it is similar to cooperative multi-tasking used in real-time operating systems, in which tasks voluntarily give up execution time when they need to wait upon some type of the event. this type of multithreading is known as block, cooperative or coarse-grained multithreading.the goal of multithreading hardware support is to allow quick switching between a blocked thread and another thread ready to run. switching from one thread to another means the hardware switches from using one register set to another. to achieve this goal, the hardware for the program visible registers, as well as some processor control registers (such as the program counter), is replicated. for example, to quickly switch between two threads, the processor is built with two sets of registers.additional hardware support for multithreading allows thread switching to be done in one cpu cycle, bringing performance improvements. also, additional hardware allows each thread to behave as if it were executing alone and not sharing any hardware resources with other threads, minimizing the amount of software changes needed within the application and the operating system to support multithreading.many families of microcontrollers and embedded processors have multiple register banks to allow quick context switching for interrupts. such schemes can be considered a type of block multithreading among the user program thread and the interrupt threads.==== interleaved multithreading ====the purpose of interleaved multithreading is to remove all data dependency stalls from the execution pipeline. since one thread is relatively independent from other threads, there is less chance of one instruction in one pipelining stage needing an output from an older instruction in the pipeline. conceptually, it is similar to preemptive multitasking used in operating systems; an analogy would be that the time slice given to each active thread is one cpu cycle.for example:cycle i + 1: an instruction from thread b is issued.cycle i + 2: an instruction from thread c is issued.this type of multithreading was first called barrel processing, in which the staves of a barrel represent the pipeline stages and their executing threads. interleaved, preemptive, fine-grained or time-sliced multithreading are more modern terminology.in addition to the hardware costs discussed in the block type of multithreading, interleaved multithreading has an additional cost of each pipeline stage tracking the thread id of the instruction it is processing. also, since there are more threads being executed concurrently in the pipeline, shared resources such as caches and tlbs need to be larger to avoid thrashing between the different threads.=== simultaneous multithreading ===the most advanced type of multithreading applies to superscalar processors. whereas a normal superscalar processor issues multiple instructions from a single thread every cpu cycle, in simultaneous multithreading (smt) a superscalar processor can issue instructions from multiple threads every cpu cycle. recognizing that any single thread has a limited amount of instruction-level parallelism, this type of multithreading tries to exploit parallelism available across multiple threads to decrease the waste associated with unused issue slots.for example:cycle i: instructions j and j + 1 from thread a and instruction k from thread b are simultaneously issued.cycle i + 1: instruction j + 2 from thread a, instruction k + 1 from thread b, and instruction m from thread c are all simultaneously issued.cycle i + 2: instruction j + 3 from thread a and instructions m + 1 and m + 2 from thread c are all simultaneously issued.to distinguish the other types of multithreading from smt, the term \"temporal multithreading\" is used to denote when instructions from only one thread can be issued at a time.in addition to the hardware costs discussed for interleaved multithreading, smt has the additional cost of each pipeline stage tracking the thread id of each instruction being processed. again, shared resources such as caches and tlbs have to be sized for the large number of active threads being processed.implementations include dec (later compaq) ev8 (not completed), intel hyper-threading technology, ibm power5/power6/power7/power8/power9, ibm z13/z14/z15, sun microsystems ultrasparc t2, cray xmt, and amd bulldozer and zen microarchitectures.'], 'implementation specific': ['a major area of research is the thread scheduler that must quickly choose from among the list of ready-to-run threads to execute next, as well as maintain the ready-to-run and stalled thread lists. an important subtopic is the different thread priority schemes that can be used by the scheduler. the thread scheduler might be implemented totally in software, totally in hardware, or as a hardware/software combination.another area of research is what type of events should cause a thread switch: cache misses, inter-thread communication, dma completion, etc.if the multithreading scheme replicates all of the software-visible state, including privileged control registers and tlbs, then it enables virtual machines to be created for each thread. this allows each thread to run its own operating system on the same processor. on the other hand, if only user-mode state is saved, then less hardware is required, which would allow more threads to be active at one time for the same die area or cost.'], 'capabilitie': ['on a large scale, the ability to treat instructions as data is what makes assemblers, compilers, linkers, loaders, and other automated programming tools possible. it makes \"programs that write programs\" possible.  this has made a sophisticated self-hosting computing ecosystem flourish around von neumann architecture machines.some high level languages leverage the von neumann architecture by providing an abstract, machine-independent way to manipulate executable code at runtime (e.g., lisp), or by using runtime information to tune just-in-time compilation (e.g. languages hosted on the java virtual machine, or languages embedded in web browsers).on a smaller scale, some repetitive operations such as bitblt or pixel and vertex shaders can be accelerated on general purpose processors with just-in-time compilation techniques. this is one use of self-modifying code that has remained popular.== development of the stored-program concept ==the mathematician alan turing, who had been alerted to a problem of mathematical logic by the lectures of max newman at the university of cambridge, wrote a paper in 1936 entitled on computable numbers, with an application to the entscheidungsproblem, which was published in the proceedings of the london mathematical society. in it he described a hypothetical machine he called a universal computing machine, now known as the \"universal turing machine\". the hypothetical machine had an infinite store (memory in today\\'s terminology) that contained both instructions and data. john von neumann became acquainted with turing while he was a visiting professor at cambridge in 1935, and also during turing\\'s phd year at the institute for advanced study in princeton, new jersey during 1936–1937. whether he knew of turing\\'s paper of 1936 at that time is not clear.in 1936, konrad zuse also anticipated, in two patent applications, that machine instructions could be stored in the same storage used for data.independently, j. presper eckert and john mauchly, who were developing the eniac at the moore school of electrical engineering of the university of pennsylvania, wrote about the stored-program concept in december 1943. in planning a new machine, edvac, eckert wrote in january 1944 that they would store data and programs in a new addressable memory device, a mercury metal delay-line memory. this was the first time the construction of a practical stored-program machine was proposed.  at that time, he and mauchly were not aware of turing\\'s work.von neumann was involved in the manhattan project at the los alamos national laboratory. it required huge amounts of calculation, and thus drew him to the eniac project, during the summer of 1944. there he joined the ongoing discussions on the design of this stored-program computer, the edvac. as part of that group, he wrote up a description titled first draft of a report on the edvac based on the work of eckert and mauchly. it was unfinished when his colleague herman goldstine circulated it, and bore only von neumann\\'s name (to the consternation of eckert and mauchly). the paper was read by dozens of von neumann\\'s colleagues in america and europe, and influenced the next round of computer designs.jack copeland considers that it is \"historically inappropriate to refer to electronic stored-program digital computers as \\'von neumann machines\\'\". his los alamos colleague stan frankel said of von neumann\\'s regard for turing\\'s ideasi know that in or about 1943 or \\'44 von neumann was well aware of the fundamental importance of turing\\'s paper of 1936….von neumann introduced me to that paper and at his urging i studied it with care. many people have acclaimed von neumann as the \"father of the computer\" (in a modern sense of the term) but i am sure that he would never have made that mistake himself. he might well be called the midwife, perhaps, but he firmly emphasized to me, and to others i am sure, that the fundamental conception is owing to turing— in so far as not anticipated by babbage…. both turing and von neumann, of course, also made substantial contributions to the \"reduction to practice\" of these concepts but i would not regard these as comparable in importance with the introduction and explication of the concept of a computer able to store in its memory its program of activities and of modifying that program in the course of these activities.at the time that the \"first draft\" report was circulated, turing was producing a report entitled proposed electronic calculator. it described in engineering and programming detail, his idea of a machine he called the automatic computing engine (ace). he presented this to the executive committee of the british national physical laboratory on february 19, 1946. although turing knew from his wartime experience at bletchley park that what he proposed was feasible, the secrecy surrounding colossus, that was subsequently maintained for several decades, prevented him from saying so. various successful implementations of the ace design were produced.both von neumann\\'s and turing\\'s papers described stored-program computers, but von neumann\\'s earlier paper achieved greater circulation and the computer architecture it outlined became known as the \"von neumann architecture\". in the 1953 publication faster than thought: a symposium on digital computing machines (edited by b. v. bowden), a section in the chapter on computers in america reads as follows:the machine of the institute for advanced studies, princetonin 1945, professor j. von neumann, who was then working at the moore school of engineering in philadelphia, where the e.n.i.a.c. had been built, issued on behalf of a group of his co-workers, a report on the logical design of digital computers. the report contained a detailed proposal for the design of the machine that has since become known as the e.d.v.a.c. (electronic discrete variable automatic computer). this machine has only recently been completed in america, but the von neumann report inspired the construction of the e.d.s.a.c. (electronic delay-storage automatic calculator) in cambridge (see page 130).in 1947, burks, goldstine and von neumann published another report that outlined the design of another type of machine (a parallel machine this time) that would be exceedingly fast, capable perhaps of 20,000 operations per second. they pointed out that the outstanding problem in constructing such a machine was the development of suitable memory with instantaneously accessible contents. at first they suggested using a special vacuum tube—called the \"selectron\"—which the princeton laboratories of rca had invented. these tubes were expensive and difficult to make, so von neumann subsequently decided to build a machine based on the williams memory. this machine—completed in june, 1952 in princeton—has become popularly known as the maniac. the design of this machine inspired at least half a dozen machines now being built in america, all known affectionately as \"johniacs\".in the same book, the first two paragraphs of a chapter on ace read as follows:automatic computation at the national physical laboratoryone of the most modern digital computers which embodies developments and improvements in the technique of automatic electronic computing was recently demonstrated at the national physical laboratory, teddington, where it has been designed and built by a small team of mathematicians and electronics research engineers on the staff of the laboratory, assisted by a number of production engineers from the english electric company, limited. the equipment so far erected at the laboratory is only the pilot model of a much larger installation which will be known as the automatic computing engine, but although comparatively small in bulk and containing only about 800 thermionic valves, as can be judged from plates xii, xiii and xiv, it is an extremely rapid and versatile calculating machine.the basic concepts and abstract principles of computation by a machine were formulated by dr. a. m. turing, f.r.s., in a paper1. read before the london mathematical society in 1936, but work on such machines in britain was delayed by the war. in 1945, however, an examination of the problems was made at the national physical laboratory by mr. j. r. womersley, then superintendent of the mathematics division of the laboratory. he was joined by dr. turing and a small staff of specialists, and, by 1947, the preliminary planning was sufficiently advanced to warrant the establishment of the special group already mentioned. in april, 1948, the latter became the electronics section of the laboratory, under the charge of mr. f. m. colebrook.== early von neumann-architecture computers ==the first draft described a design that was used by many universities and corporations to construct their computers. among these various computers, only illiac and ordvac had compatible instruction sets.arc2 (birkbeck, university of london) officially came online on may 12, 1948.manchester baby (victoria university of manchester, england) made its first successful run of a stored program on june 21, 1948.edsac (university of cambridge, england) was the first practical stored-program electronic computer (may 1949)manchester mark 1 (university of manchester, england) developed from the baby (june 1949)csirac (council for scientific and industrial research) australia (november 1949)mesm in kyiv, ukraine (november 1950)edvac (ballistic research laboratory, computing laboratory at aberdeen proving ground 1951)ordvac (u-illinois) at aberdeen proving ground, maryland (completed november 1951)ias machine at princeton university (january 1952)maniac i at los alamos scientific laboratory (march 1952)illiac at the university of illinois, (september 1952)besm-1 in moscow (1952)avidac at argonne national laboratory (1953)oracle at oak ridge national laboratory (june 1953)besk in stockholm (1953)johnniac at rand corporation (january 1954)dask in denmark (1955)weizac at the weizmann institute of science in rehovot, israel (1955)perm in munich (1956)silliac in sydney (1956)== early stored-program computers ==the date information in the following chronology is difficult to put into proper order. some dates are for first running a test program, some dates are the first time the computer was demonstrated or completed, and some dates are for the first delivery or installation.the ibm ssec had the ability to treat instructions as data, and was publicly demonstrated on january 27, 1948. this ability was claimed in a us patent. however it was partially electromechanical, not fully electronic. in practice, instructions were read from paper tape due to its limited memory.the arc2 developed by andrew booth and kathleen booth at birkbeck, university of london officially came online on may 12, 1948. it featured the first rotating drum storage device.the manchester baby was the first fully electronic computer to run a stored program. it ran a factoring program for 52 minutes on june 21, 1948, after running a simple division program and a program to show that two numbers were relatively prime.the eniac was modified to run as a primitive read-only stored-program computer (using the function tables for program rom) and was demonstrated as such on september 16, 1948, running a program by adele goldstine for von neumann.the binac ran some test programs in february, march, and april 1949, although was not completed until september 1949.the manchester mark 1 developed from the baby project.  an intermediate version of the mark 1 was available to run programs in april 1949, but was not completed until october 1949.the edsac ran its first program on may 6, 1949.the edvac was delivered in august 1949, but it had problems that kept it from being put into regular operation until 1951.the csir mk i ran its first program in november 1949.the seac was demonstrated in april 1950.the pilot ace ran its first program on may 10, 1950, and was demonstrated in december 1950.the swac was completed in july 1950.the whirlwind was completed in december 1950 and was in actual use in april 1951.the first era atlas (later the commercial era 1101/univac 1101) was installed in december 1950.'], 'evolution': ['through the decades of the 1960s and 1970s computers generally became both smaller and faster, which led to evolutions in their architecture. for example, memory-mapped i/o lets input and output devices be treated the same as memory. a single system bus could be used to provide a modular system with lower cost. this is sometimes called a \"streamlining\" of the architecture.in subsequent decades, simple microcontrollers would sometimes omit features of the model to lower cost and size.larger computers added features for higher performance.'], 'design limitation': ['=== von neumann bottleneck ===the shared bus between the program memory and data memory leads to the von neumann bottleneck, the limited throughput (data transfer rate) between the central processing unit (cpu) and memory compared to the amount of memory.  because the single bus can only access one of the two classes of memory at a time, throughput is lower than the rate at which the cpu can work.  this seriously limits the effective processing speed when the cpu is required to perform minimal processing on large amounts of data.  the cpu is continually forced to wait for needed data to move to or from memory.  since cpu speed and memory size have increased much faster than the throughput between them, the bottleneck has become more of a problem, a problem whose severity increases with every new generation of cpu.the von neumann bottleneck was described by john backus in his 1977 acm turing award lecture.  according to backus:surely there must be a less primitive way of making big changes in the store than by pushing vast numbers of words back and forth through the von neumann bottleneck. not only is this tube a literal bottleneck for the data traffic of a problem, but, more importantly, it is an intellectual bottleneck that has kept us tied to word-at-a-time thinking instead of encouraging us to think in terms of the larger conceptual units of the task at hand. thus programming is basically planning and detailing the enormous traffic of words through the von neumann bottleneck, and much of that traffic concerns not significant data itself, but where to find it.==== mitigations ====there are several known methods for mitigating the von neumann performance bottleneck.  for example, the following all can improve performance:providing a cache between the cpu and the main memoryproviding separate caches or separate access paths for data and instructions (the so-called modified harvard architecture)using branch predictor algorithms and logicproviding a limited cpu stack or other on-chip scratchpad memory to reduce memory accessimplementing the cpu and the memory hierarchy as a system on chip, providing greater locality of reference and thus reducing latency and increasing throughput between processor registers and main memorythe problem can also be sidestepped somewhat by using parallel computing, using for example the non-uniform memory access (numa) architecture—this approach is commonly employed by supercomputers. it is less clear whether the intellectual bottleneck that backus criticized has changed much since 1977. backus\\'s proposed solution has not had a major influence. modern functional programming and object-oriented programming are much less geared towards \"pushing vast numbers of words back and forth\" than earlier languages like fortran were, but internally, that is still what computers spend much of their time doing, even highly parallel supercomputers.as of 1996, a database benchmark study found that three out of four cpu cycles were spent waiting for memory. researchers expect that increasing the number of simultaneous instruction streams with multithreading or single-chip multiprocessing will make this bottleneck even worse.  in the context of multi-core processors, additional overhead is required to maintain cache coherence between processors and threads.=== self-modifying code ===aside from the von neumann bottleneck, program modifications can be quite harmful, either by accident or design.  in some simple stored-program computer designs, a malfunctioning program can damage itself, other programs, or the operating system, possibly leading to a computer crash. memory protection and other forms of access control can usually protect against both accidental and malicious program changes.'], 'further reading': ['', 'clements, alan (2013). \"8.3.7 predication\". computer organization & architecture: themes and variations. cengage learning. pp. 532–9. isbn 1-285-41542-6.', '', 'patterson, d.; hennessy, j. (2004). computer organization and design: the hardware/software interface. morgan kaufmann. isbn 1-55860-604-1.hamacher, v. c.; vrasenic, z. g.; zaky, s. g. (2001). computer organization. mcgraw-hill. isbn 0-07-232086-9.stallings, william (2002). computer organization and architecture. prentice hall. isbn 0-13-035119-9.hayes, j. p. (2002). computer architecture and organization. mcgraw-hill. isbn 0-07-286198-3.schneider, gary michael (1985). the principles of computer organization. wiley. pp. 6–7. isbn 0-471-88552-5.mano, m. morris (1992). computer system architecture. prentice hall. p. 3. isbn 0-13-175563-3.abd-el-barr, mostafa; el-rewini, hesham (2004). fundamentals of computer organization and architecture. wiley. p. 1. isbn 0-471-46741-3.gardner, j (2001). \"pc processor microarchitecture\". extremetech.gilreath, william f.; laplante, phillip a. (2012) [2003]. computer architecture: a minimalist perspective. springer. isbn 978-1-4615-0237-1.patterson, david a. (10 october 2018). a new golden age for computer architecture. us berkeley acm a.m. turing laureate colloquium. ctwj53r07yi.'], 'advantage': ['the main purpose of predication is to avoid jumps over very small sections of program code, increasing the effectiveness of pipelined execution and avoiding problems with the cache. it also has a number of more subtle benefits:functions that are traditionally computed using simple arithmetic and bitwise operations may be quicker to compute using predicated instructions.predicated instructions with different predicates can be mixed with each other and with unconditional code, allowing better instruction scheduling and so even better performance.elimination of unnecessary branch instructions can make the execution of necessary branches, such as those that make up loops, faster by lessening the load on branch prediction mechanisms.elimination of the cost of a branch misprediction which can be high on deeply pipelined architectures.instruction sets that have comprehensive condition codes generated by instructions may reduce code size further by directly using the condition registers in or as predication.'], 'disadvantage': [\"predication's primary drawback is in increased encoding space. in typical implementations, every instruction reserves a bitfield for the predicate specifying under what conditions that instruction should have an effect. when available memory is limited, as on embedded devices, this space cost can be prohibitive. however, some architectures such as thumb-2 are able to avoid this issue (see below). other detriments are the following:predication complicates the hardware by adding levels of logic to critical paths and potentially degrades clock speed.a predicated block includes cycles for all operations, so shorter paths may take longer and be penalized.predication is not usually speculated and causes a longer dependency chain. for ordered data this translates to a performance loss compared to a predictable branch.predication is most effective when paths are balanced or when the longest path is the most frequently executed, but determining such a path is very difficult at compile time, even in the presence of profiling information.\"], 'etymology': ['according to the oxford english dictionary, the first known use of computer was in a 1613 book called the yong mans gleanings by the english writer richard brathwait: \"i haue  [sic] read the truest computer of times, and the best arithmetician that euer [sic] breathed, and he reduceth thy dayes into a short number.\" this usage of the term referred to a human computer, a person who carried out calculations or computations. the word continued with the same meaning until the middle of the 20th century. during the latter part of this period women were often hired as computers because they could be paid less than their male counterparts. by 1943, most human computers were women.the online etymology dictionary gives the first attested use of computer in the 1640s, meaning \\'one who calculates\\'; this is an \"agent noun from compute (v.)\". the online etymology dictionary states that the use of the term to mean \"\\'calculating machine\\' (of any type) is from 1897.\"  the online etymology dictionary indicates that the \"modern use\" of the term, to mean \\'programmable digital electronic computer\\' dates from \"1945 under this name; [in a] theoretical [sense] from 1937, as turing machine\".', 'although first proposed in 1956, the term \"computer science\" appears in a 1959 article in communications of the acm,in which louis fein argues for the creation of a graduate school in computer sciences analogous to the creation of harvard business school in 1921, justifying the name by arguing that, like management science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline.his efforts, and those of others such as numerical analyst george forsythe, were rewarded: universities went on to create such departments, starting with purdue in 1962. despite its name, a significant amount of computer science does not involve the study of computers themselves. because of this, several alternative names have been proposed. certain departments of major universities prefer the term computing science, to emphasize precisely that difference. danish scientist peter naur suggested the term datalogy, to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. the first scientific institution to use the term was the department of datalogy at the university of copenhagen, founded in 1969, with peter naur being the first professor in datalogy. the term is used mainly in the scandinavian countries. an alternative term, also proposed by naur, is data science; this is now used for a multi-disciplinary field of data analysis, including statistics and databases.in the early days of computing, a number of terms for the practitioners of the field of computing were suggested in the communications of the acm—turingineer, turologist, flow-charts-man, applied meta-mathematician, and applied epistemologist. three months later in the same journal, comptologist was suggested, followed next year by hypologist. the term computics has also been suggested. in europe, terms derived from contracted translations of the expression \"automatic information\" (e.g. \"informazione automatica\" in italian) or \"information and mathematics\" are often used, e.g. informatique (french), informatik (german), informatica (italian, dutch), informática (spanish, portuguese), informatika (slavic languages and hungarian) or pliroforiki (πληροφορική, which means informatics) in greek. similar words have also been adopted in the uk (as in the school of informatics, university of edinburgh). \"in the u.s., however, informatics is linked with applied computing, or computing in the context of another domain.\"a folkloric quotation, often attributed to—but almost certainly not first formulated by—edsger dijkstra, states that \"computer science is no more about computers than astronomy is about telescopes.\" the design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. for example, the study of computer hardware is usually considered part of computer engineering, while the study of commercial computer systems and their deployment is often called information technology or information systems. however, there has been much cross-fertilization of ideas between the various computer-related disciplines. computer science research also often intersects other disciplines, such as cognitive science, linguistics, mathematics, physics, biology, earth science, statistics, philosophy, and logic.computer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science. early computer science was strongly influenced by the work of mathematicians such as kurt gödel, alan turing, john von neumann, rózsa péter and alonzo church and there continues to be a useful interchange of ideas between the two fields in areas such as mathematical logic, category theory, domain theory, and algebra.the relationship between computer science and software engineering is a contentious issue, which is further muddied by disputes over what the term \"software engineering\" means, and how computer science is defined. david parnas, taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines.the academic, political, and funding aspects of computer science tend to depend on whether a department is formed with a mathematical emphasis or with an engineering emphasis. computer science departments with a mathematics emphasis and with a numerical orientation consider alignment with computational science. both types of departments tend to make efforts to bridge the field educationally if not across all research.'], 'hardware': ['the term hardware covers all of those parts of a computer that are tangible physical objects. circuits, computer chips, graphic cards, sound cards, memory (ram), motherboard, displays, power supplies, cables, keyboards, printers and \"mice\" input devices are all hardware.=== history of computing hardware ====== other hardware topics ===a general-purpose computer has four main components: the arithmetic logic unit (alu), the control unit, the memory, and the input and output devices (collectively termed i/o). these parts are interconnected by buses, often made of groups of wires. inside each of these parts are thousands to trillions of small electrical circuits which can be turned off or on by means of an electronic switch. each circuit represents a bit (binary digit) of information so that when the circuit is on it represents a \"1\", and when off it represents a \"0\" (in positive logic representation). the circuits are arranged in logic gates so that one or more of the circuits may control the state of one or more of the other circuits.=== input devices ===when unprocessed data is sent to the computer with the help of input devices, the data is processed and sent to output devices. the input devices may be hand-operated or automated. the act of processing is mainly regulated by the cpu. some examples of input devices are:computer keyboarddigital cameradigital videographics tabletimage scannerjoystickmicrophonemouseoverlay keyboardreal-time clocktrackballtouchscreenlight pen=== output devices ===the means through which computer gives output are known as output devices. some examples of output devices are:computer monitorprinterpc speakerprojectorsound cardvideo card=== control unit ===the control unit (often called a control system or central controller) manages the computer\\'s various components; it reads and interprets (decodes) the program instructions, transforming them into control signals that activate other parts of the computer. control systems in advanced computers may change the order of execution of some instructions to improve performance.a key component common to all cpus is the program counter, a special memory cell (a register) that keeps track of which location in memory the next instruction is to be read from.the control system\\'s function is as follows— this is a simplified description, and some of these steps may be performed concurrently or in a different order depending on the type of cpu:read the code for the next instruction from the cell indicated by the program counter.decode the numerical code for the instruction into a set of commands or signals for each of the other systems.increment the program counter so it points to the next instruction.read whatever data the instruction requires from cells in memory (or perhaps from an input device). the location of this required data is typically stored within the instruction code.provide the necessary data to an alu or register.if the instruction requires an alu or specialized hardware to complete, instruct the hardware to perform the requested operation.write the result from the alu back to a memory location or to a register or perhaps an output device.jump back to step (1).since the program counter is (conceptually) just another set of memory cells, it can be changed by calculations done in the alu. adding 100 to the program counter would cause the next instruction to be read from a place 100 locations further down the program. instructions that modify the program counter are often known as \"jumps\" and allow for loops (instructions that are repeated by the computer) and often conditional instruction execution (both examples of control flow).the sequence of operations that the control unit goes through to process an instruction is in itself like a short computer program, and indeed, in some more complex cpu designs, there is another yet smaller computer called a microsequencer, which runs a microcode program that causes all of these events to happen.=== central processing unit (cpu) ===the control unit, alu, and registers are collectively known as a central processing unit (cpu). early cpus were composed of many separate components. since the 1970s, cpus have typically been constructed on a single mos integrated circuit chip called a microprocessor.=== arithmetic logic unit (alu) ===the alu is capable of performing two classes of operations: arithmetic and logic. the set of arithmetic operations that a particular alu supports may be limited to addition and subtraction, or might include multiplication, division, trigonometry functions such as sine, cosine, etc., and square roots. some can operate only on whole numbers (integers) while others use floating point to represent real numbers, albeit with limited precision. however, any computer that is capable of performing just the simplest operations can be programmed to break down the more complex operations into simple steps that it can perform. therefore, any computer can be programmed to perform any arithmetic operation—although it will take more time to do so if its alu does not directly support the operation. an alu may also compare numbers and return boolean truth values (true or false) depending on whether one is equal to, greater than or less than the other (\"is 64 greater than 65?\"). logic operations involve boolean logic: and, or, xor, and not. these can be useful for creating complicated conditional statements and processing boolean logic.superscalar computers may contain multiple alus, allowing them to process several instructions simultaneously. graphics processors and computers with simd and mimd features often contain alus that can perform arithmetic on vectors and matrices.=== memory ===a computer\\'s memory can be viewed as a list of cells into which numbers can be placed or read. each cell has a numbered \"address\" and can store a single number. the computer can be instructed to \"put the number 123 into the cell numbered 1357\" or to \"add the number that is in cell 1357 to the number that is in cell 2468 and put the answer into cell 1595.\" the information stored in memory may represent practically anything. letters, numbers, even computer instructions can be placed into memory with equal ease. since the cpu does not differentiate between different types of information, it is the software\\'s responsibility to give significance to what the memory sees as nothing but a series of numbers.in almost all modern computers, each memory cell is set up to store binary numbers in groups of eight bits (called a byte). each byte is able to represent 256 different numbers (28 = 256); either from 0 to 255 or −128 to +127. to store larger numbers, several consecutive bytes may be used (typically, two, four or eight). when negative numbers are required, they are usually stored in two\\'s complement notation. other arrangements are possible, but are usually not seen outside of specialized applications or historical contexts. a computer can store any kind of information in memory if it can be represented numerically. modern computers have billions or even trillions of bytes of memory.the cpu contains a special set of memory cells called registers that can be read and written to much more rapidly than the main memory area. there are typically between two and one hundred registers depending on the type of cpu. registers are used for the most frequently needed data items to avoid having to access main memory every time data is needed. as data is constantly being worked on, reducing the need to access main memory (which is often slow compared to the alu and control units) greatly increases the computer\\'s speed.computer main memory comes in two principal varieties:random-access memory or ramread-only memory or romram can be read and written to anytime the cpu commands it, but rom is preloaded with data and software that never changes, therefore the cpu can only read from it. rom is typically used to store the computer\\'s initial start-up instructions. in general, the contents of ram are erased when the power to the computer is turned off, but rom retains its data indefinitely. in a pc, the rom contains a specialized program called the bios that orchestrates loading the computer\\'s operating system from the hard disk drive into ram whenever the computer is turned on or reset. in embedded computers, which frequently do not have disk drives, all of the required software may be stored in rom. software stored in rom is often called firmware, because it is notionally more like hardware than software. flash memory blurs the distinction between rom and ram, as it retains its data when turned off but is also rewritable. it is typically much slower than conventional rom and ram however, so its use is restricted to applications where high speed is unnecessary.in more sophisticated computers there may be one or more ram cache memories, which are slower than registers but faster than main memory. generally computers with this sort of cache are designed to move frequently needed data into the cache automatically, often without the need for any intervention on the programmer\\'s part.=== input/output (i/o) ===i/o is the means by which a computer exchanges information with the outside world. devices that provide input or output to the computer are called peripherals. on a typical personal computer, peripherals include input devices like the keyboard and mouse, and output devices such as the display and printer. hard disk drives, floppy disk drives and optical disc drives serve as both input and output devices. computer networking is another form of i/o.i/o devices are often complex computers in their own right, with their own cpu and memory. a graphics processing unit might contain fifty or more tiny computers that perform the calculations necessary to display 3d graphics. modern desktop computers contain many smaller computers that assist the main cpu in performing i/o. a 2016-era flat screen display contains its own computer circuitry.=== multitasking ===while a computer may be viewed as running one gigantic program stored in its main memory, in some systems it is necessary to give the appearance of running several programs simultaneously. this is achieved by multitasking i.e. having the computer switch rapidly between running each program in turn. one means by which this is done is with a special signal called an interrupt, which can periodically cause the computer to stop executing instructions where it was and do something else instead. by remembering where it was executing prior to the interrupt, the computer can return to that task later. if several programs are running \"at the same time\". then the interrupt generator might be causing several hundred interrupts per second, causing a program switch each time. since modern computers typically execute instructions several orders of magnitude faster than human perception, it may appear that many programs are running at the same time even though only one is ever executing in any given instant. this method of multitasking is sometimes termed \"time-sharing\" since each program is allocated a \"slice\" of time in turn.before the era of inexpensive computers, the principal use for multitasking was to allow many people to share the same computer. seemingly, multitasking would cause a computer that is switching between several programs to run more slowly, in direct proportion to the number of programs it is running, but most programs spend much of their time waiting for slow input/output devices to complete their tasks. if a program is waiting for the user to click on the mouse or press a key on the keyboard, then it will not take a \"time slice\" until the event it is waiting for has occurred. this frees up time for other programs to execute so that many programs may be run simultaneously without unacceptable speed loss.=== multiprocessing ===some computers are designed to distribute their work across several cpus in a multiprocessing configuration, a technique once employed in only large and powerful machines such as supercomputers, mainframe computers and servers. multiprocessor and multi-core (multiple cpus on a single integrated circuit) personal and laptop computers are now widely available, and are being increasingly used in lower-end markets as a result.supercomputers in particular often have highly unique architectures that differ significantly from the basic stored-program architecture and from general-purpose computers. they often feature thousands of cpus, customized high-speed interconnects, and specialized computing hardware. such designs tend to be useful for only specialized tasks due to the large scale of program organization required to successfully utilize most of the available resources at once. supercomputers usually see usage in large-scale simulation, graphics rendering, and cryptography applications, as well as with other so-called \"embarrassingly parallel\" tasks.'], 'software': ['software refers to parts of the computer which do not have a material form, such as programs, data, protocols, etc. software is that part of a computer system that consists of encoded information or computer instructions, in contrast to the physical hardware from which the system is built. computer software includes computer programs, libraries and related non-executable data, such as online documentation or digital media. it is often divided into system software and application software computer hardware and software require each other and neither can be realistically used on its own. when software is stored in hardware that cannot easily be modified, such as with bios rom in an ibm pc compatible computer, it is sometimes called \"firmware\".=== languages ===there are thousands of different programming languages—some intended for general purpose, others useful for only highly specialized applications.=== programs ===the defining feature of modern computers which distinguishes them from all other machines is that they can be programmed. that is to say that some type of instructions (the program) can be given to the computer, and it will process them. modern computers based on the von neumann architecture often have machine code in the form of an imperative programming language. in practical terms, a computer program may be just a few instructions or extend to many millions of instructions, as do the programs for word processors and web browsers for example. a typical modern computer can execute billions of instructions per second (gigaflops) and rarely makes a mistake over many years of operation. large computer programs consisting of several million instructions may take teams of programmers years to write, and due to the complexity of the task almost certainly contain errors.==== stored program architecture ====this section applies to most common ram machine–based computers.in most cases, computer instructions are simple: add one number to another, move some data from one location to another, send a message to some external device, etc. these instructions are read from the computer\\'s memory and are generally carried out (executed) in the order they were given. however, there are usually specialized instructions to tell the computer to jump ahead or backwards to some other place in the program and to carry on executing from there. these are called \"jump\" instructions (or branches). furthermore, jump instructions may be made to happen conditionally so that different sequences of instructions may be used depending on the result of some previous calculation or some external event. many computers directly support subroutines by providing a type of jump that \"remembers\" the location it jumped from and another instruction to return to the instruction following that jump instruction.program execution might be likened to reading a book. while a person will normally read each word and line in sequence, they may at times jump back to an earlier place in the text or skip sections that are not of interest. similarly, a computer may sometimes go back and repeat the instructions in some section of the program over and over again until some internal condition is met. this is called the flow of control within the program and it is what allows the computer to perform tasks repeatedly without human intervention.comparatively, a person using a pocket calculator can perform a basic arithmetic operation such as adding two numbers with just a few button presses. but to add together all of the numbers from 1 to 1,000 would take thousands of button presses and a lot of time, with a near certainty of making a mistake. on the other hand, a computer may be programmed to do this with just a few simple instructions. the following example is written in the mips assembly language:once told to run this program, the computer will perform the repetitive addition task without further human intervention. it will almost never make a mistake and a modern pc can complete the task in a fraction of a second.==== machine code ====in most computers, individual instructions are stored as machine code with each instruction being given a unique number (its operation code or opcode for short). the command to add two numbers together would have one opcode; the command to multiply them would have a different opcode, and so on. the simplest computers are able to perform any of a handful of different instructions; the more complex computers have several hundred to choose from, each with a unique numerical code. since the computer\\'s memory is able to store numbers, it can also store the instruction codes. this leads to the important fact that entire programs (which are just lists of these instructions) can be represented as lists of numbers and can themselves be manipulated inside the computer in the same way as numeric data. the fundamental concept of storing programs in the computer\\'s memory alongside the data they operate on is the crux of the von neumann, or stored program, architecture. in some cases, a computer might store some or all of its program in memory that is kept separate from the data it operates on. this is called the harvard architecture after the harvard mark i computer. modern von neumann computers display some traits of the harvard architecture in their designs, such as in cpu caches.while it is possible to write computer programs as long lists of numbers (machine language) and while this technique was used with many early computers, it is extremely tedious and potentially error-prone to do so in practice, especially for complicated programs. instead, each basic instruction can be given a short name that is indicative of its function and easy to remember – a mnemonic such as add, sub, mult or jump. these mnemonics are collectively known as a computer\\'s assembly language. converting programs written in assembly language into something the computer can actually understand (machine language) is usually done by a computer program called an assembler.==== programming language ====programming languages provide various ways of specifying programs for computers to run. unlike natural languages, programming languages are designed to permit no ambiguity and to be concise. they are purely written languages and are often difficult to read aloud. they are generally either translated into machine code by a compiler or an assembler before being run, or translated directly at run time by an interpreter. sometimes programs are executed by a hybrid method of the two techniques.===== low-level languages =====machine languages and the assembly languages that represent them (collectively termed low-level programming languages) are generally unique to the particular architecture of a computer\\'s central processing unit (cpu). for instance, an arm architecture cpu (such as may be found in a smartphone or a hand-held videogame) cannot understand the machine language of an x86 cpu that might be in a pc. historically a significant number of other cpu architectures were created and saw extensive use, notably including the mos technology 6502 and 6510 in addition to the zilog z80.===== high-level languages =====although considerably easier than in machine language, writing long programs in assembly language is often difficult and is also error prone. therefore, most practical programs are written in more abstract high-level programming languages that are able to express the needs of the programmer more conveniently (and thereby help reduce programmer error). high level languages are usually \"compiled\" into machine language (or sometimes into assembly language and then into machine language) using another computer program called a compiler. high level languages are less related to the workings of the target computer than assembly language, and more related to the language and structure of the problem(s) to be solved by the final program. it is therefore often possible to use different compilers to translate the same high level language program into the machine language of many different types of computer. this is part of the means by which software like video games may be made available for different computer architectures such as personal computers and various video game consoles.==== program design ====program design of small programs is relatively simple and involves the analysis of the problem, collection of inputs, using the programming constructs within languages, devising or using established procedures and algorithms, providing data for output devices and solutions to the problem as applicable. as problems become larger and more complex, features such as subprograms, modules, formal documentation, and new paradigms such as object-oriented programming are encountered. large programs involving thousands of line of code and more require formal software methodologies.the task of developing large software systems presents a significant intellectual challenge. producing software with an acceptably high reliability within a predictable schedule and budget has historically been difficult; the academic and professional discipline of software engineering concentrates specifically on this challenge.==== bugs ====errors in computer programs are called \"bugs\". they may be benign and not affect the usefulness of the program, or have only subtle effects. but in some cases, they may cause the program or the entire system to \"hang\", becoming unresponsive to input such as mouse clicks or keystrokes, to completely fail, or to crash. otherwise benign bugs may sometimes be harnessed for malicious intent by an unscrupulous user writing an exploit, code designed to take advantage of a bug and disrupt a computer\\'s proper execution. bugs are usually not the fault of the computer. since computers merely execute the instructions they are given, bugs are nearly always the result of programmer error or an oversight made in the program\\'s design. admiral grace hopper, an american computer scientist and developer of the first compiler, is credited for having first used the term \"bugs\" in computing after a dead moth was found shorting a relay in the harvard mark ii computer in september 1947.'], 'networking and the internet': ['computers have been used to coordinate information between multiple locations since the 1950s. the u.s. military\\'s sage system was the first large-scale example of such a system, which led to a number of special-purpose commercial systems such as sabre. in the 1970s, computer engineers at research institutions throughout the united states began to link their computers together using telecommunications technology. the effort was funded by arpa (now darpa), and the computer network that resulted was called the arpanet. the technologies that made the arpanet possible spread and evolved.in time, the network spread beyond academic and military institutions and became known as the internet. the emergence of networking involved a redefinition of the nature and boundaries of the computer. computer operating systems and applications were modified to include the ability to define and access the resources of other computers on the network, such as peripheral devices, stored information, and the like, as extensions of the resources of an individual computer. initially these facilities were available primarily to people working in high-tech environments, but in the 1990s the spread of applications like e-mail and the world wide web, combined with the development of cheap, fast networking technologies like ethernet and adsl saw computer networking become almost ubiquitous. in fact, the number of computers that are networked is growing phenomenally. a very large proportion of personal computers regularly connect to the internet to communicate and receive information. \"wireless\" networking, often utilizing mobile phone networks, has meant networking is becoming increasingly ubiquitous even in mobile computing environments.'], 'unconventional computer': ['a computer does not need to be electronic, nor even have a processor, nor ram, nor even a hard disk. while popular usage of the word \"computer\" is synonymous with a personal electronic computer, the modern definition of a computer is literally: \"a device that computes, especially a programmable [usually] electronic machine that performs high-speed mathematical or logical operations or that assembles, stores, correlates, or otherwise processes information.\" any device which processes information qualifies as a computer, especially if the processing is purposeful.'], 'future': ['there is active research to make computers out of many promising new types of technology, such as optical computers, dna computers, neural computers, and quantum computers. most computers are universal, and are able to calculate any computable function, and are limited only by their memory capacity and operating speed. however different designs of computers can give very different performance for particular problems; for example quantum computers can potentially break some modern encryption algorithms (by quantum factoring) very quickly.=== computer architecture paradigms ===there are many types of computer architectures:quantum computer vs. chemical computerscalar processor vs. vector processornon-uniform memory access (numa) computersregister machine vs. stack machineharvard architecture vs. von neumann architecturecellular architectureof all these abstract machines, a quantum computer holds the most promise for revolutionizing computing. logic gates are a common abstraction which can apply to most of the above digital or analog paradigms. the ability to store and execute lists of instructions called programs makes computers extremely versatile, distinguishing them from calculators. the church–turing thesis is a mathematical statement of this versatility: any computer with a minimum capability (being turing-complete) is, in principle, capable of performing the same tasks that any other computer can perform. therefore, any type of computer (netbook, supercomputer, cellular automaton, etc.) is able to perform the same computational tasks, given enough time and storage capacity.=== artificial intelligence ===a computer will solve problems in exactly the way it is programmed to, without regard to efficiency, alternative solutions, possible shortcuts, or possible errors in the code. computer programs that learn and adapt are part of the emerging field of artificial intelligence and machine learning. artificial intelligence based products generally fall into two major categories: rule-based systems and pattern recognition systems. rule-based systems attempt to represent the rules used by human experts and tend to be expensive to develop. pattern-based systems use data about a problem to generate conclusions. examples of pattern-based systems include voice recognition, font recognition, translation and the emerging field of on-line marketing.'], 'professions and organization': ['as the use of computers has spread throughout society, there are an increasing number of careers involving computers.the need for computers to work well together and to be able to exchange information has spawned the need for many standards organizations, clubs and societies of both a formal and informal nature.'], 'philosophy': ['=== epistemology of computer science ===despite the word \"science\" in its name, there is debate over whether or not computer science is a discipline of science, mathematics, or engineering. allen newell and herbert a. simon argued in 1975, computer science is an empirical discipline. we would have called it an experimental science, but like astronomy, economics, and geology, some of its unique forms of observation and experience do not fit a narrow stereotype of the experimental method. nonetheless, they are experiments. each new machine that is built is an experiment. actually constructing the machine poses a question to nature; and we listen for the answer by observing the machine in operation and analyzing it by all analytical and measurement means available. it has since been argued that computer science can be classified as an empirical science since it makes use of empirical testing to evaluate the correctness of programs, but a problem remains in defining the laws and theorems of computer science (if any exist) and defining the nature of experiments in computer science. proponents of classifying computer science as an engineering discipline argue that the reliability of computational systems is investigated in the same way as bridges in civil engineering and airplanes in aerospace engineering. they also argue that while empirical sciences observe what presently exists, computer science observes what is possible to exist and while scientists discover laws from observation, no proper laws have been found in computer science and it is instead concerned with creating phenomena.proponents of classifying computer science as a mathematical discipline argue that computer programs are physical realizations of mathematical entities and programs can be deductively reasoned through mathematical formal methods. computer scientists edsger w. dijkstra and tony hoare regard instructions for computer programs as mathematical sentences and interpret formal semantics for programming languages as mathematical axiomatic systems.=== paradigms of computer science ===a number of computer scientists have argued for the distinction of three separate paradigms in computer science. peter wegner argued that those paradigms are science, technology, and mathematics. peter denning\\'s working group argued that they are theory, abstraction (modeling), and design. amnon h. eden described them as the \"rationalist paradigm\" (which treats computer science as a branch of mathematics, which is prevalent in theoretical computer science, and mainly employs deductive reasoning), the \"technocratic paradigm\" (which might be found in engineering approaches, most prominently in software engineering), and the \"scientific paradigm\" (which approaches computer-related artifacts from the empirical perspective of natural sciences, identifiable in some branches of artificial intelligence).computer science focuses on methods involved in design, specification, programming, verification, implementation and testing of human-made computing systems.'], 'field': ['computer science is no more about computers than astronomy is about telescopes.as a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.csab, formerly called computing sciences accreditation board—which is made up of representatives of the association for computing machinery (acm), and the ieee computer society (ieee cs)—identifies four areas that it considers crucial to the discipline of computer science: theory of computation, algorithms and data structures, programming methodology and languages, and computer elements and architecture. in addition to these four areas, csab also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical and symbolic computation as being important areas of computer science.=== theoretical computer science ===theoretical computer science is mathematical and abstract in spirit, but it derives its motivation from the practical and everyday computation. its aim is to understand the nature of computation and, as a consequence of this understanding, provide more efficient methodologies.==== theory of computation ====according to peter denning, the fundamental question underlying computer science is, \"what can be automated?\" theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. in an effort to answer the first question, computability theory examines which computational problems are solvable on various theoretical models of computation. the second question is addressed by computational complexity theory, which studies the time and space costs associated with different approaches to solving a multitude of computational problems.the famous p = np? problem, one of the millennium prize problems, is an open problem in the theory of computation.==== information and coding theory ====information theory, closely related to probability and statistics, is related to the quantification of information. this was developed by claude shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data.coding theory is the study of the properties of codes (systems for converting information from one form to another) and their fitness for a specific application. codes are used for data compression, cryptography, error detection and correction, and more recently also for network coding. codes are studied for the purpose of designing efficient and reliable data transmission methods.==== data structures and algorithms ====data structures and algorithms are the studies of commonly used computational methods and their computational efficiency.==== programming language theory and formal methods ====programming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and their individual features. it falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, and linguistics. it is an active research area, with numerous dedicated academic journals.formal methods are a particular kind of mathematically based technique for the specification, development and verification of software and hardware systems. the use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. they form an important theoretical underpinning for software engineering, especially where safety or security is involved. formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. for industrial use, tool support is required. however, the high cost of using formal methods means that they are usually only used in the development of high-integrity and life-critical systems, where safety or security is of utmost importance. formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification.=== computer systems and computational processes ======= artificial intelligence ====artificial intelligence (ai) aims to or is required to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, learning, and communication found in humans and animals. from its origins in cybernetics and in the dartmouth conference (1956), artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such as applied mathematics, symbolic logic, semiotics, electrical engineering, philosophy of mind, neurophysiology, and social intelligence. ai is associated in the popular mind with robotic development, but the main field of practical application has been as an embedded component in areas of software development, which require computational understanding. the starting point in the late 1940s was alan turing\\'s question \"can computers think?\", and the question remains effectively unanswered, although the turing test is still used to assess computer output on the scale of human intelligence. but the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data.==== computer architecture and organization ====computer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. it focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory. computer engineers study computational logic and design of computer hardware, from individual processor components, microcontrollers, personal computers to supercomputers and embedded systems. the term “architecture” in computer literature can be traced to the work of lyle r. johnson and frederick p. brooks, jr., members of the machine organization department in ibm\\'s main research center in 1959.==== concurrent, parallel and distributed computing ====concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. a number of mathematical models have been developed for general concurrent computation including petri nets, process calculi and the parallel random access machine model. when multiple computers are connected in a network while using concurrency, this is known as a distributed system. computers within that distributed system have their own private memory, and information can be exchanged to achieve common goals.==== computer networks ====this branch of computer science aims to manage networks between computers worldwide.==== computer security and cryptography ====computer security is a branch of computer technology with the objective of protecting information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users.historical cryptography is the art of writing and deciphering secret messages. modern cryptography is the scientific study of problems relating to distributed computations that can be attacked. technologies studied in modern cryptography include symmetric and asymmetric encryption, digital signatures, cryptographic hash functions, key-agreement protocols, blockchain, zero-knowledge proofs, and garbled circuits.==== databases and data mining ====a database is intended to organize, store, and retrieve large amounts of data easily. digital databases are managed using database management systems to store, create, maintain, and search data, through database models and query languages. data mining is a process of discovering patterns in large data sets.==== computer graphics and visualization ====computer graphics is the study of digital visual contents and involves the synthesis and manipulation of image data. the study is connected to many other fields in computer science, including computer vision, image processing, and computational geometry, and is heavily applied in the fields of special effects and video games.==== image and sound processing ====information can take the form of images, sound, video or other multimedia. bits of information can be streamed via signals. its processing is the central notion of informatics, the european view on computing, which studies information processing algorithms independently of the type of information carrier - whether it is electrical, mechanical or biological. this field plays important role in information theory, telecommunications, information engineering and has applications in medical image computing and speech synthesis, among others. what is the lower bound on the complexity of fast fourier transform algorithms? is one of unsolved problems in theoretical computer science.=== applied computer science ======= computational science, finance and engineering ====scientific computing (or computational science) is the field of study concerned with constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems. a major usage of scientific computing is simulation of various processes, including computational fluid dynamics, physical, electrical, and electronic systems and circuits, as well as societies and social situations (notably war games) along with their habitats, among many others. modern computers enable optimization of such designs as complete aircraft. notable in electrical and electronic circuit design are spice, as well as software for physical realization of new (or modified) designs. the latter includes essential design software for integrated circuits.==== social computing and human–computer interaction ====social computing is an area that is concerned with the intersection of social behavior and computational systems. human–computer interaction research develops theories, principles, and guidelines for user interface designers.==== software engineering ====software engineering is the study of designing, implementing, and modifying the software in order to ensure it is of high quality, affordable, maintainable, and fast to build. it is a systematic approach to software design, involving the application of engineering practices to software. software engineering deals with the organizing and analyzing of software—it doesn\\'t just deal with the creation or manufacture of new software, but its internal arrangement and maintenance. for example software testing, systems engineering, technical debt and software development processes.'], 'discoverie': ['the philosopher of computing bill rapaport noted three great insights of computer science:gottfried wilhelm leibniz\\'s, george boole\\'s, alan turing\\'s, claude shannon\\'s, and samuel morse\\'s insight: there are only two objects that a computer has to deal with in order to represent \"anything\".all the information about any computable problem can be represented using only 0 and 1 (or any other bistable pair that can flip-flop between two easily distinguishable states, such as \"on/off\", \"magnetized/de-magnetized\", \"high-voltage/low-voltage\", etc.).alan turing\\'s insight: there are only five actions that a computer has to perform in order to do \"anything\".every algorithm can be expressed in a language for a computer consisting of only five basic instructions:move left one location;move right one location;read symbol at current location;print 0 at current location;print 1 at current location.corrado böhm and giuseppe jacopini\\'s insight: there are only three ways of combining these actions (into more complex ones) that are needed in order for a computer to do \"anything\".only three rules are needed to combine any set of basic instructions into more complex ones:sequence: first do this, then do that; selection: if such-and-such is the case, then do this, else do that;repetition: while such-and-such is the case, do this.note that the three rules of boehm\\'s and jacopini\\'s insight can be further simplified with the use of goto (which means it is more elementary than structured programming).'], 'programming paradigm': ['programming languages can be used to accomplish different tasks in different ways. common programming paradigms include:functional programming, a style of building the structure and elements of computer programs that treats computation as the evaluation of mathematical functions and avoids state and mutable data. it is a declarative programming paradigm, which means programming is done with expressions or declarations instead of statements.imperative programming, a programming paradigm that uses statements that change a program\\'s state. in much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. imperative programming focuses on describing how a program operates.object-oriented programming, a programming paradigm based on the concept of \"objects\", which may contain data, in the form of fields, often known as attributes; and code, in the form of procedures, often known as methods. a feature of objects is that an object\\'s procedures can access and often modify the data fields of the object with which they are associated. thus object-oriented computer programs are made out of objects that interact with one another.service-oriented programming, a programming paradigm that uses \"services\" as the unit of computer work, to design and implement integrated business applications and mission critical software programsmany languages offer support for multiple paradigms, making the distinction more a matter of style than of technical capabilities.'], 'academia': ['conferences are important events for computer science research. during these conferences, researchers from the public and private sectors present their recent work and meet. unlike in most other academic fields, in computer science, the prestige of conference papers is greater than that of journal publications. one proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.'], 'education': ['computer science, known by its near synonyms, computing, computer studies, has been taught in uk schools since the days of batch processing, mark sensitive cards and paper tape but usually to a select few students. in 1981, the bbc produced a micro-computer and classroom network and computer studies became common for gce o level students (11–16-year-old), and computer science to a level students. its importance was recognised, and it became a compulsory part of the national curriculum, for key stage 3 & 4. in september 2014 it became an entitlement for all pupils over the age of 4.in the us, with 14,000 school districts deciding the curriculum, provision was fractured. according to a 2010 report by the association for computing machinery (acm) and computer science teachers association (csta), only 14 out of 50 states have adopted significant education standards for high school computer science.israel, new zealand, and south korea have included computer science in their national secondary education curricula, and several others are following.'], 'relation to instruction set architecture': ['the isa is roughly the same as the programming model of a processor as seen by an assembly language programmer or compiler writer. the isa includes the instructions, execution model, processor registers, address and data formats among other things. the microarchitecture includes the constituent parts of the processor and how these interconnect and interoperate to implement the isa.the microarchitecture of a machine is usually represented as (more or less detailed) diagrams that describe the interconnections of the various microarchitectural elements of the machine, which may be anything from single gates and registers, to complete arithmetic logic units (alus) and even larger elements. these diagrams generally separate the datapath (where data is placed) and the control path (which can be said to steer the data).the person designing a system usually draws the specific microarchitecture as a kind of data flow diagram. like a block diagram, the microarchitecture diagram shows microarchitectural elements such as the arithmetic and logic unit and the register file as a single schematic symbol. typically, the diagram connects those elements with arrows, thick lines and thin lines to distinguish between three-state buses (which require a three-state buffer for each device that drives the bus), unidirectional buses (always driven by a single source, such as the way the address bus on simpler computers is always driven by the memory address register), and individual control lines. very simple computers have a single data bus organization –  they have a single three-state bus. the diagram of more complex computers usually shows multiple three-state buses, which help the machine do more operations simultaneously.each microarchitectural element is in turn represented by a schematic describing the interconnections of logic gates used to implement it. each logic gate is in turn represented by a circuit diagram describing the connections of the transistors used to implement it in some particular logic family. machines with different microarchitectures may have the same instruction set architecture, and thus be capable of executing the same programs. new microarchitectures and/or circuitry solutions, along with advances in semiconductor manufacturing, are what allows newer generations of processors to achieve higher performance while using the same isa.in principle, a single microarchitecture could execute several different isas with only minor changes to the microcode.'], 'aspect': ['the pipelined datapath is the most commonly used datapath design in microarchitecture today. this technique is used in most modern microprocessors, microcontrollers, and dsps. the pipelined architecture allows multiple instructions to overlap in execution, much like an assembly line. the pipeline includes several different stages which are fundamental in microarchitecture designs. some of these stages include instruction fetch, instruction decode, execute, and write back. some architectures include other stages such as memory access. the design of pipelines is one of the central microarchitectural tasks.execution units are also essential to microarchitecture. execution units include arithmetic logic units (alu), floating point units (fpu), load/store units, branch prediction, and simd. these units perform the operations or calculations of the processor. the choice of the number of execution units, their latency and throughput is a central microarchitectural design task. the size, latency, throughput and connectivity of memories within the system are also microarchitectural decisions.system-level design decisions such as whether or not to include peripherals, such as memory controllers, can be considered part of the microarchitectural design process. this includes decisions on the performance-level and connectivity of these peripherals.unlike architectural design, where achieving a specific performance level is the main goal, microarchitectural design pays closer attention to other constraints. since microarchitecture design decisions directly affect what goes into a system, attention must be paid to issues such as chip area/cost, power consumption, logic complexity, ease of connectivity, manufacturability, ease of debugging, and testability.'], 'microarchitectural concept': ['=== instruction cycles ===to run programs, all single- or multi-chip cpus:read an instruction and decode itfind any associated data that is needed to process the instructionprocess the instructionwrite the results outthe instruction cycle is repeated continuously until the power is turned off.=== multicycle microarchitecture ===historically, the earliest computers were multicycle designs. the smallest, least-expensive computers often still use this technique. multicycle architectures often use the least total number of logic elements and reasonable amounts of power. they can be designed to have deterministic timing and high reliability. in particular, they have no pipeline to stall when taking conditional branches or interrupts.  however, other microarchitectures often perform more instructions per unit time, using the same logic family.  when discussing \"improved performance,\" an improvement is often relative to a multicycle design.in a multicycle computer, the computer does the four steps in sequence, over several cycles of the clock. some designs can perform the sequence in two clock cycles by completing successive stages on alternate clock edges, possibly with longer operations occurring outside the main cycle. for example, stage one on the rising edge of the first cycle, stage two on the falling edge of the first cycle, etc.in the control logic, the combination of cycle counter, cycle state (high or low) and the bits of the instruction decode register determine exactly what each part of the computer should be doing. to design the control logic, one can create a table of bits describing the control signals to each part of the computer in each cycle of each instruction. then, this logic table can be tested in a software simulation running test code.  if the logic table is placed in a memory and used to actually run a real computer, it is called a microprogram. in some computer designs, the logic table is optimized into the form of combinational logic made from logic gates, usually using a computer program that optimizes logic. early computers used ad-hoc logic design for control until maurice wilkes invented this tabular approach and called it microprogramming.=== increasing execution speed ===complicating this simple-looking series of steps is the fact that the memory hierarchy, which includes caching, main memory and non-volatile storage like hard disks (where the program instructions and data reside), has always been slower than the processor itself. step (2) often introduces a lengthy (in cpu terms) delay while the data arrives over the computer bus. a considerable amount of research has been put into designs that avoid these delays as much as possible. over the years, a central goal was to execute more instructions in parallel, thus increasing the effective execution speed of a program. these efforts introduced complicated logic and circuit structures. initially, these techniques could only be implemented on expensive mainframes or supercomputers due to the amount of circuitry needed for these techniques. as semiconductor manufacturing progressed, more and more of these techniques could be implemented on a single semiconductor chip. see moore\\'s law.=== instruction set choice ===instruction sets have shifted over the years, from originally very simple to sometimes very complex (in various respects). in recent years, load–store architectures, vliw and epic types have been in fashion. architectures that are dealing with data parallelism include simd and vectors. some labels used to denote classes of cpu architectures are not particularly descriptive, especially so the cisc label; many early designs retroactively denoted \"cisc\" are in fact significantly simpler than modern risc processors (in several respects).however, the choice of instruction set architecture may greatly affect the complexity of implementing high-performance devices. the prominent strategy, used to develop the first risc processors, was to simplify instructions to a minimum of individual semantic complexity combined with high encoding regularity and simplicity. such uniform instructions were easily fetched, decoded and executed in a pipelined fashion and a simple strategy to reduce the number of logic levels in order to reach high operating frequencies; instruction cache-memories compensated for the higher operating frequency and inherently low code density while large register sets were used to factor out as much of the (slow) memory accesses as possible.=== instruction pipelining ===one of the first, and most powerful, techniques to improve performance is the use of instruction pipelining. early processor designs would carry out all of the steps above for one instruction before moving onto the next. large portions of the circuitry were left idle at any one step; for instance, the instruction decoding circuitry would be idle during execution and so on.pipelining improves performance by allowing a number of instructions to work their way through the processor at the same time. in the same basic example, the processor would start to decode (step 1) a new instruction while the last one was waiting for results. this would allow up to four instructions to be \"in flight\" at one time, making the processor look four times as fast. although any one instruction takes just as long to complete (there are still four steps) the cpu as a whole \"retires\" instructions much faster.risc makes pipelines smaller and much easier to construct by cleanly separating each stage of the instruction process and making them take the same amount of time—one cycle. the processor as a whole operates in an assembly line fashion, with instructions coming in one side and results out the other. due to the reduced complexity of the classic risc pipeline, the pipelined core and an instruction cache could be placed on the same size die that would otherwise fit the core alone on a cisc design. this was the real reason that risc was faster. early designs like the sparc and mips often ran over 10 times as fast as intel and motorola cisc solutions at the same clock speed and price.pipelines are by no means limited to risc designs. by 1986 the top-of-the-line vax implementation (vax 8800) was a heavily pipelined design, slightly predating the first commercial mips and sparc designs. most modern cpus (even embedded cpus) are now pipelined, and microcoded cpus with no pipelining are seen only in the most area-constrained embedded processors. large cisc machines, from the vax 8800 to the modern pentium 4 and athlon, are implemented with both microcode and pipelines. improvements in pipelining and caching are the two major microarchitectural advances that have enabled processor performance to keep pace with the circuit technology on which they are based.=== cache ===it was not long before improvements in chip manufacturing allowed for even more circuitry to be placed on the die, and designers started looking for ways to use it. one of the most common was to add an ever-increasing amount of cache memory on-die. cache is very fast and expensive memory. it can be accessed in a few cycles as opposed to many needed to \"talk\" to main memory. the cpu includes a cache controller which automates reading and writing from the cache. if the data is already in the cache it is accessed from there – at considerable time savings, whereas if it is not the processor is \"stalled\" while the cache controller reads it in.risc designs started adding cache in the mid-to-late 1980s, often only 4 kb in total. this number grew over time, and typical cpus now have at least 2 mb, while more powerful cpus come with 4 or 6 or 12mb or even 32mb or more, with the most being 768mb in the newly released epyc milan-x line, organized in multiple levels of a memory hierarchy. generally speaking, more cache means more performance, due to reduced stalling.caches and pipelines were a perfect match for each other. previously, it didn\\'t make much sense to build a pipeline that could run faster than the access latency of off-chip memory. using on-chip cache memory instead, meant that a pipeline could run at the speed of the cache access latency, a much smaller length of time. this allowed the operating frequencies of processors to increase at a much faster rate than that of off-chip memory.=== branch prediction ===one barrier to achieving higher performance through instruction-level parallelism stems from pipeline stalls and flushes due to branches. normally, whether a conditional branch will be taken isn\\'t known until late in the pipeline as conditional branches depend on results coming from a register. from the time that the processor\\'s instruction decoder has figured out that it has encountered a conditional branch instruction to the time that the deciding register value can be read out, the pipeline needs to be stalled for several cycles, or if it\\'s not and the branch is taken, the pipeline needs to be flushed. as clock speeds increase the depth of the pipeline increases with it, and some modern processors may have 20 stages or more. on average, every fifth instruction executed is a branch, so without any intervention, that\\'s a high amount of stalling.techniques such as branch prediction and speculative execution are used to lessen these branch penalties. branch prediction is where the hardware makes educated guesses on whether a particular branch will be taken. in reality one side or the other of the branch will be called much more often than the other. modern designs have rather complex statistical prediction systems, which watch the results of past branches to predict the future with greater accuracy. the guess allows the hardware to prefetch instructions without waiting for the register read. speculative execution is a further enhancement in which the code along the predicted path is not just prefetched but also executed before it is known whether the branch should be taken or not. this can yield better performance when the guess is good, with the risk of a huge penalty when the guess is bad because instructions need to be undone.=== superscalar ===even with all of the added complexity and gates needed to support the concepts outlined above, improvements in semiconductor manufacturing soon allowed even more logic gates to be used.in the outline above the processor processes parts of a single instruction at a time. computer programs could be executed faster if multiple instructions were processed simultaneously. this is what superscalar processors achieve, by replicating functional units such as alus. the replication of functional units was only made possible when the die area of a single-issue processor no longer stretched the limits of what could be reliably manufactured. by the late 1980s, superscalar designs started to enter the market place.in modern designs it is common to find two load units, one store (many instructions have no results to store), two or more integer math units, two or more floating point units, and often a simd unit of some sort. the instruction issue logic grows in complexity by reading in a huge list of instructions from memory and handing them off to the different execution units that are idle at that point. the results are then collected and re-ordered at the end.=== out-of-order execution ===the addition of caches reduces the frequency or duration of stalls due to waiting for data to be fetched from the memory hierarchy, but does not get rid of these stalls entirely. in early designs a cache miss would force the cache controller to stall the processor and wait. of course there may be some other instruction in the program whose data is available in the cache at that point. out-of-order execution allows that ready instruction to be processed while an older instruction waits on the cache, then re-orders the results to make it appear that everything happened in the programmed order. this technique is also used to avoid other operand dependency stalls, such as an instruction awaiting a result from a long latency floating-point operation or other multi-cycle operations.=== register renaming ===register renaming refers to a technique used to avoid unnecessary serialized execution of program instructions because of the reuse of the same registers by those instructions. suppose we have two groups of instruction that will use the same register. one set of instructions is executed first to leave the register to the other set, but if the other set is assigned to a different similar register, both sets of instructions can be executed in parallel (or) in series.=== multiprocessing and multithreading ===computer architects have become stymied by the growing mismatch in cpu operating frequencies and dram access times. none of the techniques that exploited instruction-level parallelism (ilp) within one program could make up for the long stalls that occurred when data had to be fetched from main memory. additionally, the large transistor counts and high operating frequencies needed for the more advanced ilp techniques required power dissipation levels that could no longer be cheaply cooled. for these reasons, newer generations of computers have started to exploit higher levels of parallelism that exist outside of a single program or program thread.this trend is sometimes known as throughput computing. this idea originated in the mainframe market where online transaction processing emphasized not just the execution speed of one transaction, but the capacity to deal with massive numbers of transactions. with transaction-based applications such as network routing and web-site serving greatly increasing in the last decade, the computer industry has re-emphasized capacity and throughput issues.one technique of how this parallelism is achieved is through multiprocessing systems, computer systems with multiple cpus. once reserved for high-end mainframes and supercomputers, small-scale (2–8) multiprocessors servers have become commonplace for the small business market. for large corporations, large scale (16–256) multiprocessors are common. even personal computers with multiple cpus have appeared since the 1990s.with further transistor size reductions made available with semiconductor technology advances, multi-core cpus have appeared where multiple cpus are implemented on the same silicon chip. initially used in chips targeting embedded markets, where simpler and smaller cpus would allow multiple instantiations to fit on one piece of silicon. by 2005, semiconductor technology allowed dual high-end desktop cpus cmp chips to be manufactured in volume. some designs, such as sun microsystems\\' ultrasparc t1 have reverted to simpler (scalar, in-order) designs in order to fit more processors on one piece of silicon.another technique that has become more popular recently is multithreading. in multithreading, when the processor has to fetch data from slow system memory, instead of stalling for the data to arrive, the processor switches to another program or program thread which is ready to execute. though this does not speed up a particular program/thread, it increases the overall system throughput by reducing the time the cpu is idle.conceptually, multithreading is equivalent to a context switch at the operating system level. the difference is that a multithreaded cpu can do a thread switch in one cpu cycle instead of the hundreds or thousands of cpu cycles a context switch normally requires. this is achieved by replicating the state hardware (such as the register file and program counter) for each active thread.a further enhancement is simultaneous multithreading. this technique allows superscalar cpus to execute instructions from different programs/threads simultaneously in the same cycle.'], 'categorie': ['computer architecture simulators can be classified into many different categories depending on the context.scope: microarchitecture simulators model the microprocessor and its components. full-system simulators also model the processor, memory systems, and i/o devices.detail: functional simulators, such as instruction set simulators, achieve the same function as modeled components. they can be simulated faster if timing is not considered. timing simulators are functional simulators that also reproduce timing. timing simulators can be further categorized into digital cycle-accurate and analog sub-cycle simulators.workload: trace-driven simulators (also called event-driven simulators) react to pre-recorded streams of instructions with some fixed input. execution-driven simulators allow dynamic change of instructions to be executed depending on different input data.=== full-system simulators ===a full-system simulator is execution-driven architecture simulation at such a level of detail that complete software stacks from real systems can run on the simulator without any modification. a full system simulator provides virtual hardware that is independent of the nature of the host computer. the full-system model typically includes processor cores, peripheral devices, memories, interconnection buses, and network connections. emulators are full system simulators that imitate obsolete hardware instead of under development hardware.the defining property of full-system simulation compared to an instruction set simulator is that the model allows real device drivers and operating systems to be run, not just single programs.  thus, full-system simulation makes it possible to simulate individual computers and networked computer nodes with all their software, from network device drivers to operating systems, network stacks, middleware, servers, and application programs.full system simulation can speed the system development process by making it easier to detect, recreate and repair flaws. the use of multi-core processors is driving the need for full system simulation, because it can be extremely difficult and time-consuming to recreate and debug errors without the controlled environment provided by virtual hardware. this also allows the software development to take place before the hardware is ready, thus helping to validate design decisions.=== cycle-accurate simulator ===a cycle-accurate simulator is a computer program that simulates a microarchitecture on a cycle-by-cycle basis. in contrast an instruction set simulator simulates an instruction set architecture usually faster but not cycle-accurate to a specific implementation of this architecture; they are often used when emulating older hardware, where time precision is important for legacy reasons. often, a cycle-accurate simulator is used when designing new microprocessors – they can be tested, and benchmarked accurately (including running full operating system, or compilers) without actually building a physical chip, and easily change design many times to meet expected plan.cycle-accurate simulators must ensure that all operations are executed in the proper virtual (or real if it is possible) time – branch prediction, cache misses, fetches, pipeline stalls, thread context switching, and many other subtle aspects of microprocessors.']})\n",
      "['intro', 'history', 'further reading', 'source', 'type']\n"
     ]
    }
   ],
   "source": [
    "# run related_paper_section_content separately\n",
    "important_subsections, related_paper_section_content = get_important_subsections_and_content(RELATED_TITLES)\n",
    "important_subsections.insert(0, 'intro')\n",
    "# print(important_subsections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b746d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['intro', 'history', 'note', 'source', 'type']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_subsections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c3fc8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['intro', 'history', 'subcategorie', 'role', 'design goal', 'see also', 'reference', 'source', 'external link', 'uses of word', 'word size choice', 'size familie', 'table of word size', 'note', 'background', 'type', 'eliminating hazard', 'overview', 'types of multithreading', 'implementation specific', 'capabilitie', 'evolution', 'design limitation', 'further reading', 'advantage', 'disadvantage', 'etymology', 'hardware', 'software', 'networking and the internet', 'unconventional computer', 'future', 'professions and organization', 'philosophy', 'field', 'discoverie', 'programming paradigm', 'academia', 'education', 'relation to instruction set architecture', 'aspect', 'microarchitectural concept', 'categorie'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_paper_section_content.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e0ebcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80de4563fe434609a1c29936bdf7e0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/737 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c063cbb660df41b19f2ac58f65e9cf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fb7579c5564993a25f812e5852f24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c250d8c6c0b46cba3758c2f12b5352b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/650 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e7b423eaa34df4a4db9b8a159b5415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dc56f9adcc4d08be9f8008d7b67913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/15.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9489717871d1433c8907f0f31b9fae10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ce0e87e4c445f3a4def3b2f5e29700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20a51d509c0458289651f894476dcb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cbd7b3705bb4018acf1d640df976bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a98b111feac45dc94e4554842f9b56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72322a6181894164a226a5136ce424db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3e4c813821496ba79b1c38c37f830c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/328 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a54ba9b5c6b477bb157c0e136a17ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbf71e98e09473fab1ef5740f67a8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3cd137b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_embeddings = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "584cfe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:46<00:00,  9.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# Creates word embeddings for subsection headings\n",
    "features = []\n",
    "for subsections in tqdm(important_subsections):\n",
    "    paras = related_paper_section_content[subsections]\n",
    "    topic_emb = np.average(model.encode(paras), 0)\n",
    "    features.append(topic_emb)\n",
    "    topic_embeddings[subsections] = topic_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "260925ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'intro': array([-0.0208666 , -0.00589552, -0.00109883, ..., -0.01456317,\n",
       "                    -0.01239052,  0.00554677], dtype=float32),\n",
       "             'history': array([-0.00404924, -0.00525453,  0.01348945, ..., -0.00970293,\n",
       "                     0.00595382,  0.00850123], dtype=float32),\n",
       "             'further reading': array([-0.01379063, -0.01322948, -0.00039736, ...,  0.00573622,\n",
       "                    -0.01940511,  0.00202804], dtype=float32),\n",
       "             'source': array([-0.01102134, -0.013382  ,  0.00431951, ...,  0.00935034,\n",
       "                    -0.01108901,  0.00824041], dtype=float32),\n",
       "             'type': array([ 0.02489299, -0.00868182, -0.01139153, ...,  0.02240595,\n",
       "                     0.01339949,  0.03120554], dtype=float32)})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58392213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(url):\n",
    "    try:\n",
    "        session = HTMLSession()\n",
    "        response = session.get(url)\n",
    "        return response\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "        \n",
    "def google_search(query):\n",
    "    query = urllib.parse.quote_plus(query)\n",
    "    response = get_source(\"https://www.google.com/search?q=\" + query)\n",
    "    links = list(set(response.html.absolute_links))\n",
    "    # Get rid of these from the domains that are used\n",
    "    google_domains = ('https://www.google.', \n",
    "                      'https://google.',\n",
    "                      'https://www.google.com/search?',\n",
    "                      'https://webcache.googleusercontent.', \n",
    "                      'http://webcache.googleusercontent.', \n",
    "                      'https://policies.google.',\n",
    "                      'https://support.google.',\n",
    "                      'https://maps.google.',\n",
    "                      'https://www.coursera.org',\n",
    "                      'https://www.youtube.com',\n",
    "                     'https://online.umich.edu/',\n",
    "                      'https://docs.oracle.com/',\n",
    "                      'https://www.cise.ufl.edu/~mssz/CompOrg/CDA-lang.html',\n",
    "                      'https://study.com/academy',\n",
    "                      'https://www.redhat.com',\n",
    "                      'https://www.oreilly.com',\n",
    "                      'https://scholar.google.com',\n",
    "                      'https://machinelearningknowledge',\n",
    "                      'https://interestingengineering.com',\n",
    "                      'https://www.nature.com/',\n",
    "                      'https://machinelearningmastery.com',\n",
    "                      'https://www.thelancet.com/',\n",
    "                      'https://m.youtube.com',\n",
    "                      'https://www.mathworks.com',\n",
    "                      'https://www.deeplearningbook'\n",
    "                     )\n",
    "    \n",
    "    for url in links[:]:\n",
    "        url_check = url.split('#')[0]\n",
    "        if url_check in urls_visited or url.startswith(google_domains):\n",
    "            links.remove(url)\n",
    "        if url_check not in urls_visited:\n",
    "            urls_visited.add(url_check)\n",
    "        if url[-3:] == 'pdf':\n",
    "            links.remove(url)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6eda5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_from_url(results):\n",
    "    data = []\n",
    "    for url in results:\n",
    "        print(url)\n",
    "        # Specially collect data from wikipedia\n",
    "        if url.startswith('http://en.wikipedia.org/wiki/') or url.startswith('https://en.wikipedia.org/wiki/'):\n",
    "            search_term = url.replace('http://en.wikipedia.org/wiki/', '').replace('https://en.wikipedia.org/wiki/', '').replace('_', ' ').replace('%E2%80%93', '-').replace('%27', \"'\")\n",
    "            sentences = wiki.WikipediaPage(title=search_term).content\n",
    "            text_info = ''\n",
    "            for sent in sentences.split('.'):\n",
    "                if sent == '' or len(sent) > 500 or len(sent) < 10:\n",
    "                    continue\n",
    "                sent_emb = torch.from_numpy(model.encode(sent))\n",
    "                if float(sent_emb @ topic_emb) < 0.3:\n",
    "                    continue\n",
    "                text_info += (sent + '. ')\n",
    "\n",
    "            item = {\n",
    "                'title': search_term,\n",
    "                'link': url,\n",
    "                'text': text_info,\n",
    "                #'emb': model.encode(text_info)\n",
    "            }\n",
    "            data.append(item) \n",
    "        else:\n",
    "            try: \n",
    "                page = requests.get(url, timeout=(5, 10))\n",
    "            except requests.exceptions.Timeout as err: \n",
    "                #print(\"here\")\n",
    "                continue\n",
    "            #print(page)\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\",from_encoding=\"iso-8859-1\")\n",
    "            p = soup.find_all('p')\n",
    "            paragraphs = []\n",
    "            for x in p:\n",
    "                paragraphs.append(str(x))\n",
    "            if len(paragraphs) == 0:\n",
    "                continue\n",
    "            text_info = ''\n",
    "            for para in paragraphs:\n",
    "                if para == '':\n",
    "                    continue\n",
    "                sentences = html_text.extract_text(para, guess_layout=False)\n",
    "                for sent in sentences.split('.'):\n",
    "                    if sent == '' or len(sent) > 500 or len(sent) < 10:\n",
    "                        continue\n",
    "                    sent_emb = torch.from_numpy(model.encode(sent))\n",
    "                    if float(sent_emb @ topic_emb) < 0.3:\n",
    "                        continue\n",
    "                    text_info += (sent + '. ')\n",
    "            if len(text_info) < 100 or len(text_info) > 10000: \n",
    "                continue\n",
    "            item = {\n",
    "                'title': \"<UNK>\",\n",
    "                'link': url,\n",
    "                'text': text_info,\n",
    "                #'emb': model.encode(text_info)\n",
    "            }\n",
    "            data.append(item)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8d4d4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Category:Computer_architecture',\n",
       " 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'https://www.britannica.com/technology/computer-architecture',\n",
       " 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'https://geteducationskills.com/computer-architecture/',\n",
       " 'https://www.techopedia.com/definition/26757/computer-architecture',\n",
       " 'https://www.sciencedirect.com/topics/computer-science/computer-architecture',\n",
       " 'https://www.tutorialspoint.com/what-is-computer-architecture',\n",
       " 'https://www.computersciencedegreehub.com/faq/what-is-computer-architecture/',\n",
       " 'https://dl.acm.org/doi/10.1109/MAHC.1988.10039',\n",
       " 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'https://edurev.in/studytube/A-Brief-History-of-Computer-Architecture-Computer-/987e1c94-0ef4-4ebd-b172-277f3deb72c1_t',\n",
       " 'https://www.computer.org/csdl/magazine/an/1988/04/man1988040277/13rRUxZRbrm',\n",
       " 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'https://www.quora.com/What-are-good-books-for-computer-architecture',\n",
       " 'https://warwick.ac.uk/fac/sci/dcs/teaching/modules/cs257/',\n",
       " 'https://safari.ethz.ch/digitaltechnik/spring2021/doku.php?id=readings',\n",
       " 'https://www.quora.com/What-are-some-good-books-on-Computer-Architecture-for-beginners?top_ans=1974891',\n",
       " 'https://safari.ethz.ch/architecture/fall2020/doku.php?id=readings',\n",
       " 'https://www.goodreads.com/shelf/show/computer-architecture',\n",
       " 'https://www.quora.com/What-is-a-good-book-to-learn-computer-architecture',\n",
       " 'https://www.quora.com/What-is-the-best-book-in-computer-architecture-that-is-easy-to-understand-and-written-in-lucid-language-as-well',\n",
       " 'https://www.quora.com/What-are-some-good-books-on-Computer-Architecture-for-beginners',\n",
       " 'https://www.amazon.com/Readings-Computer-Architecture-Morgan-Kaufmann/dp/1558605398',\n",
       " 'https://www.quora.com/What-is-the-best-way-and-source-to-learn-computer-architecture?top_ans=47987712',\n",
       " 'https://www.quora.com/What-is-the-best-way-to-learn-computer-organization-and-architecture',\n",
       " 'https://www.sigarch.org/call-contributions/first-workshop-on-open-source-computer-architecture-research-oscar/',\n",
       " 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'https://github.com/rajesh-s/computer-engineering-resources',\n",
       " 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'https://www.quora.com/What-is-the-best-source-and-method-to-study-computer-architecture',\n",
       " 'https://www.quora.com/What-is-the-best-way-and-source-to-learn-computer-architecture',\n",
       " 'https://github.com/topics/computer-architecture',\n",
       " 'https://www.w3schools.in/computer-fundamentals/types-of-computer-architecture',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-architecture-and-organisations',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-architectures-in-a-CPU',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-system-architecture?top_ans=20669228',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-system-architecture',\n",
       " 'https://www.quora.com/What-are-other-types-of-computer-system-architecture-apart-from-Von-Neumann',\n",
       " 'https://www.quora.com/What-are-the-most-commonly-used-computer-architectures',\n",
       " 'https://www.researchgate.net/publication/241056162_Types_of_Computer_Architectures']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_visited = set()\n",
    "results = []\n",
    "for text in important_subsections:\n",
    "    if text == 'intro':\n",
    "        results.extend(google_search(\"what is \" + TITLE))\n",
    "    else:\n",
    "        results.extend(google_search(TITLE + \" \" + text.lower()))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a9131984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Category:Computer_architecture 2\n",
      "https://online.sunderland.ac.uk/what-is-computer-architecture/ 22\n",
      "https://en.wikipedia.org/wiki/Computer_architecture 32\n",
      "https://en.wikipedia.org/wiki/Word_(computer_architecture) 27\n",
      "https://www.britannica.com/technology/computer-architecture 3\n",
      "https://www.educba.com/types-of-computer-architecture/ 51\n",
      "https://en.wikipedia.org/wiki/Microarchitecture 40\n",
      "https://geteducationskills.com/computer-architecture/ 22\n",
      "https://www.techopedia.com/definition/26757/computer-architecture 22\n",
      "https://www.sciencedirect.com/topics/computer-science/computer-architecture 4\n",
      "https://www.tutorialspoint.com/what-is-computer-architecture 19\n",
      "https://www.computersciencedegreehub.com/faq/what-is-computer-architecture/ 9\n",
      "https://dl.acm.org/doi/10.1109/MAHC.1988.10039 21\n",
      "https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/ 18\n",
      "https://edurev.in/studytube/A-Brief-History-of-Computer-Architecture-Computer-/987e1c94-0ef4-4ebd-b172-277f3deb72c1_t 8\n",
      "https://www.computer.org/csdl/magazine/an/1988/04/man1988040277/13rRUxZRbrm 0\n",
      "https://techwithtech.com/best-computer-architecture-books/ 152\n",
      "https://www.quora.com/What-are-good-books-for-computer-architecture 1\n",
      "https://warwick.ac.uk/fac/sci/dcs/teaching/modules/cs257/ 37\n",
      "https://safari.ethz.ch/digitaltechnik/spring2021/doku.php?id=readings 4\n",
      "https://www.quora.com/What-are-some-good-books-on-Computer-Architecture-for-beginners?top_ans=1974891 1\n",
      "https://safari.ethz.ch/architecture/fall2020/doku.php?id=readings 4\n",
      "https://www.goodreads.com/shelf/show/computer-architecture 1\n",
      "https://www.quora.com/What-is-a-good-book-to-learn-computer-architecture 1\n",
      "https://www.quora.com/What-is-the-best-book-in-computer-architecture-that-is-easy-to-understand-and-written-in-lucid-language-as-well 1\n",
      "https://www.quora.com/What-are-some-good-books-on-Computer-Architecture-for-beginners 1\n",
      "https://www.amazon.com/Readings-Computer-Architecture-Morgan-Kaufmann/dp/1558605398 1\n",
      "https://www.quora.com/What-is-the-best-way-and-source-to-learn-computer-architecture?top_ans=47987712 1\n",
      "https://www.quora.com/What-is-the-best-way-to-learn-computer-organization-and-architecture 1\n",
      "https://www.sigarch.org/call-contributions/first-workshop-on-open-source-computer-architecture-research-oscar/ 17\n",
      "https://en.wikipedia.org/wiki/Instruction_set_architecture 50\n",
      "https://github.com/rajesh-s/computer-engineering-resources 24\n",
      "https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext 168\n",
      "https://www.quora.com/What-is-the-best-source-and-method-to-study-computer-architecture 1\n",
      "https://www.quora.com/What-is-the-best-way-and-source-to-learn-computer-architecture 1\n",
      "https://github.com/topics/computer-architecture 36\n",
      "https://www.w3schools.in/computer-fundamentals/types-of-computer-architecture 14\n",
      "https://www.quora.com/What-are-the-types-of-computer-architecture-and-organisations 1\n",
      "https://www.quora.com/What-are-the-types-of-computer-architectures-in-a-CPU 1\n",
      "https://www.quora.com/What-are-the-types-of-computer-system-architecture?top_ans=20669228 1\n",
      "https://www.quora.com/What-are-the-types-of-computer-system-architecture 1\n",
      "https://www.quora.com/What-are-other-types-of-computer-system-architecture-apart-from-Von-Neumann 1\n",
      "https://www.quora.com/What-are-the-most-commonly-used-computer-architectures 1\n",
      "https://www.researchgate.net/publication/241056162_Types_of_Computer_Architectures 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "raw_dataset = defaultdict(list)\n",
    "cleaned_para = []\n",
    "\n",
    "# Get website urls and the paragraph tags in them\n",
    "for result in results:\n",
    "    temp_dataset = ''\n",
    "    paragraphs = []\n",
    "    temp_cleaned_para = []\n",
    "    try:\n",
    "        page = requests.get(result, timeout=(5, 10), headers=headers)\n",
    "    except:\n",
    "        print(\"here\")\n",
    "        continue\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    p = soup.find_all('p')\n",
    "    \n",
    "    \n",
    "    for x in p:\n",
    "        paragraphs.append(str(x))\n",
    "    for i, para in enumerate(paragraphs):\n",
    "        if para != '':\n",
    "            temp_cleaned_para.append(html_text.extract_text(para, guess_layout=False))\n",
    "\n",
    "    for i, para in enumerate(temp_cleaned_para):\n",
    "        if len(nltk.word_tokenize(para)) > 30 and len(nltk.word_tokenize(para)) < 150:\n",
    "            para = re.sub('[\\[].*?[\\]]', '', para)\n",
    "            raw_dataset[result].append(para)\n",
    "            cleaned_para.append(para)\n",
    "    \n",
    "    print(result, len(p))\n",
    "len(cleaned_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6ddae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_reference = {}\n",
    "for key, val in raw_dataset.items():\n",
    "    for v in val:\n",
    "        paragraph_reference[v] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "426228ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'All computers, no matter their size, are based around a set of rules stating how software and hardware join together and interact to make them work. This is what is known as computer architecture. In this article we’re going to delve into what computer architecture actually is.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'Computer architecture is the organisation of the components which make up a computer system and the meaning of the operations which guide its function. It defines what is seen on the machine interface, which is targeted by programming languages and their compilers.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'System design includes all hardware parts of a computer, including data processors, multiprocessors, memory controllers, and direct memory access. It also includes the graphics processing unit (GPU). This part is the physical computer system.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'This includes the functions and capabilities of the central processing unit (CPU). It is the embedded programming language and defines what programming it can perform or process. This part is the software that makes the computer run, such as operating systems like Windows on a PC or iOS on an Apple iPhone, and includes data formats and the programmed instruction set.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'Microarchitecture is also known as computer organisation and defines the data processing and storage element and how they should be implemented into the ISA. It is the hardware implementation of how an ISA is implemented in a particular processor.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'CISC processors have a single processing unit, external memory, and a small register set with hundreds of different instructions. These processors have a single instruction to perform a task, and have the advantage of making the job of the programmer easier, as fewer lines of code are needed to get the job done. This approach uses less memory, but can take longer to complete instructions.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'The RISC architecture was the result of a rethink, which has led to the development of high-performance processors. The hardware is kept as simple and fast as possible, and complex instructions can be performed with simpler instructions.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'Microprocessors are digital systems which read and execute machine language instructions. Instructions are represented in a symbolic format called an assembly language. These are processors which are implemented on a single, integrated circuit. Common microprocessors used today are the Intel Pentium series, IBM PowerPC, and the Sun SPARC, among others. Nearly all modern processors are microprocessors, which are often available as standard on von Neumann machines.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'Mathematician John von Neumann and his colleagues proposed the von Neumann architecture in 1945, which stated that a computer consists of: a processor with an arithmetic and logic unit (ALU) and a control unit; a memory unit that can communicate directly with the processor using connections called buses; connections for input/output devices; and a secondary storage for saving and backing up data.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'The central computation concept of this architecture is that instructions and data are both loaded into the same memory unit, which is the main memory of the computer and consists of a set of addressable locations. The processor can then access the instructions and data required for the execution of a computer program using dedicated connections called buses – an address bus which is used to identify the addressed location and a data bus which is used to transfer the contents to and from a location.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'Computers as physical objects have changed dramatically in the 76 years since the von Neumann architecture was proposed. Supercomputers in the 1940s took up a whole room but had very basic functionality, compared to a modern smartwatch which is small in size but has dramatically higher performance. However, at their core, computers have changed very little and almost all of those created between then and now have been run on virtually the same von Neumann architecture.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'There are a number of reasons why the von Neumann architecture has proven to be so successful. It is relatively easy to implement in hardware, and von Neumann machines are deterministic and introspectable. They can be described mathematically and every step of their computing process is understood. You can also rely on them to always generate the same output on one set of inputs.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'The biggest challenge with von Neumann machines is that they can be difficult to code. This has led to the growth of computer programming, which takes real-world problems and explains them to von Neumann machines.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'When a software program is being written, an algorithm is reduced to the formal instructions that a von Neumann machine can follow. However, the challenge is that not all algorithms and problems are easy to reduce, leaving unsolved problems.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'The Harvard architecture keeps instructions and data in separate memories, and the processor accesses these memories using separate buses. The processor is connected to the ‘instructions memory’ using a dedicated set of address and data buses, and is connected to the ‘data memory’ using a different set of address and data buses.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'At the University of Sunderland we offer a 100% online learning MSc Computer Science course, designed for individuals who aren’t from a computer science background and want to change their career path, or for those who want to incorporate computer science knowledge into their current field for career progression.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'Study part-time and entirely online and grow your global network as you connect with peers from all over the world. Apply today and start within weeks, we have six start dates a year.': 'https://online.sunderland.ac.uk/what-is-computer-architecture/',\n",
       " 'In computer engineering, computer architecture is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. The architecture of a system refers to its structure in terms of separately specified components of that system and their interrelationships. ': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation.  In other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation. ': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'The first documented computer architecture was in the correspondence between Charles Babbage and Ada Lovelace, describing the analytical engine. When building the computer Z1 in 1936, Konrad Zuse described in two patent applications for his future projects that machine instructions could be stored in the same storage used for data, i.e., the stored-program concept.   Two other early and important examples are:': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " \"The term “architecture” in computer literature can be traced to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM's main research center in 1959. Johnson had the opportunity to write a proprietary research communication about the Stretch, an IBM-developed supercomputer for Los Alamos National Laboratory (at the time known as Los Alamos Scientific Laboratory). To describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that seemed more useful than “machine organization”. \": 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Subsequently, Brooks, a Stretch designer, opened Chapter 2 of a book called Planning a Computer System: Project Stretch by stating, “Computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.” ': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Brooks went on to help develop the IBM System/360 (now called the IBM zSeries) line of computers, in which “architecture” became a noun defining “what the user needs to know”.  Later, computer users came to use the term in many less explicit ways. ': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'The earliest computer architectures were designed on paper and then directly built into the final hardware form.  Later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (TTL) computer—such as the prototypes of the 6800 and the PA-RISC —tested, and tweaked, before committing to the final hardware form. As of the 1990s, new computer architectures are typically \"built\", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a FPGA as a soft microprocessor; or both—before committing to the final hardware form. ': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'There are other technologies in computer architecture. The following technologies are used in bigger companies like Intel, and were estimated in 2002  to count for 1% of all of computer architecture:': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. The case of instruction set architecture can be used to illustrate the balance of these competing factors. More complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 Loop instruction).  However, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. The increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'The implementation involves integrated circuit design, packaging, power, and cooling. Optimization of the design requires familiarity with compilers, operating systems to logic design, and packaging. ': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " \"An instruction set architecture (ISA) is the interface between the computer's software and hardware and also can be viewed as the programmer's view of the machine. Computers do not understand high-level programming languages such as Java, C++, or most programming languages used. A processor only understands instructions encoded in some numerical fashion, usually as binary numbers. Software tools, such as compilers, translate those high level languages into instructions that the processor can understand.\": 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Besides instructions, the ISA defines items in the computer that are available to a program—e.g., data types, registers, addressing modes, and memory. Instructions locate these available items with register indexes (or names) and memory addressing modes.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'The ISA of a computer is usually described in a small instruction manual, which describes how the instructions are encoded. Also, it may define short (vaguely) mnemonic names for the instructions. The names can be recognized by a software development tool called an assembler. An assembler is a computer program that translates a human-readable form of the ISA into a computer-readable form. Disassemblers are also widely available, usually in debuggers and software programs to isolate and correct malfunctions in binary computer programs.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'ISAs vary in quality and completeness. A good ISA compromises between programmer convenience (how easy the code is to understand), size of the code (how much code is required to do a specific action), cost of the computer to interpret the instructions (more complexity means more hardware needed to decode and execute the instructions), and speed of the computer (with more complex decoding hardware comes longer decode time). Memory organization defines how instructions interact with the memory, and how memory interacts with itself.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'During design emulation, emulators can run programs written in a proposed instruction set. Modern emulators can measure size, cost, and speed to determine whether a particular ISA is meeting its goals.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " \"Computer organization helps optimize performance-based products. For example, software engineers need to know the processing power of processors. They may need to optimize software in order to gain the most performance for the lowest price. This can require quite a detailed analysis of the computer's organization. For example, in an SD card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.\": 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Computer organization also helps plan the selection of a processor for a particular project. Multimedia projects may need very rapid data access, while virtual machines may need fast interrupts. Sometimes certain tasks need additional components as well. For example, a computer capable of running a virtual machine needs virtual memory hardware so that the memory of different virtual computers can be kept separated. Computer organization and features also affect power consumption and processor cost.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Once an instruction set and micro-architecture have been designed, a practical machine must be developed. This design process is called the implementation. Implementation is usually not considered architectural design, but rather hardware design engineering. Implementation can be further broken down into several steps:': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'The exact form of a computer system depends on the constraints and goals. Computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. Sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Modern computer performance is often described in instructions per cycle (IPC), which measures the efficiency of the architecture at any clock frequency; a faster IPC rate means the computer is faster. Older computers had IPC counts as low as 0.1 while modern processors easily reach near 1. Superscalar processors may reach three to five IPC by executing several instructions per clock cycle. ': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Counting machine-language instructions would be misleading because they can do varying amounts of work in different ISAs. The \"instruction\" in the standard measurements is not a count of the ISA\\'s machine-language instructions, but a unit of measurement, usually based on the speed of the VAX computer architecture.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " \"Many people used to measure a computer's speed by the clock rate (usually in MHz or GHz). This refers to the cycles per second of the main clock of the CPU. However, this metric is somewhat misleading, as a machine with a higher clock rate may not necessarily have greater performance. As a result, manufacturers have moved away from clock speed as a measure of performance.\": 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'There are two main types of speed: latency and throughput. Latency is the time between the start of a process and its completion. Throughput is the amount of work done per unit time. Interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Performance is affected by a very wide range of design choices — for example, pipelining a processor usually makes latency worse, but makes throughput better. Computers that control machinery usually need low interrupt latencies. These computers operate in a real-time environment and fail if an operation is not completed in a specified amount of time. For example, computer-controlled anti-lock brakes must begin braking within a predictable and limited time period after the brake pedal is sensed or else failure of the brake will occur.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " \"Benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. Although benchmarking shows strengths, it shouldn't be how you choose a computer. Often the measured machines split on different measures. For example, one system might handle scientific applications quickly, while another might render video games more smoothly. Furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but don't offer similar advantages to general tasks.\": 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Power efficiency is another important measurement in modern computers. A higher power efficiency can often be traded for lower speed or higher cost. The typical measurement when referring to power consumption in computer architecture is MIPS/W (millions of instructions per second per watt).': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'Modern circuits have less power required per transistor as the number of transistors per chip grows.  This is because each transistor that is put in a new chip requires its own power supply and requires new pathways to be built to power it. However the number of transistors per chip is starting to increase at a slower rate. Therefore, power efficiency is starting to become as important, if not more important than fitting more and more transistors into a single chip. Recent processor designs have shown this emphasis as they put more focus on power efficiency rather than cramming as many transistors into a single chip as possible.  In the world of embedded computers, power efficiency has long been an important goal next to throughput and latency.': 'https://en.wikipedia.org/wiki/Computer_architecture',\n",
       " 'In computing, a word is the natural unit of data used by a particular processor design. A word is a fixed-sized datum handled as a unit by the instruction set or the hardware of the processor. The number of bits or digits  in a word (the word size, word width, or word length) is an important characteristic of any specific processor design or computer architecture.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'The size of a word is reflected in many aspects of a computer\\'s structure and operation; the majority of the registers in a processor are usually word sized and the largest datum that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. The largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used).': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Documentation for computers with fixed word size commonly stated memory sizes in words rather than bytes or characters. The documentation sometimes used metric prefixes correctly, sometimes with rounding, e.g., 65 kilowords (KW) meaning for 65536 words, and sometimes used them incorrectly, with kilowords (KW) meaning 1024 words (2 10) and megawords (MW) meaning 1,048,576 words (2 20). With standardization on 8-bit bytes and byte addressability, stating memory sizes in bytes, kilobytes, and megabytes with powers of 1024 rather than 1000 has become the norm, although there is some use of the IEC binary prefixes.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Several of the earliest computers (and a few modern as well) used binary-coded decimal rather than plain binary, typically having a word size of 10 or 12 decimal digits, and some early decimal computers had no fixed word length at all. Early binary systems tended to use word lengths that were some multiple of 6-bits, with the 36-bit word being especially common on mainframe computers. The introduction of ASCII led to the move to systems with word lengths that were a multiple of 8-bits, with 16-bit machines being popular in the 1970s before the move to modern processors with 32 or 64 bits.  Special-purpose designs like digital signal processors, may have any word length from 4 to 80 bits. ': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'The size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. If multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see Size families below).': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'When a computer architecture is designed, the choice of a word size is of substantial importance. There are design considerations which encourage particular bit-group sizes for particular uses (e.g. for addresses), and these considerations point to different sizes for different uses. However, considerations of economy in design strongly push for one size, or a very few sizes related by multiples or fractions (submultiples) to a primary size. That preferred size becomes the word size of the architecture.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Character size was in the past (pre-variable-sized character encoding) one of the influences on unit of address resolution and the choice of word size. Before the mid-1960s, characters were most often stored in six bits; this allowed no more than 64 characters, so the alphabet was limited to upper case. Since it is efficient in time and space to have the word size be a multiple of the character size, word sizes in this period were usually multiples of 6 bits (in binary machines). A common choice then was the 36-bit word, which is also a good size for the numeric properties of a floating point format.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'After the introduction of the IBM System/360 design, which used eight-bit characters and supported lower-case letters, the standard size of a character (or more accurately, a byte) became eight bits. Word sizes thereafter were naturally multiples of eight bits, with 16, 32, and 64 bits being commonly used.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Early machine designs included some that used what is often termed a variable word length. In this type of organization, an operand had no fixed length. Depending on the machine and the instruction, the length might be denoted by a count field, by a delimiting character, or by an additional bit called, e.g., flag, word mark. Such machines often used binary-coded decimal in 4-bit digits, or in 6-bit characters, for numbers. This class of machines included the IBM 702, IBM 705, IBM 7080, IBM 7010, UNIVAC 1050, IBM 1401, IBM 1620, and RCA 301.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Most of these machines work on one unit of memory at a time and since each instruction or datum is several units long, each instruction takes several cycles just to access memory. These machines are often quite slow because of this. For example, instruction fetches on an IBM 1620 Model I take 8 cycles just to read the 12 digits of the instruction (the Model II reduced this to 6 cycles, or 4 cycles if the instruction did not need both address fields). Instruction execution took a completely variable number of cycles, depending on the size of the operands.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'The memory model of an architecture is strongly influenced by the word size. In particular, the resolution of a memory address, that is, the smallest unit that can be designated by an address, has often been chosen to be the word. In this approach, the word-addressable machine approach, address values which differ by one designate adjacent memory words. This is natural in machines which deal almost always in word (or multiple-word) units, and has the advantage of allowing instructions to use minimally sized fields to contain addresses, which can permit a smaller instruction size or a larger variety of instructions.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'When byte processing is to be a significant part of the workload, it is usually more advantageous to use the byte, rather than the word, as the unit of address resolution. Address values which differ by one designate adjacent bytes in memory. This allows an arbitrary character within a character string to be addressed straightforwardly. A word can still be addressed, but the address to be used requires a few more bits than the word-resolution alternative. The word size needs to be an integer multiple of the character size in this organization. This addressing approach was used in the IBM 360, and has been the most common approach in machines designed since then.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'When the workload involves processing fields of different sizes, it can be advantageous to address to the bit. Machines with bit addressing may have some instructions that use a programmer-defined byte size and other instructions that operate on fixed data sizes. As an example, on the IBM 7030  (\"Stretch\"), a floating point instruction can only address words while an integer arithmetic instruction can specify a field length of 1-64 bits, a byte size of 1-8 bits and an accumulator offset of 0-127 bits.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'In at byte-addressable machine with storage-to-storage (SS) instructions, there are typically move instructions to copy one or multiple bytes from one arbitrary location to another. In a byte-oriented (byte-addressable) machine without SS instructions, moving a single byte from one arbitrary location to another is typically:': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Individual bytes can be accessed on a word-oriented machine in one of two ways. Bytes can be manipulated by a combination of shift and mask operations in registers. Moving a single byte from one arbitrary location to another may require the equivalent of the following:': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Alternatively many word-oriented machines implement byte operations with instructions using special byte pointers in registers or memory. For example, the PDP-10 byte pointer contained the size of the byte in bits (allowing different-sized bytes to be accessed), the bit position of the byte within the word, and the word address of the data. Instructions could automatically adjust the pointer to the next byte on, for example, load and deposit (store) operations.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Different amounts of memory are used to store data values with different degrees of precision. The commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word). Converting the index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. In some cases this relationship can also avoid the use of division operations. As a result, most modern computer designs have word sizes (and other operand sizes) that are a power of two times the size of a byte.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'As computer designs have grown more complex, the central importance of a single word size to an architecture has decreased. Although more capable hardware can use a wider variety of sizes of data, market forces exert pressure to maintain backward compatibility while extending processor capability. As a result, what might have been the central word size in a fresh design has to coexist as an alternative size to the original word size in a backward compatible design. The original word size remains available in future designs, forming the basis of a size family.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'In the mid-1970s, DEC designed the VAX to be a 32-bit successor of the 16-bit PDP-11. They used word for a 16-bit quantity, while longword referred to a 32-bit quantity; this terminology is the same as the terminology used for the PDP-11. This was in contrast to earlier machines, where the natural unit of addressing memory would be called a word, while a quantity that is one half a word would be called a halfword. In fitting with this scheme, a VAX quadword is 64 bits. They continued this 16-bit word/32-bit longword/64-bit quadword terminology with the 64-bit Alpha.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'A similar phenomenon has developed in Intel\\'s x86 assembly language – because of the support for various sizes (and backward compatibility) in the instruction set, some instruction mnemonics carry \"d\" or \"q\" identifiers denoting \"double-\", \"quad-\" or \"double-quad-\", which are in terms of the architecture\\'s original 16-bit word size.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'An example with a different word size is the IBM System/360 family. In the System/360 architecture, System/370 architecture and System/390 architecture, there are 8-bit byte s, 16-bit halfword s, 32-bit word s and 64-bit doubleword s. The z/Architecture, which is the 64-bit member of that architecture family, continues to refer to 16-bit halfword s, 32-bit word s, and 64-bit doubleword s, and additionally features 128-bit quadword s.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'Often carefully written source code – written with source-code compatibility and software portability in mind – can be recompiled to run on a variety of processors, even ones with different data word lengths or different address widths or both.': 'https://en.wikipedia.org/wiki/Word_(computer_architecture)',\n",
       " 'computer architecture, structure of a digital computer, encompassing the design and layout of its instruction set and storage registers. The architecture of a computer is chosen with regard to the types of programs that will be run on it (business, scientific, general-purpose, etc.). Its principal components or subsystems, each of which could be said to have an architecture of its own, are input/output, storage, communication, control, and processing.': 'https://www.britannica.com/technology/computer-architecture',\n",
       " 'Computer architecture consists of rules and methods or procedures which describe the implementation, functionality of the computer systems. Architecture is built as per the user’s needs by taking care of the economic and financial constraints. Earlier architecture is designed on paper built with hardware form.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'After it is built-in transistor-transistor logic the architecture is built, tested and formed in the hardware form. We can define computer architecture based on its performance, efficiency, reliability, and cost of the computer system. It deals with software and hardware technology standards. The computer system has the processor, memory, I/O devices and communication channels that connect to it.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'The memory we have a single read/write memory available for read and write instructions and data. When we talk about memory, it is nothing but the single location which is used for reading and writing instructions for the data and instructions are also present in it. Data and instructions are stored in a single read/write memory within the computer system.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'Each memory has multiple locations and each location has a unique address. We can address the contents of memory by its location irrespective of what type of data and instructions are present in the memory, because of which we can read or write any data and instructions. Execution always occurs in a sequential manner unless the change is required. For example, suppose we are executing an instruction from line 1 to line 10 but now we required to execute line 50 instead of line 11 then we jump to instruction 50 and execute it.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'There is a bus (address bus/data bus/control bus) used for the instruction and data code execution. Input device takes data or instruction and the Central processing unit (CPU) performs one operation at a time, either fetching data or instruction in/out of the memory. Once the operation is done it is sent to the output device. Control and logic units for processing operations are within the central processing unit.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'Harvard architecture is used when data and code is present in different memory blocks. A separate memory block is needed for data and instruction. Data can be accessed by one memory location and instruction can be accessed by a different location. It has data storage entirely contained within the central processing unit (CPU). A single set of clock cycles is required. The pipeline is possible. It is complex to design. CPU can read and write instructions and process data access. Harvard architecture has different access codes and data address spaces that is, the instruction address zero is not the same as data address zero. Instruction address zero identifies 24-byte value and data address zero identifies 8-byte value which is not the part of the 24-byte value.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'Modified harvard architecture is like a harvard architecture machine and it has a common address space for the separate data and instruction cache. It has digital signal processors that will execute small or highly audio or video algorithms and it is reproducible. Microcontrollers have a small number of programs and data memory and it speeds up the processing by executing parallel instructions and data access.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'We can observe in the below image, there are separate data and instruction memory that is a bus available to perform operations. It is contained entirely within the Central processing unit. It can perform Input/output operation simultaneously and it has a separate arithmetic and logic unit.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'To make up the architecture, instruction set architecture is needed because it has a set of instructions that the processor understands. It has two instruction set one is RISC (reduced instruction set computer) and the second is CISC (complex instruction set computer).': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'Reduced instruction set computer architecture was realized in the 90’s by IBM. Instruction has multiple address modes, but programs do not use all of them that is the reason multiple address modes were reduced. This helps the compiler to easily write the instructions, performed is increased.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'Complex instruction set architecture is the root of compilers because earlier compilers were not there to write programs, to ease programming instructions are added. The best performance is obtained by using simple instruction from ISA.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'Microarchitecture is known as computer organizations and it is the way when instruction set architecture is a built-in processor. Instruction set architecture is implemented with various microarchitecture and it varies because of changing technology.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'Microarchitecture performs in a certain way. It reads the instruction and decodes it, will find parallel data to process the instruction and then will process the instruction and output will be generated.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'It is used in microprocessors, microcontrollers. Some architectures overlap multiple instructions while executing but this does not happen in microarchitecture. Execution units like arithmetic logic units, floating-point units, load units, etc are needed and it performs the operation of the processor. There are microarchitecture decisions within the system such as size, latency, and connectivity of the memories.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'The name defines itself, the design will satisfy user requirements such as architecture, module, interfaces and data for a system and it is connected to product development. It is the process of taking marketing information and creating product design to be manufacture. Modular systems are made by standardizing hardware and software.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'We have learned about computer architecture and its types. How functionality, implementation works in processing. Instruction set architecture is needed to do the needful instruction execution and data processing should be done in a different and single memory location in different types of computer architectures. Read/write operations are performed.': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'This is a guide to Types of Computer Architecture. Here we discuss the basic concept and different types of computer architecture in detail. You may also have a look at the following articles to learn more –': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'This website or its third-party tools use cookies, which are necessary to its functioning and required to achieve the purposes illustrated in the cookie policy. By closing this banner, scrolling this page, clicking a link or continuing to browse otherwise, you agree to our Privacy Policy': 'https://www.educba.com/types-of-computer-architecture/',\n",
       " 'In computer engineering, microarchitecture, also called computer organization and sometimes abbreviated as µarch or uarch, is the way a given instruction set architecture (ISA) is implemented in a particular processor.  A given ISA may be implemented with different microarchitectures;   implementations may vary due to different goals of a given design or due to shifts in technology. ': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'The ISA is roughly the same as the programming model of a processor as seen by an assembly language programmer or compiler writer. The ISA includes the instructions, execution model, processor registers, address and data formats among other things. The microarchitecture includes the constituent parts of the processor and how these interconnect and interoperate to implement the ISA.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'The microarchitecture of a machine is usually represented as (more or less detailed) diagrams that describe the interconnections of the various microarchitectural elements of the machine, which may be anything from single gates and registers, to complete arithmetic logic units (ALUs) and even larger elements. These diagrams generally separate the datapath (where data is placed) and the control path (which can be said to steer the data). ': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Each microarchitectural element is in turn represented by a schematic describing the interconnections of logic gates used to implement it. Each logic gate is in turn represented by a circuit diagram describing the connections of the transistors used to implement it in some particular logic family. Machines with different microarchitectures may have the same instruction set architecture, and thus be capable of executing the same programs. New microarchitectures and/or circuitry solutions, along with advances in semiconductor manufacturing, are what allows newer generations of processors to achieve higher performance while using the same ISA.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'The pipelined datapath is the most commonly used datapath design in microarchitecture today. This technique is used in most modern microprocessors, microcontrollers, and DSPs. The pipelined architecture allows multiple instructions to overlap in execution, much like an assembly line. The pipeline includes several different stages which are fundamental in microarchitecture designs.  Some of these stages include instruction fetch, instruction decode, execute, and write back. Some architectures include other stages such as memory access. The design of pipelines is one of the central microarchitectural tasks.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Execution units are also essential to microarchitecture. Execution units include arithmetic logic units (ALU), floating point units (FPU), load/store units, branch prediction, and SIMD. These units perform the operations or calculations of the processor. The choice of the number of execution units, their latency and throughput is a central microarchitectural design task. The size, latency, throughput and connectivity of memories within the system are also microarchitectural decisions.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'System-level design decisions such as whether or not to include peripherals, such as memory controllers, can be considered part of the microarchitectural design process. This includes decisions on the performance-level and connectivity of these peripherals.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Unlike architectural design, where achieving a specific performance level is the main goal, microarchitectural design pays closer attention to other constraints. Since microarchitecture design decisions directly affect what goes into a system, attention must be paid to issues such as chip area/cost, power consumption, logic complexity, ease of connectivity, manufacturability, ease of debugging, and testability.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Historically, the earliest computers were multicycle designs. The smallest, least-expensive computers often still use this technique. Multicycle architectures often use the least total number of logic elements and reasonable amounts of power. They can be designed to have deterministic timing and high reliability. In particular, they have no pipeline to stall when taking conditional branches or interrupts. However, other microarchitectures often perform more instructions per unit time, using the same logic family. When discussing \"improved performance,\" an improvement is often relative to a multicycle design.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'In a multicycle computer, the computer does the four steps in sequence, over several cycles of the clock. Some designs can perform the sequence in two clock cycles by completing successive stages on alternate clock edges, possibly with longer operations occurring outside the main cycle. For example, stage one on the rising edge of the first cycle, stage two on the falling edge of the first cycle, etc.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Instruction sets have shifted over the years, from originally very simple to sometimes very complex (in various respects). In recent years, load–store architectures, VLIW and EPIC types have been in fashion. Architectures that are dealing with data parallelism include SIMD and Vectors. Some labels used to denote classes of CPU architectures are not particularly descriptive, especially so the CISC label; many early designs retroactively denoted \" CISC\" are in fact significantly simpler than modern RISC processors (in several respects).': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'However, the choice of instruction set architecture may greatly affect the complexity of implementing high-performance devices. The prominent strategy, used to develop the first RISC processors, was to simplify instructions to a minimum of individual semantic complexity combined with high encoding regularity and simplicity. Such uniform instructions were easily fetched, decoded and executed in a pipelined fashion and a simple strategy to reduce the number of logic levels in order to reach high operating frequencies; instruction cache-memories compensated for the higher operating frequency and inherently low code density while large register sets were used to factor out as much of the (slow) memory accesses as possible.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'One of the first, and most powerful, techniques to improve performance is the use of instruction pipelining. Early processor designs would carry out all of the steps above for one instruction before moving onto the next. Large portions of the circuitry were left idle at any one step; for instance, the instruction decoding circuitry would be idle during execution and so on.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Pipelining improves performance by allowing a number of instructions to work their way through the processor at the same time. In the same basic example, the processor would start to decode (step 1) a new instruction while the last one was waiting for results. This would allow up to four instructions to be \"in flight\" at one time, making the processor look four times as fast. Although any one instruction takes just as long to complete (there are still four steps) the CPU as a whole \"retires\" instructions much faster.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'RISC makes pipelines smaller and much easier to construct by cleanly separating each stage of the instruction process and making them take the same amount of time—one cycle. The processor as a whole operates in an assembly line fashion, with instructions coming in one side and results out the other. Due to the reduced complexity of the classic RISC pipeline, the pipelined core and an instruction cache could be placed on the same size die that would otherwise fit the core alone on a CISC design. This was the real reason that RISC was faster. Early designs like the SPARC and MIPS often ran over 10 times as fast as Intel and Motorola CISC solutions at the same clock speed and price.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Pipelines are by no means limited to RISC designs. By 1986 the top-of-the-line VAX implementation (VAX 8800) was a heavily pipelined design, slightly predating the first commercial MIPS and SPARC designs. Most modern CPUs (even embedded CPUs) are now pipelined, and microcoded CPUs with no pipelining are seen only in the most area-constrained embedded processors.  Large CISC machines, from the VAX 8800 to the modern Pentium 4 and Athlon, are implemented with both microcode and pipelines. Improvements in pipelining and caching are the two major microarchitectural advances that have enabled processor performance to keep pace with the circuit technology on which they are based.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'It was not long before improvements in chip manufacturing allowed for even more circuitry to be placed on the die, and designers started looking for ways to use it. One of the most common was to add an ever-increasing amount of cache memory on-die. Cache is very fast and expensive memory. It can be accessed in a few cycles as opposed to many needed to \"talk\" to main memory. The CPU includes a cache controller which automates reading and writing from the cache. If the data is already in the cache it is accessed from there – at considerable time savings, whereas if it is not the processor is \"stalled\" while the cache controller reads it in.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'RISC designs started adding cache in the mid-to-late 1980s, often only 4 KB in total. This number grew over time, and typical CPUs now have at least 2 MB, while more powerful CPUs come with 4 or 6 or 12MB or even 32MB or more, with the most being 768MB in the newly released EPYC Milan-X line, organized in multiple levels of a memory hierarchy. Generally speaking, more cache means more performance, due to reduced stalling.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " \"Caches and pipelines were a perfect match for each other. Previously, it didn't make much sense to build a pipeline that could run faster than the access latency of off-chip memory. Using on-chip cache memory instead, meant that a pipeline could run at the speed of the cache access latency, a much smaller length of time. This allowed the operating frequencies of processors to increase at a much faster rate than that of off-chip memory.\": 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Even with all of the added complexity and gates needed to support the concepts outlined above, improvements in semiconductor manufacturing soon allowed even more logic gates to be used.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'In the outline above the processor processes parts of a single instruction at a time. Computer programs could be executed faster if multiple instructions were processed simultaneously. This is what superscalar processors achieve, by replicating functional units such as ALUs. The replication of functional units was only made possible when the die area of a single-issue processor no longer stretched the limits of what could be reliably manufactured. By the late 1980s, superscalar designs started to enter the market place.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'In modern designs it is common to find two load units, one store (many instructions have no results to store), two or more integer math units, two or more floating point units, and often a SIMD unit of some sort. The instruction issue logic grows in complexity by reading in a huge list of instructions from memory and handing them off to the different execution units that are idle at that point. The results are then collected and re-ordered at the end.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'The addition of caches reduces the frequency or duration of stalls due to waiting for data to be fetched from the memory hierarchy, but does not get rid of these stalls entirely. In early designs a cache miss would force the cache controller to stall the processor and wait. Of course there may be some other instruction in the program whose data is available in the cache at that point. Out-of-order execution allows that ready instruction to be processed while an older instruction waits on the cache, then re-orders the results to make it appear that everything happened in the programmed order. This technique is also used to avoid other operand dependency stalls, such as an instruction awaiting a result from a long latency floating-point operation or other multi-cycle operations.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Register renaming refers to a technique used to avoid unnecessary serialized execution of program instructions because of the reuse of the same registers by those instructions. Suppose we have two groups of instruction that will use the same register. One set of instructions is executed first to leave the register to the other set, but if the other set is assigned to a different similar register, both sets of instructions can be executed in parallel (or) in series.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Computer architects have become stymied by the growing mismatch in CPU operating frequencies and DRAM access times. None of the techniques that exploited instruction-level parallelism (ILP) within one program could make up for the long stalls that occurred when data had to be fetched from main memory. Additionally, the large transistor counts and high operating frequencies needed for the more advanced ILP techniques required power dissipation levels that could no longer be cheaply cooled. For these reasons, newer generations of computers have started to exploit higher levels of parallelism that exist outside of a single program or program thread.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'This trend is sometimes known as throughput computing. This idea originated in the mainframe market where online transaction processing emphasized not just the execution speed of one transaction, but the capacity to deal with massive numbers of transactions. With transaction-based applications such as network routing and web-site serving greatly increasing in the last decade, the computer industry has re-emphasized capacity and throughput issues.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'One technique of how this parallelism is achieved is through multiprocessing systems, computer systems with multiple CPUs. Once reserved for high-end mainframes and supercomputers, small-scale (2–8) multiprocessors servers have become commonplace for the small business market. For large corporations, large scale (16–256) multiprocessors are common. Even personal computers with multiple CPUs have appeared since the 1990s.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " \"With further transistor size reductions made available with semiconductor technology advances, multi-core CPUs have appeared where multiple CPUs are implemented on the same silicon chip. Initially used in chips targeting embedded markets, where simpler and smaller CPUs would allow multiple instantiations to fit on one piece of silicon. By 2005, semiconductor technology allowed dual high-end desktop CPUs CMP chips to be manufactured in volume. Some designs, such as Sun Microsystems ' UltraSPARC T1 have reverted to simpler (scalar, in-order) designs in order to fit more processors on one piece of silicon.\": 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Another technique that has become more popular recently is multithreading. In multithreading, when the processor has to fetch data from slow system memory, instead of stalling for the data to arrive, the processor switches to another program or program thread which is ready to execute. Though this does not speed up a particular program/thread, it increases the overall system throughput by reducing the time the CPU is idle.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Conceptually, multithreading is equivalent to a context switch at the operating system level. The difference is that a multithreaded CPU can do a thread switch in one CPU cycle instead of the hundreds or thousands of CPU cycles a context switch normally requires. This is achieved by replicating the state hardware (such as the register file and program counter) for each active thread.': 'https://en.wikipedia.org/wiki/Microarchitecture',\n",
       " 'Computer Architecture: In computer manufacturing, computer engineering is a set of rules and methods that describe the functionality, organization, and utilization of computer systems. Some definitions of engineering define it as describing the wherewithals and programming model of a computer but not a particular utilization. In oth er definitio ns computer architecture proves instruction set architecture desig n, microarchitect ure design, logic design, and utilization.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'The term “ engineering ” in computer literature can be delineated to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM’s main research center in 1959. Johnson had the opportunity to write a proprietary research transmission about the Stretch, an IBM-developed supercomputer for Los A lamos National Workshop (at the time known as Los A lamos Scientific Laboratory). To portray the level of detail for discussing the luxuriously embellished computer, he noted that his explanation of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that suggested more useful than “machine management ”.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'Although the term computer engineering sounds very complicated, its definition is easier than one might think. Computer engineering is a science or a set of rules stating how brain software and hardware are joined together and interact to make a computer work. It not only determines how the brain works but also of which technologies the computer is capable. Brains continue to be a major part of our lives, and brain architects reestablish to develop new and better policies and technologies.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'Computer engineering is a specification describing how housewares and software technologies interact to create a brain podium or system. When we think of the word architecture, we think of establishing a house or a building. Keeping that same principle in mind, computer architecture suggests building a computer and all that goes into a brain system. Computer architecture consists of three main categories.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'This book is about designing and manufacturing specialized brains. We all know what a brain is. It’s that box that sits on your desk, quietly purring away (or rattling if the fan is shot), running your programs, and systematically crashing (if you’re not running some diversity of Unix). Inside that box are the televisions that run your software, store your instruction, and connect you to the world. It’s all about processing information. Designing a computer, therefore, is about designing a machine that holds and manipulates data.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'To become a computer architect, often called a computer network architect, the candidate must have at least a bachelor’s degree in computer science, engineering, information systems, or a related field. The best programs for aspiring computer architects are computer-based fields because they offer students the most hands-on experience in database design or network security, both of which are important for computer architects. These classes also teach the students various technologies used in different networks.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'Some students choose to complete an MBA (master’s of business administration) with a focus on information systems. The advantage of this program is that it offers both computer-related and business courses. Even after earning the degree, applicants may be required to have at least five years of experience working with IT systems before being hired as a computer architect. Some computer architects go on to become computer and information systems managers once they’ve obtained sufficient experience.': 'https://www.computersciencedegreehub.com/faq/what-is-computer-architecture/',\n",
       " 'As long as we have computers and all the parts that go into a computer system, there will continue to be a demand for computer architects. Computer architects are expected to see an employment growth of 6% between 2016 and 2026 as reported by the U.S. Bureau of Labor Statistics (BLS). While cloud computing has decreased the need for computer architects somewhat, they will continue to be in demand as businesses continue to increase their technology needs. The BLS reports that computer architects nationwide earned wages ranging from $58,160 to $162,390 as of May 2017 with the average wage at $107,870.': 'https://www.computersciencedegreehub.com/faq/what-is-computer-architecture/',\n",
       " 'In contrast, the embedded computer is normally dedicated to a specific task. In many cases, an embedded system is used to replace application-specific electronics. The advantage of using an embedded microprocessor over dedicated electronics is that the functionality of the system is determined by the software, not the hardware. This makes the embedded system easier to produce, and much easier to evolve, than a complicated circuit.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'The embedded system typically has one application and one application only, which is permanently running. The embedded computer may or may not have an operating system, and rarely does it provide the user with the ability to arbitrarily install new software. The software is normally contained in the system’s nonvolatile memory, unlike a desktop computer where the nonvolatile memory contains boot software and (maybe) low-level drivers only.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'Embedded hardware is often much simpler than a desktop system, but it can also be far more complex too. An embedded computer may be implemented in a single chip with just a few support components, and its purpose may be as crude as a controller for a garden-watering system. Alternatively, the embedded computer may be a 150-processor, distributed parallel machine responsible for all the flight and control systems of a commercial jet. As diverse as embedded hardware may be, the underlying principles of design are the same.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'This chapter introduces some important concepts relating to computer architecture, with specific emphasis on those topics relevant to embedded systems. Its purpose is to give you grounding before moving on to the more hands-on information that begins in Chapter 2. In this chapter, you’ll learn about the basics of processors, interrupts, the difference between RISC and CISC, parallel systems, memory, and I/O.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'Computer architecture is the organization of the components making up a computer system and the semantics or meaning of the operations that guide its function. As such, the computer architecture governs the design of a family of computers and defines the logical interface that is targeted by programming languages and their compilers. The organization determines the mix of functional units in which the system is composed and the structure of their interconnectivity.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'The architecture semantics is the meaning of what the systems do under user direction and how their functional units are controlled to work together. An important embodiment of semantics is the instruction set architecture (ISA) of the system. The ISA is a logical (usually binary) representative encoding of the basic set of distinct operations that a computer architecture may perform, and by which application programs specify the useful work to be done. At the machine level, the hardware (sometimes controlled by firmware) system directly interprets and executes a sequence or partially ordered set of these basic operations.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'This is true for all computer cores, from those few in the smallest mobile phones to potentially millions making up the world’s largest supercomputers. High-performance computer architecture extends structure to a hierarchy of functional elements, whether small and limited in capability or possibly entire processor cores themselves. In this chapter many different classes of the structure are presented, each exploiting concurrency in its own particular way. But in all cases, this more broad definition of a general architecture for high-performance computing emphasizes aspects of the system that contribute to achieving performance.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'A high-performance computer is designed to go fast, and its organization and semantics are specially devised to deliver computational speed. This chapter introduces the basic foundations of computer architecture in general and for high-performance computer systems in particular. It is here, at the structural and logical levels, that parallelism of operation in its many forms and size is first presented. This chapter provides a first examination of the principal forms of supercomputer architecture and the underlying concepts that govern their performance.': 'https://geteducationskills.com/computer-architecture/',\n",
       " 'Vulnerability management is a security practice specifically designed to proactively prevent the exploitation of IT vulnerabilities that could potentially harm a system or organization.The practice involves identifying, classifying, mitigating and fixing known vulnerabilities within a system. It is... View Full Term': 'https://www.techopedia.com/definition/26757/computer-architecture',\n",
       " 'Computer architecture is a specification detailing how a set of software and hardware technology standards interact to form a computer system or platform. In short, computer architecture refers to how a computer system is designed and what technologies it is compatible with.': 'https://www.techopedia.com/definition/26757/computer-architecture',\n",
       " 'As with other contexts and meanings of the word architecture, computer architecture is likened to the art of determining the needs of the user/system/technology, and creating a logical design and standards based on those requirements.': 'https://www.techopedia.com/definition/26757/computer-architecture',\n",
       " 'A very good example of computer architecture is von Neumann architecture, which is still used by most types of computers today. This was proposed by the mathematician John von Neumann in 1945. It describes the design of an electronic computer with its CPU, which includes the arithmetic logic unit, control unit, registers, memory for data and instructions, an input/output interface and external storage functions.': 'https://www.techopedia.com/definition/26757/computer-architecture',\n",
       " \"Techopedia™ is your go-to tech source for professional IT insight and inspiration. We aim to be a site that isn't trying to be the first to break news stories, but instead help you better understand technology and — we hope — make better decisions as a result.\": 'https://www.techopedia.com/definition/26757/computer-architecture',\n",
       " 'Computer architecture can be defined as a set of rules and methods that describe the functionality, management and implementation of computers. To be precise, it is nothing but rules by which a system performs and operates.': 'https://www.tutorialspoint.com/what-is-computer-architecture',\n",
       " 'Instruction set Architecture or ISA − Whenever an instruction is given to processor, its role is to read and act accordingly. It allocates memory to instructions and also acts upon memory address mode (Direct Addressing mode or Indirect Addressing mode).': 'https://www.tutorialspoint.com/what-is-computer-architecture',\n",
       " \"For Example − Instruction set architecture (ISA) acts as a bridge between computer's software and hardware. It works as a programmer's view of a machine.\": 'https://www.tutorialspoint.com/what-is-computer-architecture',\n",
       " 'Computers can only understand binary language (i.e., 0, 1) and users understand high level language (i.e., if else, while, conditions, etc). So to communicate between user and computer, Instruction set Architecture plays a major role here, translating high level language to binary language.': 'https://www.tutorialspoint.com/what-is-computer-architecture',\n",
       " 'Although the term computer architecture sounds very complicated, its definition is easier than one might think. Computer architecture is a science or a set of rules stating how computer software and hardware are joined together and interact to make a computer work. It not only determines how the computer works but also of which technologies the computer is capable. Computers continue to be a major part of our lives, and computer architects continue to develop new and better programs and technologies.': 'https://www.computersciencedegreehub.com/faq/what-is-computer-architecture/',\n",
       " 'Computer architecture is a specification describing how hardware and software technologies interact to create a computer platform or system. When we think of the word architecture, we think of building a house or a building. Keeping that same principle in mind, computer architecture involves building a computer and all that goes into a computer system. Computer architecture consists of three main categories.': 'https://www.computersciencedegreehub.com/faq/what-is-computer-architecture/',\n",
       " 'To become a computer architect, often called computer network architect, the candidate must have at least a bachelor’s degree in computer science, engineering, information systems or a related field. The best programs for aspiring computer architects are computer-based fields because they offer students the most hands-on experience in database design or network security, both of which are important for computer architects. These classes also teach the students various technologies used in different networks.': 'https://www.computersciencedegreehub.com/faq/what-is-computer-architecture/',\n",
       " 'Computer architecture concentrates on the logical aspects of computer design as opposed to the physical or electronic aspects. The underlying logical design of most modern computers is still based on that of the earliest electronic computers despite decades of progress in electronic circuitry. the innovations that have occurred in computer architecture have been driven by two different goals: higher performance and lower cost. Performance driven improvements have yielded computer systems with increasingly higher computation speeds and throughput. Cost driven improvements have yielded systems that are easier to use and applicable to a broader range of automatic control problems. Improvements in electronic circuitry have not led directly to architectural innovations; computers that pioneered new circuit technologies usually relied on older architectural concepts.': 'https://dl.acm.org/doi/10.1109/MAHC.1988.10039',\n",
       " 'I have a bigger agenda. My advisor, Michael D. Smith, taught me “There are no new ideas in computer architecture, only old ones whose time has come.” Mike’s maxim matches my experience: Anton used every parallelism technique I know save threading to show that special-purpose machines could deliver multiple orders of magnitude speedup; the first TPU combined systolic arrays, decoupled access/execute, and CISC, breathing new life into old (and let’s be honest, unpopular) ideas. I’ll bet that the next transformative machine also combines old ideas in surprising new ways.': 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'As this is a blog post, I can blithely ignore peer-reviewed rigor, adopt a more informal, subjective style, fail to remember important contributions, and make tart and most likely wrong comments along the way. But I have to keep things brief, so I’m going to present my history in bullet points and summarize huge, complicated areas with sentence fragments. Also, I’m going to focus on the machines and the people who built them more than particular techniques (although those also play a key role). With all these caveats, here’s my subjective, biased, and incomplete history of computer architecture, as a first draft for the lore and epic tales of our field.': 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'Around WWII, a number of proto-computers are built and used for cryptography, artillery ballistics tables, and the design of nuclear weapons. 5 I find the principled stances of Computer Scientists who refuse government or military funding to be admirable, but I wonder if they know how martial the origins of our field are. They include:': 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'In 1949, the Eckert-Mauchly computer company builds the BINAC, the first commercial computer. UNIVAC follows in 1951, with the US Census as a customer. The computer industry blooms during the 50s, but the Eckert-Mauchly computer company isn’t one of the big winners.': 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'Let me pause here, ending the first installment of this history with IBM largely in control, but with threats to their hegemony on the way. I’ll resume in Part 2 in a few days.': 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'About the Author: Cliff Young is a software engineer in Google Research, where he works on codesign for deep learning accelerators. He is one of the designers of Google’s Tensor Processing Unit (TPU) and one of the founders of the MLPerf benchmark. Previously, Cliff built special-purpose supercomputers for molecular dynamics at D. E. Shaw Research and was a Member of Technical Staff at Bell Labs.': 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'Disclaimer: These posts are written by individual contributors to share their thoughts on the Computer Architecture Today blog for the benefit of the community. Any views or opinions represented in this blog are personal, belong solely to the blog author and do not represent those of ACM SIGARCH or its parent organization, ACM.': 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/',\n",
       " 'SIGARCH serves a unique community of computer professionals working on the forefront of computer design in both industry and academia. It is ACM’s primary forum to interchange ideas about tomorrow’s hardware and its interactions with software.': 'https://www.sigarch.org/call-contributions/first-workshop-on-open-source-computer-architecture-research-oscar/',\n",
       " 'This site is maintained by volunteers working in many programs of ACM SIGARCH. We thank you for visiting! If you have questions about the site, please send a note to our content editor.': 'https://www.sigarch.org/call-contributions/first-workshop-on-open-source-computer-architecture-research-oscar/',\n",
       " 'A Brief History of Computer Architecture Computer Architecture is the field of study of selecting and interconnecting hardware components to create computers that satisfy functional performance and cost goals. It refers to those attributes of the computer system that are visible to a programmer and have a direct effect on the execution of a program.': 'https://edurev.in/studytube/A-Brief-History-of-Computer-Architecture-Computer-/987e1c94-0ef4-4ebd-b172-277f3deb72c1_t',\n",
       " 'If you’re taking your first computer architecture class, the best computer architecture book for your needs should define all the essential concepts in a manner that is accessible.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'You should also consider the scope of the book. It’s a good idea to invest in a few textbooks that provide you with a comprehensive overview of the different components, their functions, and other important concepts.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'As you learn more about computer architecture, you will probably develop an interest in specific areas of study, some questions you want to answer, and some components you want to learn how to design.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'Pay attention to the publication date and edition. You can usually find lower prices when shopping for older editions of textbooks, but computer architecture is a topic where you need recent material.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'With over 500 pages, this textbook is the best computer architecture book for you if you’re looking for a comprehensive survey of all the essential concepts you need to master.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'While it’s important to study computer architecture concepts as they apply to programming, you should supplement this textbook with additional material that doesn’t focus on what programmers need to know.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'We like this textbook because of how comprehensive it is. It gives you an introduction to the more abstract concepts tied to computer architecture, and you will also learn about the different components of a computer in a more-hands fashion.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'One of the main draws of this textbook is the additional resources you get when you purchase it. These resources add value for instructors, and you can also use these resources if you’re studying by yourself.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'Some textbooks take a more abstract and academic approach to discuss computer architecture but relying on real-world examples makes important concepts feel more concrete and prepares you for a career in the field of computer architecture.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'There is a collection of online resources with an eBook version of the textbook with some interactive features, some additional activities, and quizzes you can use to test your knowledge. Instructors can access more material.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'These resources add value to the textbook, and the activities and quizzes will come in handy if you’re a student who learns better when they can apply the concepts they just read about.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'This classic award-winning textbook is the best computer architecture book for students who have completed some computer architecture courses and for professionals who need to catch up on the latest innovations in their field.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'The sixth edition of this textbook features a lot of new material. There are new chapters about topics like processors, system architecture, and stacked memory. You will also find new content that looks at modern systems like warehouse-scale computers and data centers.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'This textbook will introduce you to the RISC-V architecture standard. You can find the entire standard published in this book, and there are different real-world examples to illustrate it.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'We like this textbook because it takes everything that is complex about computer architecture and design and makes it accessible. It explores every aspect of the different topics discussed in a thorough manner.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'We also like the practical approach this textbook takes. It uses current computer architecture standards and basic engineering principles that you need to know about to design systems with performance and efficiency in mind.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'You will also find comprehensive review sections and can access additional reviews online. We like these review sections before they’re a convenient way to study for a test or get a quick refresher on a topic.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'The first half of the book covers the different hardware components, and you will learn about software hierarchy in the second half. The book paints a comprehensive picture of the process of building your own computer.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'This book is a guide to the recent innovations that are shaping the world of computer architecture. It also covers basic topics like transistors, circuitry, logic gates, pipelining, and more.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'We like this book because it covers an impressive scope. It discusses every hardware component in detail and introduces you to concepts that are important for thinking about the bigger picture and designing networks.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'The book features fourteen chapters that mix basic computer architecture concepts and innovations. There are exercises and activities that will teach you how to implement a processor or write a program.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'It’s a great book if you’re close to graduating and want something that will bring you up to date on the latest innovations in your field.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'We highly recommend this study guide if you’re taking a computer architecture class and feel a little lost. It’s shorter than other books, but you can use this study guide as a reference to look up core computer architecture concepts whenever you need a quick refresher.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'We like this book because it’s short and straight to the point. There are different tools that will help you retain information and ensure that you fully understand all the different computer architecture concepts.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'You will find different chapters that explain all the fundamentals of computer architecture. This content isn’t as detailed as other books, but it will sum up what your instructor explained in class. It’s a great resource for getting a refresher before a test or supplementing your notes.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'You will find chapter summaries if you need a quick definition of an important concept, more than 200 practice problems with step-by-step solutions, and some review questions to help you study.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'Even though the book is short, it covers a wide range of topics, including instruction sets, cache, memories, I/O systems, pipelining, logic, parallelism, processors, and more.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'Think of this book as a reference or go-to study guide. The information is easy to understand, and it’s a great tool to have if you’re taking a computer architecture class that feels challenging.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'This book is a little different from the other textbooks on our list. It focuses on the Raspberry Pi and uses this small computer to help you learn about important computer architecture concepts.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'Using the Raspberry Pi as a point of reference makes complex ideas more concrete, and it will help you develop a thorough understanding of how this small computer works before you move on to studying more advanced machines.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'The focus on the Raspberry Pi makes this book a little different from what a computer architecture instructor would require you to read for class, but it’s a fun way of learning about computer architecture.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'This book discusses microprocessors in-depth. While a majority of computer architecture textbooks dedicate a chapter to this topic, microprocessors are complex enough to warrant reading an entire book that combines the basics of computer architecture and exploring microprocessor components.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'We recommend this book because it will teach you everything there is to know about microprocessors. It uses illustrations and some real-world examples to help you understand abstract concepts.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'There are some chapters that address more advanced concepts like RISC and CISC standards, memory hierarchy, branch prediction, caching, best practices for performance, and more.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'This book is a compilation of lectures and papers on the topics of computer architecture and deep learning. It looks at how one can apply deep learning concepts to computer architecture and explore possible applications that could shape information technology in the near future.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'We recommend this book because deep learning is one of the top innovations that are currently transforming the IT field, and this book is a great way to catch up on how deep learning applies to computer architecture.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'It’s also a great reference to have when writing academic papers. You will find research from experts that you can quote in your papers and some thought-provoking lectures you can use as a basis for developing your own thesis when writing assignments.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'We like this book because the material is engaging and easy to read. There are plenty of real-world examples, and the author explains advanced concepts in a way that is very accessible.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'This book focuses on the issue of security in processor design. There are a lot of interesting ideas about implementing new features that can protect the code and data on a processor.': 'https://techwithtech.com/best-computer-architecture-books/',\n",
       " 'The module aims to provide students with a fundamental knowledge of computer hardware and computer systems, with an emphasis on system design and performance. There is a prerequisite of CS132 Computer Organisation and Architecture. This module is only available to students in the second year of their degree and is not available as an unusual option to students in other years of study.': 'https://warwick.ac.uk/fac/sci/dcs/teaching/modules/cs257/',\n",
       " 'The module aims to provide students with a fundamental knowledge of computer hardware and computer systems, with an emphasis on system design and performance. The module concentrates on the principles underlying systems organisation, issues in computer system design, and contrasting implementations of modern systems. The module is central to the aims of the Computing Systems degree course, for which it is core.': 'https://warwick.ac.uk/fac/sci/dcs/teaching/modules/cs257/',\n",
       " 'Background reading of concepts covered in the module from recommended reading and realised research papers. Consultation of technical manuals covering specific architectures for the purposes of the coursework. Exam revision.': 'https://warwick.ac.uk/fac/sci/dcs/teaching/modules/cs257/',\n",
       " 'Note: This module is only available to students in the second year of their degree and is not available as an unusual option to students in other years of study.': 'https://warwick.ac.uk/fac/sci/dcs/teaching/modules/cs257/',\n",
       " 'Department of Computer Science, University of Warwick, CV4 7AL E-mail: comp-sci at dcs dot warwick dot ac dot uk, Telephone: +44 (0)24 7652 3193': 'https://warwick.ac.uk/fac/sci/dcs/teaching/modules/cs257/',\n",
       " 'We use cookies to give you the best online experience. Please let us know if you agree to functional, advertising and performance cookies. You can update your cookie preferences at any time.': 'https://warwick.ac.uk/fac/sci/dcs/teaching/modules/cs257/',\n",
       " 'OSCAR 2022 is the first edition of a workshop aimed at fostering the community of researchers who are interested in developing and sharing open-source hardware and software for the design of next-generation computer architectures.': 'https://www.sigarch.org/call-contributions/first-workshop-on-open-source-computer-architecture-research-oscar/',\n",
       " 'Workshop Format: OSCAR will have a mix of invited talks and presentations selected from the submissions to this call for participation. Abstract should be submitted in PDF format (max 2 pages) and include title, authors, affiliations and e-mail address of the contact author. Submissions of early works and position papers are encouraged. Workshop submissions do not preclude publishing at future conference venues. While no formal proceedings are planned, the OSCAR organizers may seek the realization of a journal special issue collecting a subset of the contributions, after the workshop.': 'https://www.sigarch.org/call-contributions/first-workshop-on-open-source-computer-architecture-research-oscar/',\n",
       " 'In computer science, an instruction set architecture (ISA), also called computer architecture, is an abstract model of a computer. A device that executes instructions described by that ISA, such as a central processing unit (CPU), is called an implementation.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'In general, an ISA defines the supported instructions, data types, registers, the hardware support for managing main memory, fundamental features (such as the memory consistency, addressing modes, virtual memory), and the input/output model of a family of implementations of the ISA.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'An ISA specifies the behavior of machine code running on implementations of that ISA in a fashion that does not depend on the characteristics of that implementation, providing binary compatibility between implementations. This enables multiple implementations of an ISA that differ in characteristics such as performance, physical size, and monetary cost (among other things), but that are capable of running the same machine code, so that a lower-performance, lower-cost machine can be replaced with a higher-cost, higher-performance machine without having to replace software. It also enables the evolution of the microarchitectures of the implementations of that ISA, so that a newer, higher-performance implementation of an ISA can run software that runs on previous generations of implementations.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'If an operating system maintains a standard and compatible application binary interface (ABI) for a particular ISA, machine code will run on future implementations of that ISA and operating system. However, if an ISA supports running multiple operating systems, it does not guarantee that machine code for one operating system will run on another operating system, unless the first operating system supports running machine code built for the other operating system.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'An ISA can be extended by adding instructions or other capabilities, or adding support for larger addresses and data values; an implementation of the extended ISA will still be able to execute machine code for versions of the ISA without those extensions. Machine code using those extensions will only run on implementations that support those extensions.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'An instruction set architecture is distinguished from a microarchitecture, which is the set of processor design techniques used, in a particular processor, to implement the instruction set. Processors with different microarchitectures can share a common instruction set. For example, the Intel Pentium and the AMD Athlon implement nearly identical versions of the x86 instruction set, but they have radically different internal designs.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " \"Prior to NPL , the company's computer designers had been free to honor cost objectives not only by selecting technologies but also by fashioning functional and architectural refinements. The SPREAD compatibility objective, in contrast, postulated a single architecture for a series of five processors spanning a wide range of cost and performance. None of the five engineering design teams could count on being able to bring about adjustments in architectural specifications as a way of easing difficulties in achieving cost and performance objectives. : p.137\": 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " \"Some virtual machines that support bytecode as their ISA such as Smalltalk, the Java virtual machine, and Microsoft 's Common Language Runtime, implement this by translating the bytecode for commonly used code paths into native machine code. In addition, these virtual machines execute less frequently used code paths by interpretation (see: Just-in-time compilation). Transmeta implemented the x86 instruction set atop VLIW processors in this fashion.\": 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'An ISA may be classified in a number of different ways. A common classification is by architectural complexity. A complex instruction set computer (CISC) has many specialized instructions, some of which may only be rarely used in practical programs. A reduced instruction set computer (RISC) simplifies the processor by efficiently implementing only the instructions that are frequently used in programs, while the less common operations are implemented as subroutines, having their resulting additional processor execution time offset by infrequent use. ': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Other types include very long instruction word (VLIW) architectures, and the closely related long instruction word (LIW) and explicitly parallel instruction computing (EPIC) architectures. These architectures seek to exploit instruction-level parallelism with less hardware than RISC and CISC by making the compiler responsible for instruction issue and scheduling.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Architectures with even less complexity have been studied, such as the minimal instruction set computer (MISC) and one instruction set computer (OISC). These are theoretically important types, but have not been commercialized.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Processors may include \"complex\" instructions in their instruction set. A single \"complex\" instruction does something that may take many instructions on other computers. Such instructions are typified by instructions that take multiple steps, control multiple functional units, or otherwise appear on a larger scale than the bulk of simple instructions implemented by the given processor. Some examples of \"complex\" instructions include:': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Complex instructions are more common in CISC instruction sets than in RISC instruction sets, but RISC instruction sets may include them as well. RISC instruction sets generally do not include ALU operations with memory operands, or instructions to move large blocks of memory, but most RISC instruction sets include SIMD or vector instructions that perform the same arithmetic operation on multiple pieces of data at the same time. SIMD instructions have the ability of manipulating large vectors and matrices in minimal time. SIMD instructions allow easy parallelization of algorithms commonly involved in sound, image, and video processing. Various SIMD implementations have been brought to market under trade names such as MMX, 3DNow!, and AltiVec.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'On traditional architectures, an instruction includes an opcode that specifies the operation to perform, such as add contents of memory to register —and zero or more operand specifiers, which may specify registers, memory locations, or literal data. The operand specifiers may have addressing modes determining their meaning or may be in fixed fields. In very long instruction word (VLIW) architectures, which include many microcode architectures, multiple simultaneous opcodes and operands are specified in a single instruction.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Most stack machines have \" 0-operand\" instruction sets in which arithmetic and logical operations lack any operand specifier fields; only instructions that push operands onto the evaluation stack that pop operands from the stack into variables have operand specifiers. The instruction set carries out most ALU actions with postfix (reverse Polish notation) operations that work only on the expression stack, not on data registers or arbitrary main memory cells. This can be very convenient for compiling high-level languages, because most arithmetic expressions can be easily translated into postfix notation. ': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Conditional instructions often have a predicate field—a few bits that encode the specific condition to cause an operation to be performed rather than not performed. For example, a conditional branch instruction will transfer control if the condition is true, so that execution proceeds to a different part of the program, and not transfer control if the condition is false, so that execution continues sequentially. Some instruction sets also have conditional moves, so that the move will be executed, and the data stored in the target location, if the condition is true, and not executed, and the target location not modified, if the condition is false. Similarly, IBM z/Architecture has a conditional store instruction. A few instruction sets include a predicate field in every instruction; this is called branch predication.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " '(In the examples that follow, a, b, and c are (direct or calculated) addresses referring to memory cells, while reg1 and so on refer to machine registers.)': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Due to the large number of bits needed to encode the three registers of a 3-operand instruction, RISC architectures that have 16-bit instructions are invariably 2-operand designs, such as the Atmel AVR, TI MSP430, and some versions of ARM Thumb. RISC architectures that have 32-bit instructions are usually 3-operand designs, such as the ARM, AVR32, MIPS, Power ISA, and SPARC architectures.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Each instruction specifies some number of operands (registers, memory locations, or immediate values) explicitly. Some instructions give one or both operands implicitly, such as by being stored on top of the stack or in an implicit register. If some of the operands are given implicitly, fewer operands need be specified in the instruction. When a \"destination operand\" explicitly specifies the destination, an additional operand must be supplied. Consequently, the number of operands encoded in an instruction may differ from the mathematically necessary number of arguments for a logical or arithmetic operation (the arity). Operands are either encoded in the \"opcode\" representation of the instruction, or else are given as values or addresses following the opcode.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Register pressure measures the availability of free registers at any point in time during the program execution. Register pressure is high when a large number of the available registers are in use; thus, the higher the register pressure, the more often the register contents must be spilled into memory. Increasing the number of registers in an architecture decreases register pressure but increases the cost. ': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'While embedded instruction sets such as Thumb suffer from extremely high register pressure because they have small register sets, general-purpose RISC ISAs like MIPS and Alpha enjoy low register pressure. CISC ISAs like x86-64 offer low register pressure despite having smaller register sets. This is due to the many addressing modes and optimizations (such as sub-register addressing, memory operands in ALU instructions, absolute addressing, PC-relative addressing, and register-to-register spills) that CISC ISAs offer. ': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'A RISC instruction set normally has a fixed instruction length (often 4 bytes = 32 bits), whereas a typical CISC instruction set may have instructions of widely varying length (1 to 15 bytes for x86). Fixed-length instructions are less complicated to handle than variable-length instructions for several reasons (not having to check whether an instruction straddles a cache line or virtual memory page boundary,  for instance), and are therefore somewhat easier to optimize for speed.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'In early 1960s computers, main memory was expensive and very limited, even on mainframes. Minimizing the size of a program to make sure it would fit in the limited memory was often central. Thus the size of the instructions needed to perform a particular task, the code density, was an important characteristic of any instruction set. It remained important on the initially-tiny memories of minicomputers and then microprocessors. Density remains important today, for smartphone applications, applications downloaded into browsers over slow Internet connections, and in ROMs for embedded applications. A more general advantage of increased density is improved effectiveness of caches and instruction prefetch.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Computers with high code density often have complex instructions for procedure entry, parameterized returns, loops, etc. (therefore retroactively named Complex Instruction Set Computers, CISC). However, more typical, or frequent, \"CISC\" instructions merely combine a basic ALU operation, such as \"add\", with the access of one or more operands in memory (using addressing modes such as direct, indirect, indexed, etc.). Certain architectures may allow two or three operands (including the result) directly in memory or may be able to perform functions such as automatic pointer increment, etc. Software-implemented instruction sets may have even more complex and powerful instructions.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Reduced instruction-set computers, RISC, were first widely implemented during a period of rapidly growing memory subsystems. They sacrifice code density to simplify implementation circuitry, and try to increase performance via higher clock frequencies and more registers. A single RISC instruction typically performs only a single operation, such as an \"add\" of registers or a \"load\" from a memory location into a register. A RISC instruction set normally has a fixed instruction length, whereas a typical CISC instruction set has instructions of widely varying length. However, as RISC computers normally require more and often longer instructions to implement a given task, they inherently make less optimal use of bus bandwidth and cache memories.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Certain embedded RISC ISAs like Thumb and AVR32 typically exhibit very high density owing to a technique called code compression. This technique packs two 16-bit instructions into one 32-bit word, which is then unpacked at the decode stage and executed as two instructions. ': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Minimal instruction set computers (MISC) are a form of stack machine, where there are few separate instructions (16-64), so that multiple instructions can be fit into a single machine word. These types of cores often take little silicon to implement, so they can be easily realized in an FPGA or in a multi-core form. The code density of MISC is similar to the code density of RISC; the increased instruction density is offset by requiring more of the primitive instructions to do a task.  ': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'The instructions constituting a program are rarely specified using their internal, numeric form (machine code); they may be specified by programmers using an assembly language or, more commonly, may be generated from high-level programming languages by compilers.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'The design of instruction sets is a complex issue. There were two stages in history for the microprocessor. The first was the CISC (Complex Instruction Set Computer), which had many different instructions. In the 1970s, however, places like IBM did research and found that many instructions in the set could be eliminated. The result was the RISC (Reduced Instruction Set Computer), an architecture that uses a smaller set of instructions. A simpler instruction set may offer the potential for higher speeds, reduced processor size, and reduced power consumption. However, a more complex set may optimize common operations, improve memory and cache efficiency, or simplify programming.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Some instruction set designers reserve one or more opcodes for some kind of system call or software interrupt. For example, MOS Technology 6502 uses 00 H, Zilog Z80 uses the eight codes C7,CF,D7,DF,E7,EF,F7,FF H  while Motorola 68000 use codes in the range A000..AFFF H.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'The NOP slide used in immunity-aware programming is much easier to implement if the \"unprogrammed\" state of the memory is interpreted as a NOP. ': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'On systems with multiple processors, non-blocking synchronization algorithms are much easier to implement  if the instruction set includes support for something such as \" fetch-and-add\", \" load-link/store-conditional\" (LL/SC), or \"atomic compare-and-swap\".': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Any given instruction set can be implemented in a variety of ways. All ways of implementing a particular instruction set provide the same programming model, and all implementations of that instruction set are able to run the same executables. The various ways of implementing an instruction set give different tradeoffs between cost, performance, power consumption, size, etc.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'When designing the microarchitecture of a processor, engineers use blocks of \"hard-wired\" electronic circuitry (often designed separately) such as adders, multiplexers, counters, registers, ALUs, etc. Some kind of register transfer language is then often used to describe the decoding and sequencing of each instruction of an ISA using this physical microarchitecture. There are two basic ways to build a control unit to implement this description (although many designs use middle ways or compromises):': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Some CPU designs use a writable control store —they compile the instruction set to a writable RAM or flash inside the CPU (such as the Rekursiv processor and the Imsys Cjip),  or an FPGA (reconfigurable computing).': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'An ISA can also be emulated in software by an interpreter. Naturally, due to the interpretation overhead, this is slower than directly running programs on the emulated hardware, unless the hardware running the emulator is an order of magnitude faster. Today, it is common practice for vendors of new ISAs or microarchitectures to make software emulators available to software developers before the hardware implementation is ready.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'Often the details of the implementation have a strong influence on the particular instructions selected for the instruction set. For example, many implementations of the instruction pipeline only allow a single memory load or memory store per instruction, leading to a load–store architecture (RISC). For another example, some early ways of implementing the instruction pipeline led to a delay slot.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " 'The demands of high-speed digital signal processing have pushed in the opposite direction—forcing instructions to be implemented in a particular way. For example, to perform digital filters fast enough, the MAC instruction in a typical digital signal processor (DSP) must use a kind of Harvard architecture that can fetch an instruction and two data words simultaneously, and it requires a single-cycle multiply–accumulate multiplier.': 'https://en.wikipedia.org/wiki/Instruction_set_architecture',\n",
       " \"Computer Architecture is diverse and there's constant interplay between domains that are under it. Look under each of these to find specific information or check the full list here\": 'https://github.com/rajesh-s/computer-engineering-resources',\n",
       " 'We began our Turing Lecture June 4, 2018 11 with a review of computer architecture since the 1960s. In addition to that review, here, we highlight current challenges and identify future opportunities, projecting another golden age for the field of computer architecture in the next decade, much like the 1980s when we did the research that led to our award, delivering gains in cost, energy, and security, as well as performance.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Software talks to hardware through a vocabulary called an instruction set architecture (ISA). By the early 1960s, IBM had four incompatible lines of computers, each with its own ISA, software stack, I/O system, and market nichetargeting small business, large business, scientific, and real time, respectively. IBM engineers, including ACM A.M. Turing Award laureate Fred Brooks, Jr., thought they could create a single ISA that would efficiently unify all four of these ISA bases.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'The table here lists four models of the new System/360 ISA IBM announced April 7, 1964. The data paths vary by a factor of 8, memory capacity by a factor of 16, clock rate by nearly 4, performance by 50, and cost by nearly 6. The most expensive computers had the widest control stores because more complicated data paths used more control lines. The least-costly computers had narrower control stores due to simpler hardware but needed more microinstructions since they took more clock cycles to execute a System/360 instruction.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Facilitated by microprogramming, IBM bet the future of the company that the new ISA would revolutionize the computing industry and won the bet. IBM dominated its markets, and IBM mainframe descendants of the computer family announced 55 years ago still bring in $10 billion in revenue per year.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'As seen repeatedly, although the marketplace is an imperfect judge of technological issues, given the close ties between architecture and commercial computers, it eventually determines the success of architecture innovations that often require significant engineering investment.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Integrated circuits, CISC, 432, 8086, IBM PC. When computers began using integrated circuits, Moore's Law meant control stores could become much larger. Larger memories in turn allowed much more complicated ISAs. Consider that the control store of the VAX-11/780 from Digital Equipment Corp. in 1977 was 5,120 words x 96 bits, while its predecessor used only 256 words x 56 bits.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Some manufacturers chose to make microprogramming available by letting select customers add custom features they called \"writable control store\" (WCS). The most famous WCS computer was the Alto 36 Turing laureates Chuck Thacker and Butler Lampson, together with their colleagues, created for the Xerox Palo Alto Research Center in 1973. It was indeed the first personal computer, sporting the first bit-mapped display and first Ethernet local-area network. The device controllers for the novel display and network were microprograms stored in a 4,096-word x 32-bit WCS.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Microprocessors were still in the 8-bit era in the 1970s (such as the Intel 8080) and programmed primarily in assembly language. Rival designers would add novel instructions to outdo one another, showing their advantages through assembly language examples.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Gordon Moore believed Intel's next ISA would last the lifetime of Intel, so he hired many clever computer science Ph.D.'s and sent them to a new facility in Portland to invent the next great ISA. The 8800, as Intel originally named it, was an ambitious computer architecture project for any era, certainly the most aggressive of the 1980s. It had 32-bit capability-based addressing, object-oriented architecture, variable-bit-length instructions, and its own operating system written in the then-new programming language Ada.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'This ambitious project was alas several years late, forcing Intel to start an emergency replacement effort in Santa Clara to deliver a 16-bit microprocessor in 1979. Intel gave the new team 52 weeks to develop the new \"8086\" ISA and design and build the chip. Given the tight schedule, designing the ISA took only 10 person-weeks over three regular calendar weeks, essentially by extending the 8-bit registers and instruction set of the 8080 to 16 bits. The team completed the 8086 on schedule but to little fanfare when announced.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"To Intel's great fortune, IBM was developing a personal computer to compete with the Apple II and needed a 16-bit microprocessor. IBM was interested in the Motorola 68000, which had an ISA similar to the IBM 360, but it was behind IBM's aggressive schedule. IBM switched instead to an 8-bit bus version of the 8086. When IBM announced the PC on August 12, 1981, the hope was to sell 250,000 PCs by 1986. The company instead sold 100 million worldwide, bestowing a very bright future on the emergency replacement Intel ISA.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Intel's original 8800 project was renamed iAPX-432 and finally announced in 1981, but it required several chips and had severe performance problems. It was discontinued in 1986, the year after Intel extended the 16-bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits. Moore's prediction was thus correct that the next ISA would last as long as Intel did, but the marketplace chose the emergency replacement 8086 rather than the anointed 432. As the architects of the Motorola 68000 and iAPX-432 both learned, the marketplace is rarely patient.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'From complex to reduced instruction set computers. The early 1980s saw several investigations into complex instruction set computers (CISC) enabled by the big microprograms in the larger control stores. With Unix demonstrating that even operating systems could use high-level languages, the critical question became: \"What instructions would compilers generate?\" instead of \"What assembly language would programmers use?\" Significantly raising the hardware/software interface created an opportunity for architecture innovation.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"In today's post-PC era, x86 shipments have fallen almost 10% per year since the peak in 2011, while chips with RISC processors have skyrocketed to 20 billion.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'For example, Figure 1 shows the RISC-I 8 and MIPS 12 microprocessors developed at the University of California, Berkeley, and Stanford University in 1982 and 1983, respectively, that demonstrated the benefits of RISC. These chips were eventually presented at the leading circuit conference, the IEEE International Solid-State Circuits Conference, in 1984. 33, 35 It was a remarkable moment when a few graduate students at Berkeley and Stanford could build microprocessors that were arguably superior to what industry could build.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'These academic chips inspired many companies to build RISC microprocessors, which were the fastest for the next 15 years. The explanation is due to the following formula for processor performance:': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'DEC engineers later showed 2 that the more complicated CISC ISA executed about 75% of the number instructions per program as RISC (the first term), but in a similar technology CISC executed about five to six more clock cycles per instruction (the second term), making RISC microprocessors approximately 4x faster.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Such formulas were not part of computer architecture books in the 1980s, leading us to write Computer Architecture: A Quantitative Approach 13 in 1989. The subtitle suggested the theme of the book: Use measurements and benchmarks to evaluate trade-offs quantitatively instead of relying more on the architect's intuition and experience, as in the past. The quantitative approach we used was also inspired by what Turing laureate Donald Knuth's book had done for algorithms. 20\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'VLIW, EPIC, Itanium. The next ISA innovation was supposed to succeed both RISC and CISC. Very long instruction word (VLIW) 7 and its cousin, the explicitly parallel instruction computer (EPIC), the name Intel and Hewlett Packard gave to the approach, used wide instructions with multiple independent operations bundled together in each instruction. VLIW and EPIC advocates at the time believed if a single instruction could specify, say, six independent operationstwo data transfers, two integer operations, and two floating point operationsand compiler technology could efficiently assign operations into the six instruction slots, the hardware could be made simpler. Like the RISC approach, VLIW and EPIC shifted work from the hardware to the compiler.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'AMD and Intel used 500-person design teams and superior semiconductor technology to close the performance gap between x86 and RISC. Again inspired by the performance advantages of pipelining simple vs. complex instructions, the instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly. AMD and Intel then pipelined the execution of the RISC microinstructions. Any ideas RISC designers were using for performanceseparate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneouslycould then be incorporated into the x86. AMD and Intel shipped roughly 350 million x86 microprocessors annually at the peak of the PC era in 2011. The high volumes and low margins of the PC industry also meant lower prices than RISC computers.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Given the hundreds of millions of PCs sold worldwide each year, PC software became a giant market. Whereas software providers for the Unix marketplace would offer different software versions for the different commercial RISC ISAsAlpha, HP-PA, MIPS, Power, and SPARCthe PC market enjoyed a single ISA, so software developers shipped \"shrink wrap\" software that was binary compatible with only the x86 ISA. A much larger software base, similar performance, and lower prices led the x86 to dominate both desktop computers and small-server markets by 2000.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Apple helped launch the post-PC era with the iPhone in 2007. Instead of buying microprocessors, smartphone companies built their own systems on a chip (SoC) using designs from other companies, including RISC processors from ARM. Mobile-device designers valued die area and energy efficiency as much as performance, disadvantaging CISC ISAs. Moreover, arrival of the Internet of Things vastly increased both the number of processors and the required trade-offs in die size, power, cost, and performance. This trend increased the importance of design time and cost, further disadvantaging CISC processors. In today's post-PC era, x86 shipments have fallen almost 10% per year since the peak in 2011, while chips with RISC processors have skyrocketed to 20 billion. Today, 99% of 32-bit and 64-bit processors are RISC.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Concluding this historical review, we can say the marketplace settled the RISC-CISC debate; CISC won the later stages of the PC era, but RISC is winning the post-PC era. There have been no new CISC ISAs in decades. To our surprise, the consensus on the best ISA principles for general-purpose processors today is still RISC, 35 years after their introduction.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '\"If a problem has no solution, it may not be a problem, but a factnot to be solved, but to be coped with over time.\" Shimon Peres': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Although Moore's Law held for many decades (see Figure 2), it began to slow sometime around 2000 and by 2018 showed a roughly 15-fold gap between Moore's prediction and current capability, an observation Moore made in 2003 that was inevitable. 27 The current expectation is that the gap will continue to grow as CMOS technology approaches fundamental limits.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Accompanying Moore\\'s Law was a projection made by Robert Dennard called \"Dennard scaling,\" 5 stating that as transistor density increased, power consumption per transistor would drop, so the power per mm 2 of silicon would be near constant. Since the computational capability of a mm 2 of silicon was increasing with each new generation of technology, computers would become more energy efficient. Dennard scaling began to slow significantly in 2007 and faded to almost nothing by 2012 (see Figure 3).': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Between 1986 and about 2002, the exploitation of instruction level parallelism (ILP) was the primary architectural method for gaining performance and, along with improvements in speed of transistors, led to an annual performance increase of approximately 50%. The end of Dennard scaling meant architects had to find more efficient ways to exploit parallelism.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'To see how challenging such a design is, consider the difficulty of correctly predicting the outcome of 15 branches. If a processor architect wants to limit wasted work to only 10% of the time, the processor must predict each branch correctly 99.3% of the time. Few general-purpose programs have branches that can be predicted so accurately.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'To appreciate how this wasted work adds up, consider the data in Figure 4, showing the fraction of instructions that are effectively executed but turn out to be wasted because the processor speculated incorrectly. On average, 19% of the instructions are wasted for these benchmarks on an Intel Core i7. The amount of wasted energy is greater, however, since the processor must use additional energy to restore the state when it speculates incorrectly. Measurements like these led many to conclude architects needed a different approach to achieve performance improvements. The multicore era was thus born.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Real programs have more complex structures of course, with portions that allow varying numbers of processors to be used at any given moment in time. Nonetheless, the need to communicate and synchronize periodically means most applications have some portions that can effectively use only a fraction of the processors. Although Amdahl's Law is more than 50 years old, it remains a difficult hurdle.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"An era without Dennard scaling, along with reduced Moore's Law and Amdahl's Law in full effect means inefficiency limits improvement in performance to only a few percent per year (see Figure 6). Achieving higher rates of performance improvementas was seen in the 1980s and 1990swill require new architectural approaches that use the integrated-circuit capability much more efficiently. We will return to what approaches might work after discussing another major shortcoming of modern computerstheir support, or lack thereof, for computer security.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"Inherent inefficiencies in general-purpose processors, whether from ILP techniques or multicore, combined with the end of Dennard scaling and Moore's Law, make it highly unlikely, in our view, that processor architects and designers can sustain significant rates of performance improvements in general-purpose processors. Given the importance of improving performance to enable new software capabilities, we must ask: What other approaches might be promising?\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'An interesting research direction concerns whether some of the performance gap can be closed with new compiler technology, possibly assisted by architectural enhancements. Although the challenges in efficiently translating and implementing high-level scripting languages like Python are difficult, the potential gain is enormous. Achieving even 25% of the potential gain could result in Python programs running tens to hundreds of times faster. This simple example illustrates how great the gap is between modern languages emphasizing programmer productivity and traditional approaches emphasizing performance.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Second, DSAs can make more effective use of the memory hierarchy. Memory accesses have become much more costly than arithmetic computations, as noted by Horowitz. 16 For example, accessing a block in a 32-kilobyte cache involves an energy cost approximately 200x higher than a 32-bit integer add. This enormous differential makes optimizing memory accesses critical to achieving high-energy efficiency. General-purpose processors run code in which memory accesses typically exhibit spatial and temporal locality but are otherwise not very predictable at compile time. CPUs thus use multilevel caches to increase bandwidth and hide the latency in relatively slow, off-chip DRAMs. These multilevel caches often consume approximately half the energy of the processor but avoid almost all accesses to the off-chip DRAMs that require approximately 10x the energy of a last-level cache access.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'When caches work well. When caches work well, the locality is very high, meaning, by definition, most of the cache is idle most of the time.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'In applications where the memory-access patterns are well defined and discoverable at compile time, which is true of typical DSLs, programmers and compilers can optimize the use of the memory better than can dynamically allocated caches. DSAs thus usually use a hierarchy of memories with movement controlled explicitly by the software, similar to how vector processors operate. For suitable applications, user-controlled memories can use much less energy than caches.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Third, DSAs can use less precision when it is adequate. General-purpose CPUs usually support 32- and 64-bit integer and floating-point (FP) data. For many applications in machine learning and graphics, this is more accuracy than is needed. For example, in deep neural networks (DNNs), inference regularly uses 4-, 8-, or 16-bit integers, improving both data and computational throughput. Likewise, for DNN training applications, FP is useful, but 32 bits is enough and 16 bits often works.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Finally, DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'DSAs require targeting of high-level operations to the architecture, but trying to extract such structure and information from a general-purpose language like Python, Java, C, or Fortran is simply too difficult. Domain specific languages (DSLs) enable this process and make it possible to program DSAs efficiently. For example, DSLs can make vector, dense matrix, and sparse matrix operations explicit, enabling the DSL compiler to map the operations to the processor efficiently. Examples of DSLs include Matlab, a language for operating on matrices, TensorFlow, a dataflow language used for programming DNNs, P4, a language for programming SDNs, and Halide, a language for image processing specifying high-level transformations.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'The challenge when using DSLs is how to retain enough architecture independence that software written in a DSL can be ported to different architectures while also achieving high efficiency in mapping the software to the underlying DSA. For example, the XLA system translates Tensorflow to heterogeneous processors that use Nvidia GPUs or Tensor Processor Units (TPUs). 40 Balancing portability among DSAs along with efficiency is an interesting research challenge for language designers, compiler creators, and DSA architects.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Example DSA TPU v1. As an example DSA, consider the Google TPU v1, which was designed to accelerate neural net inference. 17, 18 The TPU has been in production since 2015 and powers applications ranging from search queries to language translation to image recognition to AlphaGo and AlphaZero, the DeepMind programs for playing Go and Chess. The goal was to improve the performance and energy efficiency of deep neural net inference by a factor of 10.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'CPUs. Intel offers CPUs with many cores enhanced by large multi-level caches and one-dimensional SIMD instructions, the kind of FPGAs used by Microsoft, and a new neural network processor that is closer to a TPU than to a CPU. 19': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'In addition to these large players, dozens of startups are pursuing their own proposals. 25 To meet growing demand, architects are interconnecting hundreds to thousands of such chips to form neural-network supercomputers.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'This avalanche of DNN architectures makes for interesting times in computer architecture. It is difficult to predict in 2019 which (or even if any) of these many directions will win, but the marketplace will surely settle the competition just as it settled the architectural debates of the past.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Inspired by the success of open source software, the second opportunity in computer architecture is open ISAs. To create a \"Linux for processors\" the field needs industry-standard open ISAs so the community can create open source cores, in addition to individual companies owning proprietary ones. If many organizations design processors using the same ISA, the greater competition may drive even quicker innovation. The goal is to provide processors for chips that cost from a few cents to $100.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'The first example is RISC-V (called \"RISC Five\"), the fifth RISC architecture developed at the University of California, Berkeley. 32 RISC-V\\'s has a community that maintains the architecture under the stewardship of the RISC-V Foundation (http://riscv.org/). Being open allows the ISA evolution to occur in public, with hardware and software experts collaborating before decisions are finalized. An added benefit of an open foundation is the ISA is unlikely to expand primarily for marketing reasons, sometimes the only explanation for extensions of proprietary instruction sets.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'RISC-V is a modular instruction set. A small base of instructions run the full open source software stack, followed by optional standard extensions designers can include or omit depending on their needs. This base includes 32-bit address and 64-bit address versions. RISC-V can grow only through optional extensions; the software stack still runs fine even if architects do not embrace new extensions. Proprietary architectures generally require upward binary compatibility, meaning when a processor company adds new feature, all future processors must also include it. Not so for RISC-V, whereby all enhancements are optional and can be deleted if not needed by an application. Here are the standard extensions so far, using initials that stand for their full names:': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'A third distinguishing feature of RISC-V is the simplicity of the ISA. While not readily quantifiable, here are two comparisons to the ARMv8 architecture, as developed by the ARM company contemporaneously:': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Fewer instructions. RISC-V has many fewer instructions. There are 50 in the base that are surprisingly similar in number and nature to the original RISC-I. 30 The remaining standard extensionsM, A, F, and Dadd 53 instructions, plus C added another 34, totaling 137. ARMv8 has more than 500; and': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Simplicity reduces the effort to both design processors and verify hardware correctness. As the RISC-V targets range from data-center chips to IoT devices, design verification can be a significant part of the cost of development.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Fourth, RISC-V is a clean-slate design, starting 25 years later, letting its architects learn from mistakes of its predecessors. Unlike first-generation RISC architectures, it avoids microarchitecture or technology-dependent features (such as delayed branches and delayed loads) or innovations (such as register windows) that were superseded by advances in compiler technology.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Beyond RISC-V, Nvidia also announced (in 2017) a free and open architecture 29 it calls Nvidia Deep Learning Accelerator (NVDLA), a scalable, configurable DSA for machine-learning inference. Configuration options include data type (int8, int16, or fp16 ) and the size of the two-dimensional multiply matrix. Die size scales from 0.5 mm 2 to 3 mm 2 and power from 20 milliWatts to 300 milliWatts. The ISA, software stack, and implementation are all open.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'The Manifesto for Agile Software Development (2001) by Beck et al. 1 revolutionized software development, overcoming the frequent failure of the traditional elaborate planning and documentation in waterfall development. Small programming teams quickly developed working-but-incomplete prototypes and got customer feedback before starting the next iteration. The scrum version of agile development assembles teams of five to 10 programmers doing sprints of two to four weeks per iteration.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Once again inspired by a software success, the third opportunity is agile hardware development. The good news for architects is that modern electronic computer aided design (ECAD) tools raise the level of abstraction, enabling agile development, and this higher level of abstraction increases reuse across designs.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'For research purposes, we could stop at tape in, as area, energy, and performance estimates are highly accurate. However, it would be like running a long race and stopping 100 yards before the finish line because the runner can accurately predict the final time. Despite all the hard work in race preparation, the runner would miss the thrill and satisfaction of actually crossing the finish line. One advantage hardware engineers have over software engineers is they build physical things. Getting chips back to measure, run real programs, and show to their friends and family is a great joy of hardware design.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Many researchers assume they must stop short because fabricating chips is unaffordable. When designs are small, they are surprisingly inexpensive. Architects can order 100 1-mm 2 chips for only $14,000. In 28 nm, 1 mm 2 holds millions of transistors, enough area for both a RISC-V processor and an NVLDA accelerator. The outermost level is expensive if the designer aims to build a large chip, but an architect can demonstrate many novel ideas with small chips.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'To benefit from the lessons of history, architects must appreciate that software innovations can also inspire architects, that raising the abstraction level of the hardware/software interface yields opportunities for innovation, and that the marketplace ultimately settles computer architecture debates. The iAPX-432 and Itanium illustrate how architecture investment can exceed returns, while the S/360, 8086, and ARM deliver high annual returns lasting decades with no end in sight.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"The end of Dennard scaling and Moore's Law and the deceleration of performance gains for standard microprocessors are not problems that must be solved but facts that, recognized, offer breathtaking opportunities. High-level, domain-specific languages and architectures, freeing architects from the chains of proprietary instruction sets, along with demand from the public for improved security, will usher in a new golden age for computer architects. Aided by open source ecosystems, agilely developed chips will convincingly demonstrate advances and thereby accelerate commercial adoption. The ISA philosophy of the general-purpose processors in these chips will likely be RISC, which has stood the test of time. Expect the same rapid improvement as in the last golden age, but this time in terms of cost, energy, and security, as well as in performance.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '1. Beck, K., Beedle, M., Van Bennekum, A., Cockburn, A., Cunningham, W., Fowler, M. ... and Kern, J. Manifesto for Agile Software Development, 2001; https://agilemanifesto.org/': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '2. Bhandarkar, D. and Clark, D.W. Performance from architecture: Comparing a RISC and a CISC with similar hardware organization. In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (Santa Clara, CA, Apr. 811). ACM Press, New York, 1991, 310319.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '4. Dally, W. et al. Hardware-enabled artificial intelligence. In Proceedings of the Symposia on VLSI Technology and Circuits (Honolulu, HI, June 1822). IEEE Press, 2018, 36.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '5. Dennard, R. et al. Design of ion-implanted MOSFETs with very small physical dimensions. IEEE Journal of Solid State Circuits 9, 5 (Oct. 1974), 256268.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '6. Emer, J. and Clark, D. A characterization of processor performance in the VAX-11/780. In Proceedings of the 11 th International Symposium on Computer Architecture (Ann Arbor, MI, June). ACM Press, New York, 1984, 301310.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '8. Fitzpatrick, D.T., Foderaro, J.K., Katevenis, M.G., Landman, H.A., Patterson, D.A., Peek, J.B., Peshkess, Z., Séquin, C.H., Sherburne, R.W., and Van Dyke, K.S. A RISCy approach to VLSI. ACM SIGARCH Computer Architecture News 10, 1 (Jan. 1982), 2832.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '10. Fowers, J. et al. A configurable cloud-scale DNN processor for real-time AI. In Proceedings of the 45 th ACM/IEEE Annual International Symposium on Computer Architecture (Los Angeles, CA, June 26). IEEE, 2018, 114.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '11. Hennessy, J. and Patterson, D. A New Golden Age for Computer Architecture. Turing Lecture delivered at the 45 th ACM/IEEE Annual International Symposium on Computer Architecture (Los Angeles, CA, June 4, 2018); http://iscaconf.org/isca2018/turing_lecture.html; https://www.youtube.com/watch?v=3LVeEjsn8Ts': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '12. Hennessy, J., Jouppi, N., Przybylski, S., Rowen, C., Gross, T., Baskett, F., and Gill, J. MIPS: A microprocessor architecture. ACM SIGMICRO Newsletter 13, 4 (Oct. 5, 1982), 1722.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '14. Hill, M. A primer on the meltdown and Spectre hardware security design flaws and their important implications, Computer Architecture Today blog (Feb. 15, 2018); https://www.sigarch.org/a-primer-on-the-meltdown-spectre-hardware-security-design-flaws-and-their-important-implications/': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '15. Hopkins, M. A critical look at IA-64: Massive resources, massive ILP, but can it deliver? Microprocessor Report 14, 2 (Feb. 7, 2000), 15.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"16. Horowitz M. Computing's energy problem (and what we can do about it). In Proceedings of the IEEE International Solid-State Circuits Conference Digest of Technical Papers (San Francisco, CA, Feb. 913). IEEE Press, 2014, 1014.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '17. Jouppi, N., Young, C., Patil, N., and Patterson, D. A domain-specific architecture for deep neural networks. Commun. ACM 61, 9 (Sept. 2018), 5058.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '18. Jouppi, N.P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R., Bates, S., Bhatia, S., Boden, N., Borchers, A., and Boyle, R. In-datacenter performance analysis of a tensor processing unit. In Proceedings of the 44 th ACM/IEEE Annual International Symposium on Computer Architecture (Toronto, ON, Canada, June 2428). IEEE Computer Society, 2017, 112.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '22. Kung, H. and Leiserson, C. Systolic arrays (for VLSI). Chapter in Sparse Matrix Proceedings Vol. 1. Society for Industrial and Applied Mathematics, Philadelphia, PA, 1979, 256282.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '23. Lee, Y., Waterman, A., Cook, H., Zimmer, B., Keller, B., Puggelli, A. ... and Chiu, P. An agile approach to building RISC-V microprocessors. IEEE Micro 36, 2 (Feb. 2016), 820.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '25. Metz, C. Big bets on A.I. open a new frontier for chip start-ups, too. The New York Times (Jan. 14, 2018).': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"27. Moore, G. No exponential is forever: But 'forever' can be delayed! . In Proceedings of the IEEE International Solid-State Circuits Conference Digest of Technical Papers (San Francisco, CA, Feb. 13). IEEE, 2003, 2023.\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '28. Moore, G. Progress in digital integrated electronics. In Proceedings of the International Electronic Devices Meeting (Washington, D.C., Dec.). IEEE, New York, 1975, 1113.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '33. Rowen, C., Przbylski, S., Jouppi, N., Gross, T., Shott, J., and Hennessy, J. A pipelined 32b NMOS microprocessor. In Proceedings of the IEEE International Solid-State Circuits Conference Digest of Technical Papers (San Francisco, CA, Feb. 2224) IEEE, 1984, 180181.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '34. Schwarz, M., Schwarzl, M., Lipp, M., and Gruss, D. Netspectre: Read arbitrary memory over network. arXiv preprint, 2018; https://arxiv.org/pdf/1807.10535.pdf': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '35. Sherburne, R., Katevenis, M., Patterson, D., and Sequin, C. A 32b NMOS microprocessor with a large register file. In Proceedings of the IEEE International Solid-State Circuits Conference (San Francisco, CA, Feb. 2224). IEEE Press, 1984, 168169.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '36. Thacker, C., MacCreight, E., and Lampson, B. Alto: A Personal Computer. CSL-79-11, Xerox Palo Alto Research Center, Palo Alto, CA, Aug. 7,1979; http://people.scs.carleton.ca/~soma/distos/fall2008/alto.pdf': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " \"37. Turner, P., Parseghian, P., and Linton, M. Protecting against the new 'L1TF' speculative vulnerabilities. Google blog, Aug. 14, 2018; https://cloud.google.com/blog/products/gcp/protectingagainst-the-new-l1tf-speculative-vulnerabilities\": 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '38. Van Bulck, J. et al. Foreshadow: Extracting the keys to the Intel SGX kingdom with transient out-of-order execution. In Proceedings of the 27 th USENIX Security Symposium (Baltimore, MD, Aug. 1517). USENIX Association, Berkeley, CA, 2018.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " '39. Wilkes, M. and Stringer, J. Micro-programming and the design of the control circuits in an electronic digital computer. Mathematical Proceedings of the Cambridge Philosophical Society 49, 2 (Apr. 1953), 230238.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'John L. Hennessy (hennnessy@stanford.edu) is Past-President of Stanford University, Stanford, CA, USA, and is Chairman of Alphabet Inc., Mountain View, CA, USA.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'David A. Patterson (pattrsn@berkeley.edu) is the Pardee Professor of Computer Science, Emeritus at the University of California, Berkeley, CA, USA, and a Distinguished Engineer at Google, Mountain View, CA, USA.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and full citation on the first page. Copyright for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or fee. Request permission to publish from permissions@acm.org or fax (212) 869-0481.': 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext',\n",
       " 'For those who want the fastest possible simulation, and do not care about any form of datapath visualization, there should be an option to select an ISA simulator processor model.': 'https://github.com/topics/computer-architecture',\n",
       " 'A list of time-lasting classic books, which could not only help you figure out how it works, but also grasp when it works and why it works in that way.': 'https://github.com/topics/computer-architecture',\n",
       " 'Using HDL, from Boolean algebra and elementary logic gates to building a Central Processing Unit, a memory system, and a hardware platform, leading up to a 16-bit general-purpose computer. Then, implementing the modern software hierarchy designed to enable the translation and execution of object-based, high-level languages on a bare-bone computer hardware platform; Including Virtual machine,Compiler and Operating system.': 'https://github.com/topics/computer-architecture',\n",
       " 'A collection of curated resources for learning Computer Science subjects and skills, that I garnered throughout my tenure as a CSE student. Contributions, and report of broken links are welcome.': 'https://github.com/topics/computer-architecture',\n",
       " '通过issue和README来记录日常学习研究笔记 关注 机器学习系统，深度学习， LLVM，性能剖视， Linux操作系统内核 话题 关注 C/C++. JAVA. Python. Golang. Chisel. 编程语言话题 ( Writing Blogs using github issue and markdown! (inculding Machine Learning algs and system, LLVM, Linux kernel, java, python, c++, golang)': 'https://github.com/topics/computer-architecture',\n",
       " 'Earlier, computer architects designed computer architecture on paper. It was then directly built into a final hardware form. Later, they assembled computer architecture designs materially in the form of transistor-transistor logic (TTL) computers. By the 1990s, new computer architectures are typically built, examined, and tweaked inside another computer architecture, in a computer architecture simulator, or the interior part of an FPGA, as a microprocessor before perpetrating to the ultimate hardware form.': 'https://www.w3schools.in/computer-fundamentals/types-of-computer-architecture',\n",
       " 'It enables versatile implementations of an ISA; commonly differ in features such as performance, physical size, and monetary price. It empowers the evolution of the micro-architectures, implementing ISA as an exclusive, higher-performance system that can run software on preceding generations of execution.': 'https://www.w3schools.in/computer-fundamentals/types-of-computer-architecture',\n",
       " 'Simply, it is a logical form of all electronic elements and data pathways present in the microprocessor, designed in a specific way. It allows for the optimal completion of instructions. In academe, it is called computer organization. System Design System design itself defines a design that can serve user requirements like system architecture, computer modules having various interfaces, and data management within a system. The term product development is connective to the system design. It is the process by which we can take marketing information to create a product design.': 'https://www.w3schools.in/computer-fundamentals/types-of-computer-architecture',\n",
       " 'System design itself defines a design that can serve user requirements like system architecture, computer modules having various interfaces, and data management within a system. The term product development is connective to the system design. It is the process by which we can take marketing information to create a product design.': 'https://www.w3schools.in/computer-fundamentals/types-of-computer-architecture',\n",
       " 'If you are on a personal connection, like at home, you can run an anti-virus scan on your device to make sure it is not infected with malware.': 'https://www.researchgate.net/publication/241056162_Types_of_Computer_Architectures'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f40d817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "link_2_title = {}\n",
    "\n",
    "raw_dataset = defaultdict(str)\n",
    "\n",
    "for result in results:\n",
    "    temp_dataset = ''\n",
    "    paragraphs = []\n",
    "    temp_cleaned_para = []\n",
    "    try:\n",
    "        page = requests.get(result, timeout=(5, 10), headers=headers)\n",
    "    except:\n",
    "        continue\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    p = soup.find_all('p')\n",
    "    title = str(soup.find('title'))\n",
    "    link_2_title[result] = html_text.extract_text(title)\n",
    "    \n",
    "    for x in p:\n",
    "        paragraphs.append(str(x))\n",
    "    for i, para in enumerate(paragraphs):\n",
    "        if para != '':\n",
    "            temp_cleaned_para.append(html_text.extract_text(para, guess_layout=False))\n",
    "\n",
    "    for i, para in enumerate(temp_cleaned_para):\n",
    "        if len(nltk.word_tokenize(para)) > 30 and len(nltk.word_tokenize(para)) < 150:\n",
    "            para = re.sub('[\\[].*?[\\]]', '', para)\n",
    "            cleaned_para.append(para)\n",
    "            temp_dataset += para\n",
    "            \n",
    "    raw_dataset[result] = temp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3ef9d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://en.wikipedia.org/wiki/Category:Computer_architecture': 'Category:Computer architecture - Wikipedia',\n",
       " 'https://online.sunderland.ac.uk/what-is-computer-architecture/': 'What is computer architecture? - University of Sunderland',\n",
       " 'https://en.wikipedia.org/wiki/Computer_architecture': 'Computer architecture - Wikipedia',\n",
       " 'https://en.wikipedia.org/wiki/Word_(computer_architecture)': 'Word (computer architecture) - Wikipedia',\n",
       " 'https://www.britannica.com/technology/computer-architecture': 'computer architecture | Definition & Facts | Britannica',\n",
       " 'https://www.educba.com/types-of-computer-architecture/': 'Types of Computer Architecture | 5 Useful Types of Computer Architecture',\n",
       " 'https://en.wikipedia.org/wiki/Microarchitecture': 'Microarchitecture - Wikipedia',\n",
       " 'https://geteducationskills.com/computer-architecture/': 'What Is Computer Architecture? – Get Education',\n",
       " 'https://www.techopedia.com/definition/26757/computer-architecture': 'What is Computer Architecture? - Definition from Techopedia',\n",
       " 'https://www.sciencedirect.com/topics/computer-science/computer-architecture': 'Just a moment...',\n",
       " 'https://www.tutorialspoint.com/what-is-computer-architecture': 'What is computer architecture?',\n",
       " 'https://www.computersciencedegreehub.com/faq/what-is-computer-architecture/': 'What is Computer Architecture? - Computer Science Degree Hub',\n",
       " 'https://dl.acm.org/doi/10.1109/MAHC.1988.10039': 'A Historical Overview of Computer Architecture | IEEE Annals of the History of Computing',\n",
       " 'https://www.sigarch.org/a-brief-and-biased-history-of-computer-architecture-part-1/': 'A Brief and Biased History of Computer Architecture (Part 1) | SIGARCH',\n",
       " 'https://edurev.in/studytube/A-Brief-History-of-Computer-Architecture-Computer-/987e1c94-0ef4-4ebd-b172-277f3deb72c1_t': 'A Brief History of Computer Architecture Notes - Computer Science Engineering (CSE)',\n",
       " 'https://www.computer.org/csdl/magazine/an/1988/04/man1988040277/13rRUxZRbrm': 'CSDL | IEEE Computer Society',\n",
       " 'https://techwithtech.com/best-computer-architecture-books/': '12 Best Computer Architecture Books (+ Pros & Cons)',\n",
       " 'https://www.quora.com/What-are-good-books-for-computer-architecture': 'What are good books for computer architecture? - Quora',\n",
       " 'https://warwick.ac.uk/fac/sci/dcs/teaching/modules/cs257/': 'CS257 Advanced Computer Architecture',\n",
       " 'https://safari.ethz.ch/digitaltechnik/spring2021/doku.php?id=readings': 'readings [Digital Design and Computer Architecture - Spring 2021]',\n",
       " 'https://www.quora.com/What-are-some-good-books-on-Computer-Architecture-for-beginners?top_ans=1974891': 'What are some good books on Computer Architecture for beginners? - Quora',\n",
       " 'https://safari.ethz.ch/architecture/fall2020/doku.php?id=readings': 'readings [Computer Architecture - Fall 2020]',\n",
       " 'https://www.goodreads.com/shelf/show/computer-architecture': 'Computer Architecture Books',\n",
       " 'https://www.quora.com/What-is-a-good-book-to-learn-computer-architecture': 'What is a good book to learn computer architecture? - Quora',\n",
       " 'https://www.quora.com/What-is-the-best-book-in-computer-architecture-that-is-easy-to-understand-and-written-in-lucid-language-as-well': 'What is the best book in computer architecture that is easy to understand and written in lucid language as well? - Quora',\n",
       " 'https://www.quora.com/What-are-some-good-books-on-Computer-Architecture-for-beginners': 'What are some good books on Computer Architecture for beginners? - Quora',\n",
       " 'https://www.amazon.com/Readings-Computer-Architecture-Morgan-Kaufmann/dp/1558605398': 'Amazon.com',\n",
       " 'https://www.quora.com/What-is-the-best-way-and-source-to-learn-computer-architecture?top_ans=47987712': 'What is the best way and source to learn computer architecture? - Quora',\n",
       " 'https://www.quora.com/What-is-the-best-way-to-learn-computer-organization-and-architecture': 'What is the best way to learn computer organization and architecture? - Quora',\n",
       " 'https://www.sigarch.org/call-contributions/first-workshop-on-open-source-computer-architecture-research-oscar/': 'First Workshop on Open-Source Computer Architecture Research (OSCAR) | SIGARCH',\n",
       " 'https://en.wikipedia.org/wiki/Instruction_set_architecture': 'Instruction set architecture - Wikipedia',\n",
       " 'https://github.com/rajesh-s/computer-engineering-resources': 'GitHub - rajesh-s/computer-engineering-resources: A curated list of Computer Engineering resources',\n",
       " 'https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext': 'A New Golden Age for Computer Architecture | February 2019 | Communications of the ACM',\n",
       " 'https://www.quora.com/What-is-the-best-source-and-method-to-study-computer-architecture': 'What is the best source and method to study computer architecture? - Quora',\n",
       " 'https://www.quora.com/What-is-the-best-way-and-source-to-learn-computer-architecture': 'What is the best way and source to learn computer architecture? - Quora',\n",
       " 'https://github.com/topics/computer-architecture': 'computer-architecture · GitHub Topics · GitHub',\n",
       " 'https://www.w3schools.in/computer-fundamentals/types-of-computer-architecture': 'Types of Computer Architecture - Computer Fundamentals',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-architecture-and-organisations': 'What are the types of computer architecture and organisations? - Quora',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-architectures-in-a-CPU': 'What are the types of computer architectures in a CPU? - Quora',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-system-architecture?top_ans=20669228': 'What are the types of computer system architecture? - Quora',\n",
       " 'https://www.quora.com/What-are-the-types-of-computer-system-architecture': 'What are the types of computer system architecture? - Quora',\n",
       " 'https://www.quora.com/What-are-other-types-of-computer-system-architecture-apart-from-Von-Neumann': 'What are other types of computer system architecture apart from Von Neumann? - Quora',\n",
       " 'https://www.quora.com/What-are-the-most-commonly-used-computer-architectures': 'What are the most commonly used computer architectures? - Quora',\n",
       " 'https://www.researchgate.net/publication/241056162_Types_of_Computer_Architectures': 'Please Wait... | Cloudflare'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_2_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3049524",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"/Users/arpan/Documents/FORWARD_LAB\"\n",
    "word_embeddings = {}\n",
    "f = open(join(mypath, 'glove.6B.300d.txt'), encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e966a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_vectors = []\n",
    "webside_embeddings = {}\n",
    "for key, val in raw_dataset.items():\n",
    "    if len(val) != 0:\n",
    "        v = sum([word_embeddings.get(w, np.zeros((300,))) for w in val.split()])/(len(val.split())+0.001)\n",
    "    else:\n",
    "        v = np.zeros((300,))\n",
    "    webside_embeddings[key] = v\n",
    "    website_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebfb12a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(website_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fdbcf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = np.zeros([len(website_vectors), len(website_vectors)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98eae614",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(website_vectors)):\n",
    "    for j in range(len(website_vectors)):\n",
    "        if i != j:\n",
    "            sim_mat[i][j] = cosine_similarity\\\n",
    "            (website_vectors[i].reshape(1,300), \\\n",
    "             website_vectors[j].reshape(1,300))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f12a1b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.98459789, ..., 0.90930794, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.98459789, 0.        , ..., 0.91273369, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.90930794, 0.91273369, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e0f9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e576156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(raw_dataset.keys())), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9b1e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_para = list(set(cleaned_para))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bbb209f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd27063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = []\n",
    "for i in cleaned_para:\n",
    "    if len(i) != 0:\n",
    "        v = sum([word_embeddings.get(w, np.zeros((300,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "    else:\n",
    "        v = np.zeros((300,))\n",
    "    sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "713948b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = np.zeros([len(cleaned_para), len(cleaned_para)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90dc95db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cleaned_para)):\n",
    "    for j in range(len(cleaned_para)):\n",
    "        if i != j:\n",
    "            sim_mat[i][j] = cosine_similarity\\\n",
    "            (sentence_vectors[i].reshape(1,300), \\\n",
    "             sentence_vectors[j].reshape(1,300))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6757000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b96357cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(cleaned_para)), reverse=True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea022b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = []\n",
    "for sent in cleaned_para:\n",
    "    for _, sentence in ranked_sentences:\n",
    "        if sent == sentence:\n",
    "            paragraphs.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb8d7d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97019712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Electrically Erasable Programmable ROM (EEPROM): The next level of erasability is the EEPROM, which can be erased under software control. This is the most flexible type of ROM, and is now commonly used for holding BIOS programs. When you hear reference to a \"flash BIOS\" or doing a BIOS upgrade by \"flashing\", this refers to reprogramming the BIOS EEPROM with a special software program. Here we are blurring the line a bit between what \"read-only\" really means, but remember that this rewriting is done maybe once a year or so,',\n",
       " 'Different amounts of memory are used to store data values with different degrees of precision. The commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word). Converting the index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. In some cases this relationship can also avoid the use of division operations. As a result, most modern computer designs have word sizes (and other operand sizes) that are a power of two times the size of a byte.',\n",
       " 'An ISA specifies the behavior of machine code running on implementations of that ISA in a fashion that does not depend on the characteristics of that implementation, providing binary compatibility between implementations. This enables multiple implementations of an ISA that differ in characteristics such as performance, physical size, and monetary cost (among other things), but that are capable of running the same machine code, so that a lower-performance, lower-cost machine can be replaced with a higher-cost, higher-performance machine without having to replace software. It also enables the evolution of the microarchitectures of the implementations of that ISA, so that a newer, higher-performance implementation of an ISA can run software that runs on previous generations of implementations.',\n",
       " 'Programmable ROM (PROM): This is a type of ROM that can be programmed using special equipment (a PROM programmer.); it can be written to, but only once. This is useful for companies that make their own ROMs from software they write, because when they change their code they can create new PROMs without requiring expensive equipment. This is similar to the way a CD-ROM recorder works by letting you \"burn\" programs onto blanks once and then letting you read from them many times. In fact, programming a PROM is also called burning, just like burning a CD-R, and it is comparable in terms of its flexibility.',\n",
       " 'Pipelining improves performance by allowing a number of instructions to work their way through the processor at the same time. In the same basic example, the processor would start to decode (step 1) a new instruction while the last one was waiting for results. This would allow up to four instructions to be \"in flight\" at one time, making the processor look four times as fast. Although any one instruction takes just as long to complete (there are still four steps) the CPU as a whole \"retires\" instructions much faster.',\n",
       " 'When byte processing is to be a significant part of the workload, it is usually more advantageous to use the byte, rather than the word, as the unit of address resolution. Address values which differ by one designate adjacent bytes in memory. This allows an arbitrary character within a character string to be addressed straightforwardly. A word can still be addressed, but the address to be used requires a few more bits than the word-resolution alternative. The word size needs to be an integer multiple of the character size in this organization. This addressing approach was used in the IBM 360, and has been the most common approach in machines designed since then.',\n",
       " 'The memory model of an architecture is strongly influenced by the word size. In particular, the resolution of a memory address, that is, the smallest unit that can be designated by an address, has often been chosen to be the word. In this approach, the word-addressable machine approach, address values which differ by one designate adjacent memory words. This is natural in machines which deal almost always in word (or multiple-word) units, and has the advantage of allowing instructions to use minimally sized fields to contain addresses, which can permit a smaller instruction size or a larger variety of instructions.',\n",
       " 'Computer architecture is the organisation of the components which make up a computer system and the meaning of the operations which guide its function. It defines what is seen on the machine interface, which is targeted by programming languages and their compilers.',\n",
       " 'However, the choice of instruction set architecture may greatly affect the complexity of implementing high-performance devices. The prominent strategy, used to develop the first RISC processors, was to simplify instructions to a minimum of individual semantic complexity combined with high encoding regularity and simplicity. Such uniform instructions were easily fetched, decoded and executed in a pipelined fashion and a simple strategy to reduce the number of logic levels in order to reach high operating frequencies; instruction cache-memories compensated for the higher operating frequency and inherently low code density while large register sets were used to factor out as much of the (slow) memory accesses as possible.',\n",
       " 'This is a guide to Types of Computer Architecture. Here we discuss the basic concept and different types of computer architecture in detail. You may also have a look at the following articles to learn more –',\n",
       " 'The size of a word is reflected in many aspects of a computer\\'s structure and operation; the majority of the registers in a processor are usually word sized and the largest datum that can be transferred to and from the working memory in a single operation is a word in many (not all) architectures. The largest possible address size, used to designate a location in memory, is typically a hardware word (here, \"hardware word\" means the full-sized natural word of the processor, as opposed to any other definition used).',\n",
       " 'Pipelines are by no means limited to RISC designs. By 1986 the top-of-the-line VAX implementation (VAX 8800) was a heavily pipelined design, slightly predating the first commercial MIPS and SPARC designs. Most modern CPUs (even embedded CPUs) are now pipelined, and microcoded CPUs with no pipelining are seen only in the most area-constrained embedded processors.  Large CISC machines, from the VAX 8800 to the modern Pentium 4 and Athlon, are implemented with both microcode and pipelines. Improvements in pipelining and caching are the two major microarchitectural advances that have enabled processor performance to keep pace with the circuit technology on which they are based.',\n",
       " 'We have learned about computer architecture and its types. How functionality, implementation works in processing. Instruction set architecture is needed to do the needful instruction execution and data processing should be done in a different and single memory location in different types of computer architectures. Read/write operations are performed.',\n",
       " 'In applications where the memory-access patterns are well defined and discoverable at compile time, which is true of typical DSLs, programmers and compilers can optimize the use of the memory better than can dynamically allocated caches. DSAs thus usually use a hierarchy of memories with movement controlled explicitly by the software, similar to how vector processors operate. For suitable applications, user-controlled memories can use much less energy than caches.',\n",
       " 'The earliest computer architectures were designed on paper and then directly built into the final hardware form.  Later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (TTL) computer—such as the prototypes of the 6800 and the PA-RISC —tested, and tweaked, before committing to the final hardware form. As of the 1990s, new computer architectures are typically \"built\", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a FPGA as a soft microprocessor; or both—before committing to the final hardware form. ',\n",
       " 'Many researchers assume they must stop short because fabricating chips is unaffordable. When designs are small, they are surprisingly inexpensive. Architects can order 100 1-mm 2 chips for only $14,000. In 28 nm, 1 mm 2 holds millions of transistors, enough area for both a RISC-V processor and an NVLDA accelerator. The outermost level is expensive if the designer aims to build a large chip, but an architect can demonstrate many novel ideas with small chips.',\n",
       " 'They are very large in size and use multiple processors and superior technology. Super computers are biggest in size, the most expensive in price than any other is classified and known as super computer. It can process trillions of instructions in seconds. This computer is not used as a PC in a home neither by a student in a college. Governments specially use this type of computer for their different calculations and heavy jobs. Different industries also use this huge computer for designing their products.',\n",
       " \"\\uf0b7 Microarchitecture, also known as Computer organization is a lower level, more concrete and detailed, description of the system that involves how the constituent parts of the system are interconnected and how they interoperate in order to implement the ISA. The size of a computer's cache for instance, is an organizational issue that generally has nothing to do with the ISA.\",\n",
       " 'Software talks to hardware through a vocabulary called an instruction set architecture (ISA). By the early 1960s, IBM had four incompatible lines of computers, each with its own ISA, software stack, I/O system, and market nichetargeting small business, large business, scientific, and real time, respectively. IBM engineers, including ACM A.M. Turing Award laureate Fred Brooks, Jr., thought they could create a single ISA that would efficiently unify all four of these ISA bases.',\n",
       " 'Computer architecture concentrates on the logical aspects of computer design as opposed to the physical or electronic aspects. The underlying logical design of most modern computers is still based on that of the earliest electronic computers despite decades of progress in electronic circuitry. the innovations that have occurred in computer architecture have been driven by two different goals: higher performance and lower cost. Performance driven improvements have yielded computer systems with increasingly higher computation speeds and throughput. Cost driven improvements have yielded systems that are easier to use and applicable to a broader range of automatic control problems. Improvements in electronic circuitry have not led directly to architectural innovations; computers that pioneered new circuit technologies usually relied on older architectural concepts.',\n",
       " 'Another technique that has become more popular recently is multithreading. In multithreading, when the processor has to fetch data from slow system memory, instead of stalling for the data to arrive, the processor switches to another program or program thread which is ready to execute. Though this does not speed up a particular program/thread, it increases the overall system throughput by reducing the time the CPU is idle.',\n",
       " 'In modern designs it is common to find two load units, one store (many instructions have no results to store), two or more integer math units, two or more floating point units, and often a SIMD unit of some sort. The instruction issue logic grows in complexity by reading in a huge list of instructions from memory and handing them off to the different execution units that are idle at that point. The results are then collected and re-ordered at the end.',\n",
       " \"Gordon Moore believed Intel's next ISA would last the lifetime of Intel, so he hired many clever computer science Ph.D.'s and sent them to a new facility in Portland to invent the next great ISA. The 8800, as Intel originally named it, was an ambitious computer architecture project for any era, certainly the most aggressive of the 1980s. It had 32-bit capability-based addressing, object-oriented architecture, variable-bit-length instructions, and its own operating system written in the then-new programming language Ada.\",\n",
       " 'Conceptually, multithreading is equivalent to a context switch at the operating system level. The difference is that a multithreaded CPU can do a thread switch in one CPU cycle instead of the hundreds or thousands of CPU cycles a context switch normally requires. This is achieved by replicating the state hardware (such as the register file and program counter) for each active thread.',\n",
       " 'Modified harvard architecture is like a harvard architecture machine and it has a common address space for the separate data and instruction cache. It has digital signal processors that will execute small or highly audio or video algorithms and it is reproducible. Microcontrollers have a small number of programs and data memory and it speeds up the processing by executing parallel instructions and data access.',\n",
       " 'Harvard architecture is used when data and code is present in different memory blocks. A separate memory block is needed for data and instruction. Data can be accessed by one memory location and instruction can be accessed by a different location. It has data storage entirely contained within the central processing unit (CPU). A single set of clock cycles is required. The pipeline is possible. It is complex to design. CPU can read and write instructions and process data access. Harvard architecture has different access codes and data address spaces that is, the instruction address zero is not the same as data address zero. Instruction address zero identifies 24-byte value and data address zero identifies 8-byte value which is not the part of the 24-byte value.',\n",
       " 'computer architecture, structure of a digital computer, encompassing the design and layout of its instruction set and storage registers. The architecture of a computer is chosen with regard to the types of programs that will be run on it (business, scientific, general-purpose, etc.). Its principal components or subsystems, each of which could be said to have an architecture of its own, are input/output, storage, communication, control, and processing.',\n",
       " 'We began our Turing Lecture June 4, 2018 11 with a review of computer architecture since the 1960s. In addition to that review, here, we highlight current challenges and identify future opportunities, projecting another golden age for the field of computer architecture in the next decade, much like the 1980s when we did the research that led to our award, delivering gains in cost, energy, and security, as well as performance.',\n",
       " \"Real programs have more complex structures of course, with portions that allow varying numbers of processors to be used at any given moment in time. Nonetheless, the need to communicate and synchronize periodically means most applications have some portions that can effectively use only a fraction of the processors. Although Amdahl's Law is more than 50 years old, it remains a difficult hurdle.\",\n",
       " \"Benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. Although benchmarking shows strengths, it shouldn't be how you choose a computer. Often the measured machines split on different measures. For example, one system might handle scientific applications quickly, while another might render video games more smoothly. Furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but don't offer similar advantages to general tasks.\",\n",
       " 'In most of the Hollywood’s movies it is used for animation purposes. This kind of computer is also helpful for forecasting weather reports worldwide. They are known for von Newman’s design i. multiple processor system with parallel processing. In such a system a task is broken down and shared among processes for faster execution. They are used for complex tasks requiring a lot of computational power.',\n",
       " 'Although the term computer engineering sounds very complicated, its definition is easier than one might think. Computer engineering is a science or a set of rules stating how brain software and hardware are joined together and interact to make a computer work. It not only determines how the brain works but also of which technologies the computer is capable. Brains continue to be a major part of our lives, and brain architects reestablish to develop new and better policies and technologies.',\n",
       " 'Simply, it is a logical form of all electronic elements and data pathways present in the microprocessor, designed in a specific way. It allows for the optimal completion of instructions. In academe, it is called computer organization. System Design System design itself defines a design that can serve user requirements like system architecture, computer modules having various interfaces, and data management within a system. The term product development is connective to the system design. It is the process by which we can take marketing information to create a product design. report this ad',\n",
       " 'The first example is RISC-V (called \"RISC Five\"), the fifth RISC architecture developed at the University of California, Berkeley. 32 RISC-V\\'s has a community that maintains the architecture under the stewardship of the RISC-V Foundation (http://riscv.org/). Being open allows the ISA evolution to occur in public, with hardware and software experts collaborating before decisions are finalized. An added benefit of an open foundation is the ISA is unlikely to expand primarily for marketing reasons, sometimes the only explanation for extensions of proprietary instruction sets.',\n",
       " 'One of the first, and most powerful, techniques to improve performance is the use of instruction pipelining. Early processor designs would carry out all of the steps above for one instruction before moving onto the next. Large portions of the circuitry were left idle at any one step; for instance, the instruction decoding circuitry would be idle during execution and so on.',\n",
       " 'Historically, the earliest computers were multicycle designs. The smallest, least-expensive computers often still use this technique. Multicycle architectures often use the least total number of logic elements and reasonable amounts of power. They can be designed to have deterministic timing and high reliability. In particular, they have no pipeline to stall when taking conditional branches or interrupts. However, other microarchitectures often perform more instructions per unit time, using the same logic family. When discussing \"improved performance,\" an improvement is often relative to a multicycle design.',\n",
       " 'The central computation concept of this architecture is that instructions and data are both loaded into the same memory unit, which is the main memory of the computer and consists of a set of addressable locations. The processor can then access the instructions and data required for the execution of a computer program using dedicated connections called buses – an address bus which is used to identify the addressed location and a data bus which is used to transfer the contents to and from a location.',\n",
       " 'Inspired by the success of open source software, the second opportunity in computer architecture is open ISAs. To create a \"Linux for processors\" the field needs industry-standard open ISAs so the community can create open source cores, in addition to individual companies owning proprietary ones. If many organizations design processors using the same ISA, the greater competition may drive even quicker innovation. The goal is to provide processors for chips that cost from a few cents to $100.',\n",
       " 'The design of instruction sets is a complex issue. There were two stages in history for the microprocessor. The first was the CISC (Complex Instruction Set Computer), which had many different instructions. In the 1970s, however, places like IBM did research and found that many instructions in the set could be eliminated. The result was the RISC (Reduced Instruction Set Computer), an architecture that uses a smaller set of instructions. A simpler instruction set may offer the potential for higher speeds, reduced processor size, and reduced power consumption. However, a more complex set may optimize common operations, improve memory and cache efficiency, or simplify programming.',\n",
       " 'When designing the microarchitecture of a processor, engineers use blocks of \"hard-wired\" electronic circuitry (often designed separately) such as adders, multiplexers, counters, registers, ALUs, etc. Some kind of register transfer language is then often used to describe the decoding and sequencing of each instruction of an ISA using this physical microarchitecture. There are two basic ways to build a control unit to implement this description (although many designs use middle ways or compromises):',\n",
       " 'The term “ engineering ” in computer literature can be delineated to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM’s main research center in 1959. Johnson had the opportunity to write a proprietary research transmission about the Stretch, an IBM-developed supercomputer for Los A lamos National Workshop (at the time known as Los A lamos Scientific Laboratory). To portray the level of detail for discussing the luxuriously embellished computer, he noted that his explanation of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that suggested more useful than “machine management ”.',\n",
       " 'Mainframe computers A mainframe is another giant computer after the super computer and can also process millions of instruction per second and capable of accessing billions of data .They are physically very large in size with very high capacity of main memory. This computer is commonly used in big hospitals, air line reservations companies, and many other huge companies prefer mainframe because of its capability of retrieving data on a huge basis. They can be linked to smaller computers and handle hundreds of users they are also used in space exploitation. The term mainframe was mainly used for earliest computers as they were big in size though today the term is used to refer to large computers. A large number of peripherals can be attached to them. They are expensive to install.',\n",
       " 'Character size was in the past (pre-variable-sized character encoding) one of the influences on unit of address resolution and the choice of word size. Before the mid-1960s, characters were most often stored in six bits; this allowed no more than 64 characters, so the alphabet was limited to upper case. Since it is efficient in time and space to have the word size be a multiple of the character size, word sizes in this period were usually multiples of 6 bits (in binary machines). A common choice then was the 36-bit word, which is also a good size for the numeric properties of a floating point format.',\n",
       " 'In early 1960s computers, main memory was expensive and very limited, even on mainframes. Minimizing the size of a program to make sure it would fit in the limited memory was often central. Thus the size of the instructions needed to perform a particular task, the code density, was an important characteristic of any instruction set. It remained important on the initially-tiny memories of minicomputers and then microprocessors. Density remains important today, for smartphone applications, applications downloaded into browsers over slow Internet connections, and in ROMs for embedded applications. A more general advantage of increased density is improved effectiveness of caches and instruction prefetch.',\n",
       " 'Each memory has multiple locations and each location has a unique address. We can address the contents of memory by its location irrespective of what type of data and instructions are present in the memory, because of which we can read or write any data and instructions. Execution always occurs in a sequential manner unless the change is required. For example, suppose we are executing an instruction from line 1 to line 10 but now we required to execute line 50 instead of line 11 then we jump to instruction 50 and execute it.',\n",
       " 'To appreciate how this wasted work adds up, consider the data in Figure 4, showing the fraction of instructions that are effectively executed but turn out to be wasted because the processor speculated incorrectly. On average, 19% of the instructions are wasted for these benchmarks on an Intel Core i7. The amount of wasted energy is greater, however, since the processor must use additional energy to restore the state when it speculates incorrectly. Measurements like these led many to conclude architects needed a different approach to achieve performance improvements. The multicore era was thus born.',\n",
       " 'Reduced instruction-set computers, RISC, were first widely implemented during a period of rapidly growing memory subsystems. They sacrifice code density to simplify implementation circuitry, and try to increase performance via higher clock frequencies and more registers. A single RISC instruction typically performs only a single operation, such as an \"add\" of registers or a \"load\" from a memory location into a register. A RISC instruction set normally has a fixed instruction length, whereas a typical CISC instruction set has instructions of widely varying length. However, as RISC computers normally require more and often longer instructions to implement a given task, they inherently make less optimal use of bus bandwidth and cache memories.',\n",
       " 'Although the term computer architecture sounds very complicated, its definition is easier than one might think. Computer architecture is a science or a set of rules stating how computer software and hardware are joined together and interact to make a computer work. It not only determines how the computer works but also of which technologies the computer is capable. Computers continue to be a major part of our lives, and computer architects continue to develop new and better programs and technologies.',\n",
       " 'At the end of the chapter the learner shall be able to; \\uf0b7 Explain the different hardware units of a computer system such as input, output, Central processing unit (CPU), main memory and secondary storage \\uf0b7 Explain how the different units of a computer interact witch each other to give the user output \\uf0b7 Explain how information is stored in a computer \\uf0b7 Explain the different storage units of a computer such as byte, Kilobyte,',\n",
       " 'In contrast, the embedded computer is normally dedicated to a specific task. In many cases, an embedded system is used to replace application-specific electronics. The advantage of using an embedded microprocessor over dedicated electronics is that the functionality of the system is determined by the software, not the hardware. This makes the embedded system easier to produce, and much easier to evolve, than a complicated circuit.',\n",
       " 'Some manufacturers chose to make microprogramming available by letting select customers add custom features they called \"writable control store\" (WCS). The most famous WCS computer was the Alto 36 Turing laureates Chuck Thacker and Butler Lampson, together with their colleagues, created for the Xerox Palo Alto Research Center in 1973. It was indeed the first personal computer, sporting the first bit-mapped display and first Ethernet local-area network. The device controllers for the novel display and network were microprograms stored in a 4,096-word x 32-bit WCS.',\n",
       " 'In the outline above the processor processes parts of a single instruction at a time. Computer programs could be executed faster if multiple instructions were processed simultaneously. This is what superscalar processors achieve, by replicating functional units such as ALUs. The replication of functional units was only made possible when the die area of a single-issue processor no longer stretched the limits of what could be reliably manufactured. By the late 1980s, superscalar designs started to enter the market place.',\n",
       " 'The architecture semantics is the meaning of what the systems do under user direction and how their functional units are controlled to work together. An important embodiment of semantics is the instruction set architecture (ISA) of the system. The ISA is a logical (usually binary) representative encoding of the basic set of distinct operations that a computer architecture may perform, and by which application programs specify the useful work to be done. At the machine level, the hardware (sometimes controlled by firmware) system directly interprets and executes a sequence or partially ordered set of these basic operations.',\n",
       " 'Several of the earliest computers (and a few modern as well) used binary-coded decimal rather than plain binary, typically having a word size of 10 or 12 decimal digits, and some early decimal computers had no fixed word length at all. Early binary systems tended to use word lengths that were some multiple of 6-bits, with the 36-bit word being especially common on mainframe computers. The introduction of ASCII led to the move to systems with word lengths that were a multiple of 8-bits, with 16-bit machines being popular in the 1970s before the move to modern processors with 32 or 64 bits.  Special-purpose designs like digital signal processors, may have any word length from 4 to 80 bits. ',\n",
       " 'Conditional instructions often have a predicate field—a few bits that encode the specific condition to cause an operation to be performed rather than not performed. For example, a conditional branch instruction will transfer control if the condition is true, so that execution proceeds to a different part of the program, and not transfer control if the condition is false, so that execution continues sequentially. Some instruction sets also have conditional moves, so that the move will be executed, and the data stored in the target location, if the condition is true, and not executed, and the target location not modified, if the condition is false. Similarly, IBM z/Architecture has a conditional store instruction. A few instruction sets include a predicate field in every instruction; this is called branch predication.',\n",
       " 'A Brief History of Computer Architecture Computer Architecture is the field of study of selecting and interconnecting hardware components to create computers that satisfy functional performance and cost goals. It refers to those attributes of the computer system that are visible to a programmer and have a direct effect on the execution of a program.',\n",
       " 'The addition of caches reduces the frequency or duration of stalls due to waiting for data to be fetched from the memory hierarchy, but does not get rid of these stalls entirely. In early designs a cache miss would force the cache controller to stall the processor and wait. Of course there may be some other instruction in the program whose data is available in the cache at that point. Out-of-order execution allows that ready instruction to be processed while an older instruction waits on the cache, then re-orders the results to make it appear that everything happened in the programmed order. This technique is also used to avoid other operand dependency stalls, such as an instruction awaiting a result from a long latency floating-point operation or other multi-cycle operations.',\n",
       " 'Computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. The case of instruction set architecture can be used to illustrate the balance of these competing factors. More complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 Loop instruction).  However, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. The increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.',\n",
       " 'The challenge when using DSLs is how to retain enough architecture independence that software written in a DSL can be ported to different architectures while also achieving high efficiency in mapping the software to the underlying DSA. For example, the XLA system translates Tensorflow to heterogeneous processors that use Nvidia GPUs or Tensor Processor Units (TPUs). 40 Balancing portability among DSAs along with efficiency is an interesting research challenge for language designers, compiler creators, and DSA architects.',\n",
       " \"Prior to NPL , the company's computer designers had been free to honor cost objectives not only by selecting technologies but also by fashioning functional and architectural refinements. The SPREAD compatibility objective, in contrast, postulated a single architecture for a series of five processors spanning a wide range of cost and performance. None of the five engineering design teams could count on being able to bring about adjustments in architectural specifications as a way of easing difficulties in achieving cost and performance objectives. : p.137\",\n",
       " 'Some students choose to complete an MBA (master’s of business administration) with a focus on information systems. The advantage of this program is that it offers both computer-related and business courses. Even after earning the degree, applicants may be required to have at least five years of experience working with IT systems before being hired as a computer architect. Some computer architects go on to become computer and information systems managers once they’ve obtained sufficient experience.',\n",
       " 'Complex instructions are more common in CISC instruction sets than in RISC instruction sets, but RISC instruction sets may include them as well. RISC instruction sets generally do not include ALU operations with memory operands, or instructions to move large blocks of memory, but most RISC instruction sets include SIMD or vector instructions that perform the same arithmetic operation on multiple pieces of data at the same time. SIMD instructions have the ability of manipulating large vectors and matrices in minimal time. SIMD instructions allow easy parallelization of algorithms commonly involved in sound, image, and video processing. Various SIMD implementations have been brought to market under trade names such as MMX, 3DNow!, and AltiVec.',\n",
       " 'It was not long before improvements in chip manufacturing allowed for even more circuitry to be placed on the die, and designers started looking for ways to use it. One of the most common was to add an ever-increasing amount of cache memory on-die. Cache is very fast and expensive memory. It can be accessed in a few cycles as opposed to many needed to \"talk\" to main memory. The CPU includes a cache controller which automates reading and writing from the cache. If the data is already in the cache it is accessed from there – at considerable time savings, whereas if it is not the processor is \"stalled\" while the cache controller reads it in.',\n",
       " 'The size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. If multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see Size families below).',\n",
       " 'The RISC architecture was the result of a rethink, which has led to the development of high-performance processors. The hardware is kept as simple and fast as possible, and complex instructions can be performed with simpler instructions.',\n",
       " 'There are two main types of speed: latency and throughput. Latency is the time between the start of a process and its completion. Throughput is the amount of work done per unit time. Interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).',\n",
       " \"The term “architecture” in computer literature can be traced to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM's main research center in 1959. Johnson had the opportunity to write a proprietary research communication about the Stretch, an IBM-developed supercomputer for Los Alamos National Laboratory (at the time known as Los Alamos Scientific Laboratory). To describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of “system architecture”, a term that seemed more useful than “machine organization”. \",\n",
       " 'This is true for all computer cores, from those few in the smallest mobile phones to potentially millions making up the world’s largest supercomputers. High-performance computer architecture extends structure to a hierarchy of functional elements, whether small and limited in capability or possibly entire processor cores themselves. In this chapter many different classes of the structure are presented, each exploiting concurrency in its own particular way. But in all cases, this more broad definition of a general architecture for high-performance computing emphasizes aspects of the system that contribute to achieving performance.',\n",
       " \"Inherent inefficiencies in general-purpose processors, whether from ILP techniques or multicore, combined with the end of Dennard scaling and Moore's Law, make it highly unlikely, in our view, that processor architects and designers can sustain significant rates of performance improvements in general-purpose processors. Given the importance of improving performance to enable new software capabilities, we must ask: What other approaches might be promising?\",\n",
       " 'An ISA may be classified in a number of different ways. A common classification is by architectural complexity. A complex instruction set computer (CISC) has many specialized instructions, some of which may only be rarely used in practical programs. A reduced instruction set computer (RISC) simplifies the processor by efficiently implementing only the instructions that are frequently used in programs, while the less common operations are implemented as subroutines, having their resulting additional processor execution time offset by infrequent use. ',\n",
       " 'Microarchitecture is also known as computer organisation and defines the data processing and storage element and how they should be implemented into the ISA. It is the hardware implementation of how an ISA is implemented in a particular processor.',\n",
       " \"The end of Dennard scaling and Moore's Law and the deceleration of performance gains for standard microprocessors are not problems that must be solved but facts that, recognized, offer breathtaking opportunities. High-level, domain-specific languages and architectures, freeing architects from the chains of proprietary instruction sets, along with demand from the public for improved security, will usher in a new golden age for computer architects. Aided by open source ecosystems, agilely developed chips will convincingly demonstrate advances and thereby accelerate commercial adoption. The ISA philosophy of the general-purpose processors in these chips will likely be RISC, which has stood the test of time. Expect the same rapid improvement as in the last golden age, but this time in terms of cost, energy, and security, as well as in performance.\",\n",
       " 'Erasable Programmable ROM (EPROM): An EPROM is a ROM that can be erased and reprogrammed. A little glass window is installed in the top of the ROM package, through which you can actually see the chip that holds the memory. Ultraviolet light of a specific frequency can be shined through this window for a specified period of time, which will erase the EPROM and allow it to be reprogrammed again. Obviously this is much more useful than a regular PROM, but it does require the erasing light. Continuing the \"CD\" analogy, this technology is analogous to a reusable CD-RW.',\n",
       " 'Each microarchitectural element is in turn represented by a schematic describing the interconnections of logic gates used to implement it. Each logic gate is in turn represented by a circuit diagram describing the connections of the transistors used to implement it in some particular logic family. Machines with different microarchitectures may have the same instruction set architecture, and thus be capable of executing the same programs. New microarchitectures and/or circuitry solutions, along with advances in semiconductor manufacturing, are what allows newer generations of processors to achieve higher performance while using the same ISA.',\n",
       " 'The exact form of a computer system depends on the constraints and goals. Computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. Sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.',\n",
       " 'AMD and Intel used 500-person design teams and superior semiconductor technology to close the performance gap between x86 and RISC. Again inspired by the performance advantages of pipelining simple vs. complex instructions, the instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly. AMD and Intel then pipelined the execution of the RISC microinstructions. Any ideas RISC designers were using for performanceseparate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneouslycould then be incorporated into the x86. AMD and Intel shipped roughly 350 million x86 microprocessors annually at the peak of the PC era in 2011. The high volumes and low margins of the PC industry also meant lower prices than RISC computers.',\n",
       " 'A high-performance computer is designed to go fast, and its organization and semantics are specially devised to deliver computational speed. This chapter introduces the basic foundations of computer architecture in general and for high-performance computer systems in particular. It is here, at the structural and logical levels, that parallelism of operation in its many forms and size is first presented. This chapter provides a first examination of the principal forms of supercomputer architecture and the underlying concepts that govern their performance.',\n",
       " 'The demands of high-speed digital signal processing have pushed in the opposite direction—forcing instructions to be implemented in a particular way. For example, to perform digital filters fast enough, the MAC instruction in a typical digital signal processor (DSP) must use a kind of Harvard architecture that can fetch an instruction and two data words simultaneously, and it requires a single-cycle multiply–accumulate multiplier.',\n",
       " 'As computer designs have grown more complex, the central importance of a single word size to an architecture has decreased. Although more capable hardware can use a wider variety of sizes of data, market forces exert pressure to maintain backward compatibility while extending processor capability. As a result, what might have been the central word size in a fresh design has to coexist as an alternative size to the original word size in a backward compatible design. The original word size remains available in future designs, forming the basis of a size family.',\n",
       " 'VLIW, EPIC, Itanium. The next ISA innovation was supposed to succeed both RISC and CISC. Very long instruction word (VLIW) 7 and its cousin, the explicitly parallel instruction computer (EPIC), the name Intel and Hewlett Packard gave to the approach, used wide instructions with multiple independent operations bundled together in each instruction. VLIW and EPIC advocates at the time believed if a single instruction could specify, say, six independent operationstwo data transfers, two integer operations, and two floating point operationsand compiler technology could efficiently assign operations into the six instruction slots, the hardware could be made simpler. Like the RISC approach, VLIW and EPIC shifted work from the hardware to the compiler.',\n",
       " 'Register renaming refers to a technique used to avoid unnecessary serialized execution of program instructions because of the reuse of the same registers by those instructions. Suppose we have two groups of instruction that will use the same register. One set of instructions is executed first to leave the register to the other set, but if the other set is assigned to a different similar register, both sets of instructions can be executed in parallel (or) in series.',\n",
       " 'Cache memory After Random Access Memory ( RAM) Cache memory is a type of very fast memory that is used to improve the speed of a computer doubling it in some cases. It acts as an intermediate store between the CPU and the maim memory, and works by storing the most frequently or recently used instructions and data so that it will be very fast to retrieve them again.',\n",
       " 'Minimal instruction set computers (MISC) are a form of stack machine, where there are few separate instructions (16-64), so that multiple instructions can be fit into a single machine word. These types of cores often take little silicon to implement, so they can be easily realized in an FPGA or in a multi-core form. The code density of MISC is similar to the code density of RISC; the increased instruction density is offset by requiring more of the primitive instructions to do a task.  ',\n",
       " 'Most of these machines work on one unit of memory at a time and since each instruction or datum is several units long, each instruction takes several cycles just to access memory. These machines are often quite slow because of this. For example, instruction fetches on an IBM 1620 Model I take 8 cycles just to read the 12 digits of the instruction (the Model II reduced this to 6 cycles, or 4 cycles if the instruction did not need both address fields). Instruction execution took a completely variable number of cycles, depending on the size of the operands.',\n",
       " 'Embedded hardware is often much simpler than a desktop system, but it can also be far more complex too. An embedded computer may be implemented in a single chip with just a few support components, and its purpose may be as crude as a controller for a garden-watering system. Alternatively, the embedded computer may be a 150-processor, distributed parallel machine responsible for all the flight and control systems of a commercial jet. As diverse as embedded hardware may be, the underlying principles of design are the same.',\n",
       " \"Computer organization helps optimize performance-based products. For example, software engineers need to know the processing power of processors. They may need to optimize software in order to gain the most performance for the lowest price. This can require quite a detailed analysis of the computer's organization. For example, in an SD card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.\",\n",
       " 'In computer engineering, microarchitecture, also called computer organization and sometimes abbreviated as µarch or uarch, is the way a given instruction set architecture (ISA) is implemented in a particular processor.  A given ISA may be implemented with different microarchitectures;   implementations may vary due to different goals of a given design or due to shifts in technology. ',\n",
       " 'An instruction set architecture is distinguished from a microarchitecture, which is the set of processor design techniques used, in a particular processor, to implement the instruction set. Processors with different microarchitectures can share a common instruction set. For example, the Intel Pentium and the AMD Athlon implement nearly identical versions of the x86 instruction set, but they have radically different internal designs.',\n",
       " 'The microarchitecture of a machine is usually represented as (more or less detailed) diagrams that describe the interconnections of the various microarchitectural elements of the machine, which may be anything from single gates and registers, to complete arithmetic logic units (ALUs) and even larger elements. These diagrams generally separate the datapath (where data is placed) and the control path (which can be said to steer the data). ',\n",
       " 'Counting machine-language instructions would be misleading because they can do varying amounts of work in different ISAs. The \"instruction\" in the standard measurements is not a count of the ISA\\'s machine-language instructions, but a unit of measurement, usually based on the speed of the VAX computer architecture.',\n",
       " 'This includes the functions and capabilities of the central processing unit (CPU). It is the embedded programming language and defines what programming it can perform or process. This part is the software that makes the computer run, such as operating systems like Windows on a PC or iOS on an Apple iPhone, and includes data formats and the programmed instruction set.',\n",
       " 'Subsequently, Brooks, a Stretch designer, opened Chapter 2 of a book called Planning a Computer System: Project Stretch by stating, “Computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.” ',\n",
       " 'RISC makes pipelines smaller and much easier to construct by cleanly separating each stage of the instruction process and making them take the same amount of time—one cycle. The processor as a whole operates in an assembly line fashion, with instructions coming in one side and results out the other. Due to the reduced complexity of the classic RISC pipeline, the pipelined core and an instruction cache could be placed on the same size die that would otherwise fit the core alone on a CISC design. This was the real reason that RISC was faster. Early designs like the SPARC and MIPS often ran over 10 times as fast as Intel and Motorola CISC solutions at the same clock speed and price.',\n",
       " 'There are a number of reasons why the von Neumann architecture has proven to be so successful. It is relatively easy to implement in hardware, and von Neumann machines are deterministic and introspectable. They can be described mathematically and every step of their computing process is understood. You can also rely on them to always generate the same output on one set of inputs.',\n",
       " 'Computer architects have become stymied by the growing mismatch in CPU operating frequencies and DRAM access times. None of the techniques that exploited instruction-level parallelism (ILP) within one program could make up for the long stalls that occurred when data had to be fetched from main memory. Additionally, the large transistor counts and high operating frequencies needed for the more advanced ILP techniques required power dissipation levels that could no longer be cheaply cooled. For these reasons, newer generations of computers have started to exploit higher levels of parallelism that exist outside of a single program or program thread.',\n",
       " \"An era without Dennard scaling, along with reduced Moore's Law and Amdahl's Law in full effect means inefficiency limits improvement in performance to only a few percent per year (see Figure 6). Achieving higher rates of performance improvementas was seen in the 1980s and 1990swill require new architectural approaches that use the integrated-circuit capability much more efficiently. We will return to what approaches might work after discussing another major shortcoming of modern computerstheir support, or lack thereof, for computer security.\",\n",
       " 'Reduced instruction set computer architecture was realized in the 90’s by IBM. Instruction has multiple address modes, but programs do not use all of them that is the reason multiple address modes were reduced. This helps the compiler to easily write the instructions, performed is increased.',\n",
       " 'ROM: A mask programmed read only memory that can be only be produced by the manufacturer. It is designed to perform a specific function and cannot be changed. This is inflexible and so regular ROMs are only used generally for programs that are static (not changing often) and mass-produced. This product is analogous to a commercial software CD-ROM that you purchase in a store.',\n",
       " 'An ISA can also be emulated in software by an interpreter. Naturally, due to the interpretation overhead, this is slower than directly running programs on the emulated hardware, unless the hardware running the emulator is an order of magnitude faster. Today, it is common practice for vendors of new ISAs or microarchitectures to make software emulators available to software developers before the hardware implementation is ready.',\n",
       " 'CISC processors have a single processing unit, external memory, and a small register set with hundreds of different instructions. These processors have a single instruction to perform a task, and have the advantage of making the job of the programmer easier, as fewer lines of code are needed to get the job done. This approach uses less memory, but can take longer to complete instructions.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cfa0c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [01:38<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = defaultdict(list)\n",
    "label = []\n",
    "for sentence in tqdm(paragraphs):\n",
    "    temp = []\n",
    "    for i in features:\n",
    "        temp.append(float(cosine_similarity([i], [model.encode(sentence)])[0][0]))\n",
    "    label.append(important_subsections[np.argmax(temp)])\n",
    "    dataset[important_subsections[np.argmax(temp)]].append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19d51465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "74\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for k, v in dataset.items():\n",
    "    print(len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29384c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba5d8940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['type', 'intro', 'history'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1f69ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:20<00:00,  4.94it/s]\n"
     ]
    }
   ],
   "source": [
    "embs = []\n",
    "\n",
    "for sentence in tqdm(paragraphs):\n",
    "    embs.append(model.encode(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa432f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "x = pca.fit_transform(embs)[:,0]\n",
    "y = pca.fit_transform(embs)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4765a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bef5be25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAJBCAYAAABxiHCMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABgcUlEQVR4nO3dd5xddZ3/8dc559aZO72mkYSEJIQkdBJCEwRS6EWlCLvKD0SEiHVlAcuiC4vu2ncVVxeVIigIohCKSBDpndAJJXUyvc9t53x/fwwZGCYhycy9c255P//w4f3c9mG+mTvv+z3f8z2WMcYgIiIiIllh+92AiIiISCFT2BIRERHJIoUtERERkSxS2BIRERHJIoUtERERkSxS2BIRERHJIoUtERERkSwK+N3A9nR09OF5mdsKrKYmRltbb8ZeTzJHY5O7NDa5S2OTuzQ2uSlb42LbFlVVpVu9L+fDlueZjIatLa8puUljk7s0NrlLY5O7NDa5abzHRYcRRURERLJIYUtEREQki3L+MKKIiIiML9dN09HRQjqd9LuVjGtutvE8b9TPDwRCVFXV4Tg7HqEUtkRERGSYjo4WIpESSksbsSzL73YyKhCwSadHF7aMMfT1ddPR0UJt7YQdfp4OI4qIiMgw6XSS0tLyggtaY2VZFqWl5Ts946ewJSIiIiMoaG3daH4uClsiIiIiWaSwJSIiIjmrt7eXSy75kt9tjInCloiIiOSsnp5uXn/9Nb/bGBOdjSgiIiJj9siLTdy6ag1t3QlqysOcfNgMDtyjccyv+4MffJfW1hYuueTLTJs2nc985nMA/Pu/f4uFCw/k0UcfxrIs3nxzDb29vfzzP5/D0qXH0N/fz3/913/w5ptr8DyPM888m6OOWjrmfkZDM1siIiIyJo+82MSv73qFtu4EAG3dCX591ys88mLTmF/74ou/Qm1tHRdeeDH33Xc3xhgGBgZ48snHOeSQjwDQ0tLMz372K370o//hpz/9IW1trfz6179k9uzd+dWvruOnP72G3/zmV2zYsH7M/YyGZrZERERkTG5dtYbkB/auSqY9bl21JiOzWwCTJk2msXECzz77NJs3N7F48cGEQiEAli8/jkAgQH19A/Pn78nzzz/Lk08+TiIR5y9/+RMA8Xict956k6lTd8lIPztDYUtERETGZMuM1o7WR+uYY47n3ntXsnnzZj796fOG6u/fzd0YD8cJ4Hkul19+BbNnzwGgvb2N8vKKjPazo3QYUURERMakpjy8U/Wd4TgOrusCcPjhH+Wpp56gvb2VPfaYN/SY+++/F2MMTU2beOml1ey5517ss8/+3HbbHwBobW3ln/7pdDZvHvthzdFQ2BIREZExOfmwGYQCwyNFKGBz8mEzxvza1dU1NDQ0ctFFnyEcjjBv3nyOPHLJsMckEnHOOecsvvKVz/OVr1xKRUUln/70uSQSCc466+N8/vPnc8EFK5g0afKY+xkNHUYUERGRMdmyLisbZyMGAgF+9rNfvXtdwl5effVVLrjg88Mec/jhR7J8+XHDaqWlMb7+9SvG/P6ZoLAlIiIiY3bgHo0ZWwy/NS+//CJf+tIKPvWpc6mpqc3a+2SDwpaIiIjkvLlz53HXXfePqF966TfHv5mdpDVbMm48Ay3dCV7b0E1HXwos43dLIiIiWaeZLRkXnoFVz2/it3e9DIBjW3zx9H3YY2olnqfQJSIihUszWzIu2noSQ0ELwPUM/33Lc3QPpH3sSkREJPsUtmRcdPaO3NiuL56mL57yoRsREZHxo7Al46K2MkrAsYbVaioiVMRCPnUkIiIyPhS2ZFxUlQT54un7UBoNAlBbGeGLp+9DNKB/giIi8uFeeeUlrrpq23tmPfTQg/zud9eNY0c7RwvkZdzsPqWSqz67mL54ivKSEJGAjdHaeBGRgpB8/WGST9yC6W3DitUQ2v8UQrstzshrz5kzl699be4273/11Ze3eV8uUNiScWOMoTTkUBpy/G5FREQyKPn6wyT+fi2kkwCY3rbB25CRwPX000/yq19dA8DcuXvw3HPP0tnZwcUXf4XGxgncfvutADQ2TqCpaRMvvria5uYmTj754+y33wFcffV36OnpJhKJ8qUvfZVZs3Yfc087Q2FLRERExiT5xC1DQWtIOknyiVsyNru1RSqV5uc//z8eeuhBfvGL/+FXv7qOE044GYBjjjmeX/7y5ySTCa677vcAnHvu2Xzyk//MYYcdwerVL/Cv//oVbrjhVkKh8VszrAUzIiIiMiamt22n6mOxcOGBAOy66wx6erq3+pi5c+cB0N/fz/r16znssCMAmDdvPuXlFaxd+07G+/owClsiIiIyJlasZqfqY7FlRsqyLMw2Fv6Gw2EAjPFGPMYYg+u6Ge/rwyhsiYiIyJiE9j8FAh84LBcIDdbHgeM4Ww1QpaUxJk2azKpVg9dUXL36Bdra2th11xnj0tcWWrMlIiIiY7JlXVa2zkbcnr322ofvfOebVFdXj7jv61+/gu9+99/55S9/TjAY4qqrvkcwGByXvrawzLbm4HJEW1tvRq+dV1dXRktLT8ZeTzJHY5O7NDa5S2OTu/J5bJqa3qGxcarfbWRFIGCTTntjeo2t/Xxs26KmJrbVx+swooiIiEgWKWyJiIiIZJHCloiIiEgWKWyJiIiIZJHCloiIiEgWKWyJiIiIZJHCloiIiOS0p59+kgsvPG9YrbW1hS9/ecU2n9Pb28sll3wp263tEIUtERERyTu1tXV873s/2ub9PT3dvP76a+PY0bZpB3kREREZs8ebnuZPa1bSkeikKlzJ8TOWckDjPhl7/c7OTr785RVs2LCeXXaZyuc+93m++MWL+MMf7uCee1Zyww2/wbZtJk6cyOWXX8EPfvBdWltbuOSSL3Plld/jL3/5E7/73XXYts2sWXP4whe+SklJCcceeySzZu1Oe3sbU6dOY5999uOEE04G4KKLPsP551/EHnvMG1PvmtkSERGRMXm86WlueOUWOhKdAHQkOrnhlVt4vOnpjL3H5s1NfPGL/8L11/+B9vY2nnji8aH7fvGL/+H73/8Jv/rVdeyyyzTWrn2biy/+CrW1dVx55fdYs+YNfvObX/GTn1zD9dffTCQS5f/+7xfAYIj75Cf/iWuvvYETTjiZe+65C4Cmpk10dHSMOWiBwpaIiIiM0Z/WrCTlpYbVUl6KP61ZmbH3mDlzNyZOnIRt20ydOp2urs6h+w466BA++9lz+OlPf8jixYew226zhz332Wef4qCDDqGiohKA448/iaeeei+sbQlUe++9L62tLWzatJGVK//C0qXLM9K7wpaIiIiMyZYZrR2tj4bjOEP/37IsGhsnDN2++OIv8+1vX015eTlXXHE5d99957DnjrzGssF13aFb4XBk6HWXLTuW++67m/vvv5elS4/JSO8KWyIiIjImVeHKnapnUjqd5rTTTqKyspKzzvoUS5cew2uvvYrjOEOBau+99+Whhx6ku7sLgD/96Tb23nu/rb7esmXHctttt1Bf30BtbV1GelTYEhERkTE5fsZSgnZwWC1oBzl+xtKsv3cgEOCccz7DxRdfwDnnnMWzzz7DaaedSXV1DQ0NjVx00WeYOXM3zjrrU1x44Xl84hMn09vbw3nnfXarr9fQ0EhDQyPLlh2XsR4tY8wH59ZySltb71am/0avrq6MlpaejL2eZI7GJndpbHKXxiZ35fPYNDW9Q2Pj1J16TrbPRsyUQMAmnfa2ep8xhra2Vi688Dx+85ubCIVCW33c1n4+tm1RUxPb+nuOrWUZT5Zl4Tg2ruuS2xFZRESKzQGN++RkuNoZDzzwV/7zP6/iS1/62jaD1mgobOWJ7niaJ17ezAtr2th/bgN7zaylNORs/4kiIiKyQw4//EgOP/zIjL+uwlYeSLqGH938LG9u7Abg+TdaOXDeBM45dnctuhMREclx+ludBzZ3DAwFrS0eWb2Jtp6ETx2JiEihy/El3b4Zzc9FYSsvbH1gLaxx7kNERIpBIBCir69bgesDjDH09XUTCOzcei4dRswD9VVRZkyqYM2GrqHaQQsmUB3L3OI9ERGRLaqq6ujoaKG3t9PvVjLOtm08b+tnI+6IQCBEVdXO7b+lsJUHwo7NRR/bk6dfbWb1m23sN6eB+TNqsDWxJSIiWeA4AWprJ2z/gXnIjy05FLbyRHkkwOF7TeLIfSfjup62fhAREckTClt5xBhDOq2UJSIikk+0QF5EREQkixS2RERERLJIYUtEREQkixS2RERERLJIYUtEREQkixS2RERERLJIYUtEREQkixS2RERERLJIYUtEREQkixS2RERERLJIYUtEREQkixS2RERERLJIYUtEREQkixS2RERERLJIYUtEREQkixS2RERERLJIYUtEREQkixS2RERERLJIYUtEREQkixS2RERERLJIYUtEREQkixS2RERERLJIYUtEREQkixS2RERERLJIYUtEREQkixS2RERERLJIYUtEREQkixS2RERERLJIYUtkKxzHxnH06yEiImMX8LsBkZxiGZpSm3jwzUdJe2kO3WURE8OTsc34By/LgqDbj+WlSIfKcD2FPxGRfKSwJfI+m1NNfPvvP8QYA8A/1j7J1w76HFPCU8e1DwcXZ9NqOv/6f7j93ZTOO4zofieQCFaOax8iIjJ2+qos8i7HsXh0w9NDQWuLe95cheNY49pLoGc9bX/6Pm5fJxiPvhf+Rvy5ldiW2e5zRUQktyhsibyfGRlmjDEwvlkLt33DiFrf6lUE033j24iIiIyZwpbIu1zXsHDSPljW8GR19K4fwU2P74ySHSkbUQtUNuA5oXHtQ0RExm5MYeuOO+5g+fLlHHXUUVx//fXbfNwDDzzAEUccMZa3EhkXjaEJXHrwCg7e5QAOmLw3XzvoQqZEJ497H1bNVEITZr5XsB0qP3IWKRS2RETyzagXyG/evJnvf//73HrrrYRCIU477TQWLlzIzJkzhz2utbWV//iP/xhzoyLjwlhMCE7ik7M/jmVBOu2BD8ukEoFyypZ/HtrXYZID2NUTSZQ0+tKLiIiMzahnth5++GEWLVpEZWUlJSUlLFmyhJUrV4543GWXXcaFF144piZFxpvreoNBy0dJp4xk3VxSk/YlEZ2AMeO8cExERDJi1DNbzc3N1NXVDd2ur6/n+eefH/aY3/zmN8ydO5c999xz1A3W1MRG/dxtqasbuR5GcoPGJndpbHKXxiZ3aWxy03iPy6jD1gdPjweGLSx+7bXXuOeee7j22mtpamoa7dvQ1taL52Xu2EldXRktLT0Zez3JHI1N7tLY5C6NTe7S2OSmbI2LbVvbnCAa9WHEhoYGWltbh243NzdTX18/dHvlypW0tLRwyimncN5559Hc3MwZZ5wx2rcTwbZ1GE1ERPLPqMPW4sWLeeSRR2hvb2dgYIB77rmHQw89dOj+FStWcPfdd3P77bdzzTXXUF9fzw033JCRpqW4BEgRbn8N79nbCLz9D8Kpdr9bEhER2WGjPozY0NDAF77wBc4++2xSqRSnnnoqCxYs4Nxzz2XFihXMnz8/k33KdhigtSdBU1s/sWiQiTUlhAP5v42abVtYbz1J690/H6oFqhqpPOkSEoEKHzsTERHZMZbZ2uKrHKI1W9tnWfDqhm6u/u2TbPlRLdyjgX9etnteBa6tjU3Y7aX9+q/hxXuH1WtO/DLJ+nnj2d64CXl90LkR3BRW1UQSgUq/WyrI35tCobHJXRqb3OTHmi1diLoADKQ8rrltNe/PpI+9uJmjF05len3mz+YcXy5eKj6iatIpH3rJvnC6i+6VPyW58TUA7GgZNaf+K/HoBJ87ExGR0cqfaQ/ZplTao717ZCDp7c//QJIKllO2z9JhNSsYxqme5FNH2eU2vTYUtAC8gR76nvwzju3vnl8iIjJ6mtkqAKWRAPvMrufpV5uHarYFE2pKfOwqMzzPIjR/CRUlFfS/cD+B6knEFp5AItqw1YtG5zPbtki3rR9RT256g6iXwiXsQ1ciIjJWClsFwAbOWjoHgKdfbaa6PMJ5J86jtjxcEJd3SQbKsHc/mrLZh2KsIHFjF1zQAvA8Q2ji7BH16O6LSVmFMZYiIsVIYatAVEQDfO6kefTG04QCNpGgXVB5xPMMHoUfOEzNrlQc/Am6HrkF3DTRWQsJzzmMRIH/d4uIFDKFrQJiAWWRwSEtpKBVTFJ2BHuPZdTOXAieixutImH0ayoiks/0KS6SYzwDiVD14A2FZhGRvKezEUVERESySDNbBSye9mjuHCAUcKitCBOwdG1BERGR8aawVaA6+lN89/qnaGrrB+DgPSdy+pGziAY1mSkiIjKe9Je3EFnwl4ffHgpaAA89t5G3NnX72JSIiEhxUtgqQEnX8MKa1hH1d5p6sHQoUUREZFwpbBWgcMBin9n1I+rTJ5aT49cdl3FmWRYdXhsvdL/Ayz0v04NmP0VEMk1rtgqQ8WDpwqm8vraDNzcO/vE8euEuTG8s87kzyTWbU5v493/8mJQ7eB3Nikg5/3Lg56iwqnzuTESkcChsFaiKaIB/+eS+tHbFCQYcqmMhbB1BlPexHMNdr94/FLQAuuLdvNz2GgfWLdTGuCIiGaKwVcCCtsWEqqjfbUiO8vDY3Ncyot7S345lWTrkLCKSIVqzJVKkbM/hiGkHj6jvWT8Xz1PQEhHJFIUtkSJlDMyvmcvH9ziO0mAJVdEKzt/vLCZFJ/ndmohIQdFhRMl7lqULb49W2ET5SOMhLGrcF8uyCZuIfpYiIhmmsCV5K+j1Y7W/Q7ptPcGqiVAzjaRT6ndbeccYCFMCRte9FhHJBoUtyUsBK03qmT/T89SdQ7XS+YcTOvAM0gR97ExERGQ4rdmSvBTob6XnqbuG1fpe+BtOX7NPHYmIiGydwpbkJZNOsrWDXiadGP9mREREPoTCluQlE6sjWDt5WC1QXodVNvIyRSIiIn5S2JK8lLSiVB57MaV7HIJdUk509iKqTvwKCTvmd2siIiLDaIG85K14qJbgIZ8iemAc14kQN/ruICIiuUdhS/Ka69m4don2LBARkZylqQARERGRLFLYEhEREckihS0RERGRLFLYEhEREckihS0RERGRLFLYEhEREckihS0RERGRLFLYEhEREckihS0RERGRLFLYEhEREckihS0RERGRLFLYEhEREckihS0RERGRLFLYEhEREckihS0RERGRLFLYEhEREckihS3JWY5jY9uW322IiIiMScDvBkQ+KOka1mzs5uEXNjK5vowDdm+gqjTod1si2WFZpF2PoGNhjN/NiEg2KGxJTrFti8dWN/F/f37p3comVj76Nv/2/xZRFtE/VykclgVNnXFueeAN1m3u5SP7TObgBRMoDTl+tyYiGabDiJJT+hMuN9332rBaV2+Stc29PnUkkh0dfSm+9cvHePLlZja393PTfa/xp4feHExhIlJQFLYkpxjA80YeSzE6viIFZkNrH/GkO6z21yfX0zOQ8qkjEckWhS3JKSUhm5MPnzmsVhoJMKU+5lNHItkRCoz8+I2EHBxbH8sihUaLYCSnGAMHz59ATXmEvz21nikNZRy+z2QqS4JaPJzjLMsilOqAgW6IVpAMVmpG8kNMqitlamMZ7zT1DNU+uXQOsYiz1dldEclfCluScyIBm71n1LDfrDoAXNdT0MpxlgWhlpdo/8uP8RL92JEY1cdeRLJmjgLXNpQEHb50+t68vr6L5o4BZk2pZEpdqYKWSAFS2JKc5bqe3y3IDgon22m94weYVAIAL95L259+QM2ZV5IIVvrbXA6LhQPsPaMGy7IUSkUKmBYHiMiYeb0dQ0FrC5McwPR3+NRRflHQEilsClsiMmZWSTnYwyfKrUAIO1ruU0ciIrlDYUtExiwVqaV6yXlgvfuRYjtULT2fRLja38ZERHKA1myJyJh5xoJd9qPurKvw+jqwY9UkI7UYow06RUQUtkQkIzxjE4/UQ6R+sKBlSCIigA4jioiIiGSVwpaIiIhIFilsiYiIiGSRwpaIiIhIFilsiYiIiGSRzkYU8VnC9djU1s9AIs2EmlKqSkPaUVxEpIAobIn4aCDl8cs/v8jTr7YAEArYXP7phUyqjvrcmYiIZIoOI4r4aH1L71DQAkimPX5950u4mtgSESkYClsiPursTY6ordvcSzLt+dCNiIhkg8KWiI8m1JaMqB04fwLRkONDNyIikg0KWyI+mlAV5YJTFlASGVw+uc/sek48dFfQAnkRkYKhBfIiPnIsiwNm17H71INIpT3KS4L6BiQiUmAUtkR85nmG0pADOnQoIlKQ9CVaREREJIsUtkRERESySGFLREREJIsUtkRERESySGFLREREJIsUtkRERESySGFLREREJIsUtkRERESySGFLREREJIsUtkRERESySGFLREREJIsUtiRrbNvyuwURERHf6ULUknFBbwCrdQ3JDa8SqJ2M0zibRLDS77ZERER8obAlGWXbhvQL99H9yC1DtdDEWZQtv5ikXeJjZyJSCLbMmHue8bkTkR2nsCUZFYq30/LY7cNqyY2vYXVthKqZPnUlIvnOtjyCXe8Qf/1xrECIyMwDSMQmYZS5JA8obElGGc8FLz2y7qZ86EZECkWo401abv4OMJiuep+8k9rTvkm8dJK/jYnsAC2Ql4zyotVEdztgWM0uKceqnOhTRyKS7wK2oefJP7MlaMHgF7jEW0/pRBzJC5rZkoxKmQClB59OsG4KA688TGjiLEr2WUY8UOF3ayKSx0wqsZVaEkUtyQcKW5JxiWAV1vzjKJu3BM8OEvf0cSgio5f2LGL7HUNi3cvvq1pEZu5PXAvlJQ+M6TDiHXfcwfLlyznqqKO4/vrrR9x/3333ccIJJ3D88cdzwQUX0NXVNZa3kzxiDKQI4SpoiUgGeLWzqDnpy0R22YPojH2p+8RlJMum+N1W3guSIGQGsCx9VmfTqGe2Nm/ezPe//31uvfVWQqEQp512GgsXLmTmzMEzznp7e/nmN7/JLbfcQkNDAz/84Q/58Y9/zGWXXZax5kVEpDikrRDUzSN6zB6ARdz1u6P85pAm0PIKXX+/CS/RT9kBx2FPO4CUoy16smHUM1sPP/wwixYtorKykpKSEpYsWcLKlSuH7k+lUnzzm9+koaEBgNmzZ7Np06axdywiIkUr7VqkFbTGLNC1jtY/fo9U6zrcnjY6/3otZt0zaIIrO0Y9s9Xc3ExdXd3Q7fr6ep5//vmh21VVVRx55JEAxONxrrnmGs4666ydfp+amthoW9ymurqyjL+mZIbGJndpbHKXxiZ35erYtL+4ekSt9+mVTFxwKE648Ge3xntcRh22zFZ2ktvaMd+enh4uuOAC5syZw0knnbTT79PW1pvRnYLr6spoaenJ2OtJ5mhscpfGJndpbHJXro6NZYEdGRk2nFgV3T0p0t2513MmZWtcbNva5gTRqA8jNjQ00NraOnS7ubmZ+vr6YY9pbm7mjDPOYM6cOXznO98Z7VuJiIhIhhgDwcl7YJeUv1e0HcoWnUTaaPvNbBj1zNbixYv58Y9/THt7O9FolHvuuYcrrrhi6H7XdTn//PNZtmwZF1xwQUaaFRERkbGLh+uo/tjXcZvXYFJxgg0zSGg3/qwZddhqaGjgC1/4AmeffTapVIpTTz2VBQsWcO6557JixQqampp46aWXcF2Xu+++G4B58+ZphktERCQHJMK1MKUWAJ1zkF2W2driqxyiNVvFQ2OTuzQ2uUtjk7s0Nrkpr9ZsSeELe/2E482EzIDfrYiIiOQtXa5HRrAsCHe9Rcdd/0O6q5lAZQNVyz9HomwXcnseVEREJPdoZktGCKW6aPvjd0l3NQOQ7txM223fI5Tu9rkzERGR/KOwJSOYnla8RP+wmtffjelt86kjERGR/KWwJSPY0RhYH/inYQewIpnfzV9ERKTQKWzJCMlILZUfOXNYrfKIs0lFanzqSEREJH9pgbyM4OHgzDyU2gmz8HrbsctqSJc24mlnYRERkZ2msCVb5VpB3NgUiE3xuxUREZG8prAlIoS9Xuhtg3ApqUgNnhl5UXkRERkdhS0ZxgO6+1MEAzZlkUBGd++X3BTp20D7n/4Tt6cdnACVh5+Ns+tiXH08iIhkhD5NZUh3PM1v7nqFp19tpiQS4FPHzGWvmTU4lmY5ClWIOJ13/2wwaAG4aTrv+xV1Z+yKG5vsb3MiIgVCK55lkAW3rlrD068ObmTaH0/z01uep6lDl+opZFail1TruhF1t6fFh25ERAqTwpYAMJD0ePSFTSPqm9r6t/JoKRQmVEqgsmFE3Y5V+9CNiEhhUtgSAIIBm8kNZSPqFaUhH7qR8ZK0olQt/SxWuOTdikXFQR/HjU3wtS8RkUKiNVsCQMCCTx0zlyt+9RjJtAfAPnPqmVynXeMLXaJiOjVnfAfT04oViZEuqSeN43dbIiIFQ2FLhkyuiXLVBQexqa2PaDjAhJoSwo4mPwudMYZEsAqqq/xuRUSkIClsyRBjoLIkSGVJpd+tiIiIFAxNW4iIiIhkkcKWiIiISBYpbImIiIhkkcKWiIiISBYpbImIiIhkkcKWiIiISBYpbImIiIhkkcKWiIiISBYpbImIiIhkkcKWiHwoy4Jk20ZCnWsIJ1qxLON3SyIieUWX65GMCZkBrL5WCERIR2twjbJ8vrNti2Dzajbc8SNMKgFOgOqln8WdvA+esfxuT0QkLyhsSUZEEy10/OVHpFrXgWVTfuBJBOYeTdoO+92ajEEw0U7bn38yGLQA3DTtd/0PtWddSSJc529zIiJ5QlMPMmYBy6Xn0VsGgxaA8eh++BacrrX+NiZjN9CNSQ4Mr3lpTF+HP/2IiOQhhS0ZMyc9QPyt50bU3c7NPnQjGRWtwAqXDK85AazSKn/6ERHJQwpbMmZeIEJ44m4j6nZZjQ/dSCYlQ1XUHHMRVigCgBUIUbP8cyQjtT53JiLFyrIgkmwl2PQcodaXCbs9fre0XVqzJWOWMgHKDzmdZPPbeP3dAJTOPxxTNdXnzmSsjDEk63Zn0jnfY6CtBbuknES4GqPF8SLik3Dvelpv/jYmFQcgWDeVimO/QCJY6W9jH0JhSzJiIDqB6tO/jenajBWK4sXqSRHyuy3JAGMgVD2BLjf2bsHffkSkeAUsj55HbhkKWgCplnfwNr8Ok/f3sbMPp7AlGZNwyqG63O82RGSMgl4/Vsc6TF8HdkU9bvlk0pa+PIn/bJMk3bp+RN3tasGaYmFMbn4bVNgSEZEhEQbof/Qm+lavGqpVfuST2LM/qr3VxHcpK0LJvEPpfviWYfXghN1I5GjQAi2QFxGRd0UTm3HffnJY0ALo/PvvCCXafepK5D3GQGjOoZTOPxwsGytcQtVR5+Dm+BphzWyJyDZZNniW63cbMg5CZoCOv/yI0jkHjrzTTQ+ukdGRRMkBiUAFwcVnUbff8RjbIRWswPNyd1YLFLZEZCssC1rTzdz9+irWdW/k8OkHMr9mHlFTsv0nS16y+ttJtW4Az8WOlOLF+4buC9ZPw5RqKxfJHa6xcYPv7veX40ELdBhRRLaiy+vkyn/8hH+se4K1XRv49bN/4P61D2LZO/ehFrTShKw0VgaX+ti21g1lRTCK5QTpfupuqg75BOEJM8AOEJ25L1XLP0eSiN8diuQthS0RGWFj3yYG0vFhtXvWPEif17tDz3dwCbe9Qt8dV9N9678RWP8kAZMYU08BkyTc/hres7cRePsfhJNaQ5RJqXA1FYd/Ei/RT9t91+KU1VC7/HxKjziXgZCugykyFjqMKCIjBKyRHw1BJ4Bt2Tu0z1ag6x1ab7lq6Hb7X35CzfEXQ+Neo+rHsiystU/TuvJn771HZSOVJ19CIlAxqteU4TwDzq6LqT19Gm5XM3ZpFV7FZFKa0RIZM81siRQAy4IgSYJWOiOvNzE2gfqS4Wt0Pjb3WEqs2Hafa9sW8TeeGFHvfepOgjt5GHKLkNtL56rrh9XSnU2YNl3sPJNcgiTKppKevD/JqpmkbAUtkUzQzJZInguYONb65+l5/A7sUJSyxaeQqp6JhzPq1ywxMb648Hxebn+NTb3N7D1xLhNDk3f4jB8nMjKU2dFyRrtNk2VcvOTAiLpxU6N7QRl3lmVhWeT8WWMi2aCZLckrlgXGccHRBzYM/jysjatpv/O/SbWuI7HxNVr/cCWh7rHP+JRZFSys3Z+Tph/LvhMXEDDBHXqe5xlCu+6DFXzfrIhlE9vvWNLu6NJWMlBO2b7Lh9WsQAinZvKoXk/Gj2VBJN6M9fLduI/fQLjjdRwUkqW4aGZL8kaSOC+2v8w9bz5IVaSC42YdxYTQREY9XVIAAlaa3qfuHFGPv/Us9t67jnkWwRhGdfmLRMkEak/7Jqn1L2JSSUK7zCNRNnnU11X0DITmH0VFSRn9z99PoHoisYUnkog0DDYpOSscb6Xt9/+GNzB4ckXv03dTc9zFeBP30tBJ0VDYkrxgWRbPtr3Ar5/9PQBruzawuvkVvn7oF6l16n3uzj8GGztaNqJuR2K+/iEzBuLRRqxZjYBF3JgxX8A66ZRhzzmaslmHYuwgcc9W0MoDbvObQ0Fri66HbqLiY3O0nYQUDR1GlLyQsuL85bW/Dqu5xuPNznd86ig3pD2bsgNOGNzq/V1WKEpo6oKcuCDraGfGtsXzDCnCpD19dOWLra2rM+kEVg78+xQZL5rZkrxgYRMJhEfUQ86OrSOyLHAcG88zBbdAN1k5nbrTv0Vy3YtYwTDByXNJRBvGPJMkkgmB+ungBMB970zZsoUnkLRLNDMpRUNhS8aVZUE42YHXsQGcIFROIulsfzsBxwvysbnH8v1HfzFUi4VKmV6x/YuPhtLdeOtfYOD1xwlP3p3IjAOIh6rH9N+RSzxjEY9NwZq7CwZD3KCgJTkjUTqRuk98nd6n7sTrbqV0r6Nh0nxcBS0pIgpbxcI2xM0AISuE7fk37JH+TbT+/jt48cE1HMHG6VQs+zyJYOV2n7tr6a7868EX8Xzzy1SEy5hbO5sKq+pDnxOwXOKP30rf6gcAiL/1HMGXHqL8pEtI2qVj/c/JKblw2FDkg4yBeGwXwkd8BtsY0sbWhJYUHYWtItBLNyvfuJ9H1z/NpPJGTp93IhOCk8b9j7NjG3qf/PNQ0AJINb2Fu+lV2GXhdp9vG4dJoSlM2WUXjDE79IHtDLTRt3rVsFqqbT1W1yaomrnT/w0iMjqua+FSvGcOS3HTKtMCZ2yX3718G397+2EG0nHeaH+bq/7xUzq98b+unO0lSTa9OaKebt+wUxcX9rwdC1ofRrNAIiIyXhS2ClyP28Mzm1YPq6XcFJv7mse9F9eOUDr34BH10OTds7Zo3Y3WUDrv0GG1YM1kqJyYlfcTERH5IB1GLHABO0A0GGEgFR9W39qZfdnmeYbw7IMp6Wii/6WHsAJByhefglczPWvvmTYOkQNOITRxNwZee5zwlLmEZhxAvMDWaxW6kNeP1bURL9GHUzWBRKS+YNf9WBaE3H4sL0k6WEbajP6ySyKSGxS2ClzMKuPMeSfxv8/cOFSbVz+bhmijL2esJQIVhA/5Z0r3PxFj26TCVaS97L5nMlCONf1gojMPxfMM8QLb+qHQhdw++lb9H/E3nhwsOAHqTr2EeMUMfxvLAtvyCLa8Qse9v8TtaSc6eyGxxZ8gHvzwE0FEZOssC0LJTnBTeNEqUsaf2KOwVeA8z7Cgej6XHlLPpt4mKsIVTC6dSNj4t3Nz2jikwzXvNjg+72kMpLOd6iQ7Ote+F7QA3DSdf/0V5Sd9naQ1/jO02RTqbaLlj98DM/hvdeDVR8GyiBz2/zTDJbKTAqTgzUdpe+B6TCpOZNoCyj7yz8DIq25km9ZsFQHHBJgYnMS+Vfsys2QmEVPid0siO8z094yopdo2YXkJH7rJLrdz41DQ2mLglUcJpEb+DETkwzld6+m495eYd5fRxN9+nv6n7sC8b4Pd8aKwJSI5za5sHFGLzlqIGyi8dXdWZOQGv055DcYJ+dCNSH5zOzaMqPW/+ghuX+e496KwJSI5LV02kepjLsJ+N4hEpi0gduCphXlYrWoK4WkL3rtt2VQd+enBS9uIyE6xS0eudQzVTcUKj/8XNa3ZEpGc5hLATNmP6jN3g3QSL1JB3OzYNTHzTdIuJfbRzxDrXIeJD555mSxtLNgzL0Wyqnoqkel7EX/rWQCsYJjyw87ECUeB8T00r7AlIjnP8wwJpxwcCv66j0mnFGrmAJCCgv/vFcmWpBOj9KPnEevaiEnFsSonkAjX+rA8XmFLRETGScgMYPW1QiBMOlqLa7SSRbIraZcMvzSbT9PEClsiIpJ10UQLHXf+mFTLWrBsyhedSGDe0aQt/7ahERkv+lohIiJZFbA8eh7/42DQAjAe3Y/citO5zt/GfODgEu5ZS+Cdhwk1v0DI1bYexUAzWyIiklWO20/izWdH1NMdm6Bqt/FvyCeWBc7GF2i94wdDtdDE2ZQtu4ikM3LbDykcmtkSEZGscp0IoYmzRtSd8jofuvFPyO2j8/5rh9WSG1+FjuKb4Ss2ClsiIpJVaROg/OBP4JRWDNVK5x2GqZ7qY1fjz/JSuP3dI+omOeBDNzKedBhRZJQsa/B/LAa3JhCRbRuITqDqtCswXZuxQhHcWAMpimtn/FSwnNK5B9P34oPvFe0AdtUE/5qScaGwJTIKXQMpHnx2I8+vaWXh3EYWzm2gLKJfJ5EPk3DKobrc7zZ84xqb6AEnY4Ui9K1+kEBVI5WHn0WipFH7qRU4/XUQ2UkJ1+O/fvcM6zb3ArBmfRcvvtXGhScvwLF8bk5EcloiWElg4enU7HMcnhMiTlhBqwhozZbITtrcMTAUtLZ47vVW2rrjPnUkIvnE9SwSThkpwn63kneCJAm7PTi253crO0UzWyI7ybG3Pn1l2/ruIiLjI0gCJ9mLCURJOiUFf/1My7II97xD1wO/IdWyjpLZiyjZ/wTiwWq/W9shClsiO6m+Isq8XWtY/WbbUO0j+0ymuqy4FvuKiD+i8SY67/0FyU1rCFTUUbXkMySqZhZ04AolWmn9/XcwqQQAfatX4fa0U7JkBSly/8L0ClsiOynoWJx3wjxeerudV9d2MH9GLbMnV+iYvIhkXcgM0PGXH5Fq2whAuquF1luvpuaT/04iVOtzd9ljOjcNBa0t4u+8QCzeAZF6n7racQpbIqMQCzssnFPHgXMbcN38WjsgIvnLGugYClpbmHQS090MtYUbtqxQdCu1CATy44iCvoyLjJIxKGiJyLhwLI9wvBk71U/ZfsuxPhAyrEiZT52ND1M+gciMfYbVKg87k2Sw0p+GdpJmtkRERHJYwCTwXrqf1n/8HoxHoKKO6o+cQdtffwPGI7bvctzSBr/bzKqkXULpRz5N6YIj8fo7cSon4FZMzpt1agpbIiIiOczp2kDHQzcN3U53tdD72hPUfewSjBXALZ9I2sqPw2ljkXRiUDcXgLTPvewsHUYUEWw8IvHNhNpeJRJvxrZ0eFQkV3g9rSNqibUvYWL1JCqmk7a0X1eu08yWSJGzLYOz9klaVv4MjAe2Q/Wyz2Im74sx2hJfxG9WbOReUqGJu+EFRi4al9ykmS2RIhccaKX97msGgxaA59Kx8ueEE+3+NiYiAHiVkynb/9ih23ZJORVH/FPRXcg7n2lmS6TImXg3eMNXQBg3hTfQBaEan7oSkS3SVoTA3idSO2sxJtmPVVZPIliuayrmEYUtkSJnlVZhBSOY1HvXdrRCUayS/LgMhkgxSBMgXToRSt8tKGjlFR1GFClyyVA1NcdfjB2JAWBHY9QcfzHJUJXPnY1NIGBjb+M6liLZFrA80j3teXfBZMkOzWxJXrMsCCU7wUvhRapIGf2T3lnGQLJ2d6rP+A7EuyFSQTJYgcmXDWw+IOAlsFteo//FBwlUNRCZcxCJkgl5sx+P5L9ovImeh39P14bXiO66NyX7H0+8gC+lI9unv0yStwImiVnzMG0P3ohJJYjO3JfYIZ8kHszvGRk/GGNIBCogVrGl4G9Do2RZFqx7ira7rxmq9T73V2pP/zfi4TofO5NiEXa7abv1KtzeTgD6XnyQZMtayk/8Gkki/jYnvtFhRMlbTudaOv967dDFSQfeeIqB51ZiW/kZFGTsQl4f3Q//YVjNJAdwW972pyEpOqa7eShobZFqfhurd+ReWVI8xhS27rjjDpYvX85RRx3F9ddfP+L+l19+mVNOOYUlS5Zw6aWXkk7n256vksvSre+MqPW/8ggBt9+HbiRnbG1WLk9n6iT/fPCahYNFGwLaeLSYjTpsbd68me9///vccMMN3H777dx000288cYbwx7zla98hcsvv5y7774bYww333zzmBsW2cIpG7kGItQwg7QdxWVwPZcUl6RdSvniU4fVrFAEp36aPw1JzgkEHBwnewd13FgDJXMPHlYrW3g86YjO7i1mo16z9fDDD7No0SIqKysBWLJkCStXruTCCy8EYMOGDcTjcfbaay8ATj75ZH70ox9xxhlnjLlpEQBqdyW8yx4k1r4IgD15Hu/MPYubr3uWZMrlpMNmMHdaFUGdkVY0jDEwdV9qjo/Rv/oBAlUTiOx+CIlIvU6VL3IBE8dueoW+1X8jUNlIdI/DSJROzPikZ9oKEz3wdKKzD8R0t2BVTsBUTSWFk9k3krwy6rDV3NxMXd17C07r6+t5/vnnt3l/XV0dmzdvHu3biYyQDJQRO/pzlHVtxKTirGEK//6rp4bu/+HNz/Kl0/dhj6mV/jUp4y5tRaBxTyKT98YYQ9w1ClpFzrIsePsp2u75xbuV5+hbvWrwxIlIfcbfL+mUQt0e1M0to6WlJ+OvL/ln1GFra6eFW+87brO9+3dUTU1sp5+zPXV1ZRl/TcmMnR+bMmhoAOCxW54bce9dj7zFQXsdRDCgb5Vjpd+b3KWx+XDpvk42PHLLsJpJxaFjLXULZmT1vTU2uWm8x2XUYauhoYEnn3xy6HZzczP19fXD7m9tfe/si5aWlmH376i2tl48L3NfS+vq9E0jV41lbGzboqxk5MLU8liY7u4BPFdTG2Oh35vcpbHZvrBJbrXuuiarPzuNTW7K1rjYtrXNCaJRrxJcvHgxjzzyCO3t7QwMDHDPPfdw6KGHDt0/adIkwuEwTz01eFjntttuG3a/SCZ5nmHfOXVEQu/NYDm2xTEHTVfQkoyzLIs+etic2kS/1TuqWXu/BEkR9npx7OL5vUjaJVQc9LFhNStcglM3zZ+GpOiMaWbrC1/4AmeffTapVIpTTz2VBQsWcO6557JixQrmz5/P9773PS677DL6+vqYO3cuZ599diZ7FxmmrizMFecdyMvvtJNKecydXk1DhTYRlAyzDG/0v8H/PPkbBlJxSkMlXLj/p5gamZbTu+5blkW45x26V11PqnUd0dmLKNn3uKLYBNgYg5myDzUnfpn+l/5OoLKByOwDSUTqtJ5PxoVlcvnTAR1GLCaZGpstkwy5/S87v+Tz703I64PODZBOYldOIBGuGdO/jR66+Pqqq0m6qaFaabCEbx76ZUpM5teYbs+Ojk040UrbDZcObQIMEJ25L9GPXkDKFM+axkDAxvNMRv+ubEs+/94UMj8OI+pyPQXKtjyC8XZIxTGlNSStqN8tjRuFLNkilO6m996fkVj3EjC451btxy4jXjp51K/ZGe8cFrQA+lL9dCa6KAmNf9jaUV7npmFBCwavulB6UAeEi+e6fem0Lgwt409hqwAFTBLvlQdofehm8NIEaydTecwK4uHMn+IsktNa3xoKWgAmGafnoZsoWXrxqGdzysPlOJaNa977ox12QpTlcNCCwaA5shYFJ+hDNyLFRddGLEBO93q6HrwBvMHLI6Va19Pz0E0ELF0uSYqL2zPyenTJlnew3PioX7PCruScfU7HtgY/Ph3b4dx9zqDcqhj1a46LikmEp84bVqr8yCdJhSr96UekiGhmqwB5Xc0javG3nqMsPUDa0Z4vUjwCtVNH1ErmHETaKR39wmhjsaByPv922GS6Et1URSqpsCt36vD10GH+dAJTUkPSyv6JHEm7hNhHP0Os/R3cvg4C1ZNwK6aMy9qlYmJbhlBfE27nJvq7ywnFJpC0S/1uS3ymsFWArNKRZxeFJ87AdXRmnhQXt3IXKj/6KboevBGTihPdbX+iex5NfIz5wjI2VXYNVdGawcJOvF7AJPBe+RutD/0ePJdg/TSqll/IQCj766aSgTKoH5zdcrP+bsXHsiDY+iott14N7x5mjkzfi9Ijzh3cVV6KVtGHLdu2cBybdNotmIXVpmoKpQs+St/zfwXAjsQoP+xs4mhthhSXtBXCmnkYNVP3AjeFG6kkbvz92HO61tHx4O+Gbqea36bnkT8Q+ci5pIvorMBCFPIG6Lj3f4eCFkD8rWcp7VwHNXN87Ez8VtRhK5JsI/nG4/SvXU1k1gEEdtmbRKDc77bGLGWXEF70CaLzPoJJDmCVN5AIVmg/GSlKxkAiUDH4aZcDvwNu58hrxMbffIbSQ/pJ2zrMn88sN4Hb3TaibuJ9PnQjuaRow1bI66Pzzz8g1boOgPjaF4nOfoXoR84h5fM330xIEYLYlPcKOfBHRkTAjlWPqIUmzMRzIvo9fR/btrCswUvq5It0sIzorAMYeO2x91Ut7MpG33qS3FC8ZyN2Nw0FrS0GXn0Eu3/k2UsiIhlTPZXSPd67dJkdjVF+6JmkjA7zw+BO95GBTZjn/0T60RsId72JQ36cSZ02DrGDPkF0t/0BcGJV1J70JVKxCT53Jn7L/ykcEZE8krRLCC0+k+iCIwcP81c06jD/+4T7NtL6u29g0oMXj+595m5qT/kabp6seYoHq4kccT6xg88gWl5GZzxQMOuBZfSKdmYrHptCx6FfpvPAz2HNHvyWWTr3ENxo8eykLCL+SFthEmW7kKyZTSJQoT/G77IsSK5bPRS0tuh59I8Erfw5fzJtHOLBKgKxKo2tAEU6s9U1kOJHNz/PW5u6Adh7xl78v5OOJFJVSbI4fyTDBE0Cu68ZPA9TVl9Ul/qRzLIsCMdbcNvWYdkOVs0uJIrgwscyWhakUyOqg+FLqUXyV1Emi4ee2zQUtACeWdPJi3vtwn51+X8m4liF0930rvo18TVPARBqnEHF0s8RD41c1CuyPeG+DbTedAUmNbhju1NaRfWplxIvomvxyY4zxhCeOh8e/sOw7RNiBxxfECcuSfEqusOIiZTLs6+3jKi//HY7jlN0P44R3I0vDQUtgGTTGhKvPYxtWz52JfnIsaHvmbuHghaA29dB8u1nsSz9e5KtS5RNpu4TXye62/6Ep+xOzQlfxDTO9bstkTEpuq8K4aDDfrvXs2ZD17D6HtNrcN3ivhq849jDLtq7RfzNp4ntuRyv+LK5jIGNh9u+YUTd7dxEwLby6pR+GT/GWMTLpxE+8nNYxpD0FMwl/xXlX8/F8yYwd/p7h8UOWjCBObtU+tdQjnBdj/CUkd8gIzP2wdXO1rKT0samZMFHR9TDM/bd6hcbzXbJ+7kupBW0pEAU3cwWQFkkwMUf25PW7ji2bVNTFsbR7zQA9sS5RHc7gIHXHwcgNHE3wrMWE9fFamUnGQP25D2pOOQTdD92O5YTpOKQ0/BqZgx7XB/drOl6m5b+dnarms6k6EQc7TklIgWkKMMWQMC2aKzUWXYflAyUEzn8/1F6wAnguZhYPXFLF7CW0Uk6pVhzl1Ez62CwLJJOGeZ958IPWH386Ilfsr5701DtnL1PY7+affEU8EWkQBTlYUT5cGlCJEonDe4DpKAlY2QMJJwyEnZsWNAC2Ni3aVjQAvjd6j/Rb3rHs0URkaxS2BIR3yS9kXsqxdNxPIr7ZBURKSxFexhRRDInaOLYXRvx4r04lQ0kIvUYtr8QcmJpA2EnRMJ9b8fww6cfRIkV0x6WIlIwFLZEZEyC3gDxR26g/8W/DxZsh9qTv0qyZvZ2L1VSaddwycEXcturd7Ohp4lDd1nEoon7gs5CE5ECorC1HeF0F6ZtLcZL41RPIRGp1bWuRN7H6trwXtAC8Fw67vkFVR//NxJ2yYc+1xhDndPIufPPIm3ShAhrYbyMO8sCx3HwPE///iQrFLY+RCTZRscfryLdNbjjvBWKUPvxrxMvmehzZyK5wwx0j6i53a1Y6TiEPjxsvfcEmwAhPB07lHEWcnvx1r/AwKv/IDRxNpHdDtTlpCTjtEB+GywLUutWDwUtAJOM0/fUX3Bs/UEQ2cKpbIQPrM8KT52PG9a1RsV/AZMg3PUmwY1PEe5Zi8N7J2U4lkfimTvouPvnxN9eTffDt9D+x6sIuyO/QIiMhWa2tsGyLNIdTSPq6bb1RIyLW6A/ul662dC7CduymFg6gVLK/G5JclyytJGa4z5Px33/izfQS3jSbCoOP5sBXThYfBYgTfr5O+l47PahWuVH/xl75mF4xiKY6KDzmXuHPcftbsV0bIRafVmQzNGn4TZ4niEybQG9T981rF4y73DSBCnEU6U6vFb+4+Gf0pPsA6A6UsmXD/wsFVaVz51JLvOMTWri3lSf8e+QSuBFKhgg5HdbIjj9zcOCFkDnA9dRO3keiS2HCi1r5Me5zs+QDNNhxA/h1uxK1ZHnYIdLsJwgZQtPwJm+34iNGQuB41g8tP7xoaAF0B7v5JnNL2Db+uSRD2eMIeGUk4jUkVLQkhxh4n0ji24akgMApMLVlO2zdNjdgcoGrMpJ49GeFBHNbH2ItBXGnnko1dP2AuORClSQLLycNciCtzvXjyiv696APdnSGToiknes8jrscAleon+oFiivw5RWA+Aai+Cey6iqm0r8tUcJTdiN0Mz9iTtaPiGZpbC1HZ5nSNjv/uIVcN7wXMPBuxzAK61vDKvvP3Ev0mnt5i0i+ScZrKTm5H+h895rSLVuIDRhBpVH/j8G7NKhx6ScGEw5gMj0RXieIa4vlpIFClsCDF6/bm7VbE6cs5S/vHYftmVz4pyl7Fo2vaBDpogULmMgXjaV8pMux04P4AZLt7meUF8qJZsUtmRI2EQ5evIRHDTpACyg1Irh6fNHRPJc0opAMOJ3G1LEFLZkGONBCTEANJsuIiIydjobUXaKpRMTRUREdopmtmSHJKw46/vWs7G3iYmxRqaUTiZkNC0vIiKyPQpbsl2e7XLnmnu57633LjZ8xLTFnDTzWGxP/4REREQ+jA4jynZ1pNqHBS2A+99+mPZUu08diYiI5A+FLdmupJvcqbqIiIi8R2FLtqsmXE1jrH5YraG0ltpIjU8diYiI5I+iX3BjMGzuTLCprY9YNMjkuhjRoDLo+4VMlBX7n8Of37iXF5tfZY+6WRyz21GEvKjfrYmIiOS8og5blgUvr+3mu9c/NVRbMLOW80+cRySgwPV+FVYVZ84+leSsBCErAp72gBAREdkRRZ0oBlIev/jT6mG1599oZUPrVq4UL+DZhExUQUtERGQnFHXYSruGrt7EiHp/PO1DN5llWRaOo1AkIiLit6IOW7FwgEXzJgyrObbFhNrSbTwjP0QSLViv3EP60esJt71KgJTfLYmIiBStol6zBYbTProbwYDNQ89tpLG6hHOO34Pa2NavCp8PIsk22n5/BV5/NwC9z9xD9fILsKYcgNG1DkVERMZdkYctKIsE+Oels/n4ETMJOjZBO78Pvbmt7wwFrS26/v47qk6bR8Iq8akrERGR4lX0YQsAAyVBx+8uMsNzR5RMOgnGg/zOkSIiInmpqNdsFSKnZheswPDDoOULTyAVKPOpIxERkeKmma0CkyhppPYTX6fv6btIdzZRuudR2JMXkPS0YEtERMQPClsFxhhDvHQyocPOJYJH2tiklbNklCzLIpTuItHcTtAqJUXY75ZERPKOwlaBcj1wdZRYxsC2PAIbn6f93v/Fi/cSmjCTiqPPIx6u3/6TtyJACqdnE15vG3asGjc2gbSVv2f+iojsKIUtEdmqUG8TLXf8EBicGk1ueoPuv/6K0uVfIkVwp17LtjzMa6to/dt1Q7WKQ0/HmXMkLgVyckoOGNzM2MZ1PYz2ehHJGZr6EJGtcrua2BK0tkisfwUn2b31J3yI4EArnQ/cMKzW9febCMZbx9KivE841YH92n0M3Hk19ut/JZzq9LslEXmXZrZEZKvskooRNaesBhOI7vRrmUTf4PYjw4oeXrwPIqPtULYImjg9915DYv3LAMTffoHw1KcpXXKR1tmJ5ADNbInIVnnlkyidf/h7BTtA1ZLzSDo7vzmuFavBLikfVrOjZVix2rG2KYDd2zwUtLZIvLMau7fZp45E5P00syUiW5WyI4QWfYLo3MOw0/2YWC2JSN2oLvuUDJRTc9JX6Lz7GlKt6wjWTKJyyWdIBMs/eKRSRKTgKGyJyDalrQjpimnU1ZXR0tIz6mBkDMRLp1B+0qXYqT68YClxK6KglSFerIHwLnuQWPviUC08dQFebHRnjopIZilsici4SVoRCGmRVqalrDBlHz2X6DvPknj7WcLT9yIwdS8SWq8lkhMUtkRECkAiWIm12+FE5hyB63okNGs4KpYF4YHNpDevAWMINMwgUTJBW2nImChsiYgUCGMMaV0yYkzC/ZtovelbmGQcACsQovYT3yBeOsnnziSf6WxEyRuWNbhpo4hINti2Rfy1R4eCFoBJJxl44a84jv5cyuhpZktynmVZhPs3klr/EiadJjxlDxKxSRgUvEQkcyzLwu0eudFuuruFoKUZQxk9hS3JeeG+DYPT+qnEYMF2qPvE5cTLpvnal0g2WZYhPNCC192MFS3HjTXqWpJZ5roe0d0Ppv/lfwyrly44kqQOz8oYKGxJTrNti8SaJ98LWgCeS+/TdxE+/AJcTx+AUngsC0Ktr9Lyx++BlwagbP9jCOx1ggJXlnk1M6g+5iK6H/49eB7lB56MVz/H77YkzylsSU6zLHAHekbUvf4eLE3ryyjYtoWX4yE95PbScffPhoIWQM8Tf6F2xv6ky6f511gRSFshrMn7UnHqHsDg5r46EVHGSiv+JKe5riEya9GIemyfpaRdHxqSvBUwcUItL+E9eTOBt/9BONXhd0vblhzA7e0cUfb6u8a/lyJkzOCecElLQUsyQzNbkvPSlVOpPflf6H7kFnDTxA44Hq9+tt9tSR6xbTCv/J22B64fqgVrp1BxwldJOGU+drZ1JlJOsH4aqea331e1cCoaSPnVlIiMmsKW5DyXAG7t7sSO/xoWkDS5+c/WtsExadIEtQFijgkmu2h76PfDaqnWdZiODVCbe+txkoSpWnI+HXf9mFTrBuxwCVVHn0syqsvviOSj3PyrJbIVqRwNWQCReBP9z97DQNMaorsfTGjGQhKBcr/bkndZnotx0yPqxsvdeaKBaCPlJ12ONdABoRJSocqcX2smIluXu3+9RPJEON1J2x/+Ha+/G4Bk8zuUtm0gdNDZpI2WReaCVLiS0vkfoe/5+4dqdqQUp3JSTh+WS1oRKJkweENBSyRvKWxJTsmHM8U+yHRsHApaW/S9+CAl+x5HOlzjU1fyfq6xie53IoHKBvpffJBg/TRi+x1LPFwN+fXPTUTykMKW5IRwuoue55/Ca15LaOIsTM2upOyo323tGNvZSs3G2JrVyiWJQDn23KWU7X4EnhVgwLMUtERkXChsie9CXj899/wPifWvDNXKF5+KveAYPC8PLslTOYlg3S6kWtYOlcoXnkgqVKU/5jnG8wweQY2LiIwrhS3xndW1cVjQAuh+9DbqZh1IPJT7h+GSToyKY7+Au341qZZ1hKfOx9TNJKU/6CIigsJWwbMsCKV7oL8DK1xKMlKD5/nd1XBbO0sML43x8mfX0kSwCmvXQwjMtEi6SlkiIvIeha0CF+5ZR/uf/hO3txMrEKLqyE/DLvvjsZV1Rj6xKidgl5QPW2QenbkvXjS/Fi8bM7jjvchYWZalvdpECohW8BawkNdPx50/Gbrsh0knaV/5M4L9m/1t7AMSgQpqTv1XSvc4hEBlA2WLTqL0kLNyel8tkWyIJNsIvP0PeOFPhDvX4OT0xhQisqP016yAWYke0p0jg5XX3QolE33oaNvikUbqj7uQ7vZO0naYRI4d6hTJtnCqg/ZbrsTtaX23cgvVx67Am7SPrs8nkuc0s1XATLgUp6x6RN2OjazlAssJkCScc2vKRMaDaX3nfUFrUNeq6wl5Az51JCKZorBVwFJOjOplF2AFI+9WLCoOO4N0rMHXvkRkJOOOPGToJfrB5M+JIiKydTqMWMCMgXjlTGrO/HdMbyt2pIxUSR2uhl0k59g1k8EJwPvOzi3b/xhSgRhotlckr+mvbhFIhKqhOjcPHYrIoGTJBOo+fjk9j/0Rt3MzpXsehTP9AJIKWiJ5T2FLRCQHGAPxsqlEj1qBZVKkrQiuVsaLFASFLcl/lqHdbaOpr5loIMrEkkbCJk+uqyjyAWljA2F0CqJI4VDYkry3PrGOq//x37hm8HjL3LrdOGfBmURMic+diYiI6GxEyXOuneS3z90yFLQAXmp5nQ19G33sSkRE5D0KW5LXkiZFU1/LiHpvqt+HbkREREZS2JK8FrVKWDxl3xH1CaX1PnQjIiIyktZsSX7zLI6ZcRSJdILHNzxHWTjG2XueSm2wPq8uYi0iIoVr1GFr48aNfOUrX6GtrY3p06fzve99j9LS0mGPaW5u5pJLLqG1tRXbtvnqV7/KgQceOOam80nI68PqbcUKRkiV1OIax++WCk6Mcs7a/TROmX0sAStIhBKMzuQSEZEcMerDiN/61rc444wzWLlyJfPmzeO///u/Rzzm6quv5vDDD+f222/nP//zP/nyl7+M6xbPpSeiic10/f7faP3dN2j57ddwn7mdgBf3u62CZHk2pZQTNlEFLRERySmjClupVIonnniCJUuWAHDyySezcuXKEY87+uijOe644wCYOnUqiUSC/v7iWLgcsFy6H7qZdNfmdyuGnsf/hNO1zte+JPcELJew149tKSSKiBSiUR1G7OjoIBaLEQgMPr2uro7NmzePeNzRRx899P9/+ctfsvvuu1NWVrZT71VTExtNix+qrm7nehiNdHcrnWtXj6ibnhbqZu2T9ffPV+MxNrkksfEN2h+8iWTTm5TMWUTF/scQqpnod1tbVWxjk080NrlLY5Obxntcthu27rrrLq688sphtWnTpo14nGVZ23yNa6+9lptuuonrrrtupxtsa+vF8zL3jb+uroyWlp6Mvd62BK0A4cm7E3/r2WF1K1Y7Lu+fj8ZrbHJFONVB+43/hhfvA6DnqZWk2jdRcvRFpExunbtSbGOTTzQ2uUtjk5uyNS62bW1zgmi7n+jLli1j2bJlw2qpVIqFCxfiui6O49DS0kJ9/dZPtb/66qtZtWoV119/PY2NjaNoPz+ljEP5IaeRal2L29MOQGyfpXiVU3zuTHKF6dw0FLS2iL/1HLGBdohkZusKy4K4NUB/up/SQCkhL5KR1xURkR03qq/PwWCQ/fbbjzvvvJPjjjuO2267jUMPPXTE46699loee+wxbrzxRsrLy8fcbL4ZiDRS9fFvYXpbsIIR3JJ6UtptQ95lBUIja04QnGBmXt+yWJd4h5899Vs6BrpoKK3lM/ueRWNwgi67JyIyjkZ9NuI3vvENbr75ZpYvX86TTz7JxRdfDMCNN97ID3/4Q4wx/PSnP6W9vZ2zzjqLE044gRNOOGGra7sKWcIpI1mxK4mSiaQVtOR9TMUkwtMWDKuVH/xxUuGqjLx+j+ni+4/+gqpQGYdN3AvXePzw8V8yQHGcpCIikissk+Pnyefrmi3ZecU4NiG3B1reJN3VTLBuKm7VVNJWOCOvvS6xFrdtLXVrVuM0ryM1fR6v1FQxZcICGkM7twi/GMcmX2hscpfGJjfl5JotEcmepFMGjXtiTYBEhr/2TLHC9P/t97h9XXgAbRvYY8ZehKYuzuwbiYjIh9K1EUVyQDbml0M97bh9XcNq7ppniSUSmX8zERHZJoUtkQJl2VtZaG8HwNKvvYjIeNKnrkiBMhUTCU3cbVitfOFxJCPVPnUkIlKctGZLpEAl7RLKl1yIu+kV0q1rCU3eHVO7Kylv2xsQi4hI5ilsiRSwRLACdlmIPW0RyQye1SsiIjtOYUukCGxv+5QgKey+FjAuXqyeFJnZfkJERBS2RIpeKN1N/8M3MvDKIwCEJ8+h/KjPEA9mZnNVEZFipwXyIkXO2/TyUNACSKx/heRrD2Pb+bO2y7Ytwm4PkVQHAcsl6PUTan0ZZ80qwu2vEfDifrcoIkVMM1siRcxxbJJrXxpRH1jzFLEFy/Dy4PuYY1LY7zxN+99+i5fop+KQj5HuaKbvhb8NPaZs0Yk4ex6HaxwfOxWRYpX7n6QikjWu6xGaMmdEPTx9z7wJJoHu9bTf9T948V4wg/Hw/UELoOexPxEYaPOnQREpegpbIkXOmbgHkel7Dd0ONkwjMvvgjF6TNJvSrWuH3TaeO/JBxoO0ds4XEX/oMKJIkUsEyik56rPEepoxxoWyBuJW1O+2dphTWjnstknGcWJVuL0dQ7Vg7RRMae04dyYiMkgzWyJCijCJsikky6eRzKOgBWDVTic0cdbQ7Z7n/kbt8Z8nMmNf7HAJ0d0XU3XMirz77xKRwqGZLRHJa4lAOWXLVkDn+sFZraqJDETriX70s8S8OK5TwoDR90oR8Y/ClojkvaQTg5rBhf4pAANpAqTtGOTH0jMRKWD6updBlmVhOQZbP1URERF5l2a2MiRu9fNc62r+vvZxplVO5qNTD6bK1oJcERGRYqewlQGWDfe+/QAr33gAgLc61vLEhue4/OAvEKPc3+ZERETEVzrglQG9Xjf3rnlweC3Zx8a+Jp86EhEZm7DXTzjeTNj0+92KSN7TzFYGWJaNYzu4rjes7ljKsiKSXywLwl1v03HXT0l3tRCoqKdq2QUkKqZhdLKByKgoDWRAqRXjxDlLh9UaYnVMKJngU0ciIqMTSnXRdtv3SHe1AJDuaqbt9u8RSnX73JlI/tLMVgYYDxY3HsDEWAPPbX6JyeUT2KN2NiWU+t2aiMhOMb1tg9eZfB9voBfT2wqVWoMqMhoKWxkSNGF2K53FnN3m4HmepttFcohDmkD3etz2Ddgl5VA9jWSgzO+2cpIdiQ2e9WPetyzCdrAi+nmJjJbCVoZ9cN2WiPjLsizsdc/QeudPh2rhyXOILbmIpKPZ5w9KRmupPPwsOu//9VCt8vCzSUVrtEGsyCgpbIlIQQulu2n/26+H1RLrXyHWuR5qZvvUVe7yjI0z8xBqG3fD623HjlWTjjXi6ZJHIqOmsCUiBc3y0ngDfSPqJjngQzf5wSWAG5sMscl+tyJSEPRVRUQKWjpUTnTOomE1ywniVE30qSMRKTaa2RKRgpY2DrEDP44TidH38j8IVk+g4rCzSETrtQZJRMaFwpaIFLx4sIrAojOo2fcEPCdEnJCCloiMG4Utod/qZXN/M0E7QEO0nqAX8bslkYxzPQvXifndhogUIYWtItfhtfEfj/yUnsTgJoa71+3Gp+efTgn6oyQiIpIJWiBfzGyPP79x31DQAni55XXe6n7bv55EREQKjMJWEUuTZk3H2yPqG3s3Y1nW+DckIiJSgBS2iliQEAsn7TWivmvlNIyuNyQiIpIRCltFzHhwyOQD2btxDwAc2+HkOcvYpVQbGYqIiGSKFsgXuRjlfHremXTP6cKxApQ75RhPhxBFREQyRWFLsL0AlXYNMDjbJSIiIpmjw4giIiIiWaSwJSIiIpJFClsiIiIiWaSwJSIiIpJFClsiIiIiWaSwJSIiIpJFClsiIiIiWaR9tiQjQuluaHsHt6+DQM1k3IoppAn63ZaIiIjvFLZkzEJeP733/ozEupeGalVLzsWefjCep2ssiohIcdNhRBm7zvXDghZA5wPXE0x2+dSQiIhI7lDYkjEzqfjIWqIfy0v50I3sqKDlEkl3EjIjx09ERDJHhxFlzJzKiViBECadHKpFdzuAdLgSdBQxJ0WTrXSvuo74W88SqGyg6uhzSVTNwBhdhFxEJNM0syVjlojUUfvxywhPnoMdiRHb+2hiB59O2jh+tyZbEbRSdN33v8TfehaAdOdmWv5wFeGBFn8bExEpUJrZkjEzxhCP7ULp8i9he0nSgRLinmZIcpU90Eli/SvDi14at6sJIvX+NCUiUsAUtiRjUgTBDoK3/ccGLBfHTZAKRPHGMZj10M3G3o1YlsXE0gnEKB+3984ZwTB2pBQv3jesbIdLfWpIRKSwKWzJuLIsCPdtpOfh35Pa/CbRWQuJ7rWUeLA66+/dYdr4j3/8hJ7kYMioCJfxL4s/R4WV/ffOJalgBZVHfpr2P/94qFay+0F45ZN87EpEpHApbMm4CiU7aPvDd4ZmVXqfuYd0+yZKlqzI6vvatsXD7zwxFLQAuhI9PNH0LEdP+mhR7QfmeQYm7kXdGd/G7WrCipZjKieTsiN+tyYiUpAUtmRcmc5NIw5fxd95gVi8A8jeDJNtW6zt2jCivq5rI/YUq6jCFoCHQzw2GWKT/W5FRKTg6WxEGVdWMDyy5gTBzm7uT6c9Dp5ywIj6okn7kk7vwCIzERGRUVLYknFlyicQnrZgWK384I+TCmd/3dSsit04ZfflhJwgYSfEx/c4nhnl07P+viIiUtx0GFHGVdIuIXbEucRa3yLd3Uywdipu1S6kx+EoXpgIH530EQ6cuB9gUWqV4mlSS0REskxhS8ZdMlAGjQuwJkBinJdKGQ+ixAAosmVaIiLiEx1GFN8YhR0RESkCClsiIiIiWaSwJSJ5xbIgbAaIpDoIWGm/2xER2S6t2RKRvGFhCLW9Rue9/0u6q4XIjH0pO+QM4qEav1sTEdkmhS0RyRvhgc203Ho1eC4A8TVPQTpJydIVpEzQ5+5ERLZOhxFFJG+4XZuHgtYW8XdewEl0+9SRiMj2KWxJzrJtCJk4jqXNsGSQFS4ZUbNLyjFOyIduRER2jMKW5KRwqgPv6VvpuvnrJFb9guhAk98tSQ4wFZOIzlr4vopF1ZHnkAyU+9aTiMj2aM2W5JyglaL3wesG1+MA6a5mEu+spvr0K0gEKv1tTnyVsksoOfSfKFnwUcxAD05lI8nYBIw2bRORHKawJTnHHugYClpbeAM9mM5NUFvpT1OSM5J2CVTPAiAFoJwlIjlOhxEl51i2A87I7wGWo7PNREQk/yhsSc5JhqupWHTSsFp48hxM5SSfOhIRERk9HUaUnOMZi+DuH6WmYVdSm14nUD0Ru2EWCSvqd2siIiI7TWFLclLKjkDt7lh1c0lp8bOIiOQxHUaUnKazzEREJN8pbImIiIhkkcKWiIiISBYpbImIiIhkkcKWiIiISBYpbImIiIhkkcKWiIiISBYpbImIiIhkkcKWiIiISBYpbImIiIhkkcKWiIiISBYpbImIiIhkkcKWiIiISBYpbImIiIhk0ajD1saNGznzzDNZunQpn/3sZ+nr69vmY3t7eznyyCN57LHHRvt2IiIiInlp1GHrW9/6FmeccQYrV65k3rx5/Pd///c2H3vFFVfQ3d092rcSERERyVujClupVIonnniCJUuWAHDyySezcuXKrT72zjvvpLS0lNmzZ4++SxEREZE8Naqw1dHRQSwWIxAIAFBXV8fmzZtHPG7jxo38+te/5qtf/erYuhQRERHJU4HtPeCuu+7iyiuvHFabNm3aiMdZljXstud5XHrppVx++eVEIpFRN1hTExv1c7elrq4s468pmaGxyV0am9ylscldGpvcNN7jYhljzM4+KZVKsXDhQp544gkcx2HTpk188pOf5K9//evQY9544w3OOeccKisrAVi7di21tbVcccUVLFq0aIffq62tF8/b6Ra3qa6ujJaWnoy9nmSOxiZ3aWxyl8Ymd2lsclO2xsW2rW1OEG13ZmtrgsEg++23H3feeSfHHXcct912G4ceeuiwx8ycOZNVq1YN3T7rrLO48MILWbhw4WjeUkRERCQvjfpsxG984xvcfPPNLF++nCeffJKLL74YgBtvvJEf/vCHmepPREREJK+N6jDieNJhxOKhscldGpvcpbHJXRqb3OTHYUTtIC8iIiKSRQpbIiIiIlmksCUiIiKSRQpbIiIiIlmksCUiIiKSRQpbIiIiIlmksCUiIiKSRQpbIiIiIlmksCUi4+YD16sXESkKo7o2oojIzgiYJE7XWlJNawiU1WA37EYiUOF3WyIi40JhS0SyyrYtrLeeovXunw/VgvXTKD/uSySdMh87ExEZHzqMKCJZFUx10/nAb4fVUs1vQ8d6fxoSERlnClsiklWWl8ZLxkfUTSrhQzciIuNPYUtEsioVqqB03mHDalYghFM9yaeORETGl9ZsiUhWucYmuv+J2KWV9L+4imDNZMoWf4xEpB6M8bs9EZGsU9gSkaxLBCqw9zqByvlH49lB4iagoCUiRUNhS0TGhedB0oqCMpaIFBmt2RIRERHJIoUtERERkSxS2BIRERHJIoUtERERkSxS2BIRERHJIoUtERERkSzS1g9SEGwbgvF2SMUxpdUkifjdkoiICKCwJQXAMSmsNY/S9rffYtJJgnW7ULn8QuLher9bExER0WFEyX+B3o103PtLTDoJQKplLd1/+w1BK+VzZyIiIgpbUgC87pYRtcTa1TipPh+6ERERGU5hS/KeVVIxohasnYLnRH3oRkREZDiFLcl7pnIKpXseOXTbCkaoPOocklbYx65EREQGaYG85L2UFSG08ONE5x6KSfRhlzeQCNeA0RWPRUTEfwpbUhDShEiX7QJl7xYUtEREJEfoMKKIiIhIFilsiYiIiGSRwpaIiIhIFilsiYiIiGSRwpaIiIhIFilsiYiIiGSRwpaIiIhIFilsiYiIiGSRwpaIiIhIFilsiYiIiGSRwpaIiIhIFilsiYiIiGSRwpaIiIhIFilsiYiIiGSRwpaIiIhIFilsiYiIiGSRwpaIiIhIFilsiYiIiGSRwpaIiIhIFgX8bmB7bNvKi9eUzNDY5C6NTe7S2OQujU1uGu9sYRljTMbfUUREREQAHUYUERERySqFLREREZEsUtgSERERySKFLREREZEsUtgSERERySKFLREREZEsUtgSERERySKFLREREZEsUtgSERERyaKCD1sbN27kzDPPZOnSpXz2s5+lr69vm4/t7e3lyCOP5LHHHhvHDovXjoxNc3Mz55xzDieccAInnXQSjzzyiA+dFo877riD5cuXc9RRR3H99dePuP/ll1/mlFNOYcmSJVx66aWk02kfuixO2xub++67jxNOOIHjjz+eCy64gK6uLh+6LD7bG5ctHnjgAY444ohx7Ey2NzZvvvkmZ511FscffzznnHNOdn9nTIE777zzzJ///GdjjDE/+clPzNVXX73Nx371q181+++/v3n00UfHq72itiNj86Uvfcn89re/NcYYs2bNGrN48WKTTqfHtc9i0dTUZA4//HDT0dFh+vr6zHHHHWdef/31YY855phjzDPPPGOMMeaSSy4x119/vQ+dFp/tjU1PT4856KCDTFNTkzHGmB/84Afmiiuu8KvdorEjvzPGGNPS0mKWLl1qDj/8cB+6LE7bGxvP88zRRx9tVq1aZYwx5rvf/e6H5oOxKuiZrVQqxRNPPMGSJUsAOPnkk1m5cuVWH3vnnXdSWlrK7Nmzx7PForWjY3P00Udz3HHHATB16lQSiQT9/f3j2muxePjhh1m0aBGVlZWUlJSwZMmSYWOyYcMG4vE4e+21F/Dhv0+SWdsbm1QqxTe/+U0aGhoAmD17Nps2bfKr3aKxvXHZ4rLLLuPCCy/0ocPitb2xefHFFykpKeHQQw8F4Pzzz+fMM8/MWj8FHbY6OjqIxWIEAgEA6urq2Lx584jHbdy4kV//+td89atfHe8Wi9aOjs3RRx9NRUUFAL/85S/ZfffdKSsrG9dei0VzczN1dXVDt+vr64eNyQfv39aYSeZtb2yqqqo48sgjAYjH41xzzTVDtyV7tjcuAL/5zW+YO3cue+6553i3V9S2NzZr166ltraWf/mXf+G4447jG9/4BiUlJVnrJ5C1Vx5nd911F1deeeWw2rRp00Y8zrKsYbc9z+PSSy/l8ssvJxKJZLPFojXasXm/a6+9lptuuonrrrsu0+3Ju4wxI2rvH5Pt3S/Zs6M/+56eHi644ALmzJnDSSedNB6tFbXtjctrr73GPffcw7XXXktTU9N4tlb0tjc26XSaxx9/nOuuu4758+fzgx/8gKuuuoqrrroqK/0UTNhatmwZy5YtG1ZLpVIsXLgQ13VxHIeWlhbq6+uHPebNN9/kzTff5NJLLwUG0+5ll13GFVdcwaJFi8at/0I22rHZ4uqrr2bVqlVcf/31NDY2jkfLRamhoYEnn3xy6HZzc/OwMWloaKC1tXXo9oeNmWTW9sZmS+2cc85h0aJF/Ou//ut4t1iUtjcuK1eupKWlhVNOOYVUKkVzczNnnHEGN9xwgx/tFpXtjU1dXR1Tp05l/vz5ABx77LGsWLEia/0U9GHEYDDIfvvtx5133gnAbbfdNnR8douZM2eyatUqbr/9dm6//XbmzZvHt7/9bQWtLNuRsYHBGa3HHnuMG2+8UUEryxYvXswjjzxCe3s7AwMD3HPPPcPGZNKkSYTDYZ566ilg22Mmmbe9sXFdl/PPP59ly5Zx6aWXasZxnGxvXFasWMHdd9/N7bffzjXXXEN9fb2C1jjZ3tjsvffetLe388orrwBw//33s8cee2StH8tsba6tgGzYsIGvfe1rtLW1MWHCBP7rv/6LiooKbrzxRpqbm/n85z8/7PFnnXUWF154IQsXLvSp4+KxvbFZsWIFBxxwALFYjPLy8qHnXXPNNUMLgSWz7rjjDn7+85+TSqU49dRTOffcczn33HNZsWIF8+fP55VXXuGyyy6jr6+PuXPncuWVVxIKhfxuuyh82Ng0NTVx0UUXDTvBZ968eXznO9/xsePisL3fmS3Wr1/P2Wefzf333+9jt8Vle2Pz3HPPccUVVzAwMEBjYyNXX301NTU1Weml4MOWiIiIiJ8K+jCiiIiIiN8UtkRERESySGFLREREJIsUtkRERESySGFLREREJIsUtkRERESySGFLREREJIsUtkRERESy6P8DwZUWOMviaE4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"darkgrid\", rc = {'figure.figsize':(10,10)})\n",
    "sns.scatterplot(x=x, y=y, hue=label, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3d1da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "x = pca.fit_transform(features)[:,0]\n",
    "y = pca.fit_transform(features)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12486b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7ce57c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"darkgrid\", rc = {'figure.figsize':(10,10)})\n",
    "sns.scatterplot(x=x, y=y, hue=important_subsections, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "326c8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_paras = []\n",
    "with open('../notebooks/bad_sentences.txt') as f:\n",
    "    for line in f:\n",
    "        bad_paras.append(line[:-1])\n",
    "bad_emb = torch.from_numpy(model.encode(bad_paras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9458d1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5057) tensor([-0.0223, -0.0101, -0.0047,  ..., -0.0330, -0.0543,  0.0088]) Although the term computer architecture sounds very complicated, its definition is easier than one might think. Computer architecture is a science or a set of rules stating how computer software and hardware are joined together and interact to make a computer work. It not only determines how the computer works but also of which technologies the computer is capable. Computers continue to be a major part of our lives, and computer architects continue to develop new and better programs and technologies.\n",
      "tensor(0.5132) tensor([-0.0262,  0.0024, -0.0032,  ..., -0.0153, -0.0432,  0.0054]) A Brief History of Computer Architecture Computer Architecture is the field of study of selecting and interconnecting hardware components to create computers that satisfy functional performance and cost goals. It refers to those attributes of the computer system that are visible to a programmer and have a direct effect on the execution of a program.\n",
      "tensor(0.9863) tensor([-0.0191,  0.0069, -0.0172,  ..., -0.0588, -0.0408, -0.0024]) Some students choose to complete an MBA (master’s of business administration) with a focus on information systems. The advantage of this program is that it offers both computer-related and business courses. Even after earning the degree, applicants may be required to have at least five years of experience working with IT systems before being hired as a computer architect. Some computer architects go on to become computer and information systems managers once they’ve obtained sufficient experience.\n"
     ]
    }
   ],
   "source": [
    "dataset_clean = defaultdict(list)\n",
    "for section in important_subsections:\n",
    "    for paras in dataset[section]:\n",
    "        prag_emb = torch.from_numpy(model.encode(paras))\n",
    "        if torch.max(prag_emb @ bad_emb.T) < 0.5 and paras != '':\n",
    "            dataset_clean[section].append(paras)\n",
    "        else:\n",
    "            print(torch.max(prag_emb @ bad_emb.T), prag_emb, paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fccd5d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline('summarization', model=\"sshleifer/distilbart-cnn-12-6\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f43e245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkIt(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc811bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ad61df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf709584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "final_summary = defaultdict(list)\n",
    "references = defaultdict(list)\n",
    "for i, subsection in tqdm(enumerate(important_subsections)):\n",
    "    text = dataset_clean[subsection]\n",
    "    if text == []:\n",
    "        continue\n",
    "        \n",
    "    num_paras = len(text)\n",
    "    if num_paras > 5:\n",
    "        groups = chunkIt(text, num_paras//5)\n",
    "        #print(len(groups))\n",
    "        \n",
    "        for group in groups:\n",
    "            ref = []\n",
    "            for sentence in group:\n",
    "                ref.append(paragraph_reference[sentence])\n",
    "            references[subsection].append(ref)\n",
    "            data = ''.join(group)\n",
    "            #print(len(tokenizer([data])['input_ids'][0]))\n",
    "            if len(tokenizer([data])['input_ids'][0]) > 1023:\n",
    "                count = 0\n",
    "                data_nlp = nlp(data)\n",
    "                sentences = list(data_nlp.sents)\n",
    "                #print(sentences)\n",
    "                data = \"\"\n",
    "                for sentence in sentences:\n",
    "                    sentence = str(sentence)\n",
    "                    #print(type(sentence))\n",
    "                    count += (2 + len(word_tokenize(sentence)))\n",
    "                    if count < 924:\n",
    "                        data += sentence\n",
    "            #print(len(tokenizer([data])['input_ids'][0]))\n",
    "            \n",
    "            summary_text = summarizer(data, max_length=len(word_tokenize(data))//2, \\\n",
    "                              min_length = len(word_tokenize(data))//4)[0]['summary_text']\n",
    "            summary_text = summary_text.replace(u'\\xa0', u' ')\n",
    "            final_summary[subsection].append(summary_text)\n",
    "    else:\n",
    "        data = ''.join(text)\n",
    "        summary_text = summarizer(data, max_length=len(word_tokenize(data))//2, \\\n",
    "                          min_length = len(word_tokenize(data))//4)[0]['summary_text']\n",
    "        summary_text = summary_text.replace(u'\\xa0', u' ')\n",
    "        final_summary[subsection].append(summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6afe209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageTool('en-US') \n",
    "for key, val in final_summary.items():\n",
    "    for i in range(len(val)):\n",
    "        val[i] = tool.correct(val[i])\n",
    "tool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "878766d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['intro', 'history', 'type'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c0898c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'intro': [' Different amounts of memory are used to store data values with different degrees of precision. The commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word) Converting index of an item in an array into the memory address offset of the item then requires only a shift operation rather than a multiplication. In some cases this relationship can also avoid the use of division operations. Most modern computer designs have word sizes (and other operand sizes) that are two times the size of a byte. An ISA specifies the behavior of machine code running on implementations of that ISA in a fashion that does not depend on the characteristics of that implementation. This enables multiple implementations of an ISA that differ in characteristics such',\n",
       "              ' Computer architecture is the organization of the components which make up a computer system. It defines what is seen on the machine interface, which is targeted by programming languages and their compilers. The choice of instruction set architecture may greatly affect the complexity of implementing high-performance devices. The largest possible address size, used to designate a location in memory, is typically a hardware word. Data processing should be done in a different and single memory location in different types of computer architectures.',\n",
       "              ' In applications where the memory-access patterns are well-defined and discoverable at compile time, programmers and compilers can optimize the use of the memory better than can dynamically allocated caches. SAS usually use a hierarchy of memories with movement controlled explicitly by the software, similar to how vector processors operate. The underlying logical design of most modern computers is still based on that of the earliest electronic computers despite decades of progress in electronic circuitry. Super computers are biggest, the most expensive in price than any other is classified and known as super computer. This computer is not used as a PC in a home nor by a student in a college.',\n",
       "              ' In multithreading, when the processor has to fetch data from slow system memory, instead of stalling for the data to arrive, the processor switches to another program or program thread which is ready to execute. The instruction issue logic grows in complexity by reading in a huge list of instructions from memory and handing them off to the different execution units that are idle at that point. The results are then collected and re-ordered at the end. The difference is that a multithreaded CPU can do a thread switch in one CPU cycle instead of the hundreds or thousands of CPU cycles a context switch normally requires.',\n",
       "              ' The architecture of a computer is chosen with regard to the types of programs that will be run on it. Its principal components or subsystems, each of which could be said to have an architecture of its own, are input/output, storage, communication, control, and processing. In most of the Hollywood’s movies it is used for animation purposes. This kind of computer is also helpful for forecasting weather reports worldwide. In such a system a task is broken down and shared among processes for faster execution. They are used for complex tasks requiring a lot of computational power.',\n",
       "              ' Computer engineering is a science or a set of rules stating how brain software and hardware are joined together and interact to make a computer work. System design itself defines a design that can serve user requirements like system architecture, computer modules having various interfaces, and data management within a system. RISC-V (called \"RISC Five\") is the fifth RISC architecture developed at the University of California, Berkeley. Multicycle architectures often use the least total number of logic elements and reasonable amounts of power. The smallest, least-expensive computers often still use this technique. Multicycle architecture is often relative to multicycle designs.',\n",
       "              ' To create a \"Linux for processors\" the field needs industry-standard open ISA\\'s, so the community can create open source cores. If many organizations design processors using the same ISA, the greater competition may drive even quicker innovation. The goal is to provide processors for chips that cost from a few cents to $100. The term“ engineering” in computer literature can be delineated to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM’s main research center in 1959. Minimizing the size of a program to make sure it would fit in the limited memory was often central. The size of the instructions needed to perform a particular task, the code density',\n",
       "              ' On average, 19% of the instructions are wasted for benchmarks on an Intel Core i7. Figure 4 shows the fraction of instructions that are effectively executed but turn out to be wasted because the processor speculates incorrectly. The advantage of using an embedded microprocessor over dedicated electronics is that the functionality of the system is determined by the software, not the hardware. The architecture semantics is the meaning of what the systems do under user direction and how their functional units are controlled to work together. In many cases, an embedded system is used to replace application-specific electronics. This makes the embedded system easier to produce, and much easier to. Evolve, then a complicated circuit than a. Complicated circuit.',\n",
       "              ' Computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. Complex instruction sets enable programmers to write more space efficient programs. Longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. The challenge when using DSL is how to retain enough architecture independence that software written in a DSL can be ported to different architectures while achieving high efficiency in mapping the software to the underlying DSA. For example, the LA system translates TensorFlow to heterogeneous processors that use Nvidia GPUs or Tensor Processor Units.',\n",
       "              \" The term ‘architecture’ in computer literature can be traced to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM's main research center in 1959. The end of Dennard scaling and Moore's Law and the deceleration of performance gains for standard microprocessors are not problems that must be solved but facts that, recognized, offer breathtaking opportunities. Expect the same rapid improvement as in the last golden age, but this time in terms of cost, energy, and security, as well as in performance.\",\n",
       "              ' AMD and Intel used 500-person design teams and superior semiconductor technology to close the performance gap between x86 and RISC. The instruction decoder translated complex x86 instructions into internal RISC-like microinstructions on the fly. The demands of high-speed digital signal processing have pushed in the opposite direction—forcing instructions to be implemented in a particular way. This chapter provides a first examination of the principal forms of supercomputer architecture and the underlying concepts that govern their performance. A high-performance computer is designed to go fast, and its organization and semantics are specially devised to deliver computational speed.',\n",
       "              ' Cache memory is a type of very fast memory that is used to improve the speed of a computer doubling it in some cases. Cache memory acts as an intermediate store between the CPU and the maim memory, and works by storing the most frequently or recently used instructions and data so that it will be very fast to retrieve them again. Embedded hardware is often much simpler than a desktop system, but it can also be far more complex too. An embedded computer may be implemented in a single chip with just a few support components, and its purpose may be as crude as a controller for a garden-watering system.',\n",
       "              ' In computer engineering, microarchitecture, also called computer organization and sometimes abbreviated as March or March, is the way a given instruction set architecture (ISA) is implemented in a particular processor. A given ISA may be implemented with different microarcharchitectures; implementations may vary due to different goals of a given design or due to shifts in technology. For example, the Intel Pentium and AMD Athlon implement nearly identical versions of the x86 instruction set, but they have radically different internal designs.',\n",
       "              ' There are a number of reasons why the von Neumann architecture has proven to be so successful. Computer architects have become stymied by the growing mismatch in CPU operating frequencies and DRAM access times. Older generations of computers have started to exploit higher levels of parallelism that exist outside a single program or program thread. We will return to what approaches might work after discussing another major shortcoming of modern computers their support, or lack thereof, for computer security.',\n",
       "              ' CISC processors have a single instruction to perform a task, and have the advantage of making the job of the programmer easier. This approach uses less memory, but can'],\n",
       "             'history': [' By 1986 the top-of-the-line VAX implementation (VAX 8800) was a heavily pipeline design, predating the first commercial MIPS and SPARC designs. Large CISC machines, from the VAX to the modern Pentium 4 and Athlon, are implemented with both microcode and pipelines. Improvements in pipe lining and caching are the two major microarchitectural advances that have enabled processor performance to keep pace with the circuit technology on which they are based. In 28 nm, 1 mm 2 holds millions of transistors, enough area for both a RISC-V processor and an NELDA accelerator. A simpler instruction set may offer the potential for higher speeds, reduced processor size, and reduced power consumption, but a more complex set may optimize common operations, improve memory and cache efficiency, or simplify programming.',\n",
       "              ' In the outline above the processor processes parts of a single instruction at a time. Multiple instructions could be executed faster if multiple instructions were processed simultaneously. This is what super scalar processors achieve, by replicating functional units such as ALUs. Early designs like SPARC and MIPS often ran over 10 times as fast as Intel and Motorola CISC solutions at the same clock speed and price. Some manufacturers chose to make microprogramming available by letting select customers add custom features they called \"writable control store\" (WCS) The most famous WCS computer was the Alto 36 Turing laureates Chuck Thicker and Butler Sampson, together with their colleagues, created for the Xerox Palo Alto Research Center in 1973. It was indeed the first personal computer, sporting the first bit-mapped display and first Ethernet local-area network. The device controllers for the novel display and network were microprograms'],\n",
       "             'type': [' The next level of erasability is the EEPROM, which can be erased under software control. This is the most flexible type of ROM, and is now commonly used for holding BIOS programs. When you hear reference to a \"flash BIOS\" or doing a BIOS upgrade by \"flashing\" this refers to reprogramming the BIOS EEPROM with a special software program. The addition of caches reduces the frequency or duration of stalls due to waiting for data to be fetched from the memory hierarchy, but does not get rid of these stalls entirely. SIMS instructions allow easy parallelization of algorithms commonly involved in sound, image, and video processing. At the end of the chapter the learner shall be able to. Explain the different hardware units of a computer system such as input, output, Central processing unit (CPU), main memory and secondary storage',\n",
       "              ' Latency is the time between the start of a process and its completion. Throughput is the amount of work done per unit time. Erasable Programmable ROM (EPROM) is a ROM that can be erased and reprogrammed. The size of a word can sometimes differ from the expected due to backward compatibility with earlier computers. If multiple compatible variations or a family of processors share a common architecture and instruction set but differ in their word sizes, their documentation and software may become notationally complex to accommodate the difference (see Size Families below) Register renaming refers to a technique used to avoid unnecessary serialized execution of program instructions.']})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6608c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics selection - intro, syntax, feature, history\n",
    "\n",
    "# intro - 5 pars -> 3 webstes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc5a7a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# INTRO\n",
    "\n",
    "# website 1 url\n",
    "# website 1 title\n",
    "\n",
    "# (2 paras ralated to intro) -> summarize this in a few sentences\n",
    "\n",
    "\n",
    "# website 2 url\n",
    "# website 2 title\n",
    "\n",
    "# (1 paras ralated to intro) -> summarize this in a few sentences\n",
    "\n",
    "# website 3 url\n",
    "# website 3 title\n",
    "\n",
    "# (12 paras ralated to intro) -> summarize this in a few sentences\n",
    "\n",
    "\n",
    "\n",
    "# HISTORY\n",
    "\n",
    "# website 1 url\n",
    "# website 1 title\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ARTICLE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f4151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67c0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5f908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f9be11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b14a1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
